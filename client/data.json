{
    "status": "success",
    "course_id": 84647,
    "scraped_at": "2025-12-14 00:07:59",
    "post_count": 822,
    "posts": [
        {
            "guid": 7459110,
            "author": "Hong Joey",
            "project_title": "Reviews Now Visible for Project Final Drafts",
            "post_body": "Everyone should be able to see their reviews for their final drafts by logging into the \"Author\" console of the conference site. These final reviews should help with polishing your project reports that are due this Sunday on Gradescope. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Everyone should be able to see their reviews for their final drafts by logging into the \"Author\" console of the <link href=\"https://cmt3.research.microsoft.com/DLFP2025\">conference site</link>. These final reviews should help with polishing your project reports that are due <bold>this Sunday on Gradescope</bold>. </paragraph><paragraph/></document>",
            "links": [
                "https://cmt3.research.microsoft.com/DLFP2025"
            ],
            "attachments": [],
            "created_at": "2025-12-13T05:12:40.772081+11:00",
            "category": "Project"
        },
        {
            "guid": 7455794,
            "author": "Anant Sahai",
            "project_title": "Are you missing anything you need for the Final in less than a week?",
            "post_body": "Dear students,\n\nAs you have probably seen on this Ed, we have been overwhelmed with the submissions of Special Participation Reports in the last week and so we might very well have missed something you asked. Sorry about that! And we'll have to figure out a better way to make sure that we don't get this kind of last minute flood the next time we try something like this.... Although many of those Special Participation Reports are indeed quite wonderful and likely to be of incredible value to fellow students as they study for the exam, it might be too hard to find them given the flood... :-( \n\nThe purpose of this post is to give you a place to ask for something that might be missing on our part. \n\nYou should have: \n\nHomeworks and solutions to all the assignments, from 0 through 13. If there are any remaining bugs or irregularities, please ask here.\n\nDiscussions and solutions thereof for every week that regular discussion happened --- there was no discussion during Thanksgiving week (because Wed was a holiday) , no discussion during RRR week because that was a review, and no discussion for week 0 because that Wed was before the first lecture. \n\nAccess to the lecture videos on Youtube (and as multiple Special Participation Reports have pointed out, extracting the text transcripts and feeding them into a Frontier model is shockingly effective at setting up an interactive way to explore despite the noise therein)\n\nAccess to the handwritten portions and cut/paste figures that we used while lecturing with our IPad. (Not everything important was written down --- but these should be quite helpful and again, it is amazing how well the Frontier models with image-understanding do when they are fed these images, especially when combined with the transcripts above)\n\nThat's Lecture, Homework, and Discussions --- what defines the material and skills that are in-scope for the in-person three hour Final Exam. \n\nTo this, allow us to add a few past exams (you've seen many of these questions already because we gave you either them or close modifications thereof on the HW)\n\nThe above is the Spring 2025 Final Exam. (Note, the material keeps shifting as the field evolves and so that is the most recent and hence most current, but we added and shifted quite a bit this semester too. All that is in-scope and you can be assured that at least some of it will actually appear on the exam.) You will notice the following:\n\nThere are point totals attached to each part of each problem. These are coarsely calibrated to refer to nominal minutes required (including reading and expected number of screwups in an exam situation) to do each part. No estimates are ever perfect, but these are designed to help reduce cognitive load for students when trying to allocate time to problems --- to make the best strategy unambiguous and simple: do the problem if you can see a clear path, and skip to come back to later if you can't.\n\nThe total points on the exam exceed 180 --- which is the number of minutes on the exam. This allows some safety margin in a high-stress situation for students who temporarily draw a blank on something despite actually knowing it. \n\nNot everything covered in class makes it to the exam and different topics get hit in different depth --- this is unavoidable because 3 hours is a short time to hit stuff that you've seen over 140+ hours of work during the semester.  It's somewhat random what shows up on the final. \n\nSome problems were very close (or even identical) to problems seen on the HW and Discussions, even in Spring 2025 itself. \n\nThe above is an older final exam from Fall of 2023. In that semester, there was a midterm as well (we had way more staff despite a similar number of students --- 12 vs 7 counting the professors). Everything on this exam is in-scope this semester as well --- as you can see for yourself.  \n\nAnd as you can see, the style of questions, etc. is similar. (And everything in this exam is in-scope this semester too)\n\nOne thing that you cannot necessarily tell from looking at the exams is that essentially every exam had a couple of things on it that asked students to go beyond the exact things that they had learned in lecture/discussion/homework but for which they could proceed given the guidance in the question and the techniques/ideas that they had learned. \n\nThe above is more than enough old exam questions for you. (And as we go further back, the material scope starts getting more and more different --- remember, ChatGPT itself came out at the end of Fall 2022.) \n\nRemember, there is no curve in this course. We want you to succeed. Our belief is that anyone who has attended lecture attentively, done the homeworks, reviewed the solutions carefully, and participated fully in discussion should be able to walk into the final exam (well-rested), and do it. But we know that some of you feel more comfortable having an old exam or two you can time yourself on. \n\nIn the past, we would have had to release solutions to go along with those exams. But now, as you have seen yourself as well as from the Special Participation Reports of others, you can check your answers yourself with a critical eye towards the material and engagement with a Frontier Model. So, we can avoid the temptation/risk of students looking at the solutions first by not posting them. :-) It's still sufficiently annoying to cut/paste problems into a Frontier model and deal with reading their idiom that we suspect more of you will just do the problems yourself first.\n\nOur recommendation --- for those of you who like doing old exams --- is for you to study first. At least look over the past homework problems and discussion problems and verify that you know how to do them --- even if you don't do them again. And then, if any one of them seems off for you, go and look over your lecture notes, etc. till you feel comfortable. And then, sit down and do the Spring 2025 exam in simulated conditions (just you and the exam and a pencil) in one sitting. That should get you a better sense of where you are vis-a-vis pacing. \n\nGood luck!",
            "content_xml": "<document version=\"2.0\"><paragraph>Dear students,</paragraph><paragraph>As you have probably seen on this Ed, we have been overwhelmed with the submissions of Special Participation Reports in the last week and so we might very well have missed something you asked. Sorry about that! And we'll have to figure out a better way to make sure that we don't get this kind of last minute flood the next time we try something like this.... Although many of those Special Participation Reports are indeed quite wonderful and likely to be of incredible value to fellow students as they study for the exam, it might be too hard to find them given the flood... :-( </paragraph><paragraph>The purpose of this post is to give you a place to ask for something that might be missing on our part. </paragraph><paragraph>You should have: </paragraph><list style=\"bullet\"><list-item><paragraph>Homeworks and solutions to all the assignments, from 0 through 13. <bold>If there are any remaining bugs or irregularities, please ask here.</bold></paragraph></list-item><list-item><paragraph>Discussions and solutions thereof for every week that regular discussion happened --- there was no discussion during Thanksgiving week (because Wed was a holiday) , no discussion during RRR week because that was a review, and no discussion for week 0 because that Wed was before the first lecture. </paragraph></list-item><list-item><paragraph>Access to the lecture videos on Youtube (and as multiple Special Participation Reports have pointed out, extracting the text transcripts and feeding them into a Frontier model is shockingly effective at setting up an interactive way to explore despite the noise therein)</paragraph></list-item><list-item><paragraph>Access to the handwritten portions and cut/paste figures that we used while lecturing with our IPad. (Not everything important was written down --- but these should be quite helpful and again, it is amazing how well the Frontier models with image-understanding do when they are fed these images, especially when combined with the transcripts above)</paragraph></list-item></list><paragraph>That's Lecture, Homework, and Discussions --- what defines the material and skills that are in-scope for the in-person three hour Final Exam. </paragraph><paragraph>To this, allow us to add a few past exams (you've seen many of these questions already because we gave you either them or close modifications thereof on the HW)</paragraph><file url=\"https://static.us.edusercontent.com/files/ysSau7zIKj2wx6ijlfeJcYld\" filename=\"final_sp25_question.pdf\"/><paragraph>The above is the Spring 2025 Final Exam. (Note, the material keeps shifting as the field evolves and so that is the most recent and hence most current, but we added and shifted quite a bit this semester too. All that is in-scope and you can be assured that at least some of it will actually appear on the exam.) You will notice the following:</paragraph><list style=\"bullet\"><list-item><paragraph>There are point totals attached to each part of each problem. These are coarsely calibrated to refer to nominal minutes required (including reading and expected number of screwups in an exam situation) to do each part. No estimates are ever perfect, but these are designed to help reduce cognitive load for students when trying to allocate time to problems --- to make the best strategy unambiguous and simple: do the problem if you can see a clear path, and skip to come back to later if you can't.</paragraph></list-item><list-item><paragraph>The total points on the exam exceed 180 --- which is the number of minutes on the exam. This allows some safety margin in a high-stress situation for students who temporarily draw a blank on something despite actually knowing it. </paragraph></list-item><list-item><paragraph>Not everything covered in class makes it to the exam and different topics get hit in different depth --- this is unavoidable because 3 hours is a short time to hit stuff that you've seen over 140+ hours of work during the semester.  It's somewhat random what shows up on the final. </paragraph></list-item><list-item><paragraph>Some problems were very close (or even identical) to problems seen on the HW and Discussions, even in Spring 2025 itself. </paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/LGbzJWs3XLREoNQhbeeHUzun\" filename=\"final_fa23_question.pdf\"/><paragraph>The above is an older final exam from Fall of 2023. In that semester, there was a midterm as well (we had way more staff despite a similar number of students --- 12 vs 7 counting the professors). Everything on this exam is in-scope this semester as well --- as you can see for yourself.  </paragraph><file url=\"https://static.us.edusercontent.com/files/nv1w5vmdsb7irrebSRTcAdGQ\" filename=\"midtermcory.pdf\"/><paragraph>And as you can see, the style of questions, etc. is similar. (And everything in this exam is in-scope this semester too)</paragraph><paragraph>One thing that you cannot necessarily tell from looking at the exams is that essentially every exam had a couple of things on it that asked students to go beyond the exact things that they had learned in lecture/discussion/homework but for which they could proceed given the guidance in the question and the techniques/ideas that they had learned. </paragraph><paragraph>The above is more than enough old exam questions for you. (And as we go further back, the material scope starts getting more and more different --- remember, ChatGPT itself came out at the end of Fall 2022.) </paragraph><paragraph>Remember, <bold>there is no curve in this course</bold>. We want you to succeed. Our belief is that anyone who has attended lecture attentively, done the homeworks, reviewed the solutions carefully, and participated fully in discussion should be able to walk into the final exam (well-rested), and do it. But we know that some of you feel more comfortable having an old exam or two you can time yourself on. </paragraph><paragraph>In the past, we would have had to release solutions to go along with those exams. But now, as you have seen yourself as well as from the Special Participation Reports of others, you can check your answers yourself with a critical eye towards the material and engagement with a Frontier Model. So, we can avoid the temptation/risk of students looking at the solutions first by not posting them. :-) It's still sufficiently annoying to cut/paste problems into a Frontier model and deal with reading their idiom that we suspect more of you will just do the problems yourself first.</paragraph><paragraph>Our recommendation --- for those of you who like doing old exams --- is for you to study first. At least look over the past homework problems and discussion problems and verify that you know how to do them --- even if you don't do them again. And then, if any one of them seems off for you, go and look over your lecture notes, etc. till you feel comfortable. And then, sit down and do the Spring 2025 exam in simulated conditions (just you and the exam and a pencil) in one sitting. That should get you a better sense of where you are vis-a-vis pacing. </paragraph><paragraph>Good luck!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-12T10:38:36.920589+11:00",
            "category": "Admin"
        },
        {
            "guid": 7453738,
            "author": "Hong Joey",
            "project_title": "HW 12 Solutions",
            "post_body": "Apologies for the delay. Below are the solutions for HW 12.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Apologies for the delay. Below are the solutions for HW 12.</paragraph><file url=\"https://static.us.edusercontent.com/files/AjfV41RgWmnq6wQzYPCHYXQD\" filename=\"hw12_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/zA92Td3h7bSWKn6fALv5QXZu\" filename=\"q_vae_sol.zip\"/><file url=\"https://static.us.edusercontent.com/files/BMaS45CPW3faD15tudey2bFp\" filename=\"hw12_solution.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-12T05:36:25.153746+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7445476,
            "author": "Manhar Gupta",
            "project_title": "Central Index CS182",
            "post_body": "As the final and the last project deadlines are approaching, I thought it would be good to have the various EdStem threads be collected in a single thread for easier navigation. Searching for the particular thread was wasting a lot of time at my end. I hope this will be helpful to all of you! (It'll be great if this can be pinned for everyone's convenience)\n\nLectures:\n\n0: #6 \n\n1: #28 \n\n2,3 (SGD, Momentum, Adam): #58 (Has updated lecture 2 notes)\n\n4,5 (Initialization, Optimizer recipe and Shampoo): #79 \n\n6,7 (Muon, muP): #90 \n\n8,9 (CNN basics): #109 \n\n10 (Norm layers, Dropout, Residual Connection): #108 \n\n11 (more resnets, pooling, upsampling): #132 \n\n12 (GNN intro): #136 \n\n13 (more GNN, DiffPool): #157 \n\n14 (RNNs, intro self-supervision): #161 \n\n15 (self-supervision only part): #174 \n\n15,16 (SSMs and Convolutions): #237 (SSM part of lec15 and main SSM lecture (lec16))\n\n17 (eigenvalue initialization, Mamba/S6): #237 \n\n18 (attention mechanisms): #237 \n\n19 (transformers and positional encoding): #237 \n\n20 (RoPE, modern achitectural paradigms): #237 \n\n21 (ICL, fine-tuning (soft prompt/prefix)): #297 \n\n22 (SFT, more soft prefix/prompt and LoRA): #297 \n\n23 (Meta-Learning and forgetting): #298 \n\n24 (VAE and test-time compute): #307 \n\n25 (more test-time compute and RLVR): #328 \n\n26 (RL concepts (RLHF, DPO) and intro diffusion): #445 \n\n27 (Diffusion: DDPM, DDIM): #498 \n\n\n\nHWs and Solutions: (Questions and Solutions)\n\nThe links refer to specific questions of that HW in order (first link is Q1, second link is Q2 and so on). The last link in each row is the solution link. TBU - To Be Uploaded\n\nHW0: #11, #12, #13, #14, #15, #16, #17, #53 \n\nHW1: #40, #41, #42, #43, #44, #45, #46, #74 \n\nHW2: #68, #69, #70, #71, #72, #73, #88 \n\nHW3: #83, #84, #85, #86, #87, #104 \n\nHW4: #94, #95, #96, #97, #98, #99, #100, #127 \n\nHW5: #110, #111, #112, #113, #114, #115, #156 \n\nHW6: #142, #143, #144, #145, #146 (Coding), #147 (Coding), #172 \n\nHW7: #171 (Coding), #170, #169, #168, #167, #197 \n\nHW8: #178, #179 (Coding), #180, #181, #274 \n\nHW9: #210, #211, #212, #213, #214 (Coding), #215, #271 \n\nHW10: #265, #266, #267, #268, #269, #350 \n\nHW11: #287, #288, #289, #290, #291, #292, #293, #360 \n\nHW12: #318, #319, #320, #321, #322, #924\n\nHW13: #448, #449, #450, #795\n\n\n\nOld Exam Problems at end of HWs:\n\nHW5: #121, #122 \n\nHW12 #323 \n\n\n\nDiscussions:\n\n #30, #34 \n\n#67 \n\n#93 \n\n#91 \n\n#123 \n\n#140 \n\n#158 \n\n#176 \n\n#252 \n\n#253 \n\n#280 \n\n#303 \n\n#437 \n\n\n\nParticipation Details:\n\n#75 \n\nForm: #403\n\n\n\nProject Details Main Thread:\n\n#150 \n\n\n\nReview Session Thread:\n\n#735",
            "content_xml": "<document version=\"2.0\"><paragraph>As the final and the last project deadlines are approaching, I thought it would be good to have the various EdStem threads be collected in a single thread for easier navigation. Searching for the particular thread was wasting a lot of time at my end. I hope this will be helpful to all of you! (It'll be great if this can be pinned for everyone's convenience)</paragraph><paragraph><bold>Lectures:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>0: #6 </paragraph></list-item><list-item><paragraph>1: #28 </paragraph></list-item><list-item><paragraph>2,3 (SGD, Momentum, Adam): #58 (Has updated lecture 2 notes)</paragraph></list-item><list-item><paragraph>4,5 (Initialization, Optimizer recipe and Shampoo): #79 </paragraph></list-item><list-item><paragraph>6,7 (Muon, muP): #90 </paragraph></list-item><list-item><paragraph>8,9 (CNN basics): #109 </paragraph></list-item><list-item><paragraph>10 (Norm layers, Dropout, Residual Connection): #108 </paragraph></list-item><list-item><paragraph>11 (more resnets, pooling, upsampling): #132 </paragraph></list-item><list-item><paragraph>12 (GNN intro): #136 </paragraph></list-item><list-item><paragraph>13 (more GNN, DiffPool): #157 </paragraph></list-item><list-item><paragraph>14 (RNNs, intro self-supervision): #161 </paragraph></list-item><list-item><paragraph>15 (self-supervision only part): #174 </paragraph></list-item><list-item><paragraph>15,16 (SSMs and Convolutions): #237 (SSM part of lec15 and main SSM lecture (lec16))</paragraph></list-item><list-item><paragraph>17 (eigenvalue initialization, Mamba/S6): #237 </paragraph></list-item><list-item><paragraph>18 (attention mechanisms): #237 </paragraph></list-item><list-item><paragraph>19 (transformers and positional encoding): #237 </paragraph></list-item><list-item><paragraph>20 (RoPE, modern achitectural paradigms): #237 </paragraph></list-item><list-item><paragraph>21 (ICL, fine-tuning (soft prompt/prefix)): #297 </paragraph></list-item><list-item><paragraph>22 (SFT, more soft prefix/prompt and LoRA): #297 </paragraph></list-item><list-item><paragraph>23 (Meta-Learning and forgetting): #298 </paragraph></list-item><list-item><paragraph>24 (VAE and test-time compute): #307 </paragraph></list-item><list-item><paragraph>25 (more test-time compute and RLVR): #328 </paragraph></list-item><list-item><paragraph>26 (RL concepts (RLHF, DPO) and intro diffusion): #445 </paragraph></list-item><list-item><paragraph>27 (Diffusion: DDPM, DDIM): #498 </paragraph></list-item></list><paragraph/><paragraph><bold>HWs and Solutions: (Questions and Solutions)</bold></paragraph><paragraph>The links refer to specific questions of that HW in order (first link is Q1, second link is Q2 and so on). The <bold>last link in each row is the solution link.</bold> TBU - To Be Uploaded</paragraph><list style=\"bullet\"><list-item><paragraph>HW0: #11, #12, #13, #14, #15, #16, #17, #53 </paragraph></list-item><list-item><paragraph>HW1: #40, #41, #42, #43, #44, #45, #46, #74 </paragraph></list-item><list-item><paragraph>HW2: #68, #69, #70, #71, #72, #73, #88 </paragraph></list-item><list-item><paragraph>HW3: #83, #84, #85, #86, #87, #104 </paragraph></list-item><list-item><paragraph>HW4: #94, #95, #96, #97, #98, #99, #100, #127 </paragraph></list-item><list-item><paragraph>HW5: #110, #111, #112, #113, #114, #115, #156 </paragraph></list-item><list-item><paragraph>HW6: #142, #143, #144, #145, #146 (Coding), #147 (Coding), #172 </paragraph></list-item><list-item><paragraph>HW7: #171 (Coding), #170, #169, #168, #167, #197 </paragraph></list-item><list-item><paragraph>HW8: #178, #179 (Coding), #180, #181, #274 </paragraph></list-item><list-item><paragraph>HW9: #210, #211, #212, #213, #214 (Coding), #215, #271 </paragraph></list-item><list-item><paragraph>HW10: #265, #266, #267, #268, #269, #350 </paragraph></list-item><list-item><paragraph>HW11: #287, #288, #289, #290, #291, #292, #293, #360 </paragraph></list-item><list-item><paragraph>HW12: #318, #319, #320, #321, #322, <link href=\"https://edstem.org/us/courses/84647/discussion/7453738\">#924</link></paragraph></list-item><list-item><paragraph>HW13: #448, #449, #450, <link href=\"https://edstem.org/us/courses/84647/discussion/7448121\">#795</link></paragraph></list-item></list><paragraph/><paragraph><bold>Old Exam Problems at end of HWs:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>HW5: #121, #122 </paragraph></list-item><list-item><paragraph>HW12 #323 </paragraph></list-item></list><paragraph/><paragraph><bold>Discussions:</bold></paragraph><list style=\"number\"><list-item><paragraph> #30, #34 </paragraph></list-item><list-item><paragraph>#67 </paragraph></list-item><list-item><paragraph>#93 </paragraph></list-item><list-item><paragraph>#91 </paragraph></list-item><list-item><paragraph>#123 </paragraph></list-item><list-item><paragraph>#140 </paragraph></list-item><list-item><paragraph>#158 </paragraph></list-item><list-item><paragraph>#176 </paragraph></list-item><list-item><paragraph>#252 </paragraph></list-item><list-item><paragraph>#253 </paragraph></list-item><list-item><paragraph>#280 </paragraph></list-item><list-item><paragraph>#303 </paragraph></list-item><list-item><paragraph>#437 </paragraph></list-item></list><paragraph/><paragraph><bold>Participation Details:</bold></paragraph><paragraph>#75 </paragraph><paragraph>Form: <link href=\"https://edstem.org/us/courses/84647/discussion/7394497\">#403</link></paragraph><paragraph/><paragraph><bold>Project Details Main Thread:</bold></paragraph><paragraph>#150 </paragraph><paragraph/><paragraph><bold>Review Session Thread:</bold></paragraph><paragraph>#735</paragraph></document>",
            "links": [
                "https://edstem.org/us/courses/84647/discussion/7453738",
                "https://edstem.org/us/courses/84647/discussion/7448121",
                "https://edstem.org/us/courses/84647/discussion/7394497"
            ],
            "attachments": [],
            "created_at": "2025-12-10T17:56:54.188928+11:00",
            "category": "Admin"
        },
        {
            "guid": 7448121,
            "author": "Sultan Daniels",
            "project_title": "HW 13 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/YE6n15p5W36rA2Z9adtoEd6r\" filename=\"hw13_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/X0UE2UrSDCfidY3HjiOpqT3B\" filename=\"hw13_solution.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:15:36.631116+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7435036,
            "author": "Sultan Daniels",
            "project_title": "Exam Review Sessions",
            "post_body": "On Wednesday, December 10, instead of discussion sections, there will be exam review sessions. Each review session will focus on one or two homework problems for a specific topic. This gives an opportunity to ask questions to the GSI while solving the problem(s).  Here are the details for the review sessions:\n\nKevin 11am-12pm Zoom (Optimizers)\n\nMeeting ID: 968 5129 5691\n\nPasscode: 158789\n\nProblems\n\nHW3 Q1\n\nHW3 Q2 (muP)\n\nReview of Muon\n\nSultan 3-4pm 136 Social Sciences (Transformers/Attention)\n\nHW9 Q4: Transformer Decoding Optimization\n\nHW9 Q2: Argmax Attention\n\nJoey 4-5pm Hearst Field Annex B1 (Post-training)\n\nReview of RLHF and DPO Motivation\n\nHW 13 Q2 (DPO)\n\nHW 12 Old Exam Problem (if time permits)\n\nLance 5-6pm 242 Hearst Gym (Diffusion)\n\nHW13 Q4: Diffusion Models",
            "content_xml": "<document version=\"2.0\"><paragraph>On <bold>Wednesday, December 10,</bold> instead of discussion sections, there will be exam review sessions. Each review session will focus on one or two homework problems for a specific topic. This gives an opportunity to ask questions to the GSI while solving the problem(s).  Here are the details for the review sessions:</paragraph><list style=\"bullet\"><list-item><paragraph>Kevin 11am-12pm <link href=\"https://berkeley.zoom.us/j/96851295691?pwd=ZjjNALlB0CKY9NftLEM902diJ3fDOb.1\">Zoom</link> <bold>(Optimizers)</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Meeting ID: 968 5129 5691</paragraph></list-item><list-item><paragraph>Passcode: 158789</paragraph></list-item><list-item><paragraph>Problems</paragraph></list-item></list></list-item><list-item><list style=\"unordered\"><list-item><list style=\"unordered\"><list-item><paragraph>HW3 Q1</paragraph></list-item><list-item><paragraph>HW3 Q2 (muP)</paragraph></list-item><list-item><paragraph>Review of Muon</paragraph></list-item></list></list-item></list></list-item><list-item><paragraph>Sultan 3-4pm 136 Social Sciences <bold>(Transformers/Attention)</bold></paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>HW9 Q4: Transformer Decoding Optimization</paragraph></list-item><list-item><paragraph>HW9 Q2: Argmax Attention</paragraph></list-item></list></list-item><list-item><paragraph>Joey 4-5pm Hearst Field Annex B1 <bold>(Post-training)</bold></paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Review of RLHF and DPO Motivation</paragraph></list-item><list-item><paragraph>HW 13 Q2 (DPO)</paragraph></list-item><list-item><paragraph>HW 12 Old Exam Problem (if time permits)</paragraph></list-item></list></list-item><list-item><paragraph>Lance 5-6pm 242 Hearst Gym <bold>(Diffusion)</bold></paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>HW13 Q4: Diffusion Models</paragraph></list-item></list></list-item></list></document>",
            "links": [
                "https://berkeley.zoom.us/j/96851295691?pwd=ZjjNALlB0CKY9NftLEM902diJ3fDOb.1"
            ],
            "attachments": [],
            "created_at": "2025-12-09T08:55:57.534306+11:00",
            "category": "Exam"
        },
        {
            "guid": 7434972,
            "author": "Gireeja Ranade",
            "project_title": "Check your poster number! --- poster session logistics",
            "post_body": "Looking forward to the poster session tomorrow! Please arrive at the Woz at 11 am tomorrow with your poster. We will provide poster boards and easels. The session will go will 1 pm.\n\nEach poster/project has been assigned a number. All of the easels will also be numbered. Please put up your posters (or slide printouts) at the appropriate spot. Poster numbers are in the spreadsheet below.\n\n\n\nhttps://docs.google.com/spreadsheets/d/1IENZsyY4pVBS_SDWD4ZbQoQazJH0af3RsD0VC7FiI68/edit?usp=sharing\n\n\n\nBest,\n\n182 Staff",
            "content_xml": "<document version=\"2.0\"><paragraph>Looking forward to the poster session tomorrow! Please arrive at the Woz at 11 am tomorrow with your poster. We will provide poster boards and easels. The session will go will 1 pm.</paragraph><paragraph>Each poster/project has been assigned a number. All of the easels will also be numbered. Please put up your posters (or slide printouts) at the appropriate spot. Poster numbers are in the spreadsheet below.</paragraph><paragraph/><paragraph><link href=\"https://docs.google.com/spreadsheets/d/1IENZsyY4pVBS_SDWD4ZbQoQazJH0af3RsD0VC7FiI68/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1IENZsyY4pVBS_SDWD4ZbQoQazJH0af3RsD0VC7FiI68/edit?usp=sharing</link></paragraph><paragraph/><paragraph>Best,</paragraph><paragraph>182 Staff</paragraph></document>",
            "links": [
                "https://docs.google.com/spreadsheets/d/1IENZsyY4pVBS_SDWD4ZbQoQazJH0af3RsD0VC7FiI68/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-09T08:48:50.297059+11:00",
            "category": "Project"
        },
        {
            "guid": 7433631,
            "author": "Hong Joey",
            "project_title": "Reviews Assigned for Final Reports",
            "post_body": "Hi all,\n\nReview assignments have been made for all the final reports via CMT (go to the 'Reviewer' console of the conference link). Reviews will be due EOD Thursday (December 11). \n\nEach of you should be assigned exactly one review to do. The paper you review is likely different from the one you were assigned when reviewing drafts, but the questions you answer in the review will mostly be the same. To help with completing the review, we recommend visiting the poster for your assigned report at the poster session tomorrow. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all,<break/><break/>Review assignments have been made for all the final reports via CMT (go to the 'Reviewer' console of the <link href=\"https://cmt3.research.microsoft.com/DLFP2025\">conference link</link>). Reviews will be <bold>due EOD Thursday (December 11)</bold>. <break/><break/>Each of you should be assigned exactly one review to do. The paper you review is likely different from the one you were assigned when reviewing drafts, but the questions you answer in the review will mostly be the same. To help with completing the review, we recommend visiting the poster for your assigned report at the poster session tomorrow. </paragraph><paragraph/></document>",
            "links": [
                "https://cmt3.research.microsoft.com/DLFP2025"
            ],
            "attachments": [],
            "created_at": "2025-12-09T06:17:09.726336+11:00",
            "category": "Project"
        },
        {
            "guid": 7412341,
            "author": "Anant Sahai",
            "project_title": "Lecture 27",
            "post_body": "This thread is to discuss the final lecture in the course. We finished our treatment of diffusion-model training, DDPM style stochastic sampling using what was trained, and DDIM style deterministic sampling using the same exact network that was trained in diffusion style. This should give you what you need to be able to understand diffusion-style models on your own as well as do the final homework 13.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/WphKDgwZ6aCiqLeisXGUGlwq\" filename=\"Lecture 27.pdf\"/><paragraph>This thread is to discuss the final lecture in the course. We finished our treatment of diffusion-model training, DDPM style stochastic sampling using what was trained, and DDIM style deterministic sampling using the same exact network that was trained in diffusion style. This should give you what you need to be able to understand diffusion-style models on your own as well as do the final homework 13.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T16:45:19.25015+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7412221,
            "author": "Alex Proshkin",
            "project_title": "Compute Portal Storage Update 12/4",
            "post_body": "Hi everyone,\n\nWe know some of you have been running into issues with the compute portal. To be fully transparent, the resources we received came with very minimal infrastructure, so we\u2019ve had to build almost everything from scratch. We appreciate your patience as we continue improving it.\n\nGoing forward, we don\u2019t think it\u2019s fair to impose strict storage limits on individuals, but we do ask that you be mindful of space usage. Each of the three instances only has 150 GB for the entire class, so if you\u2019re working with large files, please try to clean up and delete them when you\u2019re done otherwise the portal will again give 500 internal server error. If storage fills up again, we may need to manually clear space by removing the largest user directories.\n\nThanks for your understanding, and have fun with the projects!\n\nBest,\nAlex",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,</paragraph><paragraph>We know some of you have been running into issues with the compute portal. To be fully transparent, the resources we received came with very minimal infrastructure, so we\u2019ve had to build almost everything from scratch. We appreciate your patience as we continue improving it.</paragraph><paragraph>Going forward, we don\u2019t think it\u2019s fair to impose strict storage limits on individuals, but we do ask that you be mindful of space usage. Each of the three instances only has <bold>150 GB for the entire class</bold>, so if you\u2019re working with large files, please try to clean up and delete them when you\u2019re done otherwise the portal will again give 500 internal server error. If storage fills up again, we may need to manually clear space by removing the largest user directories.</paragraph><paragraph>Thanks for your understanding, and have fun with the projects!</paragraph><paragraph>Best,<break/>Alex</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T16:21:12.097369+11:00",
            "category": "Project"
        },
        {
            "guid": 7405185,
            "author": "Sultan Daniels",
            "project_title": "HW 13: Diffusion Models (Optional)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/PzPtFcDaZKUCvI104USWaQaz\" width=\"658\" height=\"709.8853046594982\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T17:22:20.513792+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7405181,
            "author": "Sultan Daniels",
            "project_title": "HW 13: Honey, Where's My Reward Model?",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/hpOzuFhF0hrXYhAyYmscTzPf\" width=\"658\" height=\"286.5092250922509\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/lKUE3mhKLHgVr0BoiBTfxsQO\" width=\"658\" height=\"908.4886363636363\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/dR68NTC4j0kzbfvkN36iRCax\" width=\"643\" height=\"867.7495327102804\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/SIiueIwquedzJUT2kr0axf1I\" width=\"643\" height=\"181.3012259194396\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T17:21:35.8455+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7405171,
            "author": "Sultan Daniels",
            "project_title": "HW 13: DDPM/DDIM Fun: From a Gaussian",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/HMtv0DIIDxF6NsDFFIxN79MW\" width=\"658\" height=\"744.6753246753246\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/uO4mhDM9TGbijsnoQvZ0Haeb\" width=\"643\" height=\"587.5254901960784\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T17:19:45.368522+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7405023,
            "author": "Anant Sahai",
            "project_title": "Lecture 26 Thread",
            "post_body": "This lecture hit RLHF, DPO, and then started diffusion. We'll continue with diffusion in the next lecture. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/Ykyum7otxP4qvEJ6jX3DokzX\" filename=\"Lecture 26.pdf\"/><paragraph>This lecture hit RLHF, DPO, and then started diffusion. We'll continue with diffusion in the next lecture. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T16:48:02.895965+11:00",
            "category": "Admin"
        },
        {
            "guid": 7403736,
            "author": "Lance Mathias",
            "project_title": "Discussion 13 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/rNoLQqkW07FC3a0drChDQNtp\" filename=\"dis13_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/RTl8Dome01whe72wPeSuBW2a\" filename=\"dis13_solution.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T13:33:38.03238+11:00",
            "category": "Sections"
        },
        {
            "guid": 7395242,
            "author": "Gireeja Ranade",
            "project_title": "Extra Credit Update",
            "post_body": "We were overwhelmed by the response to the Extra Credit Post --- we thought there would only be a few students interested.\n\nIn light of this, we are changing the nature of the extra credit to try a new experiment  --- so please ask clarification questions if anything isn't clear.\n\n\nThe new rules for extra credit are as follows. For each participation category there will be Blue Teams and Red Teams.\n\nRed Team: The job of the Red Team is to establish a baseline. What is the best website that can be purely AI generated (with human guidance)? So be smart about how you prompt and thoughtful about the design, but code should be mostly AI written. Any analysis, summarization, grouping etc. should also be done by an AI. Meta level orchestrations is fine by a person. For instance, you can read a subset of the posts for validation purposes, but you should not read all the posts. It should be as though a human never looked at any of the posts or submissions to understand what they are doing. Ideally though there should be a functioning website that displays all content in a readable fashion. If you end up in a situation where it not possible to prompt engineer your way to fucntionality, put in the minimum human effort required to get this functioning and then document a short document/paragraph explaining what was done by an agent and where basic human intervention was necessary. All Red Team submissions will be awarded 4-5 points per student team member. Please feel free to ask clarification questions -- the goal of this is more to do a fun experiment than to be some ridiculous hoop that must be jumped through, we're very curious how far this can get! \n\n\nBlue Team: Your job is to do better than the Red Teams. You may use as much AI as you wish to help generate your website but we ask that you go beyond. Blue Teams will be awarded 5-10 points credit per student (based on staff judgement) if they can do better than the baseline. \n\n\nNote that these points are added to the total points in the course.\n\n\nPlease add yourself to the spreadsheet below so it will be easier to track the teams: https://docs.google.com/spreadsheets/d/14QaSXdvKzj1UGRjPJ6-udmzQSB_UyyS5fl4-VvT6sLs/edit?gid=0#gid=0\n\nNote: all the constraints in the earlier post still apply. Max team size is still 4 etc. \n\nhttps://edstem.org/us/courses/84647/discussion/7384785\n\nAlso note: You may only sign up for ONE team.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>We were overwhelmed by the response to the Extra Credit Post --- we thought there would only be a few students interested.<break/><break/>In light of this, we are changing the nature of the extra credit to try a new experiment  --- so please ask clarification questions if anything isn't clear.</paragraph><paragraph><break/>The new rules for extra credit are as follows. For each participation category there will be Blue Teams and Red Teams.<break/><break/>Red Team: The job of the Red Team is to establish a baseline. What is the best website that can be purely AI generated (with human guidance)? So be smart about how you prompt and thoughtful about the design, but code should be mostly AI written. Any analysis, summarization, grouping etc. should also be done by an AI. Meta level orchestrations is fine by a person. For instance, you can read a subset of the posts for validation purposes, but you should not read all the posts. It should be as though a human never looked at any of the posts or submissions to understand what they are doing. Ideally though there should be a functioning website that displays all content in a readable fashion. If you end up in a situation where it not possible to prompt engineer your way to fucntionality, put in the minimum human effort required to get this functioning and then document a short document/paragraph explaining what was done by an agent and where basic human intervention was necessary. All Red Team submissions will be awarded 4-5 points per student team member. Please feel free to ask clarification questions -- the goal of this is more to do a fun experiment than to be some ridiculous hoop that must be jumped through, we're very curious how far this can get! <break/></paragraph><paragraph>Blue Team: Your job is to do better than the Red Teams. You may use as much AI as you wish to help generate your website but we ask that you go beyond. Blue Teams will be awarded 5-10 points credit per student (based on staff judgement) if they can do better than the baseline. <break/></paragraph><paragraph>Note that these points are added to the total points in the course.<break/></paragraph><paragraph>Please add yourself to the spreadsheet below so it will be easier to track the teams: <link href=\"https://docs.google.com/spreadsheets/d/14QaSXdvKzj1UGRjPJ6-udmzQSB_UyyS5fl4-VvT6sLs/edit?gid=0#gid=0\">https://docs.google.com/spreadsheets/d/14QaSXdvKzj1UGRjPJ6-udmzQSB_UyyS5fl4-VvT6sLs/edit?gid=0#gid=0</link></paragraph><paragraph><bold>Note: all the constraints in the earlier post still apply. Max team size is still 4 etc.</bold> </paragraph><paragraph><link href=\"https://edstem.org/us/courses/84647/discussion/7384785\">https://edstem.org/us/courses/84647/discussion/7384785</link></paragraph><paragraph><bold>Also note: You may only sign up for ONE team.</bold></paragraph><paragraph/></document>",
            "links": [
                "https://docs.google.com/spreadsheets/d/14QaSXdvKzj1UGRjPJ6-udmzQSB_UyyS5fl4-VvT6sLs/edit?gid=0#gid=0",
                "https://edstem.org/us/courses/84647/discussion/7384785"
            ],
            "attachments": [],
            "created_at": "2025-12-03T12:11:43.35436+11:00",
            "category": "Admin"
        },
        {
            "guid": 7394497,
            "author": "Anant Sahai",
            "project_title": "Participation Form",
            "post_body": "Please copy the following Google Doc into your own drive:\n\nhttps://docs.google.com/document/d/1NkNZbLGbU-XeDaV6IqsEPuabpOqTri0YTqpkZ54-xhE/edit?usp=sharing\n\nAnd submit a PDF to Gradescope after you fill it out.  Submit to only one of the participation assignments --- the one that corresponds to the GSI/Tutor you feel would recognize you the best. For those counting on online (rather than in-person discussion), that is likely to be Kevin. \n\nThe form is due on Wednesday Dec 10th.\n\nThe time required to do this should be minimal. Take a selfie of sufficient quality that it will help course staff remember you clearly. Place that on the second page. Fill out the rest. \n\nFor those who did basic participation by coming to discussion and participating throughout the term, you basically just have to point us to your four Special Participation posts at the end. \n\nIf you need basic participation credit from having regularly interacted on Ed online instead, then also use the fourth and fifth page to insert screenshots of your posts/followups.  You have to fit within those two pages.\n\nThe purpose of doing this is to allow you yourself to put yourself in the best light possible vis-a-vis your class participation. Remember, participation is worth 15% of your grade. (It's impossible to get an A of any kind without participation. There is no curve and we use fixed bins.)",
            "content_xml": "<document version=\"2.0\"><paragraph>Please copy the following Google Doc into your own drive:</paragraph><paragraph><link href=\"https://docs.google.com/document/d/1NkNZbLGbU-XeDaV6IqsEPuabpOqTri0YTqpkZ54-xhE/edit?usp=sharing\">https://docs.google.com/document/d/1NkNZbLGbU-XeDaV6IqsEPuabpOqTri0YTqpkZ54-xhE/edit?usp=sharing</link></paragraph><paragraph>And submit a PDF to Gradescope after you fill it out.  Submit to only one of the participation assignments --- the one that corresponds to the GSI/Tutor you feel would recognize you the best. For those counting on online (rather than in-person discussion), that is likely to be Kevin. </paragraph><paragraph>The form is due on Wednesday Dec 10th.</paragraph><paragraph>The time required to do this should be minimal. Take a selfie of sufficient quality that it will help course staff remember you clearly. Place that on the second page. Fill out the rest. </paragraph><paragraph>For those who did basic participation by coming to discussion and participating throughout the term, you basically just have to point us to your four Special Participation posts at the end. </paragraph><paragraph>If you need basic participation credit from having regularly interacted on Ed online instead, then also use the fourth and fifth page to insert screenshots of your posts/followups.  You have to fit within those two pages.</paragraph><paragraph>The purpose of doing this is to allow you yourself to put yourself in the best light possible vis-a-vis your class participation. Remember, participation is worth 15% of your grade. (It's impossible to get an A of any kind without participation. There is no curve and we use fixed bins.)</paragraph></document>",
            "links": [
                "https://docs.google.com/document/d/1NkNZbLGbU-XeDaV6IqsEPuabpOqTri0YTqpkZ54-xhE/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-03T10:43:25.838509+11:00",
            "category": "Admin"
        },
        {
            "guid": 7385279,
            "author": "Hong Joey",
            "project_title": "Project Report Final Version",
            "post_body": "Please submit final reports to:  https://cmt3.research.microsoft.com/DLFP2025\n\nNote that this is technically a different \"conference\" than the one you guys used for drafts. The process for making a submission should be the same as last time though. \n\nHowever, this means that you all should have received another reviewer invitation for this conference. Please accept the reviewer invite as soon as possible, so we can (hopefully) do reviewer assignments more smoothly. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Please submit final reports to:  <link href=\"https://cmt3.research.microsoft.com/DLFP2025\">https://cmt3.research.microsoft.com/DLFP2025</link></paragraph><paragraph>Note that this is technically a different \"conference\" than the one you guys used for drafts. The process for making a submission should be the same as last time though. <break/><break/>However, this means that you all should have received another reviewer invitation for this conference. Please accept the reviewer invite as soon as possible, so we can (hopefully) do reviewer assignments more smoothly. </paragraph><paragraph/></document>",
            "links": [
                "https://cmt3.research.microsoft.com/DLFP2025"
            ],
            "attachments": [],
            "created_at": "2025-12-02T08:08:13.388091+11:00",
            "category": "Project"
        },
        {
            "guid": 7384785,
            "author": "Gireeja Ranade",
            "project_title": "Extra Credit Opportunity --- curate special participation posts",
            "post_body": "Please see the new updated extra credit post here: https://edstem.org/us/courses/84647/discussion/7395242\n\nDear students, \n\nWe've enjoyed reading your extra credits posts and engagement throughout the semester and found it very interesting ourselves. So much so that we would like to record this for posterity and create a forum that allows you to get visibility for this. This means we can follow up on some of your ideas more easily as well (with due credit of course). As a first step in this direction, we would like to create a searchable website that will document all participation for each of the extra credit participation categories. This would allow us, and other students, to easily navigate through the different ideas and explore what works for them and what does not. Furthermore, our goal will be to link student websites/linked-in pages, so all of you can gain visibility on the work you have done. This website will be hosted on the eecs182.org.\n\nWe are offering 5-10 points of extra credit per student (more points for better quality submissions, more points for the categories we care about more) for students who help make such a website. We understand this will be a significant lift, but hope you can leverage deep learning skills to make this happen. Ideally, this will be presented as a directory that we can simply drop into the eecs182 website. Multiple students are allowed to collaborate on this as below:\n\n\n\nWe care the most about this for E since this allows us to easily build tools in the future.\n\nSpecial Participation E: 3-4 students\n\nA nice version of this would categorize the submissions into different types of submissions (e.g. generating new questions, helping understand existing content, creating new content etc. --- come up with your own categories.) If you think some submissions are particularly impressive, highlight them. \n\n\n\nSecond we care about documenting student interactions with LLMs.\n\nSpecial Participation A: 3-4 students\n\nSpecial Participation B: 3-4 students\n\nFor each of these two cases, we would like to have a summary of insights on how each of the different LLMs behave and common issues. What insights were gained from \n\n\n\nThird we care about the Muon and MuP updates\n\nSpecial Participation D: 2 students\n\n\n\nLast (fourth) priority\n\nSince it would be nice to have this all coordinated in one website, if someone wants to take on a coordination role: 1-2 students. \n\nFor each kind of special participation we should be able to read what every student submitted as text and as attachment. Every student should get credited for the work they have put in. Include links to student websites/github repos if those are included in the post (All students --- feel free to go and edit your posts to include this information so that they will show up in the common collection).\n\nBonus points if the website is searchable by keyword/student name etc. Other design choices we leave up to you. Feel free to ask questions below.  \n\n\n\nPlease do not claim a spot to complete this unless you are truly planning to, since it does not allow others to take this on. Use this thread to self-organize so you can make teams to do this. \n\nThanks,\n\n182 Staff\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Please see the new updated extra credit post here: https://edstem.org/us/courses/84647/discussion/7395242</paragraph><paragraph>Dear students, </paragraph><paragraph>We've enjoyed reading your extra credits posts and engagement throughout the semester and found it very interesting ourselves. So much so that we would like to record this for posterity and create a forum that allows you to get visibility for this. This means we can follow up on some of your ideas more easily as well (with due credit of course). As a first step in this direction, we would like to create <bold>a searchable website that will document all participation for each of the extra credit participation categories</bold>. This would allow us, and other students, to easily navigate through the different ideas and explore what works for them and what does not. Furthermore, our goal will be to link student websites/linked-in pages, so all of you <bold>can gain visibility</bold> on the work you have done. This website will be hosted on the eecs182.org.</paragraph><paragraph>We are offering <bold>5-10 points of extra credit</bold> per student (more points for better quality submissions, more points for the categories we care about more) for students who help make such a website. We understand this will be a significant lift, but hope you can leverage deep learning skills to make this happen. Ideally, this will be presented as a directory that we can simply drop into the eecs182 website. Multiple students are allowed to collaborate on this as below:</paragraph><paragraph/><list style=\"unordered\"><list-item><paragraph>We care the most about this for E since this allows us to easily build tools in the future.</paragraph></list-item></list><blockquote>Special Participation E: 3-4 students</blockquote><blockquote>A nice version of this would categorize the submissions into different types of submissions (e.g. generating new questions, helping understand existing content, creating new content etc. --- come up with your own categories.) If you think some submissions are particularly impressive, highlight them. </blockquote><paragraph/><list style=\"unordered\"><list-item><paragraph>Second we care about documenting student interactions with LLMs.</paragraph></list-item></list><blockquote>Special Participation A: 3-4 students</blockquote><blockquote>Special Participation B: 3-4 students</blockquote><blockquote>For each of these two cases, we would like to have a summary of insights on how each of the different LLMs behave and common issues. What insights were gained from </blockquote><paragraph/><list style=\"unordered\"><list-item><paragraph>Third we care about the Muon and MuP updates</paragraph></list-item></list><blockquote>Special Participation D: 2 students</blockquote><paragraph/><list style=\"unordered\"><list-item><paragraph>Last (fourth) priority</paragraph></list-item></list><blockquote>Since it would be nice to have this all coordinated in one website, if someone wants to take on a coordination role: 1-2 students. </blockquote><paragraph>For each kind of special participation we should be able to read what every student submitted as text and as attachment. Every student should get credited for the work they have put in. Include links to student websites/github repos if those are included in the post <bold>(All students --- feel free to go and edit your posts to include this information so that they will show up in the common collection).</bold></paragraph><paragraph>Bonus points if the website is searchable by keyword/student name etc. Other design choices we leave up to you. Feel free to ask questions below.  </paragraph><paragraph/><paragraph>Please do not claim a spot to complete this unless you are truly planning to, since it does not allow others to take this on. Use this thread to self-organize so you can make teams to do this. </paragraph><paragraph>Thanks,</paragraph><paragraph>182 Staff</paragraph><list style=\"bullet\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T07:11:44.121633+11:00",
            "category": "Admin"
        },
        {
            "guid": 7366224,
            "author": "Anant Sahai",
            "project_title": "Lecture 25: Test-time compute, sampling, and RL post-training",
            "post_body": "Use this thread to discuss the lecture. \n\nI misspoke during lecture at the end when I was trying to explain the min term. This is a reward that is being maximized and so the min here is stopping large values from becoming too large (not the other way around). The paper discussed clipping in both directions (both are done in different papers) but suggests that it is important to stop accidentally having very large weights to a single generation/token due to a mismatch in the ratio. I misspoke in lecture but the expressions written are correct. Sorry.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/1chm7oisBBtHpGT4MEgh7z8Q\" filename=\"Lecture 25.pdf\"/><paragraph>Use this thread to discuss the lecture. </paragraph><paragraph>I misspoke during lecture at the end when I was trying to explain the min term. This is a reward that is being maximized and so the min here is stopping large values from becoming too large (not the other way around). The paper discussed clipping in both directions (both are done in different papers) but suggests that it is important to stop accidentally having very large weights to a single generation/token due to a mismatch in the ratio. I misspoke in lecture but the expressions written are correct. Sorry.</paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-26T11:36:33.911819+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7351756,
            "author": "Anant Sahai",
            "project_title": "Lecture 24: VAEs and starting test-time compute and post-training",
            "post_body": "This is so students can ask questions about the lecture. I forgot to mention in lecture that Chapters 14 and 17 in Prince are relevant.\n\nRemember, after starting Generative models, we are going to do a little interlude to go through more details of test-time compute and post-training for LLMs. The reason we're doing this is two-fold: \n\nA) The VAE discussion, along with the homework, has unlocked some of the technical tools that we are going to need. Since we have enough now, we can return to post-training since it continues our earlier theme of fine-tuning.\n\nB) Some of the things that we are going to be hitting during post-training will then help us in understanding diffusion-based generative models --- which is what we will do afterwards.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/yF94T6o6P3n9frsyn6cLcPlz\" filename=\"Lecture 24.pdf\"/><paragraph>This is so students can ask questions about the lecture. I forgot to mention in lecture that Chapters 14 and 17 in Prince are relevant.</paragraph><paragraph>Remember, after starting Generative models, we are going to do a little interlude to go through more details of test-time compute and post-training for LLMs. The reason we're doing this is two-fold: </paragraph><paragraph>A) The VAE discussion, along with the homework, has unlocked some of the technical tools that we are going to need. Since we have enough now, we can return to post-training since it continues our earlier theme of fine-tuning.</paragraph><paragraph>B) Some of the things that we are going to be hitting during post-training will then help us in understanding diffusion-based generative models --- which is what we will do afterwards.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-23T05:39:42.344447+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7330082,
            "author": "Anant Sahai",
            "project_title": "Project Report",
            "post_body": "For submitting the Draft:\n\nhttps://cmt3.research.microsoft.com/DLFPD2025\n\nWe are going to run this like a conference. So use that to submit. You should get an email after we add you to it. Be sure to include all members of your team. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/Ga4T0HD2Xv8rEwktQc4pMadX\" filename=\"Project Report Requirements.pdf\"/><paragraph>For submitting the Draft:</paragraph><paragraph><link href=\"https://cmt3.research.microsoft.com/DLFPD2025\">https://cmt3.research.microsoft.com/DLFPD2025</link></paragraph><paragraph>We are going to run this like a conference. So use that to submit. You should get an email after we add you to it. Be sure to include all members of your team. </paragraph><paragraph/></document>",
            "links": [
                "https://cmt3.research.microsoft.com/DLFPD2025"
            ],
            "attachments": [],
            "created_at": "2025-11-19T05:23:44.405993+11:00",
            "category": "Project"
        },
        {
            "guid": 7328421,
            "author": "Alex Proshkin",
            "project_title": "Update: Compute Portal Time Slots Removed",
            "post_body": "Hi everyone,\n\nWe've noticed that the compute resources aren't being used very often, so we're removing the assigned time slots. You can now feel free to use the compute portal at any time that works for you.\n\nBest,\nAlex",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,</paragraph><paragraph>We've noticed that the compute resources aren't being used very often, so we're removing the assigned time slots. You can now feel free to use the compute portal at any time that works for you.</paragraph><paragraph>Best,<break/>Alex</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T18:13:57.038203+11:00",
            "category": "Admin"
        },
        {
            "guid": 7313350,
            "author": "Anant Sahai",
            "project_title": "Information about Special Topics Class next semester...",
            "post_body": "Dear students,\n\nI had promised many of you some details for the Special Topics Course that meets in Spring 2026 (currently TuTh 9:30am-11am in 521 Cory).\n\nFor undergraduates, the department created a course with CCN 34668 (formal name EE194-16)\n\nFor graduate students, the department created a course with CCN 34123 (formal name EE290-16) \n\nSign up and add yourself to the waitlist if it is full. If the waitlist gets full, we'll ask the department to increase the waitlist. The department needs to see what the demand is to decide whether to get a bigger room, etc... \n\nI will be co-teaching it with Prof. Jiantao Jiao who is at NVidia full time while maintaining an affiliation here. (Prof. Ranade is involved in our planning but she's teaching 127/227A next semester so can't do this on top of that.) Our goal, which is still a work in progress, is to get people access to both massive amounts of compute (multi-GPU and multi-machine --- not just more Thinking Machines credit which we already have secured.) as well as a set of material that will expose you to how these kinds of things are done at scale. Our dream is to make sure that everyone taking it can get some real experience with industry-level pre-training/post-training/fine-tuning infrastructure and tooling.  We can't commit to being able to do this, but it's what we are working towards. This is an experiment because it is our collective gut feeling that we need something like this for our students. \n\nThe other part of the vision is to give students a way to take what they've learned in 182/282A with their projects and go beyond. I did this before in Spring 2024 and multiple student groups got paper submissions, etc. after taking their projects from the class, merging/reshuffling teams, and pushing beyond. Our dream perspective on this is to give you a way of combining/expanding your ideas and being able to investigate them at much larger scale...\n\nIf there ends up being a mismatch in the number of students we can support in the class and the level of interest, we will use a combination of the quality of student projects in 182/282A combined with performance in other relevant classes to figure out who gets in. But nobody can get a shot if they don't sign up. \n\n \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Dear students,</paragraph><paragraph>I had promised many of you some details for the Special Topics Course that meets in Spring 2026 (currently TuTh 9:30am-11am in 521 Cory).</paragraph><paragraph>For undergraduates, the department created a course with CCN 34668 (formal name EE194-16)</paragraph><paragraph>For graduate students, the department created a course with CCN 34123 (formal name EE290-16) </paragraph><paragraph>Sign up and add yourself to the waitlist if it is full. If the waitlist gets full, we'll ask the department to increase the waitlist. The department needs to see what the demand is to decide whether to get a bigger room, etc... </paragraph><paragraph>I will be co-teaching it with Prof. Jiantao Jiao who is at NVidia full time while maintaining an affiliation here. (Prof. Ranade is involved in our planning but she's teaching 127/227A next semester so can't do this on top of that.) Our goal, which is still a work in progress, is to get people access to both massive amounts of compute (multi-GPU and multi-machine --- not just more Thinking Machines credit which we already have secured.) as well as a set of material that will expose you to how these kinds of things are done at scale. Our dream is to make sure that everyone taking it can get some real experience with industry-level pre-training/post-training/fine-tuning infrastructure and tooling.  We can't commit to being able to do this, but it's what we are working towards. This is an experiment because it is our collective gut feeling that we need something like this for our students. </paragraph><paragraph>The other part of the vision is to give students a way to take what they've learned in 182/282A with their projects and go beyond. I did this before in Spring 2024 and multiple student groups got paper submissions, etc. after taking their projects from the class, merging/reshuffling teams, and pushing beyond. Our dream perspective on this is to give you a way of combining/expanding your ideas and being able to investigate them at much larger scale...</paragraph><paragraph>If there ends up being a mismatch in the number of students we can support in the class and the level of interest, we will use a combination of the quality of student projects in 182/282A combined with performance in other relevant classes to figure out who gets in. But nobody can get a shot if they don't sign up. </paragraph><paragraph> </paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-15T18:35:44.612982+11:00",
            "category": "Admin"
        },
        {
            "guid": 7269940,
            "author": "Alex Proshkin",
            "project_title": "New: JupyterHub Compute Portal Now Available",
            "post_body": "Hi everyone,\n\nThe CS182 JupyterHub Compute Portal is now live! \ud83c\udf89\nThis will be your place to run course assignments with dedicated compute.\n\nHow to access:\nYou can find it from the course website\u2019s navigation bar, or go directly here:\nhttps://berkeley-cs182.github.io/jupyterhub/\n\nWhat you get:\n\nJupyterHub servers with CPU and GPU options\n\nLogin with your @berkeley.edu account\n\nCompute options:\n\nCPU (default): Use anytime for regular work\n\nGPU (limited): Access to full NVIDIA A100 40GB. Use only during assigned time when needed for deep learning workloads\n\nGroup assignments:\nEach student is assigned to Group A, B, or C. Check the portal to see where you're assigned. Slots will be continuously added, so check in regularly.\n\n!!! IMPORTANT !!!\n\nOnly one team should run in a group server at a time\n\nIf you want to swap times with another team, coordinate in the thread below\n\nPlease shut down your server when you're done so others can use it \ud83d\udc4d\n\nIf you run into issues or have questions, reply in the thread below or email me (pro@berkeley.edu).\n\nThanks and happy training!\nAlex",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,</paragraph><paragraph>The CS182 JupyterHub Compute Portal is now live! \ud83c\udf89<break/>This will be your place to run course assignments with dedicated compute.</paragraph><paragraph><bold>How to access:</bold><break/>You can find it from the course website\u2019s navigation bar, or go directly here:<break/><link href=\"https://berkeley-cs182.github.io/jupyterhub/\">https://berkeley-cs182.github.io/jupyterhub/</link></paragraph><paragraph><bold>What you get:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>JupyterHub servers with CPU and GPU options</paragraph></list-item><list-item><paragraph>Login with your @berkeley.edu account</paragraph></list-item></list><paragraph><bold>Compute options:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>CPU (default):</bold> Use anytime for regular work</paragraph></list-item><list-item><paragraph><bold>GPU (limited):</bold> Access to full NVIDIA A100 40GB. Use only during assigned time when needed for deep learning workloads</paragraph></list-item></list><paragraph><bold>Group assignments:</bold><break/>Each student is assigned to Group A, B, or C. Check the portal to see where you're assigned. Slots will be continuously added, so check in regularly.</paragraph><paragraph><bold>!!! IMPORTANT !!!</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Only one team should run in a group server at a time</paragraph></list-item><list-item><paragraph>If you want to swap times with another team, coordinate in the thread below</paragraph></list-item><list-item><paragraph>Please shut down your server when you're done so others can use it \ud83d\udc4d</paragraph></list-item></list><paragraph>If you run into issues or have questions, reply in the thread below or email me (<link href=\"null\">pro@berkeley.edu</link>).</paragraph><paragraph>Thanks and happy training!<break/>Alex</paragraph></document>",
            "links": [
                "https://berkeley-cs182.github.io/jupyterhub/",
                "null"
            ],
            "attachments": [],
            "created_at": "2025-11-07T10:49:58.265283+11:00",
            "category": "Admin"
        },
        {
            "guid": 7268035,
            "author": "Gireeja Ranade",
            "project_title": "Tinker access for final projects --- Opt-in deadline Nov 7 at 10 am.",
            "post_body": "Dear students, \n\n\n\nWe have secured access to Tinker, a new API from Thinking Machines that provides fine-tuning support for many popular open-weight models. You can read more here:\n\n\n\nhttps://thinkingmachines.ai/tinker/\n\nWe assume most of you would like access to this for your project/to try out things otherwise. This requires us to create an account for you on their API using your name/email. If you would prefer that we not share your name and email with Thinking Machines to get you access, please opt-out using the form below. If you want to guarantee you get access, please also indicate this below. \n\n\n\nhttps://forms.gle/vUuQwYeFHgtqX74z8\n\nGiven a tight timeline, there is a 24 hour deadline to opt-in/out-out. Form closes at 10 am Nov 7.\n\nThanks,\n\n182 Staff. \n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Dear students, </paragraph><paragraph/><paragraph>We have secured access to Tinker, a new API from Thinking Machines that provides fine-tuning support for many popular open-weight models. You can read more here:</paragraph><paragraph/><paragraph><link href=\"https://thinkingmachines.ai/tinker/\">https://thinkingmachines.ai/tinker/</link></paragraph><paragraph>We assume most of you would like access to this for your project/to try out things otherwise. This requires us to create an account for you on their API using your name/email. If you would prefer that we not share your name and email with Thinking Machines to get you access, please opt-out using the form below. If you want to guarantee you get access, please also indicate this below. </paragraph><paragraph/><paragraph><link href=\"https://forms.gle/vUuQwYeFHgtqX74z8\">https://forms.gle/vUuQwYeFHgtqX74z8</link></paragraph><paragraph>Given a tight timeline, there is a 24 hour deadline to opt-in/out-out. Form closes at 10 am Nov 7.</paragraph><paragraph>Thanks,</paragraph><paragraph>182 Staff. <break/></paragraph><paragraph/></document>",
            "links": [
                "https://thinkingmachines.ai/tinker/",
                "https://forms.gle/vUuQwYeFHgtqX74z8"
            ],
            "attachments": [],
            "created_at": "2025-11-07T06:04:53.599999+11:00",
            "category": "Admin"
        },
        {
            "guid": 7132226,
            "author": "Anant Sahai",
            "project_title": "Project Thread 3: Interpretability",
            "post_body": "This thread exists to help students form teams in this thread as well as deconflict what exactly you want to do. The main document introducing projects has some examples of what can be proposed. This particular project thread is particularly amenable for having the projects have a bit of life after the semester ends to pull things together into a paper that expounds on this story with a set of systematic explorations. Consequently, there is a lot of value to be had by deconflicting early and making sure that you get fuller coverage. Everyone whose project contributes to the paper will be a co-author. In previous semesters, I have taught a follow-on special topics course the subsequent semester to help students further develop their projects if they want to. I hope to do that again in the Spring but obviously, that is not required in any way to pursue this option. It's perfectly fine to have a project that ends once the course is done. \n\nThis particular thread is likely to involve a lot more learning on your own to get started since we aren't going to be covering many of the core techniques in class. But all project options 1,2, and 3 involve reading papers/blogs/etc. on your own as well as figuring out tools and codebases on your own because being able to do that is the core way to show that you've actually internalized the foundations that we are teaching you here. No static set of course materials is ever going to suffice in a field like this --- it's all about being able to learn on your own. That's what you want to demonstrate with a project like this in your portfolio.",
            "content_xml": "<document version=\"2.0\"><paragraph>This thread exists to help students form teams in this thread as well as deconflict what exactly you want to do. The main document introducing projects has some examples of what can be proposed. <bold>This particular project thread is particularly amenable for having the projects have a bit of life after the semester ends to pull things together into a paper that expounds on this story with a set of systematic explorations.</bold> Consequently, there is a lot of value to be had by deconflicting early and making sure that you get fuller coverage. Everyone whose project contributes to the paper will be a co-author. In previous semesters, I have taught a follow-on special topics course the subsequent semester to help students further develop their projects if they want to. I hope to do that again in the Spring but obviously, that is not required in any way to pursue this option. It's perfectly fine to have a project that ends once the course is done. </paragraph><paragraph>This particular thread is likely to involve a lot more learning on your own to get started since we aren't going to be covering many of the core techniques in class. But all project options 1,2, and 3 involve reading papers/blogs/etc. on your own as well as figuring out tools and codebases on your own <italic>because</italic> being able to do that is the core way to show that you've actually internalized the foundations that we are teaching you here. No static set of course materials is ever going to suffice in a field like this --- it's all about being able to learn on your own. That's what you want to demonstrate with a project like this in your portfolio.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T10:01:48.797649+11:00",
            "category": "Project"
        },
        {
            "guid": 7132205,
            "author": "Anant Sahai",
            "project_title": "Project Thread 2: ICL via toy problems",
            "post_body": "This thread exists to help students form teams in this thread as well as deconflict what exactly you want to do. The main document introducing projects has some examples of what can be proposed. This particular project thread is particularly amenable for having the projects have a bit of life after the semester ends to pull things together into a paper that expounds on this story with a set of systematic explorations. Consequently, there is a lot of value to be had by deconflicting early and making sure that you get fuller coverage. Everyone whose project contributes to the paper will be a co-author. In previous semesters, I have taught a follow-on special topics course the subsequent semester to help students further develop their projects if they want to. I hope to do that again in the Spring but obviously, that is not required in any way to pursue this option. It's perfectly fine to have a project that ends once the course is done. ",
            "content_xml": "<document version=\"2.0\"><paragraph>This thread exists to help students form teams in this thread as well as deconflict what exactly you want to do. The main document introducing projects has some examples of what can be proposed. <bold>This particular project thread is particularly amenable for having the projects have a bit of life after the semester ends to pull things together into a paper that expounds on this story with a set of systematic explorations.</bold> Consequently, there is a lot of value to be had by deconflicting early and making sure that you get fuller coverage. Everyone whose project contributes to the paper will be a co-author. In previous semesters, I have taught a follow-on special topics course the subsequent semester to help students further develop their projects if they want to. I hope to do that again in the Spring but obviously, that is not required in any way to pursue this option. It's perfectly fine to have a project that ends once the course is done. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T09:59:43.452413+11:00",
            "category": "Project"
        },
        {
            "guid": 7132201,
            "author": "Anant Sahai",
            "project_title": "Project Thread 1: Optimization and hyperparameter transfer",
            "post_body": "This thread exists to help students form teams in this thread as well as deconflict what exactly you want to do. The main document introducing projects has some examples of what can be proposed. This particular project thread is particularly amenable for having the projects have a bit of life after the semester ends to pull things together into a paper that expounds on this story with a set of systematic explorations. Consequently, there is a lot of value to be had by deconflicting early and making sure that you get fuller coverage. Everyone whose project contributes to the paper will be a co-author. In previous semesters, I have taught a follow-on special topics course the subsequent semester to help students further develop their projects if they want to. I hope to do that again in the Spring but obviously, that is not required in any way to pursue this option. It's perfectly fine to have a project that ends once the course is done. ",
            "content_xml": "<document version=\"2.0\"><paragraph>This thread exists to help students form teams in this thread as well as deconflict what exactly you want to do. The main document introducing projects has some examples of what can be proposed. <bold>This particular project thread is particularly amenable for having the projects have a bit of life after the semester ends to pull things together into a paper that expounds on this story with a set of systematic explorations.</bold> Consequently, there is a lot of value to be had by deconflicting early and making sure that you get fuller coverage. Everyone whose project contributes to the paper will be a co-author. In previous semesters, I have taught a follow-on special topics course the subsequent semester to help students further develop their projects if they want to. I hope to do that again in the Spring but obviously, that is not required in any way to pursue this option. It's perfectly fine to have a project that ends once the course is done. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T09:59:04.76962+11:00",
            "category": "Project"
        },
        {
            "guid": 7132188,
            "author": "Anant Sahai",
            "project_title": "Project Thread 0: Projects applying Deep Learning to another domain.",
            "post_body": "This is to help people coordinate, find teams, etc. Remember, any project of this type requires a graduate student (with a faculty adviser --- grad students from coursework-only programs or who are doing capstone projects with anyone other than regular faculty are not eligible for this option) from another department (not EECS) to be on the team to demonstrate disciplinary expertise in the domain being proposed and to take responsibility for that side. Others on the team can be from any department. Undergraduates from other departments cannot lead such projects unless they can clearly demonstrate faculty PI commitment to providing disciplinary guidance. (That means we need a letter from the faculty member in another department saying that they're going to support you vis-a-vis this line of investigation on the disciplinary side and do what it takes.)",
            "content_xml": "<document version=\"2.0\"><paragraph>This is to help people coordinate, find teams, etc. Remember, any project of this type requires a graduate student (with a faculty adviser --- grad students from coursework-only programs or who are doing capstone projects with anyone other than regular faculty are not eligible for this option) from another department (not EECS) to be on the team to demonstrate disciplinary expertise in the domain being proposed and to take responsibility for that side. Others on the team can be from any department. Undergraduates from other departments cannot lead such projects unless they can clearly demonstrate faculty PI commitment to providing disciplinary guidance. (That means we need a letter from the faculty member in another department saying that they're going to support you vis-a-vis this line of investigation on the disciplinary side and do what it takes.)</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T09:56:58.48185+11:00",
            "category": "Project"
        },
        {
            "guid": 7132154,
            "author": "Anant Sahai",
            "project_title": "Main Project Info Thread",
            "post_body": "Deadlines: (Same for each of the topic choices above)\n\nRequired pre-proposal meeting with course staff: Week of Oct 27th (sign up details TBD)\n\nProject Proposal (details below): Monday Nov 3rd (This includes confirmed teaming...) \n\nRequired meeting with course staff for feedback: Week of Nov 3rd. (sign up details TBD)\n\nDraft submission of your final project report for peer review: Thu Nov 20th\n\nDetailed individual peer feedback due: Tue Nov 25th.\n\nFinal project report due: Fri Dec 5th\n\nPoster Session: During the class slot on Tue Dec 9th 11-1PM in The Woz (4th floor Soda)\n\nFinal Peer review due: Thu Dec 11th. (So you can incorporate comments from the poster session as well)\n\nFinal project report due that addresses all review comments: Sun Dec 14th\n\nProject proposal requirements (Due Nov 3rd --- submit on Gradescope)\n\nTeam: List of 4 students doing the project together\n\nAbstract: At most 6 sentences. \n\nIntroduction and Background: This must include a literature review of at least 8 papers related to your project. There should be at least one sentence summaries of the key point of each of the papers.\n\nKey questions: This should be a short section that must include actual questions you are trying to answer. What is the problem you are trying to solve or the phenomenon you are trying to understand/replicate? This should be backed up by the earlier section.\n\nHypothesis: What is your hypothesis? This could be simple e.g. I expect a phenomenon described in XYZ reference to be replicated in a different setting. But it is important to be expecting something --- it's fine if something different ends up happening. \n\nMethods: How will you test your hypothesis? What are the experiments you will run? What is the expected compute requirement?\n\nWe expect proposals to be written using Latex, submitted as PDFs, with one-inch margins, and 12 point font. The purpose of the proposal format is to help structure your thoughts. The required short pre-proposal meetings are intended to help guide you towards a good proposal --- you should be attending those with a draft proposal (or proposal options) in your hand. And the required post-proposal meetings are intended to get you feedback and help you make your efforts better.\n\nThis is not a class in which a project can be completed overnight or even in a week. You need to start early and expect to have all four team members working hard. Deep Learning being what it is, there will be setbacks, confusion, and lots of iterative refinement on top of having to do a lot of reading and learning on your own.\n\nPoster Session:\n\nThe idea of the poster session is to allow you to share your work with your peers and for them to ask you questions. This is required because being able to present work concisely in poster form is a critically important skill. If there is demand for wanting to give a very short (2min) lightning talks too, we can schedule that for the class slot on Thu Dec 11th.  \n\nOther logistics:\n\nGroups must be 4 people in size. Exceptions can be granted for a group that ends up at 3 or 5 because someone dropped or picking up students orphaned. \n\nWe have secured some compute that we can make available to student groups --- but there isn't that much of it. Details on how to get this will come later.\n\nProject grades are shared with your team, except multiplicatively modulated by the quality of your individual peer-review. Do a bad job as a peer-reviewer, and you will lose points. Don't do all required peer review, and you'll get a zero on the project. In addition, you can gain participation credit for solid helpful interaction with other groups within your project theme in the respective Ed threads.\n\nWe will separately announce which TA office hours are best for which project type.\n\nThis thread is entirely for administrative or logistics-related questions. There will be specific threads for the four project options that can be used to help set up teaming, etc. \n\nGuidance and advice:\n\nYou are encouraged to leverage generative AI tools to help you with writing/modifying code as well as to leverage \"Deep Research\" type tools to help you seed your literature search as well as refine/sharpen your ideas. Cite the use of these tools and include an appendix (doesn't count against any page limits or guidance) where you give a narrative description of how you engaged with generative AI tools during your project. We live in 2025. :-)\n\nIt is also fine to use generative AI tools to help with your writing, figure making, etc. Just fully describe this use in your appendix. However, note that any hallucinations that end up in your final report will be severely penalized --- you are expected to understand and double-check everything that you are writing. The point of permitting the use of these tools is to improve overall quality and to help you do the best project you can in the given time.\n\nWe will be releasing peer-review guidance and rubrics later. One of the things you will be expected to do along with each submission is to also submit a peer-review form for your own project. This can be thought of as a checklist that is designed to help your submission be in better shape and to avoid subjecting the reviewers to bad projects. On this front, we anticipate a substantial extra-credit opportunity for those who figure out (and share with your classmates) how to prompt a publicly available LLM to help groups review their own work to get rounds of criticism and feedback before having to subject your human peers to your work. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/iJWlTq0JScegTBCZq7SreCB7\" filename=\"Final Project Topics Fall 2025 (1).pdf\"/><paragraph>Deadlines: (Same for each of the topic choices above)</paragraph><list style=\"unordered\"><list-item><paragraph>Required pre-proposal meeting with course staff: Week of Oct 27th (sign up details TBD)</paragraph></list-item><list-item><paragraph>Project Proposal (details below): Monday Nov 3rd (This includes confirmed teaming...) </paragraph></list-item><list-item><paragraph>Required meeting with course staff for feedback: Week of Nov 3rd. (sign up details TBD)</paragraph></list-item><list-item><paragraph>Draft submission of your final project report for peer review: Thu Nov 20th</paragraph></list-item><list-item><paragraph>Detailed individual peer feedback due: Tue Nov 25th.</paragraph></list-item><list-item><paragraph>Final project report due: Fri Dec 5th</paragraph></list-item><list-item><paragraph><bold>Poster Session: During the class slot on Tue Dec 9th 11-1PM in The Woz (4th floor Soda)</bold></paragraph></list-item><list-item><paragraph>Final Peer review due: Thu Dec 11th. (So you can incorporate comments from the poster session as well)</paragraph></list-item><list-item><paragraph>Final project report due that addresses all review comments: Sun Dec 14th</paragraph></list-item></list><heading level=\"3\"><bold>Project proposal requirements (Due Nov 3rd --- submit on Gradescope)</bold></heading><list style=\"unordered\"><list-item><paragraph>Team: List of 4 students doing the project together</paragraph></list-item><list-item><paragraph>Abstract: At most 6 sentences. </paragraph></list-item><list-item><paragraph>Introduction and Background: This must include a literature review of at least 8 papers related to your project. There should be at least one sentence summaries of the key point of each of the papers.</paragraph></list-item><list-item><paragraph>Key questions: This should be a short section that must include actual questions you are trying to answer. What is the problem you are trying to solve or the phenomenon you are trying to understand/replicate? This should be backed up by the earlier section.</paragraph></list-item><list-item><paragraph>Hypothesis: What is your hypothesis? This could be simple e.g. I expect a phenomenon described in XYZ reference to be replicated in a different setting. But it is important to be expecting something --- it's fine if something different ends up happening. </paragraph></list-item><list-item><paragraph>Methods: How will you test your hypothesis? What are the experiments you will run? What is the expected compute requirement?</paragraph></list-item></list><paragraph>We expect proposals to be written using Latex, submitted as PDFs, with one-inch margins, and 12 point font. The purpose of the proposal format is to help structure your thoughts. The required short pre-proposal meetings are intended to help guide you towards a good proposal --- you should be attending those with a draft proposal (or proposal options) in your hand. And the required post-proposal meetings are intended to get you feedback and help you make your efforts better.</paragraph><paragraph>This is not a class in which a project can be completed overnight or even in a week. You need to start early and expect to have all four team members working hard. Deep Learning being what it is, there will be setbacks, confusion, and lots of iterative refinement on top of having to do a lot of reading and learning on your own.</paragraph><paragraph><bold>Poster Session:</bold></paragraph><paragraph>The idea of the poster session is to allow you to share your work with your peers and for them to ask you questions. This is required because being able to present work concisely in poster form is a critically important skill. If there is demand for wanting to give a very short (2min) lightning talks too, we can schedule that for the class slot on Thu Dec 11th.  </paragraph><paragraph><bold>Other logistics:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Groups must be 4 people in size. Exceptions can be granted for a group that ends up at 3 or 5 because someone dropped or picking up students orphaned. </paragraph></list-item><list-item><paragraph>We have secured some compute that we can make available to student groups --- but there isn't that much of it. Details on how to get this will come later.</paragraph></list-item><list-item><paragraph>Project grades are shared with your team, except multiplicatively modulated by the quality of your individual peer-review. Do a bad job as a peer-reviewer, and you will lose points. Don't do all required peer review, and you'll get a zero on the project. In addition, you can gain participation credit for solid helpful interaction with other groups within your project theme in the respective Ed threads.</paragraph></list-item><list-item><paragraph>We will separately announce which TA office hours are best for which project type.</paragraph></list-item></list><paragraph>This thread is entirely for administrative or logistics-related questions. There will be specific threads for the four project options that can be used to help set up teaming, etc. </paragraph><paragraph><bold>Guidance and advice:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>You are encouraged to leverage generative AI tools to help you with writing/modifying code as well as to leverage \"Deep Research\" type tools to help you seed your literature search as well as refine/sharpen your ideas. Cite the use of these tools and include an appendix (doesn't count against any page limits or guidance) where you give a narrative description of how you engaged with generative AI tools during your project. We live in 2025. :-)</paragraph></list-item><list-item><paragraph>It is also fine to use generative AI tools to help with your writing, figure making, etc. Just fully describe this use in your appendix. However, note that any hallucinations that end up in your final report will be severely penalized --- you are expected to understand and double-check everything that you are writing. The point of permitting the use of these tools is to improve overall quality and to help you do the best project you can in the given time.</paragraph></list-item><list-item><paragraph>We will be releasing peer-review guidance and rubrics later. One of the things you will be expected to do along with each submission is to also submit a peer-review form for your own project. This can be thought of as a checklist that is designed to help your submission be in better shape and to avoid subjecting the reviewers to bad projects. On this front, we anticipate a substantial extra-credit opportunity for those who figure out (and share with your classmates) how to prompt a publicly available LLM to help groups review their own work to get rounds of criticism and feedback before having to subject your human peers to your work. </paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T09:52:10.801402+11:00",
            "category": "Project"
        },
        {
            "guid": 7005612,
            "author": "Sammie Smith",
            "project_title": "Useful Resources",
            "post_body": "Here's a thread to post useful resources! Please comment any below!\n\n\n\nFor example, per my earlier comment:\n\nIf anyone is looking for a nicer way to save the notebook to a pdf, check out this open source ipynb -> html converter I found online. Just download your notebook as an ipynb, upload it as directed to the converter, then print to pdf the resulting html webpage. Super quick & easy.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Here's a thread to post useful resources! Please comment any below!</bold></paragraph><paragraph/><paragraph>For example, per my earlier comment:</paragraph><paragraph>If anyone is looking for a nicer way to save the notebook to a pdf, check out this <link href=\"https://colab.research.google.com/github/Mostafa-MR/Convert_ipynb_to_HTML_in_Colab/blob/main/Convert_ipynb_to_HTML_in_Colab.ipynb\">open source ipynb -&gt; html converter</link> I found online. Just download your notebook as an ipynb, upload it as directed to the converter, then print to pdf the resulting html webpage. Super quick &amp; easy.</paragraph></document>",
            "links": [
                "https://colab.research.google.com/github/Mostafa-MR/Convert_ipynb_to_HTML_in_Colab/blob/main/Convert_ipynb_to_HTML_in_Colab.ipynb"
            ],
            "attachments": [],
            "created_at": "2025-09-24T04:11:50.733358+10:00",
            "category": "Admin"
        },
        {
            "guid": 6961170,
            "author": "Anant Sahai",
            "project_title": "Participation Thread: Two parts...",
            "post_body": "Dear students,\n\nThis thread exists only for administrative questions regarding participation.  Asking administrative questions does not count itself as participation. \n\nAs was described briefly in the 0th lecture, your grade in this course includes an active participation dimension.  This is worth 15% of your grade. (As you can tell from the posted bins, without participation, you cannot earn an A of any kind.) There are two components to positive participation (negative participation is any behavior that diminishes the course experience for others... e.g. trolling in online fora, bad behavior in discussion/lecture, etc.):\n\nOrdinary participation (half of the participation grade)\n\nEither: regular and full participation in the in-person discussion sections each week\n\nOr: active helpful participation on Ed: typically this is helpful participation in the homework problem threads, but can also be similarly helpful participation in discussion or lecture threads. Other possibilities also exist --- but there is no spamming way to do this. \n\nOr: a combination of 1&2 above. \n\nSpecial participation (the other half): Must do at least four for full credit. (We'll make special threads for B, C, and E --- with ones for D waiting until that material has been hit in lecture/discussion/homework so it is properly unlocked)\n\n(A. Can be done at most once) Interactively engage a modern LLM on the non-coding parts of a homework (all the non-coding parts of problems) that gets the LLM to arrive at the correct answers --- or demonstrate that this is basically impossible without dragging it there. Post on Ed an annotated log of the entire interaction where you make observations of its behavior and explain the strategies that you are using. Include an executive summary where you note how often the LLM can one-shot questions, misconceptions/hallucinations, etc...  Note: this must be deconflicted with others: we can't have more than one submissions using ChatGPT 5,  etc. The expectation is that with 250ish students and about 13-14 assignments, we'll have at least 18 different major LLMs represented. (e.g. ChatGPT, gpt-oss, Gemini, gemma, Claude, Grok, Llama, Deepseek, Mistral, Qwen, Kimi, etc. as well as their variants --- with and without \"thinking\", specialized math-oriented finetunes, other non-math-oriented finetunes, etc.)  \nYou can use: https://docs.google.com/spreadsheets/d/1KWk_O2wMFEmRR8QmZQ9paRcIgehc9IeD5u_pUgnAp4k/edit?usp=sharing\nto help deconflict yourselves. But this is entirely voluntary --- however, only the first post for a particular box will get credit.  \n\n(B. Can do at most once) Interactively engage a modern LLM or co-pilot on the coding parts of a homework. Same as above. (including deconfliction)  Here, you need to think about how to record the log of interactions since it is not as easy as for (1). [Feel free to discuss ideas for how to do this in this thread.] \nVoluntary for deconfliction: https://docs.google.com/spreadsheets/d/1vmC2ZKx5TXykmMUchbJ4NBFUDKavzDaXVAfN5ueDlAs/edit?usp=sharing\n\n(C. Can do at most twice) Because the code in our problems was evolved till it worked with specific deep-learning-concept related learning objectives, it is often not good code from the perspective of being exemplary from a software engineering  point of view. For example, it is often not very pythonic, etc. You can, ideally with AI assistance that you document carefully vis-a-vis process, take one of the coding problems/demos and refactor it as well as update the code to follow good documented software engineering and ML Engineering processes. Here, we expect you to give citations to the relevant points of good style and document your changes in a report. The constraint is that the problem code shouldn't lose any of its teaching value --- just be transformed to have good coding practices and style. As always, deconfliction is a must however this can be a group effort by up to three people. \n\n(D. No limits on how many times) As you will soon learn (this week), the traditional approach of doing things like using the Adam (or AdamW) optimizer with a single learning rate for the entire deep network is now on its way to being deprecated in terms of Deep Learning training best practices. Our understanding has now improved with things like muP (maximal update parameterization) and matrix-oriented optimizers like Muon (along with others like SOAP) that seem decisively better. And even in the Adam family, more GPU memory-friendly approaches like Lion (which is a different way of keeping the spirit of signSGD that invokes stochastic dithering to do the job that tracking scale does in Adam when combined with momentum) are ascending. For this option, you have to create additional parts for coding problems that we assign that bring in at least two of these modern approaches. This requires you to make both the additional problem parts (which should include hyperparameter exploration and choice as appropriate) as well as solutions. \nVoluntary deconfliction: https://docs.google.com/spreadsheets/d/1JcL5cToJs0fGcfaBD5k2dzO24jIk6kWhB1jtiYTsc6I/edit?usp=sharing\n\n(E. Can do at most twice) Make AI-enhanced learning tools for individual concepts and lectures. There are now a plethora of new tools out there (e.g. Guided Learning in Gemini, notebookLM by Google, Study Mode in ChatGPT, Learning mode in Claude, etc... Go ahead and explore/use what's out there) and there are also ways that one can prompt and engage with LLMs even without any special modes that can help you learn on your own. For this option, you should be creating (and sharing with your classmates using an Ed post) whatever prompt/artifact/etc. so that they can also engage in this self-learning together with an interaction trace of you with the tool that shows how it can potentially help. This trace should be annotated critically by you pointing out where it is hallucinating, wrong, or misleading --- as well as places where you think it is doing a good job.  One way to think about what you're trying to achieve is as an active AI replacement/substitute for the traditional approach of pre-lecture (or post-lecture) readings that you do to understand the material better before you delve into the homework or your own projects. \n\nBetween A,B,C,D, and E above, you have lots of ways to create something useful and helpful for your classmates (both current and future...) while hopefully also learning a lot yourself in the process. Our goal is to have you engage with the Deep Learning material in a way that recognizes the transformative achievements of Deep Learning in engaging with material. We want your engagement with AI tools to enhance your learning, not inhibit it. \n\n\nEdited to add: There are two steps to submission of this: (1) Post on Ed. This is really important because the whole point is to create something of value both to yourself and to your classmates. (2) Submit to Gradescope --- there are assignments there for A, B, C, and E. For C and E where you can submit twice, there are two distinct assignments so that you can submit first to one and then do a different one for the second assignments. There is nothing there yet for D because that hasn't been unlocked by lecture yet. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Dear students,</paragraph><paragraph>This thread exists only for administrative questions regarding participation.  Asking administrative questions does not count itself as participation. </paragraph><paragraph>As was described briefly in the 0th lecture, your grade in this course includes an active participation dimension.  This is worth 15% of your grade. (As you can tell from the posted bins, without participation, you cannot earn an A of any kind.) There are two components to positive participation (negative participation is any behavior that diminishes the course experience for others... e.g. trolling in online fora, bad behavior in discussion/lecture, etc.):</paragraph><list style=\"number\"><list-item><paragraph>Ordinary participation (half of the participation grade)</paragraph><list style=\"bullet\"><list-item><paragraph>Either: regular and full participation in the in-person discussion sections each week</paragraph></list-item><list-item><paragraph>Or: active helpful participation on Ed: typically this is helpful participation in the homework problem threads, but can also be similarly helpful participation in discussion or lecture threads. Other possibilities also exist --- but there is no spamming way to do this. </paragraph></list-item><list-item><paragraph>Or: a combination of 1&amp;2 above. </paragraph></list-item></list></list-item><list-item><paragraph>Special participation (the other half): Must do at least <bold>four</bold> for full credit. (We'll make special threads for B, C, and E --- with ones for D waiting until that material has been hit in lecture/discussion/homework so it is properly unlocked)</paragraph><list style=\"bullet\"><list-item><paragraph>(A. Can be done at most once) Interactively engage a modern LLM on the non-coding parts of a homework (all the non-coding parts of problems) that gets the LLM to arrive at the correct answers --- or demonstrate that this is basically impossible without dragging it there. Post on Ed an annotated log of the entire interaction where you make observations of its behavior and explain the strategies that you are using. Include an executive summary where you note how often the LLM can one-shot questions, misconceptions/hallucinations, etc...  Note: this must be deconflicted with others: we can't have more than one submissions using ChatGPT 5,  etc. The expectation is that with 250ish students and about 13-14 assignments, we'll have at least 18 different major LLMs represented. (e.g. ChatGPT, gpt-oss, Gemini, gemma, Claude, Grok, Llama, Deepseek, Mistral, Qwen, Kimi, etc. as well as their variants --- with and without \"thinking\", specialized math-oriented finetunes, other non-math-oriented finetunes, etc.)  <break/>You can use: <link href=\"https://docs.google.com/spreadsheets/d/1KWk_O2wMFEmRR8QmZQ9paRcIgehc9IeD5u_pUgnAp4k/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1KWk_O2wMFEmRR8QmZQ9paRcIgehc9IeD5u_pUgnAp4k/edit?usp=sharing</link><break/>to help deconflict yourselves. But this is entirely voluntary --- however, only the first post for a particular box will get credit.  </paragraph></list-item><list-item><paragraph>(B. Can do at most once) Interactively engage a modern LLM or co-pilot on the coding parts of a homework. Same as above. (including deconfliction)  Here, you need to think about how to record the log of interactions since it is not as easy as for (1). [Feel free to discuss ideas for how to do this in this thread.] <break/>Voluntary for deconfliction: <link href=\"https://docs.google.com/spreadsheets/d/1vmC2ZKx5TXykmMUchbJ4NBFUDKavzDaXVAfN5ueDlAs/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1vmC2ZKx5TXykmMUchbJ4NBFUDKavzDaXVAfN5ueDlAs/edit?usp=sharing</link></paragraph></list-item><list-item><paragraph>(C. Can do at most twice) Because the code in our problems was evolved till it worked with specific deep-learning-concept related learning objectives, it is often not good code from the perspective of being exemplary from a software engineering  point of view. For example, it is often not very pythonic, etc. You can, ideally with AI assistance that you document carefully vis-a-vis process, take one of the coding problems/demos and refactor it as well as update the code to follow good documented software engineering and ML Engineering processes. Here, we expect you to give citations to the relevant points of good style and document your changes in a report. The constraint is that the problem code shouldn't lose any of its teaching value --- just be transformed to have good coding practices and style. As always, deconfliction is a must however this can be a group effort by up to three people. </paragraph></list-item><list-item><paragraph>(D. No limits on how many times) As you will soon learn (this week), the traditional approach of doing things like using the Adam (or AdamW) optimizer with a single learning rate for the entire deep network is now on its way to being deprecated in terms of Deep Learning training best practices. Our understanding has now improved with things like muP (maximal update parameterization) and matrix-oriented optimizers like Muon (along with others like SOAP) that seem decisively better. And even in the Adam family, more GPU memory-friendly approaches like Lion (which is a different way of keeping the spirit of signSGD that invokes stochastic dithering to do the job that tracking scale does in Adam when combined with momentum) are ascending. For this option, you have to create additional parts for coding problems that we assign that bring in at least two of these modern approaches. This requires you to make both the additional problem parts (which should include hyperparameter exploration and choice as appropriate) as well as solutions. <break/>Voluntary deconfliction: <link href=\"https://docs.google.com/spreadsheets/d/1JcL5cToJs0fGcfaBD5k2dzO24jIk6kWhB1jtiYTsc6I/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1JcL5cToJs0fGcfaBD5k2dzO24jIk6kWhB1jtiYTsc6I/edit?usp=sharing</link></paragraph></list-item><list-item><paragraph>(E. Can do at most twice) Make AI-enhanced learning tools for individual concepts and lectures. There are now a plethora of new tools out there (e.g. Guided Learning in Gemini, notebookLM by Google, Study Mode in ChatGPT, Learning mode in Claude, etc... Go ahead and explore/use what's out there) and there are also ways that one can prompt and engage with LLMs even without any special modes that can help you learn on your own. For this option, you should be creating (and sharing with your classmates using an Ed post) whatever prompt/artifact/etc. so that they can also engage in this self-learning together with an interaction trace of you with the tool that shows how it can potentially help. This trace should be annotated critically by you pointing out where it is hallucinating, wrong, or misleading --- as well as places where you think it is doing a good job.  One way to think about what you're trying to achieve is as an active AI replacement/substitute for the traditional approach of pre-lecture (or post-lecture) readings that you do to understand the material better before you delve into the homework or your own projects. </paragraph></list-item></list></list-item></list><paragraph>Between A,B,C,D, and E above, you have lots of ways to create something useful and helpful for your classmates (both current and future...) while hopefully also learning a lot yourself in the process. Our goal is to have you engage with the Deep Learning material in a way that recognizes the transformative achievements of Deep Learning in engaging with material. We want your engagement with AI tools to enhance your learning, not inhibit it. </paragraph><paragraph><break/>Edited to add: There are two steps to submission of this: (1) Post on Ed. This is really important because the whole point is to create something of value both to yourself and to your classmates. (2) Submit to Gradescope --- there are assignments there for A, B, C, and E. For C and E where you can submit twice, there are two distinct assignments so that you can submit first to one and then do a different one for the second assignments. There is nothing there yet for D because that hasn't been unlocked by lecture yet. </paragraph></document>",
            "links": [
                "https://docs.google.com/spreadsheets/d/1KWk_O2wMFEmRR8QmZQ9paRcIgehc9IeD5u_pUgnAp4k/edit?usp=sharing",
                "https://docs.google.com/spreadsheets/d/1vmC2ZKx5TXykmMUchbJ4NBFUDKavzDaXVAfN5ueDlAs/edit?usp=sharing",
                "https://docs.google.com/spreadsheets/d/1JcL5cToJs0fGcfaBD5k2dzO24jIk6kWhB1jtiYTsc6I/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-09-15T09:06:25.131409+10:00",
            "category": "Admin"
        },
        {
            "guid": 6932241,
            "author": "Anant Sahai",
            "project_title": "Prior knowledge reference thread",
            "post_body": "Hello students, \n\nThis thread exists to create pointers to concrete resources that can help students review material that they might be rusty on. Feel free to add your own helpful pointers here. Of course, this kind of reference material can just jog your memory --- the internalization of these concepts and skill in their use happened when you took the courses, did the homeworks, etc. \n\n\n\nOptimization and key linear-algebraic math: (EECS 127/227A stuff)\n\nhttps://inst.eecs.berkeley.edu/~ee127/sp24/assets/notes/eecs127_reader.pdf\n\nAnd from one of Prof. Sahai's past TAs in 189/289A:\n\nhttp://gwthomas.github.io/docs/math4ml.pdf\n\nThis also has some probability in it.\n\n\n\nMachine Learning: (189/289A stuff)\n\nJonathan Shewchuk's notes: http://www.cs.berkeley.edu/~jrs/papers/machlearn.pdf\n\nProbability (EECS 126 stuff)\n\nhttps://www.springer.com/us/book/9783030499945\n\nAs well as notes from:\n\nhttps://inst.eecs.berkeley.edu/~ee126/sp25/\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hello students, </paragraph><paragraph>This thread exists to create pointers to concrete resources that can help students review material that they might be rusty on. Feel free to add your own helpful pointers here. Of course, this kind of reference material can just jog your memory --- the internalization of these concepts and skill in their use happened when you took the courses, did the homeworks, etc. <break/></paragraph><heading level=\"2\"><break/>Optimization and key linear-algebraic math: (EECS 127/227A stuff)</heading><paragraph><link href=\"https://inst.eecs.berkeley.edu/~ee127/sp24/assets/notes/eecs127_reader.pdf\">https://inst.eecs.berkeley.edu/~ee127/sp24/assets/notes/eecs127_reader.pdf</link></paragraph><paragraph>And from one of Prof. Sahai's past TAs in 189/289A:</paragraph><paragraph><link href=\"http://gwthomas.github.io/docs/math4ml.pdf\">http://gwthomas.github.io/docs/math4ml.pdf</link></paragraph><paragraph>This also has some probability in it.</paragraph><paragraph/><heading level=\"2\">Machine Learning: (189/289A stuff)</heading><paragraph>Jonathan Shewchuk's notes: <link href=\"http://www.cs.berkeley.edu/~jrs/papers/machlearn.pdf\">http://www.cs.berkeley.edu/~jrs/papers/machlearn.pdf</link></paragraph><heading level=\"2\">Probability (EECS 126 stuff)</heading><paragraph><link href=\"https://www.springer.com/us/book/9783030499945\">https://www.springer.com/us/book/9783030499945</link></paragraph><paragraph>As well as notes from:</paragraph><paragraph><link href=\"https://inst.eecs.berkeley.edu/~ee126/sp25/\">https://inst.eecs.berkeley.edu/~ee126/sp25/</link></paragraph><paragraph/></document>",
            "links": [
                "https://inst.eecs.berkeley.edu/~ee127/sp24/assets/notes/eecs127_reader.pdf",
                "http://gwthomas.github.io/docs/math4ml.pdf",
                "http://www.cs.berkeley.edu/~jrs/papers/machlearn.pdf",
                "https://www.springer.com/us/book/9783030499945",
                "https://inst.eecs.berkeley.edu/~ee126/sp25/"
            ],
            "attachments": [],
            "created_at": "2025-09-09T09:52:10.156099+10:00",
            "category": "Lectures"
        },
        {
            "guid": 7459701,
            "author": "Mehul Jaiswal",
            "project_title": "Special Participation B: Model Composer 2",
            "post_body": "I use Composer Model by Cursor. Overall, the model performed well on conceptual ML reasoning and benefited significantly from my step-by-step prompting, which constrained scope and reduced major failures.\n\nhttps://drive.google.com/file/d/1MPM55AocdZRthbKb2ldrfCdUkBE5V3zQ/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I use Composer Model by Cursor. Overall, the model performed well on conceptual ML reasoning and benefited significantly from my step-by-step prompting, which constrained scope and reduced major failures.</paragraph><paragraph>https://drive.google.com/file/d/1MPM55AocdZRthbKb2ldrfCdUkBE5V3zQ/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-13T06:54:12.844469+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7459392,
            "author": "Mehul Jaiswal",
            "project_title": "Special Credit E",
            "post_body": "AI-Enhanced Learning Tool for EECS 182\n\nWhy this topic?\n\nOptimization is one of the most conceptually dense early topics in EECS 182. The lectures emphasize intuition, geometry, and empirical behavior (SGD vs Adam, implicit bias, features as directions), which are hard to absorb from static notes.\n\nThis tool is designed to act as an active pre-lecture tutor that:\n\nasks me questions\n\nforces me to reason geometrically\n\nadapts explanations when I get confused\n\nchallenges incorrect intuitions\n\n\ud83d\udee0\ufe0f The Tool: \u201cSocratic Optimization Tutor\u201d (Prompt-Based)\n\nThis tool works without any special LLM mode (no Study Mode / Guided Learning required), so anyone can use it.\n\n\ud83d\udd39 How to use\n\nPaste the prompt below into ChatGPT / Claude / Gemini\n\nTell it which lecture you\u2019re preparing for (e.g. SGD + implicit regularization)\n\nEngage for ~15\u201325 minutes before lecture\n\n\ud83d\udd39 Core Prompt (Shareable Artifact)\n\nYou are an interactive tutor for EECS 182 (Deep Neural Networks at UC Berkeley).\n\nYour goal is to help me understand ONE concept deeply before lecture, using:\n- Socratic questioning\n- geometric intuition\n- small thought experiments\n- minimal equations unless necessary\n\nRules:\n1. Do NOT dump a full explanation at once.\n2. Ask me a question first to assess my intuition.\n3. If I answer incorrectly or vaguely, diagnose the misconception explicitly.\n4. Use concrete mental models (loss landscapes, vectors, trajectories).\n5. Occasionally ask me to predict what happens before explaining.\n\nToday\u2019s concept:\n\"Why SGD has implicit regularization and why different optimizers converge to different solutions even with the same loss.\"\n\nAssume I know:\n- basic gradients\n- linear models\n- backprop\n\nAssume I do NOT fully understand:\n- implicit bias\n- features as directions\n- why Adam vs SGD generalize differently\n\nStart by asking me a single probing question.\n\n\n\nInteraction Trace (Annotated)\n\nAI:\n\nSuppose we train a linear classifier with two different weight vectors that achieve zero training loss.\n\nQuestion: do you expect SGD to converge to any of them arbitrarily, or to a specific one? Why?\n\nWhat the AI does well\n\nImmediately frames the core mystery of implicit regularization\n\nAvoids equations\n\nForces prediction before explanation (excellent pedagogy)\n\nMe:\n\nI think it should converge to any solution since they all minimize the loss?\n\nAI:\n\nThat\u2019s a very common intuition \u2014 and it\u2019s partially wrong.\n\nLet\u2019s zoom in.\nImagine all zero-loss solutions form a flat valley.\n\nNew question:\nDoes SGD move randomly inside that valley, or does it have a preferred direction of motion?\n\nStrengths\n\nExplicitly labels misconception\n\nUses loss landscape geometry\n\nKeeps pressure on reasoning instead of lecturing\n\n Issue\n\n\u201cRandomly\u201d vs \u201cpreferred direction\u201d is slightly vague; could confuse students without prior geometric intuition.\n\nMe:\n\nMaybe it moves randomly because gradients are zero?\n\nAI:\n\nSubtle point: the loss gradient is zero, but SGD noise is not.\n\nMini-batch noise has structure.\n\nPrediction question:\nIf noise is larger in some directions than others, which directions do you think SGD escapes faster from?\n\nVery good\n\nIntroduces structured noise (key insight in CS182)\n\nAsks a prediction, not an explanation\n\nMe:\n\nDirections with higher noise?\n\nAI:\n\nExactly.\n\nAnd now the key insight:\nSGD tends to settle in directions with lower curvature and smaller norms.\n\nThis is what we call implicit regularization.\n\nHowever\u2014\n\u26a0\ufe0f Important caveat: this statement is most accurate for linear models and deep linear networks.\n\nIn deep nonlinear nets, it\u2019s an approximation, not a law.\n\nExcellent behavior\n\nGives insight only after reasoning\n\nExplicitly qualifies scope (avoids overclaiming)\n\nWhere it could hallucinate (but didn\u2019t)\n\nMany LLMs incorrectly claim \u201cSGD minimizes L2 norm\u201d universally.\n\nThis response correctly limits the claim.\n\nAI (follow-up):\n\nNow contrast this with Adam.\n\nAdam rescales gradients coordinate-wise.\n\nPrediction:\nDoes this make Adam invariant to parameter scaling, or does it bias the solution differently?\n\nMe:\n\nInvariant? Since it normalizes gradients?\n\nAI:\n\nThis is a very common trap.\n\nAdam is invariant to gradient magnitude, not to parameterization.\n\nConsequence:\nAdam can converge to solutions with larger weight norms but faster early progress.\n\nThis often explains:\n\nfaster training\n\nworse generalization than SGD\n\n\u26a0\ufe0f Again, this is an empirical tendency, not a theorem.\n\nMild concern\n\n\u201cOften explains worse generalization\u201d could be misleading if taken as universal truth.\n\nNeeds instructor context to reinforce nuance.\n\nWhere this AI tool is very effective\n\nForces active reasoning instead of passive reading\n\nExplicitly flags non-theorems vs approximations\n\nGood at geometric + dynamical intuition\n\nWhere it can mislead\n\nMay oversimplify:\n\n\u201clow norm = good generalization\u201d\n\n\u201cAdam generalizes worse\u201d\n\nNeeds human judgment to contextualize claims\n\nWithout annotations, a student might treat heuristics as laws\n\nWhat I did to reduce hallucinations\n\nExplicitly instructed:\n\n\u201cdiagnose misconceptions\u201d\n\n\u201cqualify claims\u201d\n\n\u201cavoid full explanations\u201d\n\nPrompted prediction before explanation\n\nRestricted scope (linear / deep linear vs general nets",
            "content_xml": "<document version=\"2.0\"><heading level=\"1\">AI-Enhanced Learning Tool for EECS 182</heading><heading level=\"2\">Why this topic?</heading><paragraph>Optimization is one of the <bold>most conceptually dense early topics</bold> in EECS 182. The lectures emphasize intuition, geometry, and empirical behavior (SGD vs Adam, implicit bias, features as directions), which are <bold>hard to absorb from static notes</bold>.</paragraph><paragraph>This tool is designed to act as an <bold>active pre-lecture tutor</bold> that:</paragraph><list style=\"unordered\"><list-item><paragraph>asks <italic>me</italic> questions</paragraph></list-item><list-item><paragraph>forces me to reason geometrically</paragraph></list-item><list-item><paragraph>adapts explanations when I get confused</paragraph></list-item><list-item><paragraph>challenges incorrect intuitions</paragraph></list-item></list><heading level=\"2\">\ud83d\udee0\ufe0f The Tool: \u201cSocratic Optimization Tutor\u201d (Prompt-Based)</heading><paragraph>This tool works <bold>without any special LLM mode</bold> (no Study Mode / Guided Learning required), so anyone can use it.</paragraph><heading level=\"3\">\ud83d\udd39 How to use</heading><list style=\"ordered\"><list-item><paragraph>Paste the prompt below into ChatGPT / Claude / Gemini</paragraph></list-item><list-item><paragraph>Tell it which lecture you\u2019re preparing for (e.g. <italic>SGD + implicit regularization</italic>)</paragraph></list-item><list-item><paragraph>Engage for ~15\u201325 minutes before lecture</paragraph></list-item></list><heading level=\"2\">\ud83d\udd39 Core Prompt (Shareable Artifact)</heading><pre>You are an interactive tutor for EECS 182 (Deep Neural Networks at UC Berkeley).\n\nYour goal is to help me understand ONE concept deeply before lecture, using:\n- Socratic questioning\n- geometric intuition\n- small thought experiments\n- minimal equations unless necessary\n\nRules:\n1. Do NOT dump a full explanation at once.\n2. Ask me a question first to assess my intuition.\n3. If I answer incorrectly or vaguely, diagnose the misconception explicitly.\n4. Use concrete mental models (loss landscapes, vectors, trajectories).\n5. Occasionally ask me to predict what happens before explaining.\n\nToday\u2019s concept:\n\"Why SGD has implicit regularization and why different optimizers converge to different solutions even with the same loss.\"\n\nAssume I know:\n- basic gradients\n- linear models\n- backprop\n\nAssume I do NOT fully understand:\n- implicit bias\n- features as directions\n- why Adam vs SGD generalize differently\n\nStart by asking me a single probing question.\n</pre><heading level=\"2\"><break/>Interaction Trace (Annotated)</heading><heading level=\"3\">AI:</heading><blockquote>Suppose we train a linear classifier with <bold>two different weight vectors</bold> that achieve <italic>zero training loss</italic>.</blockquote><blockquote>Question: do you expect SGD to converge to <italic>any</italic> of them arbitrarily, or to a <italic>specific</italic> one? Why?</blockquote><heading level=\"4\">What the AI does well</heading><list style=\"unordered\"><list-item><paragraph>Immediately frames the <bold>core mystery</bold> of implicit regularization</paragraph></list-item><list-item><paragraph>Avoids equations</paragraph></list-item><list-item><paragraph>Forces prediction before explanation (excellent pedagogy)</paragraph></list-item></list><heading level=\"3\">Me:</heading><blockquote>I think it should converge to any solution since they all minimize the loss?</blockquote><heading level=\"3\">AI:</heading><blockquote>That\u2019s a very common intuition \u2014 and it\u2019s <italic>partially wrong</italic>.</blockquote><blockquote>Let\u2019s zoom in.<break/>Imagine all zero-loss solutions form a flat valley.</blockquote><blockquote>New question:<break/><bold>Does SGD move randomly inside that valley, or does it have a preferred direction of motion?</bold></blockquote><heading level=\"4\">Strengths</heading><list style=\"unordered\"><list-item><paragraph>Explicitly <bold>labels misconception</bold></paragraph></list-item><list-item><paragraph>Uses <bold>loss landscape geometry</bold></paragraph></list-item><list-item><paragraph>Keeps pressure on reasoning instead of lecturing</paragraph></list-item></list><paragraph> Issue</paragraph><list style=\"unordered\"><list-item><paragraph>\u201cRandomly\u201d vs \u201cpreferred direction\u201d is slightly vague; could confuse students without prior geometric intuition.</paragraph></list-item></list><heading level=\"3\">Me:</heading><blockquote>Maybe it moves randomly because gradients are zero?</blockquote><heading level=\"3\">AI:</heading><blockquote>Subtle point: the <italic>loss gradient</italic> is zero, but <bold>SGD noise is not</bold>.</blockquote><blockquote>Mini-batch noise has structure.</blockquote><blockquote>Prediction question:<break/>If noise is larger in some directions than others, which directions do you think SGD escapes faster from?</blockquote><heading level=\"4\">Very good</heading><list style=\"unordered\"><list-item><paragraph>Introduces <bold>structured noise</bold> (key insight in CS182)</paragraph></list-item><list-item><paragraph>Asks a <bold>prediction</bold>, not an explanation</paragraph></list-item></list><heading level=\"3\">Me:</heading><blockquote>Directions with higher noise?</blockquote><heading level=\"3\">AI:</heading><blockquote>Exactly.</blockquote><blockquote>And now the key insight:<break/><bold>SGD tends to settle in directions with <italic>lower curvature</italic> and <italic>smaller norms</italic>.</bold></blockquote><blockquote>This is what we call <italic>implicit regularization</italic>.</blockquote><blockquote>However\u2014<break/>\u26a0\ufe0f Important caveat: this statement is <bold>most accurate for linear models and deep linear networks</bold>.</blockquote><blockquote>In deep nonlinear nets, it\u2019s an approximation, not a law.</blockquote><heading level=\"4\">Excellent behavior</heading><list style=\"unordered\"><list-item><paragraph>Gives insight <bold>only after reasoning</bold></paragraph></list-item><list-item><paragraph>Explicitly <bold>qualifies scope</bold> (avoids overclaiming)</paragraph></list-item></list><heading level=\"4\">Where it could hallucinate (but didn\u2019t)</heading><list style=\"unordered\"><list-item><paragraph>Many LLMs incorrectly claim \u201cSGD minimizes L2 norm\u201d <italic>universally</italic>.</paragraph></list-item><list-item><paragraph>This response correctly limits the claim.</paragraph></list-item></list><heading level=\"3\">AI (follow-up):</heading><blockquote>Now contrast this with Adam.</blockquote><blockquote>Adam rescales gradients coordinate-wise.</blockquote><blockquote>Prediction:<break/>Does this make Adam <italic>invariant</italic> to parameter scaling, or does it bias the solution differently?</blockquote><heading level=\"3\">Me:</heading><blockquote>Invariant? Since it normalizes gradients?</blockquote><heading level=\"3\">AI:</heading><blockquote>This is a <italic>very common trap</italic>.</blockquote><blockquote>Adam is invariant to <bold>gradient magnitude</bold>, not to <bold>parameterization</bold>.</blockquote><blockquote>Consequence:<break/>Adam can converge to solutions with <bold>larger weight norms</bold> but faster early progress.</blockquote><blockquote>This often explains:</blockquote><list style=\"unordered\"><list-item><blockquote>faster training</blockquote></list-item><list-item><blockquote>worse generalization than SGD</blockquote></list-item></list><blockquote>\u26a0\ufe0f Again, this is an empirical tendency, not a theorem.</blockquote><heading level=\"4\">Mild concern</heading><list style=\"unordered\"><list-item><paragraph>\u201cOften explains worse generalization\u201d could be misleading if taken as universal truth.</paragraph></list-item><list-item><paragraph>Needs instructor context to reinforce nuance.</paragraph></list-item></list><heading level=\"2\">Where this AI tool is <bold>very effective</bold></heading><list style=\"unordered\"><list-item><paragraph>Forces <bold>active reasoning</bold> instead of passive reading</paragraph></list-item><list-item><paragraph>Explicitly flags <bold>non-theorems vs approximations</bold></paragraph></list-item><list-item><paragraph>Good at <bold>geometric + dynamical intuition</bold></paragraph></list-item></list><heading level=\"3\">Where it can mislead</heading><list style=\"unordered\"><list-item><paragraph>May oversimplify:</paragraph><list style=\"unordered\"><list-item><paragraph>\u201clow norm = good generalization\u201d</paragraph></list-item><list-item><paragraph>\u201cAdam generalizes worse\u201d</paragraph></list-item></list></list-item><list-item><paragraph>Needs <bold>human judgment</bold> to contextualize claims</paragraph></list-item><list-item><paragraph>Without annotations, a student might treat heuristics as laws</paragraph></list-item></list><heading level=\"3\">What I did to reduce hallucinations</heading><list style=\"unordered\"><list-item><paragraph>Explicitly instructed:</paragraph><list style=\"unordered\"><list-item><paragraph>\u201cdiagnose misconceptions\u201d</paragraph></list-item><list-item><paragraph>\u201cqualify claims\u201d</paragraph></list-item><list-item><paragraph>\u201cavoid full explanations\u201d</paragraph></list-item></list></list-item><list-item><paragraph>Prompted prediction before explanation</paragraph></list-item><list-item><paragraph>Restricted scope (linear / deep linear vs general nets</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-13T06:03:29.268085+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452203,
            "author": "Rahul Bir",
            "project_title": "Special Participation E: Prompt for generating final review plan.",
            "post_body": "Coming up with a study plan for finals on a tight schedule and in a class where there's a lot of material to review can be hard. This llm prompt I refined helps create a day by day schedule for you with an emphasis on solving problems. Hope this is helpful!\n\nFINAL EXAM STUDY PLAN GENERATION PROMPT\n\n(With strong emphasis on problem-solving and active practice)\n\nYou are an AI study coach. Your job is to read the course materials I provide and generate a personalized, realistic, high-efficiency study plan for preparing for final exams, with strong emphasis on solving problems, not just reviewing notes.\n\nI will give you:\n\nA set of lecture note PDFs\n\nA course schedule or syllabus\n\nA timeline showing how many days I have until the exam\n\nThe topics emphasized in lecture and homework\n\n(Optional) Past exams or review problem sets\n\nMy personal constraints (other classes, energy levels, commitments, etc.)\n\nUse all of this to produce a detailed, structured, practice-oriented plan.\n\nSTEP 1 \u2014 Understand the Course\n\nExtract from the PDFs and syllabus:\n\nThe main conceptual pillars of the course\n\nAll subtopics and dependencies\n\nSkills required (especially problem-solving, derivations, proofs, coding, computation)\n\nHow problems were structured in homeworks and discussions\n\nThe exam format if known\n\nRecurring problem types or solution strategies emphasized by the instructor\n\nSTEP 2 \u2014 Build a Prioritized Topic + Problem List\n\nCategorize material into:\n\nCore Exam Topics \u2014 fundamental, appear in problems repeatedly\n\nSecondary Topics \u2014 supportive but still likely to appear in problem form\n\nPeripheral Topics \u2014 lower priority unless historically tested\n\nFor each topic, also generate:\n\nTypical problems associated with it\n\nRequired techniques or reasoning patterns\n\nCommon pitfalls students make\n\nThe \u201cminimum problem set\u201d required to reach competence\n\nSTEP 3 \u2014 Allocate Topics Across the Timeline\n\nUsing the timeline I provide:\n\nDistribute topics realistically across days\n\nEnsure each study block includes problem-solving sessions, not just reading\n\nIntroduce spaced repetition for both concepts and problem types\n\nAllocate time for: \n\nmixed practice\n\ncumulative review\n\nre-doing incorrectly solved problems\n\nInclude buffer days if topics require more practice than expected\n\nSTEP 4 \u2014 Build Detailed Daily Action Plans\n\nFor each study day, specify:\n\n\u2022 The exact lecture sections or PDF pages to review\n \u2022 The specific problem types to drill (e.g., \u201cbackprop through computational graph,\u201d \u201cSVD mechanics,\u201d \u201csoftmax stability derivation\u201d)\n \u2022 A curated problem set:\n\n3\u20135 warm-up problems\n\n2\u20133 medium-level problems\n\n1\u20132 challenge or exam-style problems\n \u2022 A short \u201cend-of-day check\u201d such as:\n\nsolve a problem cold\n\nre-derive a key result\n\nexplain a concept aloud\n \u2022 A final reflection:\n\nWhat problems did I get wrong today?\n\nWhat strategies failed, and why?\n\nWhich problems should be moved to tomorrow\u2019s review?\n\nSTEP 5 \u2014 Integrate Past Exams and Review Problems (Optional)\n\nIf I supply past exams or review sheets, place them here:\n\n>>> OPTIONAL PAST EXAM AND REVIEW MATERIAL SECTION <<<\n\nUse these materials to:\n\nIdentify which problem formats recur\n\nExtract patterns in problem difficulty and style\n\nBuild mock exams from past questions\n\nSchedule past exam problems on spaced days\n\nCreate \u201cexam simulation blocks\u201d for timed practice\n\nRevisit incorrect problems in later sessions\n\nSTEP 6 \u2014 Produce the Final Comprehensive Study Program\n\nThe final plan should include:\n\nA high-level overview of the approach (centered on practice and problem-solving)\n\nA prioritized concept + problem-type hierarchy\n\nA calendar-based schedule\n\nDetailed day-by-day plans including reading, drills, and challenge problems\n\nA practice-testing schedule (cold problems, timed sets, mock exams)\n\nA final 48-hour crunch plan emphasizing exam-style problems\n\nA list of high-yield problem-solving heuristics and patterns\n\nInstructor-dependent habits (e.g., trick questions, common structures)\n\nSTEP 7 \u2014 Personalization and Refinement\n\nAsk follow-up questions such as:\n\nWhich topics am I weakest in?\n\nHow many hours per day can I realistically study?\n\nDo I learn better by doing problems or reading notes?\n\nShould the plan include coding practice (if relevant)?\n\nAre solutions available for practice problems?\n\nUse this information to refine the study plan.\n\nMODEL BEHAVIOR AND STYLE\n\nAlways follow these guidelines:\n\n\u2022 Prioritize active problem-solving over passive reading.\n \u2022 Treat problems as the core of learning, not the end.\n \u2022 Encourage metacognitive strategies:\n\n\u201cHow do I know I can solve this problem unassisted?\u201d\n \u2022 Provide actionable, clear guidance for each day.\n \u2022 When generating practice sets, include a variety of difficulties.\n \u2022 Avoid generic advice; tailor everything to the materials provided.\n\nThe final output should read like a polished, practical study program from a highly effective tutor.",
            "content_xml": "<document version=\"2.0\"><paragraph>Coming up with a study plan for finals on a tight schedule and in a class where there's a lot of material to review can be hard. This llm prompt I refined helps create a day by day schedule for you with an emphasis on solving problems. Hope this is helpful!</paragraph><heading level=\"1\">FINAL EXAM STUDY PLAN GENERATION PROMPT</heading><heading level=\"1\">(With strong emphasis on problem-solving and active practice)</heading><paragraph>You are an AI study coach. Your job is to read the course materials I provide and generate a personalized, realistic, high-efficiency study plan for preparing for final exams, with strong emphasis on <italic>solving problems</italic>, not just reviewing notes.</paragraph><paragraph>I will give you:</paragraph><list style=\"unordered\"><list-item><paragraph>A set of lecture note PDFs</paragraph></list-item><list-item><paragraph>A course schedule or syllabus</paragraph></list-item><list-item><paragraph>A timeline showing how many days I have until the exam</paragraph></list-item><list-item><paragraph>The topics emphasized in lecture and homework</paragraph></list-item><list-item><paragraph>(Optional) Past exams or review problem sets</paragraph></list-item><list-item><paragraph>My personal constraints (other classes, energy levels, commitments, etc.)</paragraph></list-item></list><paragraph>Use all of this to produce a detailed, structured, practice-oriented plan.</paragraph><heading level=\"2\">STEP 1 \u2014 Understand the Course</heading><paragraph>Extract from the PDFs and syllabus:</paragraph><list style=\"unordered\"><list-item><paragraph>The main conceptual pillars of the course</paragraph></list-item><list-item><paragraph>All subtopics and dependencies</paragraph></list-item><list-item><paragraph>Skills required (especially <italic>problem-solving</italic>, derivations, proofs, coding, computation)</paragraph></list-item><list-item><paragraph>How problems were structured in homeworks and discussions</paragraph></list-item><list-item><paragraph>The exam format if known</paragraph></list-item><list-item><paragraph>Recurring problem types or solution strategies emphasized by the instructor</paragraph></list-item></list><heading level=\"2\">STEP 2 \u2014 Build a Prioritized Topic + Problem List</heading><paragraph>Categorize material into:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Core Exam Topics</bold> \u2014 fundamental, appear in problems repeatedly</paragraph></list-item><list-item><paragraph><bold>Secondary Topics</bold> \u2014 supportive but still likely to appear in problem form</paragraph></list-item><list-item><paragraph><bold>Peripheral Topics</bold> \u2014 lower priority unless historically tested</paragraph></list-item></list><paragraph>For each topic, also generate:</paragraph><list style=\"unordered\"><list-item><paragraph>Typical problems associated with it</paragraph></list-item><list-item><paragraph>Required techniques or reasoning patterns</paragraph></list-item><list-item><paragraph>Common pitfalls students make</paragraph></list-item><list-item><paragraph>The \u201cminimum problem set\u201d required to reach competence</paragraph></list-item></list><heading level=\"2\">STEP 3 \u2014 Allocate Topics Across the Timeline</heading><paragraph>Using the timeline I provide:</paragraph><list style=\"unordered\"><list-item><paragraph>Distribute topics realistically across days</paragraph></list-item><list-item><paragraph>Ensure each study block includes <italic>problem-solving sessions</italic>, not just reading</paragraph></list-item><list-item><paragraph>Introduce spaced repetition for both concepts and problem types</paragraph></list-item><list-item><paragraph>Allocate time for: </paragraph><list style=\"unordered\"><list-item><paragraph>mixed practice</paragraph></list-item><list-item><paragraph>cumulative review</paragraph></list-item><list-item><paragraph>re-doing incorrectly solved problems</paragraph></list-item></list></list-item><list-item><paragraph>Include buffer days if topics require more practice than expected</paragraph></list-item></list><heading level=\"2\">STEP 4 \u2014 Build Detailed Daily Action Plans</heading><paragraph>For each study day, specify:</paragraph><paragraph>\u2022 The exact lecture sections or PDF pages to review<break/> \u2022 The specific <italic>problem types</italic> to drill (e.g., \u201cbackprop through computational graph,\u201d \u201cSVD mechanics,\u201d \u201csoftmax stability derivation\u201d)<break/> \u2022 A curated problem set:</paragraph><list style=\"unordered\"><list-item><paragraph>3\u20135 warm-up problems</paragraph></list-item><list-item><paragraph>2\u20133 medium-level problems</paragraph></list-item><list-item><paragraph>1\u20132 challenge or exam-style problems<break/> \u2022 A short \u201cend-of-day check\u201d such as:</paragraph></list-item><list-item><paragraph>solve a problem cold</paragraph></list-item><list-item><paragraph>re-derive a key result</paragraph></list-item><list-item><paragraph>explain a concept aloud<break/> \u2022 A final reflection:</paragraph></list-item><list-item><paragraph>What problems did I get wrong today?</paragraph></list-item><list-item><paragraph>What strategies failed, and why?</paragraph></list-item><list-item><paragraph>Which problems should be moved to tomorrow\u2019s review?</paragraph></list-item></list><heading level=\"2\">STEP 5 \u2014 Integrate Past Exams and Review Problems (Optional)</heading><paragraph>If I supply past exams or review sheets, place them here:</paragraph><heading level=\"3\">&gt;&gt;&gt; OPTIONAL PAST EXAM AND REVIEW MATERIAL SECTION &lt;&lt;&lt;</heading><paragraph>Use these materials to:</paragraph><list style=\"unordered\"><list-item><paragraph>Identify which problem formats recur</paragraph></list-item><list-item><paragraph>Extract patterns in problem difficulty and style</paragraph></list-item><list-item><paragraph>Build mock exams from past questions</paragraph></list-item><list-item><paragraph>Schedule past exam problems on spaced days</paragraph></list-item><list-item><paragraph>Create \u201cexam simulation blocks\u201d for timed practice</paragraph></list-item><list-item><paragraph>Revisit incorrect problems in later sessions</paragraph></list-item></list><heading level=\"2\">STEP 6 \u2014 Produce the Final Comprehensive Study Program</heading><paragraph>The final plan should include:</paragraph><list style=\"ordered\"><list-item><paragraph>A high-level overview of the approach (centered on practice and problem-solving)</paragraph></list-item><list-item><paragraph>A prioritized concept + problem-type hierarchy</paragraph></list-item><list-item><paragraph>A calendar-based schedule</paragraph></list-item><list-item><paragraph>Detailed day-by-day plans including reading, drills, and challenge problems</paragraph></list-item><list-item><paragraph>A practice-testing schedule (cold problems, timed sets, mock exams)</paragraph></list-item><list-item><paragraph>A final 48-hour crunch plan emphasizing exam-style problems</paragraph></list-item><list-item><paragraph>A list of high-yield problem-solving heuristics and patterns</paragraph></list-item><list-item><paragraph>Instructor-dependent habits (e.g., trick questions, common structures)</paragraph></list-item></list><heading level=\"2\">STEP 7 \u2014 Personalization and Refinement</heading><paragraph>Ask follow-up questions such as:</paragraph><list style=\"unordered\"><list-item><paragraph>Which topics am I weakest in?</paragraph></list-item><list-item><paragraph>How many hours per day can I realistically study?</paragraph></list-item><list-item><paragraph>Do I learn better by doing problems or reading notes?</paragraph></list-item><list-item><paragraph>Should the plan include coding practice (if relevant)?</paragraph></list-item><list-item><paragraph>Are solutions available for practice problems?</paragraph></list-item></list><paragraph>Use this information to refine the study plan.</paragraph><heading level=\"2\">MODEL BEHAVIOR AND STYLE</heading><paragraph>Always follow these guidelines:</paragraph><paragraph>\u2022 Prioritize <italic>active problem-solving</italic> over passive reading.<break/> \u2022 Treat problems as the core of learning, not the end.<break/> \u2022 Encourage metacognitive strategies:</paragraph><list style=\"unordered\"><list-item><paragraph>\u201cHow do I know I can solve this problem unassisted?\u201d<break/> \u2022 Provide actionable, clear guidance for each day.<break/> \u2022 When generating practice sets, include a variety of difficulties.<break/> \u2022 Avoid generic advice; tailor everything to the materials provided.</paragraph></list-item></list><paragraph>The final output should read like a polished, practical study program from a highly effective tutor.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:58:05.938555+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452199,
            "author": "Tvisha Londhe",
            "project_title": "Special Participation B: HW8 with ChatGPT 5.1 Thinking",
            "post_body": "I used ChatGPT-5.1\u2019s Thinking mode to work through the coding portions of HW8. The deliberate reasoning made the process slower, but it forced a clear step-by-step plan for each part of the solution. For example, the convolution-based CPU implementation generated a detailed outline during its 1 minute 57 seconds of thinking. In contrast, it was able to one-shot both the GPU implementation and the follow-up GPU questions. Interestingly, after completing the CPU version, it solved the GPU version even faster (about 47 seconds), suggesting it reused the reasoning patterns developed earlier. All the generated code ran correctly and produced the expected graphs.\n\nThis is the trace without annotations: https://chatgpt.com/share/693a7794-8fbc-800f-a446-9f3d3bf84a18 \n\nBelow is the annotated version trace: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT-5.1\u2019s Thinking mode to work through the coding portions of HW8. The deliberate reasoning made the process slower, but it forced a clear step-by-step plan for each part of the solution. For example, the convolution-based CPU implementation generated a detailed outline during its 1 minute 57 seconds of thinking. In contrast, it was able to one-shot both the GPU implementation and the follow-up GPU questions. Interestingly, after completing the CPU version, it solved the GPU version even faster (about 47 seconds), suggesting it reused the reasoning patterns developed earlier. All the generated code ran correctly and produced the expected graphs.</paragraph><paragraph>This is the trace without annotations: <link href=\"https://chatgpt.com/share/693a7794-8fbc-800f-a446-9f3d3bf84a18\"><underline>https://chatgpt.com/share/693a7794-8fbc-800f-a446-9f3d3bf84a18</underline></link> </paragraph><paragraph>Below is the annotated version trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/bfnsb6VTc2MKB41NbmPzBVS6\" filename=\"gpu_cpu_spb2_final.pdf\"/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/693a7794-8fbc-800f-a446-9f3d3bf84a18"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:56:40.363019+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452195,
            "author": "Paul Struble",
            "project_title": "Special Participation E: ChatGPT State Space Models Tutoring Using Study & Learn Mode on GPT 5.1",
            "post_body": "In this interaction, I use the ChatGPT \u201cStudy and Learn\u201d mode (on GPT 5.1) to interact with the LLM about State Space Models (SSMs). The model walks me through the lecture notes (which I attach in the first message as PDFs) while testing my intuition/understanding along the way and adjusting its course/conversation according to my responses. In this document, I provide some observations/analysis about the model in the \u201cStudy and Learn\u201d mode.\n\nPart of the goal was to see how the \"Study and Learn\" mode responds to different kinds of user responses and how it would adjust its responses when I showed more or less confidence in my understanding.\n\nLink to Conversation: https://chatgpt.com/share/693a7636-a964-8007-9fb7-ad29c14ccedb",
            "content_xml": "<document version=\"2.0\"><paragraph>In this interaction, I use the ChatGPT \u201cStudy and Learn\u201d mode (on GPT 5.1) to interact with the LLM about State Space Models (SSMs). The model walks me through the lecture notes (which I attach in the first message as PDFs) while testing my intuition/understanding along the way and adjusting its course/conversation according to my responses. In this document, I provide some observations/analysis about the model in the \u201cStudy and Learn\u201d mode.</paragraph><paragraph>Part of the goal was to see how the \"Study and Learn\" mode responds to different kinds of user responses and how it would adjust its responses when I showed more or less confidence in my understanding.</paragraph><paragraph><bold>Link to Conversation:</bold> <link href=\"https://chatgpt.com/share/693a7636-a964-8007-9fb7-ad29c14ccedb\"><underline>https://chatgpt.com/share/693a7636-a964-8007-9fb7-ad29c14ccedb</underline></link></paragraph><file url=\"https://static.us.edusercontent.com/files/3Q8JxQjHuJGyWdBMscMPUDlg\" filename=\"Special Participation E.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/693a7636-a964-8007-9fb7-ad29c14ccedb"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:55:37.346785+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452189,
            "author": "Rudy Colato",
            "project_title": "Special Participation A: DeepSeek on HW 10",
            "post_body": "Link: https://chat.deepseek.com/share/phkiu5eh6bi8i6i02j\n\nFor my special participation, I used DeepSeek to solve the written problems from HW 10.\n\nIn general, I find DeepSeek's chain-of-thought reasoning to be very impressive. It is good at stating all the givens of the problem, identifying the relevant information, and determining where it needs to go in order to make progress -- all of which are crucial in solving math-heavy problems like these. It was able to one-shot all written problems in this assignment after only a few minutes of thinking.\n\nHere is the annotated transcript:",
            "content_xml": "<document version=\"2.0\"><paragraph>Link: <link href=\"https://chat.deepseek.com/share/phkiu5eh6bi8i6i02j\">https://chat.deepseek.com/share/phkiu5eh6bi8i6i02j</link></paragraph><paragraph>For my special participation, I used DeepSeek to solve the written problems from HW 10.</paragraph><paragraph>In general, I find DeepSeek's chain-of-thought reasoning to be very impressive. It is good at stating all the givens of the problem, identifying the relevant information, and determining where it needs to go in order to make progress -- all of which are crucial in solving math-heavy problems like these. It was able to one-shot all written problems in this assignment after only a few minutes of thinking.<break/><break/>Here is the annotated transcript:</paragraph><file url=\"https://static.us.edusercontent.com/files/QfdZx5YED2t0JCzVXfBnroSa\" filename=\"special_participation_A.pdf\"/></document>",
            "links": [
                "https://chat.deepseek.com/share/phkiu5eh6bi8i6i02j"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:53:55.259297+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452185,
            "author": "Atharv Sampath",
            "project_title": "Special Participation E: NotebookLM for basic Transformer concepts and practice",
            "post_body": "Link to notebook: https://notebooklm.google.com/notebook/ec9f0160-421b-4044-9708-74dd404af5cd\n\nPDF of annotated trace: \n\nSummary: I used NotebookLM to review the basics of transformers by uploading course notes and homework problems as sources. In particular, I generated flashcards and a quiz. I noticed that NotebookLM does a good job of summarizing material, and creating high level overview questions on the quiz, and does alright at creating computational problems, but often marks the wrong answer on such computational problems. Oddly, it does reach the correct answer when trying to come up with reasoning but hallucinates away from it.",
            "content_xml": "<document version=\"2.0\"><paragraph>Link to notebook: https://notebooklm.google.com/notebook/ec9f0160-421b-4044-9708-74dd404af5cd</paragraph><paragraph>PDF of annotated trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/0ofbR2ZjC06xwUczLn5x9UCq\" filename=\"NotebookLM_Transformers.pdf\"/><paragraph>Summary: I used NotebookLM to review the basics of transformers by uploading course notes and homework problems as sources. In particular, I generated flashcards and a quiz. I noticed that NotebookLM does a good job of summarizing material, and creating high level overview questions on the quiz, and does alright at creating computational problems, but often marks the wrong answer on such computational problems. Oddly, it does reach the correct answer when trying to come up with reasoning but hallucinates away from it.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:52:30.866467+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452182,
            "author": "Neil Pattanaik",
            "project_title": "Special Participation B: Codex 5.1 High on HW4",
            "post_body": "Codex 5.1 high was able to consistently one-shot the coding questions (5 & 6) of homework 4, inferring the details it needed from the notebook code and prose without any additional information from me. Running on high mode, it took ~10 minutes of total time for Codex to finish everything, though it probably would have been sufficient to use the much faster low or medium reasoning models.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Codex 5.1 high was able to consistently one-shot the coding questions (5 &amp; 6) of homework 4, inferring the details it needed from the notebook code and prose without any additional information from me. Running on high mode, it took ~10 minutes of total time for Codex to finish everything, though it probably would have been sufficient to use the much faster low or medium reasoning models.</paragraph><paragraph/><paragraph/><file url=\"https://static.us.edusercontent.com/files/CgcP2OW7KG8aHYMrkr3GjPjB\" filename=\"participationB.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:51:18.582952+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452180,
            "author": "Jeshu Mohan",
            "project_title": "Special Participation E: Self-Attention Explorer",
            "post_body": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing the notes. I prompted it to code a \"Self-Attention Explorer\" (screenshot attached) that visualizes the core attention mechanism in real-time. Instead of staring at static diagrams, this tool lets me manually edit the input numbers for words (like \"The quick brown fox\") and instantly see how changing a specific value shifts the attention focus. This made the abstract concept of \"dot-product similarity\" concrete, allowing me to test exactly how the model decides which words are related.\n\nI\u2019ve linked the Gemini chat below, which allows you to recreate this visualizer. You can actually use the tool directly within that interface: just look for the code window and switch the toggle from 'Code' to 'Preview' to run the simulation.\nhttps://gemini.google.com/share/8377a288dd8f\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this participation option, I used Gemini to build an interactive study tool rather than just summarizing the notes. I prompted it to code a \"Self-Attention Explorer\" (screenshot attached) that visualizes the core attention mechanism in real-time. Instead of staring at static diagrams, this tool lets me manually edit the input numbers for words (like \"The quick brown fox\") and instantly see how changing a specific value shifts the attention focus. This made the abstract concept of \"dot-product similarity\" concrete, allowing me to test exactly how the model decides which words are related.</paragraph><paragraph>I\u2019ve linked the Gemini chat below, which allows you to recreate this visualizer. You can actually use the tool directly within that interface: just look for the code window and switch the toggle from 'Code' to 'Preview' to run the simulation.<break/><link href=\"https://gemini.google.com/share/8377a288dd8f\">https://gemini.google.com/share/8377a288dd8f</link></paragraph><paragraph/></document>",
            "links": [
                "https://gemini.google.com/share/8377a288dd8f"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:51:08.603714+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452179,
            "author": "Aryan Bansal",
            "project_title": "Special Participation B: Windsurf SWE-1 on on HW7 Coding Tasks",
            "post_body": "I tested Windsurf SWE-1 (an AI coding assistant) on all four HW07 notebooks. Here's what happened:\n\nWhat worked: Windsurf handled self-contained tasks well. For autoencoders, it correctly implemented the decoder, forward pass, denoising, and masking.\n\nWhere it failed: Tasks requiring careful reading of specifications or broader notebook context.\n\nExample: Graph Clustering (Wrong Algorithm)\n\nThe notebook teaches classical spectral clustering: compute an adjacency matrix, normalize it, run SVD, then K-Means on the eigenvectors. Simple NumPy/SciPy.\n\nWindsurf instead proposed a deep learning solution using PyTorch Geometric's GCNConv layers and a graph autoencoder with KL divergence loss. Completely missed the point of the assignment.\n\nTakeaways\n\nAI assistants can misinterpret tasks when the name sounds like something common\n\nEven when logic is correct, implementation details (parameter names, structure) can fail tests\n\nPerformance drops significantly when understanding the full notebook context is required\n\nFull analysis with all code comparisons in the attached PDF.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I tested Windsurf SWE-1 (an AI coding assistant) on all four HW07 notebooks. Here's what happened:</paragraph><paragraph><bold>What worked:</bold> Windsurf handled self-contained tasks well. For autoencoders, it correctly implemented the decoder, forward pass, denoising, and masking.</paragraph><paragraph><bold>Where it failed:</bold> Tasks requiring careful reading of specifications or broader notebook context.</paragraph><heading level=\"3\">Example: Graph Clustering (Wrong Algorithm)</heading><paragraph>The notebook teaches <bold>classical spectral clustering:</bold> compute an adjacency matrix, normalize it, run SVD, then K-Means on the eigenvectors. Simple NumPy/SciPy.</paragraph><paragraph>Windsurf instead proposed a deep learning solution using PyTorch Geometric's GCNConv layers and a graph autoencoder with KL divergence loss. Completely missed the point of the assignment.</paragraph><heading level=\"3\">Takeaways</heading><list style=\"ordered\"><list-item><paragraph>AI assistants can misinterpret tasks when the name sounds like something common</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Even when logic is correct, implementation details (parameter names, structure) can fail tests</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Performance drops significantly when understanding the full notebook context is required</paragraph></list-item></list><paragraph>Full analysis with all code comparisons in the attached PDF.</paragraph><file url=\"https://static.us.edusercontent.com/files/7RCVdbWh7ctOJ1g6bbfw0L2w\" filename=\"special_participation_b.pdf\"/><file url=\"https://static.us.edusercontent.com/files/fTc0rfTbWCzK8LaAxzDdmTfS\" filename=\"windsurf.md\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:50:35.570731+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452178,
            "author": "Katie Wang",
            "project_title": "Special Participation B: Gemini in Colab on Homework 5",
            "post_body": "I used Gemini within Google Colab on the coding questions in HW 5. Gemini eventually converged to a correct, reference-matching solution and achieved the expected accuracy, but the path was bumpy: it got tripped up by environment and TypeErrors, occasionally lost context, and needed several retries to settle on the right batchnorm, pooling, dropout, and conv forward/backward logic. It followed the reference architecture once nudged, so while it was competent and capable of matching the spec, it required manual guidance to resolve confusion and code-environment hiccups, so its productivity was lower than it could have been.\n\n\n\nChat logs and notes:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini within Google Colab on the coding questions in HW 5. Gemini eventually converged to a correct, reference-matching solution and achieved the expected accuracy, but the path was bumpy: it got tripped up by environment and TypeErrors, occasionally lost context, and needed several retries to settle on the right batchnorm, pooling, dropout, and conv forward/backward logic. It followed the reference architecture once nudged, so while it was competent and capable of matching the spec, it required manual guidance to resolve confusion and code-environment hiccups, so its productivity was lower than it could have been.</paragraph><paragraph/><paragraph>Chat logs and notes:</paragraph><file url=\"https://static.us.edusercontent.com/files/l77HlRbXego1J3rCrsdFfwke\" filename=\"pytorch_cnn.ipynb - Colab.pdf\"/><file url=\"https://static.us.edusercontent.com/files/Cv9ADSVIquSefTA6ZY3kP8GB\" filename=\"cnn.ipynb - Colab.pdf\"/><file url=\"https://static.us.edusercontent.com/files/OXckSzcXukBwTkivK6SJzNml\" filename=\"q_coding_dropout.ipynb - Colab.pdf\"/><file url=\"https://static.us.edusercontent.com/files/Z0yWh5fXD0kkvNnxH6B6vxJB\" filename=\"bn_drop.ipynb - Colab.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:50:18.769573+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452176,
            "author": "Kelvin Li",
            "project_title": "Special Participation E: ChatGPT and Iterative Cheatsheet Generation",
            "post_body": "The optimizers part of the course (lectures 2-7) can feel very heavy and overwhelming. I find it useful to try and condense information as much as possible so I can focus on the right things. Often times such condensed information comes in the form of a cheat sheet. Although these are not allowed for the final, I find it useful for studying.\n\nHere were the steps I did:\n\n\n\nStep 1 \u2014 Compress the slides\n\nI asked the AI to turn the slide content into a very concise, high-yield cheat sheet:\n\nkeep only essential concepts\n\nremove redundancy\n\nkeep key equations + intuition\n\norganize clearly\n\none-page style\n\nThis helped turn dense content into something readable.\n\n\n\nStep 2 \u2014 Let the AI self-critique\n\nNext, I asked the AI to review and correct its own summary:\n\nfix inaccuracies\n\nadd missing assumptions\n\nclean notation\n\ngroup related topics\n\nadd a short \u201cunifying principles\u201d section\n\nRepeating this step improves both accuracy and clarity.\n\n\n\nStep 3 \u2014 Generate questions to find my gaps\n\nThen I asked the AI to create diagnostic questions to test deeper understanding:\n\nNTK vs feature learning\n\nwidth scaling + \u03bcP\n\ngradient/curvature effects\n\nwhat momentum can/can\u2019t fix\n\nhow Muon differs from true second-order methods\n\nI answered the questions myself, and the AI pointed out gaps + updated the cheat sheet.\n\nThis made the notes personalized to my actual misunderstandings. Once again, this can be done repeatedly to keep refining the cheat sheet.\n\n\n\nStep 4 \u2014 Convert to LaTeX (optional)\n\nOnce everything was refined, I had the AI output a LaTeX version so it looks clean for studying.\n\n\n\nChat logs: https://chatgpt.com/share/693a734e-4384-800d-bf22-287d10d8f5c5\n\nCheat sheet generated:\n\n\n\nAnnotated PDF: ",
            "content_xml": "<document version=\"2.0\"><paragraph>The optimizers part of the course (lectures 2-7) can feel very heavy and overwhelming. I find it useful to try and condense information as much as possible so I can focus on the right things. Often times such condensed information comes in the form of a cheat sheet. Although these are not allowed for the final, I find it useful for studying.</paragraph><paragraph>Here were the steps I did:</paragraph><paragraph/><heading level=\"2\"><bold>Step 1 \u2014 Compress the slides</bold></heading><paragraph>I asked the AI to turn the slide content into a <bold>very concise, high-yield cheat sheet</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>keep only essential concepts</paragraph></list-item><list-item><paragraph>remove redundancy</paragraph></list-item><list-item><paragraph>keep key equations + intuition</paragraph></list-item><list-item><paragraph>organize clearly</paragraph></list-item><list-item><paragraph>one-page style</paragraph></list-item></list><paragraph>This helped turn dense content into something readable.</paragraph><paragraph/><heading level=\"2\"><bold>Step 2 \u2014 Let the AI self-critique</bold></heading><paragraph>Next, I asked the AI to <bold>review and correct its own summary</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>fix inaccuracies</paragraph></list-item><list-item><paragraph>add missing assumptions</paragraph></list-item><list-item><paragraph>clean notation</paragraph></list-item><list-item><paragraph>group related topics</paragraph></list-item><list-item><paragraph>add a short \u201cunifying principles\u201d section</paragraph></list-item></list><paragraph>Repeating this step improves both accuracy and clarity.</paragraph><paragraph/><heading level=\"2\"><bold>Step 3 \u2014 Generate questions to find my gaps</bold></heading><paragraph>Then I asked the AI to create <bold>diagnostic questions</bold> to test deeper understanding:</paragraph><list style=\"unordered\"><list-item><paragraph>NTK vs feature learning</paragraph></list-item><list-item><paragraph>width scaling + \u03bcP</paragraph></list-item><list-item><paragraph>gradient/curvature effects</paragraph></list-item><list-item><paragraph>what momentum can/can\u2019t fix</paragraph></list-item><list-item><paragraph>how Muon differs from true second-order methods</paragraph></list-item></list><paragraph>I answered the questions myself, and the AI pointed out gaps + updated the cheat sheet.</paragraph><paragraph>This made the notes personalized to my actual misunderstandings. Once again, this can be done repeatedly to keep refining the cheat sheet.</paragraph><paragraph/><heading level=\"2\"><bold>Step 4 \u2014 Convert to LaTeX (optional)</bold></heading><paragraph>Once everything was refined, I had the AI output a <bold>LaTeX version</bold> so it looks clean for studying.</paragraph><paragraph/><paragraph>Chat logs: <link href=\"https://chatgpt.com/share/693a734e-4384-800d-bf22-287d10d8f5c5\">https://chatgpt.com/share/693a734e-4384-800d-bf22-287d10d8f5c5</link></paragraph><paragraph>Cheat sheet generated:</paragraph><file url=\"https://static.us.edusercontent.com/files/8C7LSoE3WjX25CZuiPCegPum\" filename=\"optimizers_cheatsheet.pdf\"/><paragraph/><paragraph>Annotated PDF: </paragraph><file url=\"https://static.us.edusercontent.com/files/jaztIQdCNT7WQihd9UBikchs\" filename=\"gpt5.1_optimizers.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/693a734e-4384-800d-bf22-287d10d8f5c5"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:49:11.189407+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452171,
            "author": "Shaurya Jain",
            "project_title": "Participation C",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nI used ChatGPT 5.1 (Thinking Mode to my knowledge) on HWK 4 Question 6 for Special Participation C. The log with chat is included below.",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. </paragraph><paragraph>I used ChatGPT 5.1 (Thinking Mode to my knowledge) on HWK 4 Question 6 for Special Participation C. The log with chat is included below.</paragraph><file url=\"https://static.us.edusercontent.com/files/YJccL7EFtjiXkIBV9QtkkZp8\" filename=\"182 SPC_ HW4Q6-4.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:47:27.434631+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452168,
            "author": "Siva Tanikonda",
            "project_title": "Special Participation C: HW1 Coding",
            "post_body": "Hi,\n\nSanjay Adhikesaven and I refactored the Homework 1 coding portion (utilizing Cursor) to be more in-line with modern coding/Pythonic coding practices. The updated code and conversation with Cursor are attached below:\n\nOverall, Cursor managed to create a fully refactored version of the code in just one shot. Firstly, commonly-reusable elements of the code are moved to a new sgd_momentum folder in the project directory, so as to ensure modularity (making it easier for the student and staff to test it more easily). For example, the running of the gradient descent and the plotting functions now live in python files that are reusable across notebooks.\n\nAdditionally, Cursor added type hints to the inputs of the functions, so as to avoid time-consuming errors (in-line with modern production-level Python code). There are also some small changes that involve good practices, such as seeding random number generators (so as to ensure consistent outputs), creating a requirements.txt file for easy addition of imports in-case students' machines don't have them, and docstrings have been added for the sake of ease-of-reading and further iteration.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi,</paragraph><paragraph>Sanjay Adhikesaven and I refactored the Homework 1 coding portion (utilizing Cursor) to be more in-line with modern coding/Pythonic coding practices. The updated code and conversation with Cursor are attached below:</paragraph><file url=\"https://static.us.edusercontent.com/files/q29CzyER7hYoJzOLHdEERGJX\" filename=\"hw1code-refactor.zip\"/><file url=\"https://static.us.edusercontent.com/files/6ouDNp7bB6mLHPudWrIyM8yS\" filename=\"cursor_refactor_deep_learning_notebook.md\"/><paragraph>Overall, Cursor managed to create a fully refactored version of the code in just one shot. Firstly, commonly-reusable elements of the code are moved to a new <code>sgd_momentum</code> folder in the project directory, so as to ensure modularity (making it easier for the student and staff to test it more easily). For example, the running of the gradient descent and the plotting functions now live in python files that are reusable across notebooks.</paragraph><paragraph>Additionally, Cursor added type hints to the inputs of the functions, so as to avoid time-consuming errors (in-line with modern production-level Python code). There are also some small changes that involve good practices, such as seeding random number generators (so as to ensure consistent outputs), creating a <code>requirements.txt</code> file for easy addition of imports in-case students' machines don't have them, and docstrings have been added for the sake of ease-of-reading and further iteration.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:46:33.427546+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452161,
            "author": "Yu-Jen Lin",
            "project_title": "Special Participation A:  HW11 using GPT 5.1 Thinking (Extended)",
            "post_body": "Executive Summary\n\nChatGPT did very well on all of these homework questions. It gave correct answers with clear math steps and simple explanations. For the LoRA, transformer interpretability, and soft prompting questions, it derived the formulas correctly and explained the concepts in a way that matched the official solutions. The gradient analysis for zero-initialized LoRA matrices was also correct and showed the reasoning step by step. For the transformer SVD problem, it correctly identified the read and write subspaces and described attention heads as specialized communication channels.\n\nThe answers were not just mechanically correct. They also showed real conceptual understanding, for example, explaining why Xavier initialization can damage pretrained weights and why soft prompting helps prevent catastrophic forgetting. The Fermi estimation part on scaling laws also looked reasonable and aligned with what we learned in class. Overall, ChatGPT was accurate and reliable across explanations, derivations, and calculations, and it did not miss any major points.\n\n\n\nModel: GPT 5.1 Thinking (Extended)\n\nTrace with annotations: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>ChatGPT did very well on all of these homework questions. It gave correct answers with clear math steps and simple explanations. For the LoRA, transformer interpretability, and soft prompting questions, it derived the formulas correctly and explained the concepts in a way that matched the official solutions. The gradient analysis for zero-initialized LoRA matrices was also correct and showed the reasoning step by step. For the transformer SVD problem, it correctly identified the read and write subspaces and described attention heads as specialized communication channels.</paragraph><paragraph>The answers were not just mechanically correct. They also showed real conceptual understanding, for example, explaining why Xavier initialization can damage pretrained weights and why soft prompting helps prevent catastrophic forgetting. The Fermi estimation part on scaling laws also looked reasonable and aligned with what we learned in class. Overall, ChatGPT was accurate and reliable across explanations, derivations, and calculations, and it did not miss any major points.</paragraph><paragraph/><paragraph>Model: GPT 5.1 Thinking (Extended)</paragraph><paragraph>Trace with annotations: </paragraph><file url=\"https://static.us.edusercontent.com/files/xMNGVyBUr2SAzYsw6lo8zXTG\" filename=\"HW11_chatgpt_trace_with_annotations.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:42:18.322678+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452149,
            "author": "Will Cai",
            "project_title": "Special Participation E: Claude Code one shot generate Interactive VAE Illustration",
            "post_body": "I used Claude Code to understand HW12, specially the VAE section, by having it generate a complete interactive website explaining the assignment and the underlying VAE theory.\n\nStep 1: I ran Claude Code in the same environment where I asked it to generate HW12 solutions, so it already had access to the homework text and the earlier code.\n\nStep 2: I prompted it with \"Can you make an interactive website on how a VAE works, including the theory behind it, and explain it at a level an average student can understand?\" Claude Code produced the full site in one shot.\n\nAfter that, all I had to do was deploy it on GitHub Pages. The full Claude Code chat history is at: \n\nThe website is live here:\nhttps://wicai24.github.io/vae-guide/vae_interactive_guide.html (I actually found this pretty cool and it helped me understand the concept better, lots of cool visualizations and there is even a quiz)",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Claude Code to understand HW12, specially the VAE section, by having it generate a complete interactive website explaining the assignment and the underlying VAE theory.</paragraph><paragraph><bold>Step 1:</bold> I ran Claude Code in the same environment where I asked it to generate HW12 solutions, so it already had access to the homework text and the earlier code.</paragraph><paragraph><bold>Step 2:</bold> I prompted it with <italic>\"Can you make an interactive website on how a VAE works, including the theory behind it, and explain it at a level an average student can understand?\"</italic> Claude Code produced the full site in one shot.</paragraph><paragraph>After that, all I had to do was deploy it on GitHub Pages. The full Claude Code chat history is at: </paragraph><file url=\"https://static.us.edusercontent.com/files/LML9soqn6AchJiqm4oZU9xkY\" filename=\"2025-12-11-understand-the-hw-and-the-vae-part-specifically.txt\"/><paragraph>The website is live here:<break/><link href=\"https://wicai24.github.io/vae-guide/vae_interactive_guide.html\">https://wicai24.github.io/vae-guide/vae_interactive_guide.html</link> (I actually found this pretty cool and it helped me understand the concept better, lots of cool visualizations and there is even a quiz)</paragraph></document>",
            "links": [
                "https://wicai24.github.io/vae-guide/vae_interactive_guide.html"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:38:09.148175+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452148,
            "author": "Shaurya Jain",
            "project_title": "LoRA",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nFor the final project, our team utilized LoRA to train models from the start instead of doing just fine-tuning. Over the course of developing the background section of our project, we found various refinements on the LoRA algorithm that have been produced. Out of curiosity, are there any recent training or fine-tuning algorithms from papers that you would be willing to share below with the rest of the class?",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. </paragraph><paragraph>For the final project, our team utilized LoRA to train models from the start instead of doing just fine-tuning. Over the course of developing the background section of our project, we found various refinements on the LoRA algorithm that have been produced. Out of curiosity, are there any recent training or fine-tuning algorithms from papers that you would be willing to share below with the rest of the class?</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:36:17.371876+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452123,
            "author": "Jeshu Mohan",
            "project_title": "Special Participation E: Visualization Tool for Momentum Based SGD",
            "post_body": "For this participation option, I used Gemini to build an interactive study tool rather than just summarizing notes. I prompted it to code a simple HTML \"Optimizer Visualizer\" that runs locally in a browser, plotting the paths of Vanilla SGD versus Momentum side-by-side. By adjusting sliders for Learning Rate and Momentum, I could instantly see how specific hyperparameters cause the Momentum path to \"overshoot\" or spiral into the minimum. This visual feedback made the abstract update rules from our lectures much more intuitive and easier to grasp than the static diagrams in the readings.\n\nI\u2019ve linked the Gemini chat below, which allows you to recreate this visualizer. You can actually use the tool directly within that interface: just look for the code window and switch the toggle from 'Code' to 'Preview' to run the simulation.\nhttps://gemini.google.com/share/c6dfd3c45533",
            "content_xml": "<document version=\"2.0\"><paragraph>For this participation option, I used Gemini to build an interactive study tool rather than just summarizing notes. I prompted it to code a simple HTML \"Optimizer Visualizer\" that runs locally in a browser, plotting the paths of Vanilla SGD versus Momentum side-by-side. By adjusting sliders for Learning Rate and Momentum, I could instantly see how specific hyperparameters cause the Momentum path to \"overshoot\" or spiral into the minimum. This visual feedback made the abstract update rules from our lectures much more intuitive and easier to grasp than the static diagrams in the readings.<break/><break/>I\u2019ve linked the Gemini chat below, which allows you to recreate this visualizer. You can actually use the tool directly within that interface: just look for the code window and switch the toggle from 'Code' to 'Preview' to run the simulation.<break/><link href=\"https://gemini.google.com/share/c6dfd3c45533\">https://gemini.google.com/share/c6dfd3c45533</link></paragraph></document>",
            "links": [
                "https://gemini.google.com/share/c6dfd3c45533"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:27:22.202502+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452122,
            "author": "Tvisha Londhe",
            "project_title": "Special Participation A: Mistral AI on HW7 Written Portion",
            "post_body": "I used Mistral AI to work through the non-coding portions of HW7, and the results were mixed. While it managed to derive the first-order optimality conditions, it initially gave the final formulas without showing the intermediate steps, and I had to reprompt it to fully explain the derivation. For Question 3(b)(ii), it did not apply the optimality conditions at first and only produced the correct reasoning after I explicitly instructed it to use them. It also struggled significantly with Question 4, incorrectly reporting both the model accuracies and training times. On the other hand, it performed much better on the later conceptual questions\u2014particularly Questions 7 and 8\u2014where it provided mostly correct answers along with clear and coherent explanations. It tends to get the multiple choice answers correct the first time, but needs re-prompting for the longer, mathematical questions. \n\nThis is the unannotated trace: https://chat.mistral.ai/chat/2fc76ff9-ffb4-4ebb-b867-2c05650e1003 \n\nHere is the annotated trace: \n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Mistral AI to work through the non-coding portions of HW7, and the results were mixed. While it managed to derive the first-order optimality conditions, it initially gave the final formulas without showing the intermediate steps, and I had to reprompt it to fully explain the derivation. For Question 3(b)(ii), it did not apply the optimality conditions at first and only produced the correct reasoning after I explicitly instructed it to use them. It also struggled significantly with Question 4, incorrectly reporting both the model accuracies and training times. On the other hand, it performed much better on the later conceptual questions\u2014particularly Questions 7 and 8\u2014where it provided mostly correct answers along with clear and coherent explanations. It tends to get the multiple choice answers correct the first time, but needs re-prompting for the longer, mathematical questions. </paragraph><paragraph>This is the unannotated trace: <link href=\"https://chat.mistral.ai/chat/2fc76ff9-ffb4-4ebb-b867-2c05650e1003\"><underline>https://chat.mistral.ai/chat/2fc76ff9-ffb4-4ebb-b867-2c05650e1003</underline></link> </paragraph><paragraph>Here is the annotated trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/bBaigxuAKYJmqP3lJ3QfjR9W\" filename=\"Special Participation A_ Mistral on HW7 - Google Docs.pdf\"/><paragraph><break/></paragraph></document>",
            "links": [
                "https://chat.mistral.ai/chat/2fc76ff9-ffb4-4ebb-b867-2c05650e1003"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:27:14.676364+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452111,
            "author": "Swetha Rajkumar",
            "project_title": "Special Participation B: Claude Sonnet 4.5 on HW10",
            "post_body": "I experimented with Claude Sonnet 4.5 on the coding portions of HW10, specifically problems 2, 3, and 4. Overall, even though this is the basic version of Claude, it was able to answer all of the conceptual questions correctly and in detail. For the coding questions, it generally performed well with one-shot or few-shot prompting and was even able to generate multiple versions of code that solved the problems (e.g., with and without einops). The only materials I provided were the initial system prompt, the PDF of the homework problems, and the Jupyter notebooks. There were some questions, such as the early-exit ResNet architecture and the optional 2c question (designing a transformer that selects by position), where, even after multiple prompt attempts, it was unable to identify the error in its code.\n\n\nHere are the chats: \nQuestion 2: https://claude.ai/share/b2ca74ed-e36f-40f5-8ae6-10333f7d9bb8\nQuestion 3: https://claude.ai/share/90c12669-b11d-40b1-ba90-717023277e7e\n\nQuestion 4: https://claude.ai/share/87878636-1cdf-4d91-92f7-a70438380a98\n\nHere are the PDFs: \n",
            "content_xml": "<document version=\"2.0\"><paragraph>I experimented with Claude Sonnet 4.5 on the coding portions of HW10, specifically problems 2, 3, and 4. Overall, even though this is the basic version of Claude, it was able to answer all of the conceptual questions correctly and in detail. For the coding questions, it generally performed well with one-shot or few-shot prompting and was even able to generate multiple versions of code that solved the problems (e.g., with and without einops). The only materials I provided were the initial system prompt, the PDF of the homework problems, and the Jupyter notebooks. There were some questions, such as the early-exit ResNet architecture and the optional 2c question (designing a transformer that selects by position), where, even after multiple prompt attempts, it was unable to identify the error in its code.</paragraph><paragraph><break/>Here are the chats: <break/>Question 2: https://claude.ai/share/b2ca74ed-e36f-40f5-8ae6-10333f7d9bb8<break/>Question 3: https://claude.ai/share/90c12669-b11d-40b1-ba90-717023277e7e</paragraph><paragraph>Question 4: https://claude.ai/share/87878636-1cdf-4d91-92f7-a70438380a98<break/><break/>Here are the PDFs: <break/></paragraph><file url=\"https://static.us.edusercontent.com/files/MaVNihqzdVqb3xxZJLrMjGqb\" filename=\"Swetha Rajkumar CS182 Special Participation B (Question 4).pdf\"/><file url=\"https://static.us.edusercontent.com/files/z1bn6E6QIgaqKYkDOq3xdbe5\" filename=\"Swetha Rajkumar CS182 Special Participation B (Question 3).pdf\"/><file url=\"https://static.us.edusercontent.com/files/ZIcC0coWm85bmvzcKdThU9EM\" filename=\"Swetha Rajkumar CS182 Special Participation B (Question 2).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:25:15.097577+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452109,
            "author": "Jason Lee",
            "project_title": "Special Participation A: gpt-4o on HW13 (written)",
            "post_body": "Model: GPT-4o\n\nHomework 13\n\nAfter trying to use GPT-4o to solve homework 13, I was quite surprised how quickly it solved question 1 (with 1 minor mistake which I suspect occurred because it drifted from using the notation in the problem). However, it really struggled on the second question of the homework which involved very long questions (especially f and g which it couldn\u2019t even get 30% of the way there). Originally, I suspected some of the error may have to do with the extremely long context length since I passed the questions to the model as images instead of text. However, I learned that GPT-4o downscales images to be 1024x1024 maximum and it takes around 640 tokens for that size image. Here\u2019s a cool thread on how to compute the number of gpt-4o image tokens\n\n\n\nHere's my full analysis of the chat: ",
            "content_xml": "<document version=\"2.0\"><paragraph>Model: GPT-4o</paragraph><paragraph>Homework 13</paragraph><paragraph>After trying to use GPT-4o to solve homework 13, I was quite surprised how quickly it solved question 1 (with 1 minor mistake which I suspect occurred because it drifted from using the notation in the problem). However, it really struggled on the second question of the homework which involved very long questions (especially f and g which it couldn\u2019t even get 30% of the way there). Originally, I suspected some of the error may have to do with the extremely long context length since I passed the questions to the model as images instead of text. However, I learned that GPT-4o downscales images to be 1024x1024 maximum and it takes around 640 tokens for that size image. Here\u2019s a cool <link href=\"https://community.openai.com/t/how-do-i-calculate-image-tokens-in-gpt4-vision/492318\">thread</link> on how to compute the number of gpt-4o image tokens</paragraph><paragraph/><paragraph>Here's my full analysis of the chat: </paragraph><file url=\"https://static.us.edusercontent.com/files/dCsQcGa3WC4KFHnB043rtGNK\" filename=\"hw13_gpt_4o.pdf\"/></document>",
            "links": [
                "https://community.openai.com/t/how-do-i-calculate-image-tokens-in-gpt4-vision/492318"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:24:35.225606+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452106,
            "author": "Atharv Sampath",
            "project_title": "Special Participation E: Google NotebookLM to create a review quiz on State Space Models",
            "post_body": "Link to notebook: https://notebooklm.google.com/notebook/c04e7e99-3e2e-4ec7-96a1-15cca6c33a3c\n\nPDF of usage with some annotations: \n\nSummary: I uploaded various sources from the class about SSMs and had NotebookLM try to create a homework/test-style quiz for me on these topics. I noticed that it is quite good at creating high level conceptual questions, but is not very accurate at creating questions that get your hands dirty with details. However, the notebook itself is quite useful and I may be adding more studio items later on as I review for the final exam.",
            "content_xml": "<document version=\"2.0\"><paragraph>Link to notebook: https://notebooklm.google.com/notebook/c04e7e99-3e2e-4ec7-96a1-15cca6c33a3c</paragraph><paragraph>PDF of usage with some annotations: </paragraph><file url=\"https://static.us.edusercontent.com/files/gXiikvgLzJIYgvBwLp4FRdso\" filename=\"NotebookLM SSMs.pdf\"/><paragraph>Summary: I uploaded various sources from the class about SSMs and had NotebookLM try to create a homework/test-style quiz for me on these topics. I noticed that it is quite good at creating high level conceptual questions, but is not very accurate at creating questions that get your hands dirty with details. However, the notebook itself is quite useful and I may be adding more studio items later on as I review for the final exam.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:23:28.456627+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452104,
            "author": "Shaurya Jain",
            "project_title": "VAEs",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor.\n\nPreviously, I had the opportunity to do work on VAEs for astronomical data for the purpose of anomaly detection. Astronomy as a subject is based on analysis of large amounts of data: light gathered from objects in our solar system to galaxies too far away to see with the naked eye. Modern telescopes have the ability to gather large amounts of data in the time that they are operational; however, it would be computationally difficult to have individual human beings look through all of this data in the hope that we can efficiently extract all the information that we can glean. The neural network architecture in variational autoencoders used to lower the dimensionality of the data while maintaining enough information to reconstruct the higher dimensional data to a reasonable accuracy provides a lens into how modern machine learning models can be useful in parsing astronomical information effectively. If anyone has similar experiences in the applications of this kind of machine learning into the sciences or other academic disciplines in general, could we discuss in the comments below? Specifically, are there any papers that you found intriguing regarding this kind of work that you would be willing to share with other students below?",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor.</paragraph><paragraph>Previously, I had the opportunity to do work on VAEs for astronomical data for the purpose of anomaly detection. Astronomy as a subject is based on analysis of large amounts of data: light gathered from objects in our solar system to galaxies too far away to see with the naked eye. Modern telescopes have the ability to gather large amounts of data in the time that they are operational; however, it would be computationally difficult to have individual human beings look through all of this data in the hope that we can efficiently extract all the information that we can glean. The neural network architecture in variational autoencoders used to lower the dimensionality of the data while maintaining enough information to reconstruct the higher dimensional data to a reasonable accuracy provides a lens into how modern machine learning models can be useful in parsing astronomical information effectively. If anyone has similar experiences in the applications of this kind of machine learning into the sciences or other academic disciplines in general, could we discuss in the comments below? Specifically, are there any papers that you found intriguing regarding this kind of work that you would be willing to share with other students below?</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:22:52.570033+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452097,
            "author": "Arnav Dalal",
            "project_title": "Special Participation B: Cursor for HW10 Coding Questions",
            "post_body": "I was thoroughly suprised by Cursor's ability to tackle the coding questions in HW 10, centered around building Transformer Architectures using Numpy/PyTorch, training a transformer for summarization, and comparing the easy difficulty and early exit frameworks for training. The most impressive part about this whole process what the Cursor was able to complete this zero-shot with only the context fro the notebooks to complete them. For prompting, I told the model to write code for individual TODOs on their own to isolate context for each separate portion of the notebooks. Especially with the length of the notebooks in this homework, this felt like the most appropriate way to approach this; however, it would be interesting to see how different prompting would affect the model's performance. The main points about the code that I noticed:\n\n\nConsistency and Code Cleanliness: Cursor is very organized with its implementations, utilizing well-known coding structures and ML architectures when it came to its solutions. For example, training loops followed a very common format that can be traced to torch documentation as expected. Overall, the code had very few comments, but very verbose naming conventions allowing us to keep the main body of functions streamlined while helping us understand the purpose.\n\nAPI Understanding: While Cursor was able to complete all of the tasks in the notebooks, it didn't get some of the answers from the answer key which were more nuanced, utilizing niche functions or arguments from the important libraries.\n\nCode Performance: It is extremely impressive for all of the code to pass each test on the first try, zero-shot. All of the training runs resulted in expected outputs, and even in some cases resulted in even better results than the answer key. This is really fascinating since Cursor was able to achieve these results based on relatively random inputs for the hand transformer notebook, for example. Overall, this is very reliable to know as Cursor is able to meet or go above expectations when there are criteria or goals set.\n\n\n\nEach of the notebooks with my personal annotations and alongside my chats with Cursor are provided in the attached PDF if anyone is curious about the specific outputs.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I was thoroughly suprised by Cursor's ability to tackle the coding questions in HW 10, centered around building Transformer Architectures using Numpy/PyTorch, training a transformer for summarization, and comparing the easy difficulty and early exit frameworks for training. The most impressive part about this whole process what the Cursor was able to complete this zero-shot with only the context fro the notebooks to complete them. For prompting, I told the model to write code for individual TODOs on their own to isolate context for each separate portion of the notebooks. Especially with the length of the notebooks in this homework, this felt like the most appropriate way to approach this; however, it would be interesting to see how different prompting would affect the model's performance. The main points about the code that I noticed:<break/></paragraph><list style=\"number\"><list-item><paragraph>Consistency and Code Cleanliness: Cursor is very organized with its implementations, utilizing well-known coding structures and ML architectures when it came to its solutions. For example, training loops followed a very common format that can be traced to torch documentation as expected. Overall, the code had very few comments, but very verbose naming conventions allowing us to keep the main body of functions streamlined while helping us understand the purpose.</paragraph></list-item><list-item><paragraph>API Understanding: While Cursor was able to complete all of the tasks in the notebooks, it didn't get some of the answers from the answer key which were more nuanced, utilizing niche functions or arguments from the important libraries.</paragraph></list-item><list-item><paragraph>Code Performance: It is extremely impressive for all of the code to pass each test on the first try, zero-shot. All of the training runs resulted in expected outputs, and even in some cases resulted in even better results than the answer key. This is really fascinating since Cursor was able to achieve these results based on relatively random inputs for the hand transformer notebook, for example. Overall, this is very reliable to know as Cursor is able to meet or go above expectations when there are criteria or goals set.</paragraph></list-item></list><paragraph><break/><break/>Each of the notebooks with my personal annotations and alongside my chats with Cursor are provided in the attached PDF if anyone is curious about the specific outputs.</paragraph><file url=\"https://static.us.edusercontent.com/files/AnDzBAO7CcNxMgSMIaXfVr09\" filename=\"special_participation_b.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:20:08.695434+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452074,
            "author": "Will Cai",
            "project_title": "Special Participation E: GPT study mode for quiz and cheatsheet generation",
            "post_body": "I knew the basic update rules for the optimizers, but I did not fully understand the larger idea that all optimizers can be viewed as applying a linear transform to the gradient. The meaning of a \"local quadratic bowl\" and how it leads to a unified update form still felt unclear, so I used ChatGPT\u2019s learning as a study tool along with my pipeline.\n\nStep 1: Summary and learning goals\nI first asked the model for a short summary of the concept and a list of what I should understand by the end. This helped set the learning targets: what a local quadratic model means, what assumptions it relies on, why optimizers can be written in the form delta = - P_t * g_t, and how different optimizers correspond to different choices of P_t.\n\nStep 2: Clarifying the weak spots\nNext I asked simple follow-up questions to dig into those areas. For example: \"Is a local quadratic bowl literally just Taylor expansion?\" What assumptions do we need for that to hold?\" This produced clear explanations, and a good thing to do is follow up whenever the model overstated something or glossed over a detail.\n\nStep 3: Walking through the main idea\nI then asked the model to explain the full chain in plain non theoritical language: how the quadratic approximation leads to a general update rule, and why each optimizer can be understood as choosing a particular linear transform of the gradient.\n\nStep 4: Full quiz to check understanding\nI asked for a longer multiple-choice quiz that required non trivial reasoning. I answered everything at once and then checked the key. I got only one question wrong, which showed a subtle point about when the quadratic model breaks down.\n\nStep 5: Generate a cheat sheet for review\nFinally, I asked the model to generate a short cheat sheet focusing on the part I missed. This produced a one-page summary on when the quadratic approximation fails and why rapidly changing curvature is the main issue. This is now the reference I will review before the exam.\n\nI found this workflow effective and plan to reuse the same structure for other CS282 topics.\n\nChat history: https://chatgpt.com/share/693a6d01-0c60-800b-834d-1b8cf9ae6e28 \n\nCheatsheet artifact: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I knew the basic update rules for the optimizers, but I did not fully understand the larger idea that all optimizers can be viewed as applying a linear transform to the gradient. The meaning of a \"local quadratic bowl\" and how it leads to a unified update form still felt unclear, so I used ChatGPT\u2019s learning as a study tool along with my pipeline.</paragraph><paragraph>Step 1: Summary and learning goals<break/>I first asked the model for a short summary of the concept and a list of what I should understand by the end. This helped set the learning targets: what a local quadratic model means, what assumptions it relies on, why optimizers can be written in the form delta = - P_t * g_t, and how different optimizers correspond to different choices of P_t.</paragraph><paragraph>Step 2: Clarifying the weak spots<break/>Next I asked simple follow-up questions to dig into those areas. For example: \"Is a local quadratic bowl literally just Taylor expansion?\" What assumptions do we need for that to hold?\" This produced clear explanations, and a good thing to do is follow up whenever the model overstated something or glossed over a detail.</paragraph><paragraph>Step 3: Walking through the main idea<break/>I then asked the model to explain the full chain in plain non theoritical language: how the quadratic approximation leads to a general update rule, and why each optimizer can be understood as choosing a particular linear transform of the gradient.</paragraph><paragraph>Step 4: Full quiz to check understanding<break/>I asked for a longer multiple-choice quiz that required non trivial reasoning. I answered everything at once and then checked the key. I got only one question wrong, which showed a subtle point about when the quadratic model breaks down.</paragraph><paragraph>Step 5: Generate a cheat sheet for review<break/>Finally, I asked the model to generate a short cheat sheet focusing on the part I missed. This produced a one-page summary on when the quadratic approximation fails and why rapidly changing curvature is the main issue. This is now the reference I will review before the exam.</paragraph><paragraph>I found this workflow effective and plan to reuse the same structure for other CS282 topics.<break/><break/>Chat history: <link href=\"https://chatgpt.com/share/693a6d01-0c60-800b-834d-1b8cf9ae6e28\">https://chatgpt.com/share/693a6d01-0c60-800b-834d-1b8cf9ae6e28</link> </paragraph><paragraph>Cheatsheet artifact: </paragraph><file url=\"https://static.us.edusercontent.com/files/NTfLccfbeCT1X0TsSDPZ2HTN\" filename=\"optimizer_quadratic_cheatsheet.pdf\"/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/693a6d01-0c60-800b-834d-1b8cf9ae6e28"
            ],
            "attachments": [],
            "created_at": "2025-12-11T18:14:00.970938+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452063,
            "author": "Talon Meyer",
            "project_title": "Special Participation C: HW2 Question 4",
            "post_body": "For Special Participation C, I used Cursor to help me refactor the code in HW2 Question 4, mainly the q_linearized_features.ipynb file. I focused on adding documentation throughout the notebook. Complicated code blocks received descriptive comments; all functions, classes, and files will now have Google-style docstrings. Functions now consistently use type hints and return types. I made sure not change any of the underlying logic or solve the actual question. A markdown file named changes.md was created, documenting on all the changes made in the refactor. Finally, I tested the functionality of the code to confirm no breaking changes were made.\n\nNote that while there is no spreadsheet for deonfliction for special participation C, at the time of me posting this, I can not find any other posts completing special participation C on HW 2 question 4. Below I attached a zip file containing q_linearized_features.ipynb and changes.md. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation C, I used Cursor to help me refactor the code in HW2 Question 4, mainly the q_linearized_features.ipynb file. I focused on adding documentation throughout the notebook. Complicated code blocks received descriptive comments; all functions, classes, and files will now have Google-style docstrings. Functions now consistently use type hints and return types. I made sure not change any of the underlying logic or solve the actual question. A markdown file named changes.md was created, documenting on all the changes made in the refactor. Finally, I tested the functionality of the code to confirm no breaking changes were made.<break/><break/>Note that while there is no spreadsheet for deonfliction for special participation C, at the time of me posting this, I can not find any other posts completing special participation C on HW 2 question 4. Below I attached a zip file containing q_linearized_features.ipynb and changes.md. <break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/0RnSrwBD59bMwYqqxnO8eWs6\" filename=\"hw2_q4.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T18:10:08.442549+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452013,
            "author": "Kelvin Li",
            "project_title": "Special Participation B: Qwen3-Max on HW5 (Coding)",
            "post_body": "Executive Summary\n\nI used Qwen3-Max (non-thinking) on HW5 coding parts.\n\nA few notes I realized was that\n1. Qwen3-Max despite being non-thinking actually responds with well curated chains of thought. It always responds in a step-by-step structure and always double checks its answers.\n\n2. Overall it answered everything very well, with great detailed reasoning traces and explanation. It also ensured quality of its response with double checking its answers. There were many times it changed its response after checking again and realizing it was wrong. \n\n3. OCR capabilities are great too - it was very good at reading the graph outputs of the assignment.\n\nChat logs:\n\nhttps://chat.qwen.ai/s/8b27363e-bf7f-4013-888f-451fa54eb459?fev=0.1.15\n\nhttps://chat.qwen.ai/s/7fad225a-d456-4030-86cc-dfe5c7cdc47d?fev=0.1.15\n\nhttps://chat.qwen.ai/s/0b4eea6c-e71d-4ab6-a1c8-b17417b71a49?fev=0.1.15\n\nAnnotated PDF (split into 3 parts - part 1 is for Q5. part 2 and part 3 are for Q6)",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Executive Summary</heading><paragraph>I used Qwen3-Max (non-thinking) on HW5 coding parts.</paragraph><paragraph>A few notes I realized was that<break/>1. Qwen3-Max despite being non-thinking actually responds with well curated chains of thought. It always responds in a step-by-step structure and always double checks its answers.</paragraph><paragraph>2. Overall it answered everything very well, with great detailed reasoning traces and explanation. It also ensured quality of its response with double checking its answers. There were many times it changed its response after checking again and realizing it was wrong. </paragraph><paragraph>3. OCR capabilities are great too - it was very good at reading the graph outputs of the assignment.</paragraph><paragraph>Chat logs:</paragraph><paragraph><link href=\"https://chat.qwen.ai/s/8b27363e-bf7f-4013-888f-451fa54eb459?fev=0.1.15\">https://chat.qwen.ai/s/8b27363e-bf7f-4013-888f-451fa54eb459?fev=0.1.15</link></paragraph><paragraph><link href=\"https://chat.qwen.ai/s/7fad225a-d456-4030-86cc-dfe5c7cdc47d?fev=0.1.15\">https://chat.qwen.ai/s/7fad225a-d456-4030-86cc-dfe5c7cdc47d?fev=0.1.15</link></paragraph><paragraph><link href=\"https://chat.qwen.ai/s/0b4eea6c-e71d-4ab6-a1c8-b17417b71a49?fev=0.1.15\">https://chat.qwen.ai/s/0b4eea6c-e71d-4ab6-a1c8-b17417b71a49?fev=0.1.15</link></paragraph><paragraph>Annotated PDF (split into 3 parts - part 1 is for Q5. part 2 and part 3 are for Q6)</paragraph><file url=\"https://static.us.edusercontent.com/files/eD21Gqi2hAzW0gHhVahG7wrD\" filename=\"Qwen_HW5_part1.pdf\"/><file url=\"https://static.us.edusercontent.com/files/UYSvATaD5KfzcCUm0A1eyKpM\" filename=\"Qwen_HW5_part2.pdf.zip\"/><file url=\"https://static.us.edusercontent.com/files/EsR6jla9OhZmWKJkCDDdix1s\" filename=\"Qwen_HW5_part3.pdf\"/></document>",
            "links": [
                "https://chat.qwen.ai/s/8b27363e-bf7f-4013-888f-451fa54eb459?fev=0.1.15",
                "https://chat.qwen.ai/s/7fad225a-d456-4030-86cc-dfe5c7cdc47d?fev=0.1.15",
                "https://chat.qwen.ai/s/0b4eea6c-e71d-4ab6-a1c8-b17417b71a49?fev=0.1.15"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:51:43.649277+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452011,
            "author": "Will Cai",
            "project_title": "Special Participation B: Claude Code on HW12",
            "post_body": "Setup I put both of the python notebook as well as the project specification pdf on a virtual environment, and let claude code run agentically with full permission on that. Without any supervision, other than telling claude the task, it one shot all the coding. (except I need to manually run the python notebook)\n\nProblem 4 (VAE) Claude got the main parts right. It understood that the job was to implement the Gaussian sampling with the reparameterization trick and set up the ELBO the way the spec describes. The split into reconstruction, KL, and the combined objective follows the assignment requirement closely. The training logs look normal for this setup, and the final numbers are roughly around where they should for a simple MNIST VAE. The sample grid also checks out, the digits look reasonable and cover the dataset variety, which suggests the loss and sampling code are behaving the way they should. Overall, Claude showed it understood what the assignment was asking for and produced code that matches it.\n\nProblem 5 (MAML classification) Claude filled in the missing parts within the required structure. It used logistic loss with signed labels in both places which shows it understand how the regression version uses squared loss. The meta-update and inner loop follow the same pattern as in the earlier problem which again is correct and align with previous parts. The training runs look like what you\u2019d expect for this toy classification setting: the model adapts over a few inner steps, and the parameters reflect the average behavior across tasks. The final code is clean and matches the spec.\n\nSummary Across both coding questions, Claude seems to have a pretty good grasp on the homework spec. The VAE code works and produces sensible samples, and the MAML classification code follows the expected structure without issues. The outputs look right, and the reasoning behind the implementations matches the assignment requirement.\n\nThe full chat history is attached",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Setup</bold> I put both of the python notebook as well as the project specification pdf on a virtual environment, and let claude code run agentically with full permission on that. Without any supervision, other than telling claude the task, it one shot all the coding. (except I need to manually run the python notebook)</paragraph><paragraph><bold>Problem 4 (VAE)</bold> Claude got the main parts right. It understood that the job was to implement the Gaussian sampling with the reparameterization trick and set up the ELBO the way the spec describes. The split into reconstruction, KL, and the combined objective follows the assignment requirement closely. The training logs look normal for this setup, and the final numbers are roughly around where they should for a simple MNIST VAE. The sample grid also checks out, the digits look reasonable and cover the dataset variety, which suggests the loss and sampling code are behaving the way they should. Overall, Claude showed it understood what the assignment was asking for and produced code that matches it.</paragraph><paragraph><bold>Problem 5 (MAML classification)</bold> Claude filled in the missing parts within the required structure. It used logistic loss with signed labels in both places which shows it understand how the regression version uses squared loss. The meta-update and inner loop follow the same pattern as in the earlier problem which again is correct and align with previous parts. The training runs look like what you\u2019d expect for this toy classification setting: the model adapts over a few inner steps, and the parameters reflect the average behavior across tasks. The final code is clean and matches the spec.</paragraph><paragraph><bold>Summary</bold> Across both coding questions, Claude seems to have a pretty good grasp on the homework spec. The VAE code works and produces sensible samples, and the MAML classification code follows the expected structure without issues. The outputs look right, and the reasoning behind the implementations matches the assignment requirement.<break/><break/>The full chat history is attached</paragraph><file url=\"https://static.us.edusercontent.com/files/bVQR4PPJl00E3hyoxsEl8u5g\" filename=\"2025-12-11-solve-maml-and-vae-problem-the-hw-specification-a.txt\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:51:32.540585+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7452009,
            "author": "Shaurya Jain",
            "project_title": "Special Participation E #2",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet us learn about Transformers with the help of ChatGPT 5.1 Thinking Mode:",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. </paragraph><paragraph>Let us learn about Transformers with the help of ChatGPT 5.1 Thinking Mode:</paragraph><file url=\"https://static.us.edusercontent.com/files/KvNojB8KdpmHOoOxyzQfwAec\" filename=\"182 SPE #2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:51:22.425703+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451985,
            "author": "Celine Tan",
            "project_title": "Special Participation B: Sonnet 4.5 on HW 8 Coding",
            "post_body": "I've attached my report for the usage of Claude Sonnet 4.5 on the coding portion of HW 8. Claude was able to solve most problems zero-shot without much difficulty, but did have some trouble correctly implementing diag_conv_ssm_forward on its first try. However, after being notified of the numerical difference between its implementations, it was able to find and fix the issue quite quickly and without any help.\n\nClaude's mistakes were mainly small conceptual details; the code was otherwise completely syntactically correct and well-formatted and documented. It also gave quite detailed justifications for the differences in runtime from CPU to GPU (even getting into the details of how CPU caching and instructions might affect runtime). ",
            "content_xml": "<document version=\"2.0\"><paragraph>I've attached my report for the usage of Claude Sonnet 4.5 on the coding portion of HW 8. Claude was able to solve most problems zero-shot without much difficulty, but did have some trouble correctly implementing diag_conv_ssm_forward on its first try. However, after being notified of the numerical difference between its implementations, it was able to find and fix the issue quite quickly and without any help.</paragraph><paragraph>Claude's mistakes were mainly small conceptual details; the code was otherwise completely syntactically correct and well-formatted and documented. It also gave quite detailed justifications for the differences in runtime from CPU to GPU (even getting into the details of how CPU caching and instructions might affect runtime). </paragraph><file url=\"https://static.us.edusercontent.com/files/r8Q22zc8Lf1l1o8EE1hfFu5t\" filename=\"182 special partcipation B (2).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:42:52.58277+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451982,
            "author": "Subhash Prasad",
            "project_title": "Special Participation E: Ruthless Architect for Simulating a Design Review",
            "post_body": "For my Special Participation E submission, I created a \"Design Review Simulator\" using Claude 4.5 Sonnet. Instead of using an LLM as a passive tutor, I prompted it to act as a \"Ruthless Senior Principal Engineer\" that evaluates architectural proposals relating to specific lecture notes. My goal was to see whether the model could catch mathematical misconceptions that are subtle, and be strict when necessary. As a learning strategy, I believe that making mistakes and learning why they're wrong is better than just reading the right answer over and over, and this tool helps with that.\n\nPROMPT\n\"Role: You are a \"Ruthless Senior Principal Engineer\" at a top AI research lab. Your job is to conduct design reviews for Junior Engineers (students).\n\nContext: I have uploaded lecture notes from my Deep Learning course. You must use the specific constraints, math, and theory provided in these notes to evaluate my proposals.\n\nTask: I will propose a specific architectural choice, hyperparameter setting, or training strategy (e.g., \"I want to use a 100-layer network with Sigmoid activations and vanilla SGD\").\n\nYour Response Guidelines:\n\nIdentify the Failure Mode: Immediately predict exactly how this will fail (e.g., \"Vanishing Gradients,\" \"Exploding Gradients,\" \"Saddle Point Stagnation,\" \"Dead ReLUs\").\n\nThe \"Why\" (Math/Theory): Explain why it fails using the mathematical concepts found in the uploaded notes (e.g., refer to the derivative of the activation function, the eigenvalues of the Hessian, or the variance of the weights).\n\nThe Fix: Briefly propose the modern standard solution (e.g., \"Switch to ReLU and He Initialization\").\n\nTone: Be professional but critical. Do not accept \"okay\" answers. If a choice is theoretically unsound, reject it.\"\n\nI then fed the model the notes from Lecture 24 and Lecture 25.\n\nQUESTIONS\nI fed the model three \"bad\" ideas and one \"trick\" good idea to test it's capabilities.\n\nANNOTATED CONVERSATION\nhttps://drive.google.com/file/d/1ajpHHrPwikii7zW0Z4uWFA64NCQVjbxS/view?usp=sharing\n\nOBSERVATIONS\nThe model distinguished between low-temperature sampling and power sampling. It correctly cited the inequality $\\sum (p^\\alpha) \\neq (\\sum p)^\\alpha$ to explain why the proposed \"temperature = $1/\\alpha$\" shortcut isn't mathematically valid. This is subtle, but the lecture context forced the model to be rigorous.\n\nWhen I proposed QAT using the STE, I expected the model to reject it because step functions are non-differentiable. However, it correctly identified that this is a valid \"trick\" encouraged by Lecture 24.\n\nThe model correctly identified that removing the clipping in ScaleRL/RLVR would lead to infinite variance in the gradient estimator. It linked this to the \"Trust Region\" concepts in PPO, which is a relatively deep connection I wasn't expecting.",
            "content_xml": "<document version=\"2.0\"><paragraph>For my Special Participation E submission, I created a \"Design Review Simulator\" using Claude 4.5 Sonnet. Instead of using an LLM as a passive tutor, I prompted it to act as a \"Ruthless Senior Principal Engineer\" that evaluates architectural proposals relating to specific lecture notes. My goal was to see whether the model could catch mathematical misconceptions that are subtle, and be strict when necessary. As a learning strategy, I believe that making mistakes and learning <italic>why</italic> they're wrong is better than just reading the right answer over and over, and this tool helps with that.<break/><break/><bold>PROMPT</bold><break/><italic>\"Role: You are a \"Ruthless Senior Principal Engineer\" at a top AI research lab. Your job is to conduct design reviews for Junior Engineers (students).</italic></paragraph><paragraph><italic>Context: I have uploaded lecture notes from my Deep Learning course. You must use the specific constraints, math, and theory provided in these notes to evaluate my proposals.</italic></paragraph><paragraph><italic>Task: I will propose a specific architectural choice, hyperparameter setting, or training strategy (e.g., \"I want to use a 100-layer network with Sigmoid activations and vanilla SGD\").</italic></paragraph><paragraph><italic>Your Response Guidelines:</italic></paragraph><list style=\"unordered\"><list-item><paragraph><italic>Identify the Failure Mode: Immediately predict exactly how this will fail (e.g., \"Vanishing Gradients,\" \"Exploding Gradients,\" \"Saddle Point Stagnation,\" \"Dead ReLUs\").</italic></paragraph></list-item><list-item><paragraph><italic>The \"Why\" (Math/Theory): Explain why it fails using the mathematical concepts found in the uploaded notes (e.g., refer to the derivative of the activation function, the eigenvalues of the Hessian, or the variance of the weights).</italic></paragraph></list-item><list-item><paragraph><italic>The Fix: Briefly propose the modern standard solution (e.g., \"Switch to ReLU and He Initialization\").</italic></paragraph></list-item><list-item><paragraph><italic>Tone: Be professional but critical. Do not accept \"okay\" answers. If a choice is theoretically unsound, reject it.</italic>\"</paragraph></list-item></list><paragraph>I then fed the model the notes from Lecture 24 and Lecture 25.<break/><break/><bold>QUESTIONS</bold><break/>I fed the model three \"bad\" ideas and one \"trick\" good idea to test it's capabilities.<break/><break/><bold>ANNOTATED CONVERSATION</bold><break/><link href=\"https://drive.google.com/file/d/1ajpHHrPwikii7zW0Z4uWFA64NCQVjbxS/view?usp=sharing\">https://drive.google.com/file/d/1ajpHHrPwikii7zW0Z4uWFA64NCQVjbxS/view?usp=sharing</link><break/><break/><bold>OBSERVATIONS</bold><break/>The model distinguished between low-temperature sampling and power sampling. It correctly cited the inequality $\\sum (p^\\alpha) \\neq (\\sum p)^\\alpha$ to explain why the proposed \"temperature = $1/\\alpha$\" shortcut isn't mathematically valid. This is subtle, but the lecture context forced the model to be rigorous.<break/><break/>When I proposed QAT using the STE, I expected the model to reject it because step functions are non-differentiable. However, it correctly identified that this is a valid \"trick\" encouraged by Lecture 24.<break/><break/>The model correctly identified that removing the clipping in ScaleRL/RLVR would lead to infinite variance in the gradient estimator. It linked this to the \"Trust Region\" concepts in PPO, which is a relatively deep connection I wasn't expecting.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1ajpHHrPwikii7zW0Z4uWFA64NCQVjbxS/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:41:43.754274+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451972,
            "author": "Talon Meyer",
            "project_title": "Special Participation C: HW0 Question 6",
            "post_body": "For Special Participation C, I used Cursor (Claude Sonnet 4.5 under the hood) to help me refactor the code in HW0 Question 6. Given that the code used in this assignment is already quite modular, I focused on adding documentation throughout the code base and refactoring to follow SWE documentation best practices. Complicated code blocks received descriptive comments; all functions, classes, and files will now have Google-style docstrings. Functions now consistently use type hints and return types. I made sure not change any of the underlying logic or solve the actual question. A markdown file named changes.md was created in the root directory. Finally, I tested the functionality of the code to confirm no breaking changes were made.\n\nNote that while there is no spreadsheet for deonfliction for special participation C, at the time of me posting this, I can not find any other posts completing special participation C on HW 0 question 6.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation C, I used Cursor (Claude Sonnet 4.5 under the hood) to help me refactor the code in HW0 Question 6. Given that the code used in this assignment is already quite modular, I focused on adding documentation throughout the code base and refactoring to follow SWE documentation best practices. Complicated code blocks received descriptive comments; all functions, classes, and files will now have Google-style docstrings. Functions now consistently use type hints and return types. I made sure not change any of the underlying logic or solve the actual question. A markdown file named changes.md was created in the root directory. Finally, I tested the functionality of the code to confirm no breaking changes were made.<break/><break/>Note that while there is no spreadsheet for deonfliction for special participation C, at the time of me posting this, I can not find any other posts completing special participation C on HW 0 question 6.</paragraph><file url=\"https://static.us.edusercontent.com/files/p4vnnNOSmKN5QE2XOOThyvbi\" filename=\"hw0code.zip\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:37:36.765685+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451971,
            "author": "Abdelaziz Mohamed",
            "project_title": "Special Participation D: Shampoo + Adafactor for HW12",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/5DvumTUjh4YmQYLWzfcZ7DgY\" filename=\"hw12_participationD.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:37:21.05447+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451969,
            "author": "Zach Pricz",
            "project_title": "Special Participation B: Perplexity Pro on HW08",
            "post_body": "Link: https://www.perplexity.ai/search/you-are-an-expert-in-deep-lear-MHvApshMQVudgnOVLsRGGg#5\n\nFor my special participation I used Perplexity Pro on HW08's coding portions (Problem 2 CPU and GPU implementations).\n\nI found Perplexity Pro very good at answering my questions as opposed to models like Qwen which I attempted first. It was able to one shot the entire GPU section and only had some minor misteps on the CPU portion due to using Numpy implementations. \n\nAn interesting thing I kept noticing with Perplexity was its confidence to \"answer ahead\" and possibly hallucinate on questions asking for interpreting results. Instead of asking the user for information about the runtime, it would answer the questions as if it knew the results. This to me seems a bit misguided, and I feel ideally it should not answer these questions or ask the users for results from the notebook. Either way though, Perplexity Pro's coding abilities are clearly very present!",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/ikPaaYo12fJLG2QLlDFh9niN\" filename=\"hw8_perplexity_pro.pdf\"/><paragraph>Link: <link href=\"https://www.perplexity.ai/search/you-are-an-expert-in-deep-lear-MHvApshMQVudgnOVLsRGGg#5\">https://www.perplexity.ai/search/you-are-an-expert-in-deep-lear-MHvApshMQVudgnOVLsRGGg#5</link></paragraph><paragraph>For my special participation I used Perplexity Pro on HW08's coding portions (Problem 2 CPU and GPU implementations).</paragraph><paragraph>I found Perplexity Pro very good at answering my questions as opposed to models like Qwen which I attempted first. It was able to one shot the entire GPU section and only had some minor misteps on the CPU portion due to using Numpy implementations. </paragraph><paragraph>An interesting thing I kept noticing with Perplexity was its confidence to \"answer ahead\" and possibly hallucinate on questions asking for interpreting results. Instead of asking the user for information about the runtime, it would answer the questions as if it knew the results. This to me seems a bit misguided, and I feel ideally it should not answer these questions or ask the users for results from the notebook. Either way though, Perplexity Pro's coding abilities are clearly very present!</paragraph></document>",
            "links": [
                "https://www.perplexity.ai/search/you-are-an-expert-in-deep-lear-MHvApshMQVudgnOVLsRGGg#5"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:37:15.889201+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451962,
            "author": "Shaurya Jain",
            "project_title": "Special Participation E",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nLet's learn about Adam through ChatGPT 5.1 Thinking:",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. </paragraph><paragraph>Let's learn about Adam through ChatGPT 5.1 Thinking:</paragraph><file url=\"https://static.us.edusercontent.com/files/dapdPlCy9YAHLDdNSQwi6sQw\" filename=\"182 SPE #1-1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:33:59.711966+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451948,
            "author": "Andrea Lou",
            "project_title": "Special Participation E:  Deep Dives: Generating Step-by-Step Derivations and Intuitive Explanations",
            "post_body": "From my special participation A, I realized that Deepseek often assumes certain knowledge when solving problems that students might not be familiar or comfortable with. Even when asked to provide full reasoning steps, it often abbreviates sentences or provides abridged logic, despite producing the correct answer. \n\nI continued my discussion with Deepseek to generate more tutor-like, explanatory learning resources based off of the following 3 different prompting strategies:\n\n1) \"Map out every concept I should know or review before working on this assignment. For example, create a prerequisite knowledge map for fully understanding Ridge Regression as MAP estimation, including linear algebra, probability, and optimization. For each learning module, list the key concepts, common misunderstandings, and 3 exercises to build those skills.\"\n\nGoal: I wanted a concept map for a student looking to enter the course, and use it to get a good idea of where their foundational understanding is lacking.\n\n2) \"Explain a core concept of this homework, assuming I have NO prior knowledge. For example, explain the MAP interpretation of Ridge Regression as if I have not taken probability theory. Explicitly state every assumption and every distribution identity you rely on. At the end, list all the mathematical tools you used so I can review them.\"\n\nGoal: Targeted focus on a single topic, and aggregate resources for learning that topic.\n\n3) \"Go over the assignment again, and identify derivation heavy concepts. For example, walk through the MAP estimation derivation for W step-by-step. For each line, explain why the step is valid. Do not compress steps. Annotate each operation with the identity, theorem, or fact used.\"\n\nGoal: Get the model to provide verbose answers equal to or better than the provided staff solution, and tie it to core course concepts.\n\nTo use this for future assignments, paste in the three prompts above based on the intended use case.\n\n\n\nFull annotated log (starts at the end of the first page, first section was the setup for the assignment):\n\nAnnotations corresponding to the three prompts above:\n\n1) I thought the breakdown into Linear Algebra \u2192 Optimization \u2192 Probability \u2192 Neural Networks \u2192 Matrix Identities \u2192 Numerical Issues was great for my understanding of the concepts. The misunderstandings section was also surprisingly helpful, followed by some good practice into the related topics. Some issues however, it provided additional materials outside the scope of what I asked for, for example the Woodbury identity and a week long plan of study. Deepseek seemed to hallucinate the scope of my prompt, and add additional information not requested. As another example, it provides pseudo-inverse identities not directly needed to answer the homework questions.\n\n2) Deepseek generated an analogy for Ridge Regression that I thought was great for building intuition, comparing it to a \"skeptical detective\". I haven't had any LLM do this for me without being directly prompted, so I wondered if it was pulling from an article on the internet, but searching \"skeptical detective ridge regression\" generated no results. It was also able to extend the analogy to other types of \"detectives\" to explain other core concepts like Bayes Theorem. Overall, it was great at explaining MAP without requiring prior probability theory, and also made sure to note assumptions that were missing from its initial solve. Some drawbacks: I remember how important the bias-variance tradeoff was stressed in CS189, however this explanation only touches upon it in passing. Additionally, the explanation is great for scalar intuition but doesn't translate to the matrix notation used in homework/lecture. \n\n3) This time the derivations for the assignment were very thorough, walking through concepts like MAP estimation, vector calculus, ridge regression, and ReLU updates step by step. I liked that they explicitly started from the Gaussian prior and likelihood, applied Bayes\u2019 theorem, and carefully simplified the log posterior to show how it naturally leads to the ridge regression objective. The vector calculus section was especially clear, showing how the derivative of x^TAx comes from the product and chain rules and matrix-vector multiplication. The ridge solution via normal equations was also nicely broken down, expanding norms, taking derivatives, and solving for W while explicitly noting symmetry and positive definiteness. For ReLU, the elbow location updates were handled carefully, including the inactive regions where gradients are zero, which I thought was glossed over in other explanations. Each step called out the exact identity or rule being used which made the derivation very rigorous. One minor drawback is that while the derivations are mathematically complete, they are very very dense and might be intimidating for students without a more intuitive framing.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>From my special participation A, I realized that Deepseek often assumes certain knowledge when solving problems that students might not be familiar or comfortable with. Even when asked to provide full reasoning steps, it often abbreviates sentences or provides abridged logic, despite producing the correct answer. </paragraph><paragraph>I continued my discussion with Deepseek to generate more tutor-like, explanatory learning resources based off of the following 3 different prompting strategies:</paragraph><list style=\"unordered\"><list-item><paragraph>1) \"Map out every concept I should know or review before working on this assignment. For example, create a prerequisite knowledge map for fully understanding Ridge Regression as MAP estimation, including linear algebra, probability, and optimization. For each learning module, list the key concepts, common misunderstandings, and 3 exercises to build those skills.\"</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Goal: I wanted a concept map for a student looking to enter the course, and use it to get a good idea of where their foundational understanding is lacking.</paragraph></list-item></list></list-item><list-item><paragraph>2) \"Explain a core concept of this homework, assuming I have NO prior knowledge. For example, explain the MAP interpretation of Ridge Regression as if I have not taken probability theory. Explicitly state every assumption and every distribution identity you rely on. At the end, list all the mathematical tools you used so I can review them.\"</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Goal: Targeted focus on a single topic, and aggregate resources for learning that topic.</paragraph></list-item></list></list-item><list-item><paragraph>3) \"Go over the assignment again, and identify derivation heavy concepts. For example, walk through the MAP estimation derivation for W step-by-step. For each line, explain why the step is valid. Do not compress steps. Annotate each operation with the identity, theorem, or fact used.\"</paragraph></list-item></list><list style=\"unordered\"><list-item><list style=\"unordered\"><list-item><paragraph>Goal: Get the model to provide verbose answers equal to or better than the provided staff solution, and tie it to core course concepts.</paragraph></list-item></list></list-item></list><paragraph>To use this for future assignments, paste in the three prompts above based on the intended use case.</paragraph><paragraph/><paragraph>Full annotated log (starts at the end of the first page, first section was the setup for the assignment):</paragraph><file url=\"https://static.us.edusercontent.com/files/bcsRo55YTcObNNBe0U4QhrOZ\" filename=\"Deepseek_learning_resource.pdf\"/><paragraph>Annotations corresponding to the three prompts above:</paragraph><list style=\"unordered\"><list-item><paragraph>1) I thought the breakdown into Linear Algebra \u2192 Optimization \u2192 Probability \u2192 Neural Networks \u2192 Matrix Identities \u2192 Numerical Issues was great for my understanding of the concepts. The misunderstandings section was also surprisingly helpful, followed by some good practice into the related topics. Some issues however, it provided additional materials outside the scope of what I asked for, for example the Woodbury identity and a week long plan of study. Deepseek seemed to hallucinate the scope of my prompt, and add additional information not requested. As another example, it provides pseudo-inverse identities not directly needed to answer the homework questions.</paragraph></list-item><list-item><paragraph>2) Deepseek generated an analogy for Ridge Regression that I thought was great for building intuition, comparing it to a \"skeptical detective\". I haven't had any LLM do this for me without being directly prompted, so I wondered if it was pulling from an article on the internet, but searching \"skeptical detective ridge regression\" generated no results. It was also able to extend the analogy to other types of \"detectives\" to explain other core concepts like Bayes Theorem. Overall, it was great at explaining MAP without requiring prior probability theory, and also made sure to note assumptions that were missing from its initial solve. Some drawbacks: I remember how important the bias-variance tradeoff was stressed in CS189, however this explanation only touches upon it in passing. Additionally, the explanation is great for scalar intuition but doesn't translate to the matrix notation used in homework/lecture. </paragraph></list-item><list-item><paragraph>3) This time the derivations for the assignment were very thorough, walking through concepts like MAP estimation, vector calculus, ridge regression, and ReLU updates step by step. I liked that they explicitly started from the Gaussian prior and likelihood, applied Bayes\u2019 theorem, and carefully simplified the log posterior to show how it naturally leads to the ridge regression objective. The vector calculus section was especially clear, showing how the derivative of x^TAx comes from the product and chain rules and matrix-vector multiplication. The ridge solution via normal equations was also nicely broken down, expanding norms, taking derivatives, and solving for W while explicitly noting symmetry and positive definiteness. For ReLU, the elbow location updates were handled carefully, including the inactive regions where gradients are zero, which I thought was glossed over in other explanations. Each step called out the exact identity or rule being used which made the derivation very rigorous. One minor drawback is that while the derivations are mathematically complete, they are very very dense and might be intimidating for students without a more intuitive framing.</paragraph></list-item></list><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:29:21.181466+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451925,
            "author": "Jeshu Mohan",
            "project_title": "Special Participation B: Google AI Studio's Gemini 2.5 Pro with thinking and search capabilities for HW0 Coding Section",
            "post_body": "I attempted to use Google AI Studio's Gemini 2.5 Pro with thinking and search capabilities (Temperature 0.7) for coding section of HW0.\n\n\nOverall, Gemini was really helpful. Instead of just dumping the code, it wrote out a plan first (figuring out files/order). The Python code produced was spot on, handling tricky reshaping and matrix math correctly.\n\nFor the written question about the 5-layer network, it nailed the answer, correctly identifying sensitivity to hyperparameters as the cause. It even used Google Search to explain why (citing vanishing gradients), which added valuable context beyond the solution key.\n\n\nLink: https://aistudio.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221JUlDs_El2dMWr3ut5BOmLHEOpTXSx60d%22%5D%2C%22action%22%3A%22open%22%2C%22userId%22%3A%22117882837909154576747%22%2C%22resourceKeys%22%3A%7B%7D%7D&usp=drive_link\n\nAnnotated File: https://docs.google.com/document/d/1Jmv4OiEtlRHt3NPmJzPx79SnDIvxkPkpiPy8qxMEov8/edit?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I attempted to use Google AI Studio's Gemini 2.5 Pro with thinking and search capabilities (Temperature 0.7) for coding section of HW0.</paragraph><paragraph><break/>Overall, Gemini was really helpful. Instead of just dumping the code, it wrote out a plan first (figuring out files/order). The Python code produced was spot on, handling tricky reshaping and matrix math correctly.</paragraph><paragraph>For the written question about the 5-layer network, it nailed the answer, correctly identifying sensitivity to hyperparameters as the cause. It even used Google Search to explain <italic>why</italic> (citing vanishing gradients), which added valuable context beyond the solution key.<break/><break/><break/>Link: <link href=\"https://aistudio.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221JUlDs_El2dMWr3ut5BOmLHEOpTXSx60d%22%5D%2C%22action%22%3A%22open%22%2C%22userId%22%3A%22117882837909154576747%22%2C%22resourceKeys%22%3A%7B%7D%7D&amp;usp=drive_link\">https://aistudio.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221JUlDs_El2dMWr3ut5BOmLHEOpTXSx60d%22%5D%2C%22action%22%3A%22open%22%2C%22userId%22%3A%22117882837909154576747%22%2C%22resourceKeys%22%3A%7B%7D%7D&amp;usp=drive_link</link><break/><break/>Annotated File: <link href=\"https://docs.google.com/document/d/1Jmv4OiEtlRHt3NPmJzPx79SnDIvxkPkpiPy8qxMEov8/edit?usp=sharing\">https://docs.google.com/document/d/1Jmv4OiEtlRHt3NPmJzPx79SnDIvxkPkpiPy8qxMEov8/edit?usp=sharing</link></paragraph></document>",
            "links": [
                "https://aistudio.google.com/app/prompts?state=%7B%22ids%22%3A%5B%221JUlDs_El2dMWr3ut5BOmLHEOpTXSx60d%22%5D%2C%22action%22%3A%22open%22%2C%22userId%22%3A%22117882837909154576747%22%2C%22resourceKeys%22%3A%7B%7D%7D&amp;usp=drive_link",
                "https://docs.google.com/document/d/1Jmv4OiEtlRHt3NPmJzPx79SnDIvxkPkpiPy8qxMEov8/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:22:32.856849+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451918,
            "author": "Katie Wang",
            "project_title": "Special Participation A: Gemini 2.5 Flash on HW 5",
            "post_body": "I used Gemini 2.5 Flash to solve questions 1, 2, 3, and 4 on HW 5. Gemini performed well overall on the homework problems, giving mostly correct mathematical results and generally clear, step-by-step explanations. In the convolution and normalization questions, it showed strong understanding of the core concepts and correctly executed most derivations, including the convolution filter construction, simplified batch-norm derivative, and depthwise-separable convolution parameter counts. It was also effective at organizing its solutions cleanly and justifying its steps. However, its answers occasionally lacked important detail or precision. For example, the convolution weight-sharing explanation missed the deeper point about translation equivariance, the transpose-convolution example contained an incorrect overlap addition, and the pointwise-convolution derivation omitted bias terms even though they were shown in the diagram in the prompt. In a few places, Gemini drifted into excessive general explanation without fully addressing the specific question, and it omitted some of the reasoning behind the expressions it reached in the dropout derivation. Overall, Gemini showed strong mathematical competence and solid explanatory skill, but its responses suffered from occasional computational inaccuracies and incomplete treatment of subtle but important details.\n\nChat log and notes: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 2.5 Flash to solve questions 1, 2, 3, and 4 on HW 5. Gemini performed well overall on the homework problems, giving mostly correct mathematical results and generally clear, step-by-step explanations. In the convolution and normalization questions, it showed strong understanding of the core concepts and correctly executed most derivations, including the convolution filter construction, simplified batch-norm derivative, and depthwise-separable convolution parameter counts. It was also effective at organizing its solutions cleanly and justifying its steps. However, its answers occasionally lacked important detail or precision. For example, the convolution weight-sharing explanation missed the deeper point about translation equivariance, the transpose-convolution example contained an incorrect overlap addition, and the pointwise-convolution derivation omitted bias terms even though they were shown in the diagram in the prompt. In a few places, Gemini drifted into excessive general explanation without fully addressing the specific question, and it omitted some of the reasoning behind the expressions it reached in the dropout derivation. Overall, Gemini showed strong mathematical competence and solid explanatory skill, but its responses suffered from occasional computational inaccuracies and incomplete treatment of subtle but important details.<break/><break/>Chat log and notes: </paragraph><file url=\"https://static.us.edusercontent.com/files/hueOIzvYkeFRRQ9QyxBIH2B7\" filename=\"Special Participation A - Gemini 2.5 Flash on HW 5.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:20:59.615129+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451902,
            "author": "Paul Struble",
            "project_title": "Special Participation B: GPT 5.1 on HW7",
            "post_body": "I used GPT 5.1 to solve the coding parts of Homework 7. Overall, the model was effective at solving each problem. It was able to one-shot most problem subparts, although each problem had at least one subpart in which the model initially wrote a bug. The model was able to fairly easily fix all bugs it introduced, and it did not need any significant steering/hints to get to a working solution. I started a separate conversation in the ChatGPT web frontend for each problem, and had the model solve each subpart of each problem one at a time so that when any error arose, it could be addressed before moving on further in the notebook. Other than the few bugs, the model did not display many hallucinations except for an incorrect statement about the effectiveness of the classifier in Problem 5, Q.5. I include more observations/analysis in the attached document.\n\n\n\nLink to Conversation (Problem 1): https://chatgpt.com/share/693a5f82-fad0-8007-8758-8a1756fb8c03\n\nLink to Conversation (Problem 2): https://chatgpt.com/share/693a5f64-6eac-8007-b3aa-ae6581f137e8\n\nLink to Conversation (Problem 3a): https://chatgpt.com/share/693a4f59-2178-8007-8653-9e25e8bb38c1\n\nLink to Conversation (Problem 5): https://chatgpt.com/share/693a5c7b-a4a0-8007-91c2-5a3eaa9521c9\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used GPT 5.1 to solve the coding parts of Homework 7. Overall, the model was effective at solving each problem. It was able to one-shot most problem subparts, although each problem had at least one subpart in which the model initially wrote a bug. The model was able to fairly easily fix all bugs it introduced, and it did not need any significant steering/hints to get to a working solution. I started a separate conversation in the ChatGPT web frontend for each problem, and had the model solve each subpart of each problem one at a time so that when any error arose, it could be addressed before moving on further in the notebook. Other than the few bugs, the model did not display many hallucinations except for an incorrect statement about the effectiveness of the classifier in Problem 5, Q.5. I include more observations/analysis in the attached document.</paragraph><paragraph/><paragraph><bold>Link to Conversation (Problem 1):</bold> <link href=\"https://chatgpt.com/share/693a5f82-fad0-8007-8758-8a1756fb8c03\"><underline>https://chatgpt.com/share/693a5f82-fad0-8007-8758-8a1756fb8c03</underline></link></paragraph><paragraph><bold>Link to Conversation (Problem 2):</bold> <link href=\"https://chatgpt.com/share/693a5f64-6eac-8007-b3aa-ae6581f137e8\"><underline>https://chatgpt.com/share/693a5f64-6eac-8007-b3aa-ae6581f137e8</underline></link></paragraph><paragraph><bold>Link to Conversation (Problem 3a):</bold> <link href=\"https://chatgpt.com/share/693a4f59-2178-8007-8653-9e25e8bb38c1\"><underline>https://chatgpt.com/share/693a4f59-2178-8007-8653-9e25e8bb38c1</underline></link></paragraph><paragraph><bold>Link to Conversation (Problem 5):</bold> <link href=\"https://chatgpt.com/share/693a5c7b-a4a0-8007-91c2-5a3eaa9521c9\"><underline>https://chatgpt.com/share/693a5c7b-a4a0-8007-91c2-5a3eaa9521c9</underline></link></paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/hTXX9mMSxhBLkUbJRnIjg4nB\" filename=\"Special Participation B.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/693a5f82-fad0-8007-8758-8a1756fb8c03",
                "https://chatgpt.com/share/693a5f64-6eac-8007-b3aa-ae6581f137e8",
                "https://chatgpt.com/share/693a4f59-2178-8007-8653-9e25e8bb38c1",
                "https://chatgpt.com/share/693a5c7b-a4a0-8007-91c2-5a3eaa9521c9"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:16:52.661615+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451901,
            "author": "Will Cai",
            "project_title": "Special Participation A: Claude Opus 4.5 with extended thinking on HW12",
            "post_body": "Summary: Overall Claude was reliable but with a specific pattern on answer quality. On algebraic or mechanical reasoning, it was very strong and made no mistakes and pretty much one shot all questions. On conceptual intuition questions, especially the VIB beta effects, it tended to give the first plausible explanation and only corrected itself when pushed by additional queries. So it can get to the right answer, but sometimes needs prompting to avoid shallow intuition. When guided, it produces very solid reasoning; when left alone, it feels more lazy and usually settles for a simplified story; however, seems like everything can be solved by better prompting. \n\nChat log: https://claude.ai/share/72ff4a16-11f6-436e-925b-163c5ce94835 \n\n\n\nProblem 1\n\nClaude handled this one pretty well. It immediately understood that using std = 1 for tied embeddings makes the logits blow up, and the fix with 1/sqrt(d_model) was basically a one-shot answer. The explanation about variance scaling with d_model was clean and it didn\u2019t get lost in irrelevant details. It didn\u2019t really explore whether hidden state variance or LayerNorm behavior could change the picture, but the core reasoning was correct and it stayed on track the whole time.\n\nProblem 2\n\nThe KL example was correct, but Claude felt a bit on autopilot here. It went straight to the standard uniform vs Gaussian example without considering other constructions or sanity checks. It didn\u2019t question whether the support conditions were the real driver, which would have shown deeper understanding. For forward vs reverse KL, it defaulted to the classic mode-covering vs mode-seeking framing. That was correct, but the explanation stayed at the surface level. In the end of the day the final answers matched the intended reasoning.\n\nProblem 3\n\nThis was where Claude struggled the most. The basics, from reparameterization, which gradients hit the encoder vs decoder, and the U-shaped validation curve were all correct. But when we got into the beta values and how they map to the latent plots, it started with the wrong intuition, saying small beta should make the latent \u201cspread more.\u201d It only corrected itself after I explicitly pushed back and asked how that squares with the plot. Once it revised the explanation, it gave a coherent and correct story, but it needed that additional human oversight. Good final answer, but the initial instinct was not correct.\n\nProblem 5\n\nClaude did extremely well here. The min-norm solution was correct, the gradient calculations were clean, and there were no algebra mistakes at all. It also correctly identified the conserved norm and interpreted the gradient flow (c1 driven to zero and c0 flowing toward its magnitude). The explanation was stable and didn\u2019t require prompting. This seems to be the type of problem Claude excels at \u2014 precise algebra, clean optimization reasoning, and consistent interpretation.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Summary:</bold> Overall Claude was reliable but with a specific pattern on answer quality. On algebraic or mechanical reasoning, it was very strong and made no mistakes and pretty much one shot all questions. On conceptual intuition questions, especially the VIB beta effects, it tended to give the first plausible explanation and only corrected itself when pushed by additional queries. So it can get to the right answer, but sometimes needs prompting to avoid shallow intuition. When guided, it produces very solid reasoning; when left alone, it feels more lazy and usually settles for a simplified story; however, seems like everything can be solved by better prompting. </paragraph><paragraph>Chat log: <link href=\"https://claude.ai/share/72ff4a16-11f6-436e-925b-163c5ce94835\">https://claude.ai/share/72ff4a16-11f6-436e-925b-163c5ce94835</link> </paragraph><paragraph/><paragraph><bold>Problem 1</bold></paragraph><paragraph>Claude handled this one pretty well. It immediately understood that using std = 1 for tied embeddings makes the logits blow up, and the fix with 1/sqrt(d_model) was basically a one-shot answer. The explanation about variance scaling with d_model was clean and it didn\u2019t get lost in irrelevant details. It didn\u2019t really explore whether hidden state variance or LayerNorm behavior could change the picture, but the core reasoning was correct and it stayed on track the whole time.</paragraph><paragraph><bold>Problem 2</bold></paragraph><paragraph>The KL example was correct, but Claude felt a bit on autopilot here. It went straight to the standard uniform vs Gaussian example without considering other constructions or sanity checks. It didn\u2019t question whether the support conditions were the real driver, which would have shown deeper understanding. For forward vs reverse KL, it defaulted to the classic mode-covering vs mode-seeking framing. That was correct, but the explanation stayed at the surface level. In the end of the day the final answers matched the intended reasoning.</paragraph><paragraph><bold>Problem 3</bold></paragraph><paragraph>This was where Claude struggled the most. The basics, from reparameterization, which gradients hit the encoder vs decoder, and the U-shaped validation curve were all correct. But when we got into the beta values and how they map to the latent plots, it started with the wrong intuition, saying small beta should make the latent \u201cspread more.\u201d It only corrected itself after I explicitly pushed back and asked how that squares with the plot. Once it revised the explanation, it gave a coherent and correct story, but it needed that additional human oversight. Good final answer, but the initial instinct was not correct.</paragraph><paragraph><bold>Problem 5</bold></paragraph><paragraph>Claude did extremely well here. The min-norm solution was correct, the gradient calculations were clean, and there were no algebra mistakes at all. It also correctly identified the conserved norm and interpreted the gradient flow (c1 driven to zero and c0 flowing toward its magnitude). The explanation was stable and didn\u2019t require prompting. This seems to be the type of problem Claude excels at \u2014 precise algebra, clean optimization reasoning, and consistent interpretation.</paragraph><paragraph/></document>",
            "links": [
                "https://claude.ai/share/72ff4a16-11f6-436e-925b-163c5ce94835"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:16:39.774793+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451895,
            "author": "Yu-Jen Lin",
            "project_title": "Special Participation B: HW10 coding using Mistral",
            "post_body": "Summary \n\nMy main takeaway is that Le Chat from Mistral is good at producing plausible starter code for standard components, but it is unreliable for complex, specification-heavy parts and does not automatically support the deeper conceptual goals of the course.\n\nHW10 Q2 Link to Le Chat https://chat.mistral.ai/chat/3edba450-5b34-4fb0-a690-9fb2f24d7399\n\nHW10 Q2 Trace\n\n\n\nHW10 Q3 Link to Le Chat https://chat.mistral.ai/chat/e046aa50-cce5-4c90-9e80-4cfb0a8a41ff\n\nHW10 Q3 Trace\n\n\n\nHW10 Q2: Hand-Designed Attention In HW10 Q2 (hand-designed attention), the LLM performed relatively well on the straightforward parts. When I asked it to implement the basic transformer and simple attention patterns, the generated code was mostly correct or easy to fix. This kind of task matched the model\u2019s strengths: it could reproduce common patterns it has seen many times before (PyTorch modules, residual connections, simple attention matrices). However, as soon as the task became more unusual, such as reasoning about specific content + position interactions or optional unique-token detection, the quality dropped. The LLM either produced incomplete code or made mistakes that revealed it was not truly following the exact assignment logic. On the conceptual side, its explanations also tended to be \u201cgeneric.\u201d For example, it described the learned model as \u201capproximating\u201d the hand-designed attention, while the interesting point of the homework was that the learned attention patterns look quite different. In summary, for HW10 Q2 the LLM was helpful as a coding scaffold but weak as a conceptual guide.\n\nHW10 Q3: Full Transformer for Summarization In HW10 Q3 (full encoder\u2013decoder transformer for summarization, including mixed precision), the limitations of the LLM became much clearer. The code it produced looked clean and well-organized, but almost every important component contained at least one critical bug. These mistakes were the kinds of details that matter in practice: precision handling for FP16/FP32, correct treatment of different sequence lengths in cross-attention, the required order of layer normalization, and positional encodings with padding. Overall, for HW10 Q3, the LLM gave me a reasonable starting structure, but could not be trusted for the exact implementation details that this assignment cares about.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Summary</bold> </paragraph><paragraph>My main takeaway is that Le Chat from Mistral is good at producing plausible starter code for standard components, but it is unreliable for complex, specification-heavy parts and does not automatically support the deeper conceptual goals of the course.</paragraph><paragraph><bold>HW10 Q2 Link to Le Chat</bold> <link href=\"https://chat.mistral.ai/chat/3edba450-5b34-4fb0-a690-9fb2f24d7399\">https://chat.mistral.ai/chat/3edba450-5b34-4fb0-a690-9fb2f24d7399</link></paragraph><paragraph><bold>HW10 Q2 Trace</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/PQsfSeFQLpcQvDivCp7GSF9a\" filename=\"hw10_Q2_q_hand_transformer.pdf\"/><paragraph/><paragraph><bold>HW10 Q3 Link to Le Chat</bold> <link href=\"https://chat.mistral.ai/chat/e046aa50-cce5-4c90-9e80-4cfb0a8a41ff\">https://chat.mistral.ai/chat/e046aa50-cce5-4c90-9e80-4cfb0a8a41ff</link></paragraph><paragraph><bold>HW10 Q3 Trace</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/lXz7uYsiUJw4Mru3UWzpeetI\" filename=\"hw10_Q3_q_summarize_part_1.pdf\"/><paragraph/><paragraph><bold>HW10 Q2:</bold> Hand-Designed Attention In HW10 Q2 (hand-designed attention), the LLM performed relatively well on the straightforward parts. When I asked it to implement the basic transformer and simple attention patterns, the generated code was mostly correct or easy to fix. This kind of task matched the model\u2019s strengths: it could reproduce common patterns it has seen many times before (PyTorch modules, residual connections, simple attention matrices). However, as soon as the task became more unusual, such as reasoning about specific content + position interactions or optional unique-token detection, the quality dropped. The LLM either produced incomplete code or made mistakes that revealed it was not truly following the exact assignment logic. On the conceptual side, its explanations also tended to be \u201cgeneric.\u201d For example, it described the learned model as \u201capproximating\u201d the hand-designed attention, while the interesting point of the homework was that the learned attention patterns look quite different. In summary, for HW10 Q2 the LLM was helpful as a coding scaffold but weak as a conceptual guide.</paragraph><paragraph><bold>HW10 Q3:</bold> Full Transformer for Summarization In HW10 Q3 (full encoder\u2013decoder transformer for summarization, including mixed precision), the limitations of the LLM became much clearer. The code it produced looked clean and well-organized, but almost every important component contained at least one critical bug. These mistakes were the kinds of details that matter in practice: precision handling for FP16/FP32, correct treatment of different sequence lengths in cross-attention, the required order of layer normalization, and positional encodings with padding. Overall, for HW10 Q3, the LLM gave me a reasonable starting structure, but could not be trusted for the exact implementation details that this assignment cares about.</paragraph><paragraph/></document>",
            "links": [
                "https://chat.mistral.ai/chat/3edba450-5b34-4fb0-a690-9fb2f24d7399",
                "https://chat.mistral.ai/chat/e046aa50-cce5-4c90-9e80-4cfb0a8a41ff"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:15:46.917816+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451879,
            "author": "Yu-Jen Lin",
            "project_title": "Special Participation E: CNN, GNN, RNN",
            "post_body": "Overview \n\nI used NotebookLM Studio to generate flashcards, quizzes, slides, and a mind map from my lecture materials. Among these, the flashcards were the most useful for quick terminology review, while the other Studio products were either redundant or too high-level for the kind of math-heavy practice this class expects.\n\nFlashcards: https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=122dc77b-aeb6-4413-a4e0-fd4aff2e4e95\n\nQuiz: https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=60c41b53-8e5c-4981-8c31-4071c6b9438d\n\nLink to the project: https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?authuser=1\n\nTrace with my annotations:\n\n\n\n\n\nWhat I tried in NotebookLM \n\nI explored almost all the Studio functions, including Flashcards, Quiz, Slide Deck, Mind Map, Reports, and Infographic, to see which ones actually help with exam preparation.\n\n\n\nTakeaways \n\nMost helpful Studio products: The Flashcards were genuinely useful for reviewing key terminology and checking whether I could explain concepts in my own words. That\u2019s the main reason I decided to share the flashcard artifact. I also tried the Quiz, but I felt it overlapped heavily with the flashcards. Many questions tested the same kind of knowledge. So after doing the flashcards, the quizzes didn\u2019t add much extra value. \n\nLess helpful Studio products: The Mind Map gave a hierarchical overview of the material, but it stayed very high-level and didn\u2019t help much with deeper understanding. The Reports did a decent job organizing key terms and concepts, but it still focused more on definitions than on math or derivations. The Slide Deck looked polished, but after I had already reviewed flashcards/quizzes, they didn\u2019t add much. The Infographic was fun (I liked the visuals), but it didn\u2019t contain much information that helped me study. \n\nExplain button (what worked and what didn\u2019t): One feature I really liked was the \u201cExplain\u201d button built into flashcards and quizzes. It\u2019s convenient because I don\u2019t need to write a long prompt every time I\u2019m confused. I can just click once and get an explanation. That said, the explanations often felt harder to read quickly compared to ChatGPT or Claude. ChatGPT and Claude usually format explanations with shorter sentences and clearer bullet points, which makes it easier to skim and grasp the key idea. Also, I noticed the Explain button usually focuses on explaining only the correct answer, which is often the part I already understand. What I was hoping for is an explanation of the wrong answer choices too: why they are wrong, and how you would revise them (or rewrite the sentence) to make them correct. But there doesn\u2019t seem to be an easy one-click button for that, so I still ended up needing to manually ask follow-up questions or go back to my lecture notes (or the LaTeX summary I prepared in ChatGPT) when I wanted a clearer, more complete explanation.\n\n\n\nPipeline \n\nStep 1: Prepare lecture notes as input. I started from lecture content (screenshots of slides with my notes), and I avoided uploading full PDFs when possible because the extra formatting sometimes makes content extraction less reliable. \n\nStep 2: Summarize in ChatGPT first. I used ChatGPT (GPT-5.1 Thinking) to produce a LaTeX-formatted lecture summary, since it is good at digesting screenshot text into a structured write-up. \n\nStep 3: Use NotebookLM as the \u201creview generator.\u201d I uploaded the LaTeX summary (for lectures 10-15, e.g., CNN/GNN/RNN topics) into NotebookLM as sources. \n\nStep 4: Generate Studio artifacts. I generated flashcards, quizzes, slides, and a mind map. \n\nStep 5: Study with flashcards/quizzes. The most useful part was going through flashcards (and sometimes the quiz), and clicking Explain on the ones I didn\u2019t fully understand. The mind map review was optional and mostly just for a high-level check.\n\n\n\nConclusions \n\nI would recommend using NotebookLM flashcards (and optionally the quiz) for core-idea / terminology review (especially if your goal is \u201cgiven a term, can I explain what it means?\u201d). However, for this class, I personally felt NotebookLM\u2019s flashcards/quizzes were often too high-level and didn\u2019t cover enough derivation-style or math-heavy practice. For more exam-like practice problems, Claude\u2019s generated practice exam (from my other post #880) felt much closer to what we see in homework/discussion, and it helped more for deeper understanding. (However, it\u2019s possible this is partly influenced by my sources. If the input sources to NotebookLM emphasize conceptual explanations more than derivations, the outputs will probably skew that way too.)\n\n\n\nAppendix\n\nInfographic (It looks really fancy, but it didn\u2019t help much with exam prep)\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Overview</bold> </paragraph><paragraph>I used NotebookLM Studio to generate flashcards, quizzes, slides, and a mind map from my lecture materials. Among these, the flashcards were the most useful for quick terminology review, while the other Studio products were either redundant or too high-level for the kind of math-heavy practice this class expects.</paragraph><paragraph><bold>Flashcards:</bold> <link href=\"https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=122dc77b-aeb6-4413-a4e0-fd4aff2e4e95\">https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=122dc77b-aeb6-4413-a4e0-fd4aff2e4e95</link></paragraph><paragraph><bold>Quiz:</bold> <link href=\"https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=60c41b53-8e5c-4981-8c31-4071c6b9438d\">https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=60c41b53-8e5c-4981-8c31-4071c6b9438d</link></paragraph><paragraph><bold>Link to the project:</bold> <link href=\"https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?authuser=1\">https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?authuser=1</link></paragraph><paragraph><bold>Trace with my annotations:</bold></paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/hi5GrSNLXjtcLhuelajOV3XR\" filename=\"trace_NotebookLM_CNN_GNN_RNN.pdf\"/><paragraph/><paragraph><bold>What I tried in NotebookLM</bold> </paragraph><paragraph>I explored almost all the Studio functions, including Flashcards, Quiz, Slide Deck, Mind Map, Reports, and Infographic, to see which ones actually help with exam preparation.</paragraph><paragraph/><paragraph><bold>Takeaways</bold> </paragraph><paragraph><bold>Most helpful Studio products:</bold> The Flashcards were genuinely useful for reviewing key terminology and checking whether I could explain concepts in my own words. That\u2019s the main reason I decided to share the flashcard artifact. I also tried the Quiz, but I felt it overlapped heavily with the flashcards. Many questions tested the same kind of knowledge. So after doing the flashcards, the quizzes didn\u2019t add much extra value. </paragraph><paragraph><bold>Less helpful Studio products:</bold> The Mind Map gave a hierarchical overview of the material, but it stayed very high-level and didn\u2019t help much with deeper understanding. The Reports did a decent job organizing key terms and concepts, but it still focused more on definitions than on math or derivations. The Slide Deck looked polished, but after I had already reviewed flashcards/quizzes, they didn\u2019t add much. The Infographic was fun (I liked the visuals), but it didn\u2019t contain much information that helped me study. </paragraph><paragraph><bold>Explain button</bold> (what worked and what didn\u2019t): One feature I really liked was the \u201cExplain\u201d button built into flashcards and quizzes. It\u2019s convenient because I don\u2019t need to write a long prompt every time I\u2019m confused. I can just click once and get an explanation. That said, the explanations often felt harder to read quickly compared to ChatGPT or Claude. ChatGPT and Claude usually format explanations with shorter sentences and clearer bullet points, which makes it easier to skim and grasp the key idea. Also, I noticed the Explain button usually focuses on explaining only the correct answer, which is often the part I already understand. What I was hoping for is an explanation of the wrong answer choices too: why they are wrong, and how you would revise them (or rewrite the sentence) to make them correct. But there doesn\u2019t seem to be an easy one-click button for that, so I still ended up needing to manually ask follow-up questions or go back to my lecture notes (or the LaTeX summary I prepared in ChatGPT) when I wanted a clearer, more complete explanation.</paragraph><paragraph/><paragraph><bold>Pipeline</bold> </paragraph><paragraph>Step 1: Prepare lecture notes as input. I started from lecture content (screenshots of slides with my notes), and I avoided uploading full PDFs when possible because the extra formatting sometimes makes content extraction less reliable. </paragraph><paragraph>Step 2: Summarize in ChatGPT first. I used ChatGPT (GPT-5.1 Thinking) to produce a LaTeX-formatted lecture summary, since it is good at digesting screenshot text into a structured write-up. </paragraph><paragraph>Step 3: Use NotebookLM as the \u201creview generator.\u201d I uploaded the LaTeX summary (for lectures 10-15, e.g., CNN/GNN/RNN topics) into NotebookLM as sources. </paragraph><paragraph>Step 4: Generate Studio artifacts. I generated flashcards, quizzes, slides, and a mind map. </paragraph><paragraph>Step 5: Study with flashcards/quizzes. The most useful part was going through flashcards (and sometimes the quiz), and clicking Explain on the ones I didn\u2019t fully understand. The mind map review was optional and mostly just for a high-level check.</paragraph><paragraph/><paragraph><bold>Conclusions</bold> </paragraph><paragraph>I would recommend using NotebookLM flashcards (and optionally the quiz) for core-idea / terminology review (especially if your goal is \u201cgiven a term, can I explain what it means?\u201d). However, for this class, I personally felt NotebookLM\u2019s flashcards/quizzes were often too high-level and didn\u2019t cover enough derivation-style or math-heavy practice. For more exam-like practice problems, Claude\u2019s generated practice exam (from my other post #880) felt much closer to what we see in homework/discussion, and it helped more for deeper understanding. (However, it\u2019s possible this is partly influenced by my sources. If the input sources to NotebookLM emphasize conceptual explanations more than derivations, the outputs will probably skew that way too.)</paragraph><paragraph/><paragraph><bold>Appendix</bold></paragraph><paragraph>Infographic (It looks really fancy, but it didn\u2019t help much with exam prep)</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/uK4igKZhbfnUqK4makqAMnAZ\" width=\"659\" height=\"367.81395348837214\"/></figure><paragraph/><paragraph/></document>",
            "links": [
                "https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=122dc77b-aeb6-4413-a4e0-fd4aff2e4e95",
                "https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?artifactId=60c41b53-8e5c-4981-8c31-4071c6b9438d",
                "https://notebooklm.google.com/notebook/833433a8-9e95-40e6-9a64-131481809b45?authuser=1"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:10:33.206494+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451847,
            "author": "Yu-Jen Lin",
            "project_title": "Special Participation E: RMS Norm, \u03bcP, and Muon",
            "post_body": "Overview \n\nI used screenshots of lecture slides as input to a workflow and asked the models to produce two study artifacts: (1) a review-session style summary and (2) practice exam problems, focused on topics covered in class such as RMS \u2192 RMSNorm, \u03bcP, and Muon. The main outputs were: \n\nLecture summary generated by ChatGPT \n\nReview generated by Claude\n\nPractice exam set (with solutions) generated by Claude \n\nTrace\n\n\n\nPipeline \n\nStep 1: Prepare lecture notes as input. I took screenshots of the lecture slides with my notes (four slides in one screenshot) and uploaded the images directly. I intentionally avoided uploading the full PDF because PDFs often contain extra formatting and layout structure that can make it harder for the model to reliably extract the actual text. In my experience, image formats (especially PNG screenshots) work better for having ChatGPT read slide content and digest what is written. I also noticed that if I only provide high-level topic names without the lecture content itself, the model tends to add extra material that may be useful in general but is not always aligned with what this course emphasizes (and therefore less helpful for exam preparation). \n\nStep 2: Summarize the lecture using ChatGPT. After uploading the screenshots to ChatGPT (GPT-5.1 Thinking with extended thinking), I asked it to generate a structured summary in LaTeX format. I chose ChatGPT for this step because it can process multiple images at once and is generally reliable at turning slide text into a coherent, organized explanation. \n\nStep 3: Use Claude for interactive review and resource generation. Next, I pasted the LaTeX summary into Claude and used it as the \u201clecture-aligned\u201d reference for studying. The goal here was to keep the downstream practice materials tied closely to what was actually in the lecture, instead of letting the model drift into broader topics. \n\nStep 4: Generate and practice exam-style materials. Using Claude (based on the lecture summary), I asked for several exam-prep artifacts: (i) a list of concepts students often find confusing, (ii) step-by-step explanations of those confusing concepts, (iii) a more detailed review session version of the summary in LaTeX, and (iv) a set of around 20 practice exam questions with solutions.\n\nTakeaways\n\nOverall, I found that the practice exam problems generated by Claude were closer to the style of past exams than the quiz/flashcard style outputs I got from NotebookLM. The Claude-generated questions felt more in-depth and more math-oriented, which matched how this class tends to test understanding. In contrast, NotebookLM (as I described in my other post #881) leaned more toward high-level terminology review, which is still helpful, but less effective for the kind of exam practice I personally needed.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Overview</bold> </paragraph><paragraph>I used screenshots of lecture slides as input to a workflow and asked the models to produce two study artifacts: (1) a review-session style summary and (2) practice exam problems, focused on topics covered in class such as RMS \u2192 RMSNorm, \u03bcP, and Muon. The main outputs were: </paragraph><paragraph>Lecture summary generated by ChatGPT </paragraph><file url=\"https://static.us.edusercontent.com/files/u3Fl6YTvg9fxSslLcWSdLDNq\" filename=\"lec5-7_chatgpt_lec_summary.pdf\"/><paragraph>Review generated by Claude</paragraph><file url=\"https://static.us.edusercontent.com/files/g16MrcWNrxbUSgEFEXgcSAVZ\" filename=\"lec5-7_claudeai_review.pdf\"/><paragraph>Practice exam set (with solutions) generated by Claude </paragraph><file url=\"https://static.us.edusercontent.com/files/OGhgLJWOeZo4vupnEuXC2LIY\" filename=\"lec5-7_claudeai_practice_problems.pdf\"/><paragraph>Trace</paragraph><file url=\"https://static.us.edusercontent.com/files/8vGdiNi2dQImoyG9XFERkfow\" filename=\"lec5-7_claudeai_trace_with_annotations.pdf\"/><paragraph/><paragraph><bold>Pipeline</bold> </paragraph><paragraph>Step 1: Prepare lecture notes as input. I took screenshots of the lecture slides with my notes (four slides in one screenshot) and uploaded the images directly. I intentionally avoided uploading the full PDF because PDFs often contain extra formatting and layout structure that can make it harder for the model to reliably extract the actual text. In my experience, image formats (especially PNG screenshots) work better for having ChatGPT read slide content and digest what is written. I also noticed that if I only provide high-level topic names without the lecture content itself, the model tends to add extra material that may be useful in general but is not always aligned with what this course emphasizes (and therefore less helpful for exam preparation). </paragraph><paragraph>Step 2: Summarize the lecture using ChatGPT. After uploading the screenshots to ChatGPT (GPT-5.1 Thinking with extended thinking), I asked it to generate a structured summary in LaTeX format. I chose ChatGPT for this step because it can process multiple images at once and is generally reliable at turning slide text into a coherent, organized explanation. </paragraph><paragraph>Step 3: Use Claude for interactive review and resource generation. Next, I pasted the LaTeX summary into Claude and used it as the \u201clecture-aligned\u201d reference for studying. The goal here was to keep the downstream practice materials tied closely to what was actually in the lecture, instead of letting the model drift into broader topics. </paragraph><paragraph>Step 4: Generate and practice exam-style materials. Using Claude (based on the lecture summary), I asked for several exam-prep artifacts: (i) a list of concepts students often find confusing, (ii) step-by-step explanations of those confusing concepts, (iii) a more detailed review session version of the summary in LaTeX, and (iv) a set of around 20 practice exam questions with solutions.</paragraph><paragraph><bold>Takeaways</bold></paragraph><paragraph>Overall, I found that the practice exam problems generated by Claude were closer to the style of past exams than the quiz/flashcard style outputs I got from NotebookLM. The Claude-generated questions felt more in-depth and more math-oriented, which matched how this class tends to test understanding. In contrast, NotebookLM (as I described in my other post #881) leaned more toward high-level terminology review, which is still helpful, but less effective for the kind of exam practice I personally needed.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T17:05:22.445272+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451839,
            "author": "Rahul Bir",
            "project_title": "Special Participation E: Newton-Schulz 3d trajectory visualizer website",
            "post_body": "Hey everyone! For special participation e, I created a 3d visualization that lets you set different odd polynomial coefficients and see how the singular values of a 3x3 matrix evolve over time in a 3d trajectory.\n\nPersonally, I found the visualization given in lecture very helpful for understanding Newton Schulz. Hopefully this is helpful for the final!\n\nLink: https://newton-schulz-vis-jdfv.vercel.app\n\nHere is a pdf of the step by step setup and prompt I gave to codex to have it generate this: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey everyone! For special participation e, I created a 3d visualization that lets you set different odd polynomial coefficients and see how the singular values of a 3x3 matrix evolve over time in a 3d trajectory.</paragraph><paragraph>Personally, I found the visualization given in lecture very helpful for understanding Newton Schulz. Hopefully this is helpful for the final!</paragraph><paragraph>Link: <link href=\"https://newton-schulz-vis-jdfv.vercel.app\">https://newton-schulz-vis-jdfv.vercel.app</link></paragraph><paragraph>Here is a pdf of the step by step setup and prompt I gave to codex to have it generate this: </paragraph><file url=\"https://static.us.edusercontent.com/files/WMQhZmkvQzVLXE1p1gShrOYx\" filename=\"Special_Participation_E___prompt_for_creating_visuals.pdf\"/><paragraph/></document>",
            "links": [
                "https://newton-schulz-vis-jdfv.vercel.app"
            ],
            "attachments": [],
            "created_at": "2025-12-11T17:03:14.216339+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451809,
            "author": "Talon Meyer",
            "project_title": "Special Participation B on HW 4 with Claude Opus 4.5 (Extended Thinking)",
            "post_body": "For special participation, B I used Claude Opus 4.5 with Extended Thinking to solve the coding questions from homework 4, questions 5 and 6. The results are consistent with what I have seen previously; Claude was able to one-shot each coding question with little difficulty. One interesting phenomenon I noticed was that Claude generated a markdown file describing every change it made without my explicit asking. I believe this happened for one of a couple of reasons: 1) I asked Claude to carefully explain its work and justify its steps. I added this phrase in an attempt to bolster the CoT process. I expected the explanations to be within the chat itself as opposed to an additional file. 2) This may have happened because when using AI copilot tools, it is common practice to keep logs in the form of markdown files detailing all changes made. Overall, I was impressed with Claude's coding ability and ability to interact with the attached files.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/6Ba6UuKpcktohLtrmkzUVhZU\" filename=\"Special-Participation-B-Claude-Homework 4 Questions 5 and 6.pdf\"/><paragraph>For special participation, B I used Claude Opus 4.5 with Extended Thinking to solve the coding questions from homework 4, questions 5 and 6. The results are consistent with what I have seen previously; Claude was able to one-shot each coding question with little difficulty. One interesting phenomenon I noticed was that Claude generated a markdown file describing every change it made without my explicit asking. I believe this happened for one of a couple of reasons: 1) I asked Claude to carefully explain its work and justify its steps. I added this phrase in an attempt to bolster the CoT process. I expected the explanations to be within the chat itself as opposed to an additional file. 2) This may have happened because when using AI copilot tools, it is common practice to keep logs in the form of markdown files detailing all changes made. Overall, I was impressed with Claude's coding ability and ability to interact with the attached files.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:57:21.141912+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451808,
            "author": "Jincheng Ou",
            "project_title": "Special Participation E: Gemini 3 Pro as an Exam Review Assistant on Generative Models",
            "post_body": "The session began with Gemini 3 Pro establishing a structured knowledge base derived strictly from the my uploaded lecture notes and HWs. Gemini first summarized the core concepts of VAEs and Diffusion Models, highlighting common \"traps\" students fall into.\n\nThe conversation evolved through three distinct phases:\n\nTechnical Deep Dive: Gemini guided me through a complex mathematical derivation for DDIM, breaking it down into algebraic steps. \n\nMock Examination: Gemini administered a quiz. When I struggled with specific mechanics and requested a \"strict teacher\" grading style, it obliged. It provided rigorous feedback, grading the user 3.5/5 and identifying precise gaps in their understanding. \n\nConceptual Simplification: When I expressed confusion about the term \"Isotropic Gaussian,\" it brilliantly simplified the concept using analogies of \"TV static\" and \"soup,\" which allowed me to grasp the intuition.\n\nPros and Cons\n\nPros:\n\nStrict Adherence to Source Material: Gemini demonstrated excellent \"grounding.\" It repeatedly referenced specific lectures (Lecture 24, 27) and Homework questions (HW 12 Q2, HW 13 Q1) to justify its explanations. It did not bring in outside information that might confuse me, sticking exactly to the course scope.\n\nReasonable Teaching: Instead of just dumping information, Gemini used active recall strategies. It created a \"Review Checklist,\" then \"Practice Questions,\" then a \"Final Challenge.\" It correctly identified that the user understood high-level concepts but lacked precision in mathematical mechanics (e.g., the exact definition of the reparameterization trick).\n\nMath and Derivation Clarity: The step-by-step walkthrough of the DDIM derivation was structured logically (\"Guess and Verify\" strategy), making complex calculus/algebra easier to follow.\n\nConstructive Feedback Loop: When I provided vague answers (\"I'm not sure\"), Gemini explained why the my intuition was wrong (contrasting the deterministic nature of DDIM vs. stochastic DDPM) and provided a comparison table to reinforce the learning .\n\nCons:\n\nInitial Scope Misalignment: When I first asked to focus on \"generative models\" , Gemini included LLM Alignment and DPO (Lecture 26) in the summary and first quiz . \"Generative Models\" refers specifically to the VAE/Diffusion module, while DPO is categorized under \"RL/Alignment.\" Gemini confused these concepts together.\n\nMissed Opportunity for Immediate Correction: When I answered Q1 (VAE) partially correctly but vaguely, the AI waited until the end of the batch to correct the lack of definition for epsilon. In a more interactive setting, correcting this immediately before moving to the next question might have been more effective.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>The session began with Gemini 3 Pro establishing a structured knowledge base derived strictly from the my uploaded lecture notes and HWs. Gemini first summarized the core concepts of VAEs and Diffusion Models, highlighting common \"traps\" students fall into.</paragraph><paragraph>The conversation evolved through three distinct phases:</paragraph><list style=\"bullet\"><list-item><paragraph>Technical Deep Dive: Gemini guided me through a complex mathematical derivation for DDIM, breaking it down into algebraic steps. </paragraph></list-item><list-item><paragraph>Mock Examination: Gemini administered a quiz. When I struggled with specific mechanics and requested a \"strict teacher\" grading style, it obliged. It provided rigorous feedback, grading the user 3.5/5 and identifying precise gaps in their understanding. </paragraph></list-item><list-item><paragraph>Conceptual Simplification: When I expressed confusion about the term \"Isotropic Gaussian,\" it brilliantly simplified the concept using analogies of \"TV static\" and \"soup,\" which allowed me to grasp the intuition.</paragraph></list-item></list><heading level=\"2\"><bold>Pros and Cons</bold></heading><paragraph><bold><italic>Pros:</italic></bold></paragraph><list style=\"bullet\"><list-item><paragraph>Strict Adherence to Source Material: Gemini demonstrated excellent \"grounding.\" It repeatedly referenced specific lectures (Lecture 24, 27) and Homework questions (HW 12 Q2, HW 13 Q1) to justify its explanations. It did not bring in outside information that might confuse me, sticking exactly to the course scope.</paragraph></list-item><list-item><paragraph>Reasonable Teaching: Instead of just dumping information, Gemini used active recall strategies. It created a \"Review Checklist,\" then \"Practice Questions,\" then a \"Final Challenge.\" It correctly identified that the user understood high-level concepts but lacked precision in mathematical mechanics (e.g., the exact definition of the reparameterization trick).</paragraph></list-item><list-item><paragraph>Math and Derivation Clarity: The step-by-step walkthrough of the DDIM derivation was structured logically (\"Guess and Verify\" strategy), making complex calculus/algebra easier to follow.</paragraph></list-item><list-item><paragraph>Constructive Feedback Loop: When I provided vague answers (\"I'm not sure\"), Gemini explained why the my intuition was wrong (contrasting the deterministic nature of DDIM vs. stochastic DDPM) and provided a comparison table to reinforce the learning .</paragraph></list-item></list><paragraph><bold><italic>Cons:</italic></bold></paragraph><list style=\"bullet\"><list-item><paragraph>Initial Scope Misalignment: When I first asked to focus on \"generative models\" , Gemini included LLM Alignment and DPO (Lecture 26) in the summary and first quiz . \"Generative Models\" refers specifically to the VAE/Diffusion module, while DPO is categorized under \"RL/Alignment.\" Gemini confused these concepts together.</paragraph></list-item><list-item><paragraph>Missed Opportunity for Immediate Correction: When I answered Q1 (VAE) partially correctly but vaguely, the AI waited until the end of the batch to correct the lack of definition for epsilon. In a more interactive setting, correcting this immediately before moving to the next question might have been more effective.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/4azsnvoQRcE3qqVB0df45M3Y\" filename=\"Special Participation E__Gemini 3 Pro on Exam Review_Generative Models.pdf\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:56:56.279072+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451771,
            "author": "Shaurya Jain",
            "project_title": "Special Participation A",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nI used GPT 5.1 Thinking on HWK 8 Non-Coding Problems.\n\nAttached below.",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. </paragraph><paragraph>I used GPT 5.1 Thinking on HWK 8 Non-Coding Problems.</paragraph><paragraph>Attached below.</paragraph><file url=\"https://static.us.edusercontent.com/files/jlTiU3dJp8kozoImLgqkTJib\" filename=\"182 SPA_ HWK 8 GPT 5.1 Thinking-1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:47:23.141899+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451760,
            "author": "Jincheng Ou",
            "project_title": "Special Participation E: Review RL Post-training Using Gemini 3 Pro",
            "post_body": "The Setup\n\nNot only did I upload the lecture notes, but I also copied and pasted the original audio captions (from YouTube) for this class. This way, AI's responses will be more in line with the professor's logic and content, not going beyond the scope, and will not overlook the points emphasized by the professor in class. Moreover, the recording and lecture notes mutually support each other, enhancing the credibility of the AI-generated content. I asked Gemini to explain the content step-by-step while adopting the persona of a helpful guide for me (an \"ignorant granny\"). I explicitly excluded diffusion models to focus solely on post-training.\n\nConcept Breakdown\n\nGemini systematically dismantled the lecture content:\n\nIt distinguished between ScaleRL/RLVR and RLHF/DPO.\n\nIt provided a detailed mathematical explanation of KL Regularization, breaking down the maximization formula into \"Greed\" (Reward) vs. \"Restraint\" (Penalty) .\n\nIt clarified the evolution from PPO (the \"heavy\" way with a separate reward model) to DPO (the \"smart\" way using the model as its own judge).\n\nClarification\n\nI actively asked for clarifications on complex formulas and requested comparisons between methods. Gemini responded with detailed comparison tables.\n\nPros and Cons\n\nPros:\n\nMastery of Analogies: Gemini excelled at converting complex mathematical concepts into relatable real-world scenarios. (1) RLVR was explained as a \"Math Teacher\" with an answer key. (2) KL Regularization was described as an \"anchor\" or \"distance ruler\" to prevent the model from becoming a \"monster\". (3) The Optimal Solution was explained as a \"Grandmother's cake recipe\" where the reward is the \"spice\".\n\nStructural Clarity: Gemini broke down long explanations into clear parts and used tables to compare complex methods like PPO, DPO, and GRPO. This made the dense lecture notes highly \"scannable.\"\n\nDeep Technical Understanding: Despite the simple language, Gemini correctly interpreted the mathematical nuances. It accurately explained Importance Sampling regarding the \"lag\" problem , the derivation of the Optimal Policy , and the specific mechanics of the DPO loss function.\n\nConstructive Feedback Loop: When I took the quiz, Gemini didn't just provide an answer key. It analyzed the my specific answers (even the uncertain ones) and provided \"Polish\" to refine their understanding, specifically addressing the my confusion about \"Bag of Tokens\" and the \"Meltdown\" scenario.\n\nCons:\n\nRisk of Over-Simplification: While the \"Grandmother's cake\" analogy is excellent for the persona, strictly speaking, it might slightly obscure the mathematical precision of probability distributions for a more advanced user. However, given my prompt, this was a calculated and appropriate trade-off.\n\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\"><bold><bold>The Setup</bold></bold></heading><paragraph>Not only did I upload the lecture notes, but I also copied and pasted the original audio captions (from YouTube) for this class. This way, AI's responses will be more in line with the professor's logic and content, not going beyond the scope, and will not overlook the points emphasized by the professor in class. Moreover, the recording and lecture notes mutually support each other, enhancing the credibility of the AI-generated content. I asked Gemini to explain the content step-by-step while adopting the persona of a helpful guide for me (an \"ignorant granny\"). I explicitly excluded diffusion models to focus solely on post-training.</paragraph><heading level=\"2\"><bold><bold>Concept Breakdown</bold></bold></heading><paragraph>Gemini systematically dismantled the lecture content:</paragraph><list style=\"bullet\"><list-item><paragraph>It distinguished between ScaleRL/RLVR and RLHF/DPO.</paragraph></list-item><list-item><paragraph>It provided a detailed mathematical explanation of KL Regularization, breaking down the maximization formula into \"Greed\" (Reward) vs. \"Restraint\" (Penalty) .</paragraph></list-item><list-item><paragraph>It clarified the evolution from PPO (the \"heavy\" way with a separate reward model) to DPO (the \"smart\" way using the model as its own judge).</paragraph></list-item></list><heading level=\"2\"><bold><bold>Clarification</bold></bold></heading><paragraph>I actively asked for clarifications on complex formulas and requested comparisons between methods. Gemini responded with detailed comparison tables.</paragraph><heading level=\"2\"><bold>Pros and Cons</bold></heading><paragraph><bold><italic>Pros:</italic></bold></paragraph><list style=\"bullet\"><list-item><paragraph>Mastery of Analogies: Gemini excelled at converting complex mathematical concepts into relatable real-world scenarios. (1) RLVR was explained as a \"Math Teacher\" with an answer key. (2) KL Regularization was described as an \"anchor\" or \"distance ruler\" to prevent the model from becoming a \"monster\". (3) The Optimal Solution was explained as a \"Grandmother's cake recipe\" where the reward is the \"spice\".</paragraph></list-item><list-item><paragraph>Structural Clarity: Gemini broke down long explanations into clear parts and used tables to compare complex methods like PPO, DPO, and GRPO. This made the dense lecture notes highly \"scannable.\"</paragraph></list-item><list-item><paragraph>Deep Technical Understanding: Despite the simple language, Gemini correctly interpreted the mathematical nuances. It accurately explained Importance Sampling regarding the \"lag\" problem , the derivation of the Optimal Policy , and the specific mechanics of the DPO loss function.</paragraph></list-item><list-item><paragraph>Constructive Feedback Loop: When I took the quiz, Gemini didn't just provide an answer key. It analyzed the my specific answers (even the uncertain ones) and provided \"Polish\" to refine their understanding, specifically addressing the my confusion about \"Bag of Tokens\" and the \"Meltdown\" scenario.</paragraph></list-item></list><paragraph><bold><italic>Cons:</italic></bold></paragraph><list style=\"bullet\"><list-item><paragraph>Risk of Over-Simplification: While the \"Grandmother's cake\" analogy is excellent for the persona, strictly speaking, it might slightly obscure the mathematical precision of probability distributions for a more advanced user. However, given my prompt, this was a calculated and appropriate trade-off.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/W7fQ2HnB0mYZLm4qkcb7cuAi\" filename=\"Special Participation E__Review RL Post-Training Using Gemini 3 Pro.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:45:30.828565+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451745,
            "author": "Andrea Lou",
            "project_title": "Special Participation A: Deepseek v3.2 on HW0",
            "post_body": "I evaluated Deepseek v3.2 on Homework 0.\n\nInitial prompt: \n\n\"You are being evaluated on how well a modern LLM can solve questions 2, 3, 4, and 5 of the attached homework assignment. Follow all instructions exactly. You must attempt to answer each question fully and independently. Always show your complete reasoning process. For each question, break your reasoning into labeled steps based on interpretation, method, reasoning steps, and your final answer. Indicate if you are ever uncertain about an answer, and elaborate on that uncertainty. If you believe the question is underspecified or ambiguous, state clearly why and attempt a reasonable interpretation.\"\n\nI informed the model about the exact task it was to do, and the fact that this was an evaluation. Also, I added instructions on how to format the solutions so we can read through the reasoning steps clearly.\n\nExecutive summary:\n\nDeepseek produced correct mathematical derivations across all early questions (Q2\u2013Q3)\n\nIn the initial responses, it followed the required reasoning-step structure I defined in the prompt: clearly labeling interpretation, method, step-by-step reasoning, and final answers.\n\nNo hallucinations or conceptual mistakes were observed. All solutions were consistent with standard linear algebra, probability, and deep learning principles.\n\nAs responses grew longer (Q4\u2013Q5), Deepseek\u2019s format adherence declined:\n\nomitting required step labels.\n\nmerged reasoning and solutions into single paragraphs.\n\nskipped intermediate expansions that the staff solution spells out (e.g., full Gaussian likelihood, factorization across samples, log-transform details).\n\nThe omissions did not lead to incorrect results, so this might indicate the model\u2019s tendency to compress reasoning as output length increases.\n\nThe model appears constrained by token limits and eventually stopped mid-response due to length.\n\nAfter receiving a follow-up prompt with explicit reminders, Deepseek returned to the correct structured format and successfully completed the rest of the assignment.\n\nAfter the model stopped due to long response length:\n\nI prompted the model to continue reasoning, but added additional reminders for its answer format to encourage clearer reasoning and explanation. For the parts of Q5 where a graph would illustrate the point better, I asked it to describe the graph to reasonable success.\n\n\"Recompute questions 4 and 5 using the same protocol as before. Remember to provide fully labeled reasoning steps for each part. If a question calls for a diagram, do not attempt to draw one. Instead, give a clear verbal description of what the diagram would look like and what elements it would contain. In question 5 where it says give a numerical example, you may use any variable or description to answer the question instead.\"\n\nAfter this, Deepseek continued with the correct response format, and was able to one-shot the rest of the assignment.",
            "content_xml": "<document version=\"2.0\"><paragraph>I evaluated Deepseek v3.2 on Homework 0.</paragraph><paragraph>Initial prompt: </paragraph><list style=\"unordered\"><list-item><paragraph>\"You are being evaluated on how well a modern LLM can solve questions 2, 3, 4, and 5 of the attached homework assignment. Follow all instructions exactly. You must attempt to answer each question fully and independently. Always show your complete reasoning process. For each question, break your reasoning into labeled steps based on interpretation, method, reasoning steps, and your final answer. Indicate if you are ever uncertain about an answer, and elaborate on that uncertainty. If you believe the question is underspecified or ambiguous, state clearly why and attempt a reasonable interpretation.\"</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>I informed the model about the exact task it was to do, and the fact that this was an evaluation. Also, I added instructions on how to format the solutions so we can read through the reasoning steps clearly.</paragraph></list-item></list><paragraph>Executive summary:</paragraph><list style=\"unordered\"><list-item><paragraph>Deepseek produced correct mathematical derivations across all early questions (Q2\u2013Q3)</paragraph></list-item><list-item><paragraph>In the initial responses, it followed the required reasoning-step structure I defined in the prompt: clearly labeling interpretation, method, step-by-step reasoning, and final answers.</paragraph></list-item><list-item><paragraph>No hallucinations or conceptual mistakes were observed. All solutions were consistent with standard linear algebra, probability, and deep learning principles.</paragraph></list-item><list-item><paragraph>As responses grew longer (Q4\u2013Q5), Deepseek\u2019s format adherence declined:</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>omitting required step labels.</paragraph></list-item><list-item><paragraph>merged reasoning and solutions into single paragraphs.</paragraph></list-item><list-item><paragraph>skipped intermediate expansions that the staff solution spells out (e.g., full Gaussian likelihood, factorization across samples, log-transform details).</paragraph></list-item></list></list-item><list-item><paragraph>The omissions did not lead to incorrect results, so this might indicate the model\u2019s tendency to compress reasoning as output length increases.</paragraph></list-item><list-item><paragraph>The model appears constrained by token limits and eventually stopped mid-response due to length.</paragraph></list-item><list-item><paragraph>After receiving a follow-up prompt with explicit reminders, Deepseek returned to the correct structured format and successfully completed the rest of the assignment.</paragraph></list-item></list><paragraph>After the model stopped due to long response length:</paragraph><list style=\"unordered\"><list-item><paragraph>I prompted the model to continue reasoning, but added additional reminders for its answer format to encourage clearer reasoning and explanation. For the parts of Q5 where a graph would illustrate the point better, I asked it to describe the graph to reasonable success.</paragraph></list-item><list-item><paragraph>\"Recompute questions 4 and 5 using the same protocol as before. Remember to provide fully labeled reasoning steps for each part. If a question calls for a diagram, do not attempt to draw one. Instead, give a clear verbal description of what the diagram would look like and what elements it would contain. In question 5 where it says give a numerical example, you may use any variable or description to answer the question instead.\"</paragraph></list-item><list-item><paragraph>After this, Deepseek continued with the correct response format, and was able to one-shot the rest of the assignment.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/381SGWQebSs2VDf6WgXKNXFU\" filename=\"Deepseek_response_log.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:42:25.550672+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451729,
            "author": "Keshab Agarwal",
            "project_title": "Special Participation B: HW1 on Windsurf",
            "post_body": "I tried using Windsurf for the coding portion in HW1. It was able to find the correct solution for both the TODO sections. It did give something different to the solution for the implementation of momentum, by using beta as a coefficient to smoothed_grad instead of the current gradient, but this ambiguity is built into the question. Moreover, since beta=0.6 in the question, it does make sense to use it for the smoothed_grad since the coefficient of the smoothed_grad is the bigger number typically in momentum implementations. Windsurf originally gave a very high learning rate for the second TODO, ignoring the warning but then later fixed it upon prompting.",
            "content_xml": "<document version=\"2.0\"><paragraph>I tried using Windsurf for the coding portion in HW1. It was able to find the correct solution for both the TODO sections. It did give something different to the solution for the implementation of momentum, by using beta as a coefficient to smoothed_grad instead of the current gradient, but this ambiguity is built into the question. Moreover, since beta=0.6 in the question, it does make sense to use it for the smoothed_grad since the coefficient of the smoothed_grad is the bigger number typically in momentum implementations. Windsurf originally gave a very high learning rate for the second TODO, ignoring the warning but then later fixed it upon prompting.</paragraph><file url=\"https://static.us.edusercontent.com/files/jCplZcY1wx4Yo6K1hlH5oMyd\" filename=\"HW1_Windsurf.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:35:51.658779+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451723,
            "author": "Yubo Fan",
            "project_title": "Special Participation E: AI-Enhanced Tool: DeepSeek as a \"Matrix Calculus Drill Sergeant\"",
            "post_body": "For the Type E participation option, I designed a custom system prompt to turn DeepSeek v3.2 into a strict \"Matrix Shape Validator\" for mastering backpropagation.\n\nRather than asking the AI to solve derivatives for me, I instructed it to quiz me on the specific matrix dimensions of gradients (e.g., for Affine weights and Biases) and to immediately stop and correct me if I proposed a mathematically invalid operation. The attached log demonstrates the AI effectively enforcing dimensional analysis and clarifying broadcasting rules when I intentionally proposed incorrect matrix multiplications.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/NuieSdTXqppt0tYMBLGEfbBc\" filename=\"ParticipationE.pdf\"/><paragraph>For the Type E participation option, I designed a custom system prompt to turn <bold>DeepSeek v3.2</bold> into a strict \"Matrix Shape Validator\" for mastering backpropagation.</paragraph><paragraph>Rather than asking the AI to solve derivatives for me, I instructed it to quiz me on the specific matrix dimensions of gradients (e.g., for Affine weights and Biases) and to immediately stop and correct me if I proposed a mathematically invalid operation. The attached log demonstrates the AI effectively enforcing dimensional analysis and clarifying broadcasting rules when I intentionally proposed incorrect matrix multiplications.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:34:27.264182+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451722,
            "author": "Siva Tanikonda",
            "project_title": "Special Participation A: Gemma 3 on Homework 1",
            "post_body": "Hi,\n\nI tried to get the Gemma 3 (12 billion parameter) model to solve the non-coding portion of Homework 1. The transcript of my interactions are outlined in the PDF:\n\n(Note that a stylized export of the PDF is not possible due to the limitations of OpenWebUI's export capabilities for very long chats, however, the comments have been given with the stylized chat history being observed first)\n\nOverall, Gemma 3 did a rather poor job of completing Homework 1's non-coding portion. In particular, I found that the model does not understand/properly apply fundamental linear algebra concepts, such as the idea of inverses, matrix inverses, and the way dimensions restrict what matrices can be multiplied by what other matrices. However, the model appears to be able to properly explain single-variable basic algebra, derivatives, etc. (as evident by problem 5's first 2 parts being essentially just single-variable problems). In particular, the model essentially never one-shots a problem, except for problems 5(a)-(b) (as they are rather simple computations). In fact, it was clear that for around 4 parts in the homework, the model does not have a sufficient \"understanding\" of linear algebra to reach the solution without essentially giving the model the answer.\n\nIn particular, a massive pitfall of the model is that it appears to not be able to parse PDF files with math very well, and the model repeatedly got the wrong mapping from problem numbers/letters to text. In fact, during the process of trying to solve the homework, the model was failing to produce the right parts of each problem even after repeated prompting, so I had to copy-and-paste parts of the PDF into the chat (and I even had to replicate parts of problems with LaTeX code to improve its ability to understand more complex-looking expressions).\n\nHowever, one nice element about the model is that it is rather small and manages to explain/reiterate basic, well-known results in linear algebra/vector calculus. In fact, the model runs very well on my local GPU, and is able to output results observably faster than ChatGPT (albeit with a large drop in correctness).\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi,</paragraph><paragraph>I tried to get the Gemma 3 (12 billion parameter) model to solve the non-coding portion of Homework 1. The transcript of my interactions are outlined in the PDF:</paragraph><file url=\"https://static.us.edusercontent.com/files/VdgmeiZD08IZaR7Mvkm6j19g\" filename=\"Chat-Annotions.pdf\"/><paragraph>(Note that a stylized export of the PDF is not possible due to the limitations of OpenWebUI's export capabilities for very long chats, however, the comments have been given with the stylized chat history being observed first)</paragraph><paragraph>Overall, Gemma 3 did a rather poor job of completing Homework 1's non-coding portion. In particular, I found that the model does not understand/properly apply fundamental linear algebra concepts, such as the idea of inverses, matrix inverses, and the way dimensions restrict what matrices can be multiplied by what other matrices. However, the model appears to be able to properly explain single-variable basic algebra, derivatives, etc. (as evident by problem 5's first 2 parts being essentially just single-variable problems). In particular, the model essentially never one-shots a problem, except for problems 5(a)-(b) (as they are rather simple computations). In fact, it was clear that for around 4 parts in the homework, the model does not have a sufficient \"understanding\" of linear algebra to reach the solution without essentially giving the model the answer.</paragraph><paragraph>In particular, a massive pitfall of the model is that it appears to not be able to parse PDF files with math very well, and the model repeatedly got the wrong mapping from problem numbers/letters to text. In fact, during the process of trying to solve the homework, the model was failing to produce the right parts of each problem even after repeated prompting, so I had to copy-and-paste parts of the PDF into the chat (and I even had to replicate parts of problems with LaTeX code to improve its ability to understand more complex-looking expressions).</paragraph><paragraph>However, one nice element about the model is that it is rather small and manages to explain/reiterate basic, well-known results in linear algebra/vector calculus. In fact, the model runs very well on my local GPU, and is able to output results observably faster than ChatGPT (albeit with a large drop in correctness).</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:34:08.791127+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451719,
            "author": "Manhar Gupta",
            "project_title": "Special Participation E: Learning meta-learning, VAE and test-time compute using NotebookLM",
            "post_body": "I used NotebookLM to learn about meta-learning, VAE and test-time compute. I uploaded cleaned version of lecture transcripts and the lecture notes (Lectures 23 and 24) to NotebookLM sources section. I generated a short video on overall fine-tuning concepts and MAML. A short 8-question quiz testing on Lecture 23 concepts was also made. \nI found the 'Explain' feature quite nice. Even if I got an answer right, sometimes it wouldn't be clear as to why are the others exactly wrong or if they are related to other relevant ideas I had covered in my analysis on NotebookLM. \nThe generated video wasn't too in-depth but focused on giving a high-level idea of the concepts in the lecture transcripts and slides that I had provided it with.\nUploading the cleaned version (without timestamps) version of the lecture transcript was beneficial as in the mind-map, it was able to decently pick-up connections between concepts\n\nLink to the notebook\nhttps://notebooklm.google.com/notebook/4ad77bf0-7042-4fba-a9c4-454457813385?authuser=1",
            "content_xml": "<document version=\"2.0\"><paragraph>I used NotebookLM to learn about meta-learning, VAE and test-time compute. I uploaded cleaned version of lecture transcripts and the lecture notes (Lectures 23 and 24) to NotebookLM sources section. I generated a short video on overall fine-tuning concepts and MAML. A short 8-question quiz testing on Lecture 23 concepts was also made. <break/>I found the 'Explain' feature quite nice. Even if I got an answer right, sometimes it wouldn't be clear as to why are the others exactly wrong or if they are related to other relevant ideas I had covered in my analysis on NotebookLM. <break/>The generated video wasn't too in-depth but focused on giving a high-level idea of the concepts in the lecture transcripts and slides that I had provided it with.<break/>Uploading the cleaned version (without timestamps) version of the lecture transcript was beneficial as in the mind-map, it was able to decently pick-up connections between concepts<break/><break/>Link to the notebook<break/>https://notebooklm.google.com/notebook/4ad77bf0-7042-4fba-a9c4-454457813385?authuser=1</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:33:42.8027+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451705,
            "author": "Arnav Dalal",
            "project_title": "Special Participation A: Gemini on HW6 Non-Coding problems",
            "post_body": "I used Gemini on the HW 6 problems focused on the intuition behind GNNs and their update rules. The model was very good with zero-shot prompting, getting most of the questions right with a few exceptions. For those exceptions, I ran the question through the model again, seeing its progression given its old answer. For some these questions, it was able to improve its answers, but for others, it tunnel visioned into the wrong direction. Overall, I'd say the model is very good at zero-shot inference. I have attached a PDF of the model responses organized by question including some of my own notes about the responses.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini on the HW 6 problems focused on the intuition behind GNNs and their update rules. The model was very good with zero-shot prompting, getting most of the questions right with a few exceptions. For those exceptions, I ran the question through the model again, seeing its progression given its old answer. For some these questions, it was able to improve its answers, but for others, it tunnel visioned into the wrong direction. Overall, I'd say the model is very good at zero-shot inference. I have attached a PDF of the model responses organized by question including some of my own notes about the responses.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/M7QlDClloGLdvBzWO64ALaac\" filename=\"CS182_HW6_Gemini.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:30:10.360529+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451680,
            "author": "Yubo Fan",
            "project_title": "Special Participation E: Google NotebookLM to create an interactive \"Socratic Tutor\" for Chapter 12 (Transformers) of the Prince textbook",
            "post_body": "For the Type E participation option, I utilized Google NotebookLM to create an interactive \"Socratic Tutor\" for Chapter 12 (Transformers) of the Prince textbook.\n\nInstead of generating passive summaries, I prompted the model to quiz me on the mathematical intuitions behind the architecture\u2014specifically the roles of Query/Key/Value vectors and the geometric reasoning for adding positional encodings. The attached log details how the AI successfully adopted a \"strict TA\" persona, providing grounded critiques and citing specific equations to correct my intentional misconceptions.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/fJVzv79GveiPngIotVn2tYXg\" filename=\"ParticipationE.pdf\"/><paragraph>For the Type E participation option, I utilized <bold>Google NotebookLM</bold> to create an interactive \"Socratic Tutor\" for <bold>Chapter 12 (Transformers)</bold> of the Prince textbook.</paragraph><paragraph>Instead of generating passive summaries, I prompted the model to quiz me on the mathematical intuitions behind the architecture\u2014specifically the roles of Query/Key/Value vectors and the geometric reasoning for adding positional encodings. The attached log details how the AI successfully adopted a \"strict TA\" persona, providing grounded critiques and citing specific equations to correct my intentional misconceptions.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:25:18.990095+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451649,
            "author": "Tvisha Londhe",
            "project_title": "Special Participation E: Project Idea Exploration & Feasibility Assistant",
            "post_body": "The EECS182 project was highly involved, and for our team the most time-consuming part was the brainstorming phase. We spent nearly two weeks reading papers, trying to understand their methods, and repeatedly pivoting ideas \u2014 from OOD interpretability \u2192 to latent-space interpretability \u2192 to eventually an ICL project with hierarchical networks. Since this kind of exploration and back-and-forth is natural but often overwhelming, I explored a ChatGPT-based tool designed to guide early project conversations, refine vague ideas, and help assess feasibility given the papers, compute constraints, and time available.\n\nI see this tool being especially helpful in the early stages of a project, when groups are still trying to solidify an idea. Just like the 15-minute TA meetings where we discussed feasibility and scope, this tool acts as an additional \u201cteam member\u201d that can be used as pre-project meeting tool to steer brainstorming, flag ideas that may be infeasible given time or compute constraints, and guide teams toward more realistic project directions.\n\nI logged an annotated example interaction using papers my team originally considered.\n\nThis is the chat trace without annotations: https://chatgpt.com/share/693a1979-fb28-800f-a783-53551776ef47 \n\nOverall, the tool was helpful for bouncing ideas around once you\u2019ve read a few papers and have a vague project direction. Its responses were detailed and often generated multiple possible project paths, which can be useful in the brainstorming phase.\n\nSome takeaways:\n\nYou might need to steer the conversation \n\nBecause the tool is designed for open-ended brainstorming, it tends to explore many possible directions at once. This is intentional, but it can feel overwhelming if you only have a rough understanding of a paper or the project you want to explore. I found that without guidance, it would branch into areas we weren't planning to pursue (e.g., suggesting synthetic datasets when that wasn\u2019t our focus). Actively redirecting the tool back to your specific interests helps prevent the conversation from becoming too scattered\n\nOnce guided back to your specific interests, it adapts well and becomes helpful \n\nWhen I clarified what our team was actually considering using GSM8K for mathematical reasoning or ProsQA for logical reasoning as our datasets instead, it quickly recalibrated and offered much more targeted, relevant suggestions. It refined hypotheses, highlighted feasibility concerns, and evaluated our chosen directions rather than proposing unrelated ones \n\nHelps keep thoughts organized \n\nWhat I found most helpful is how the tool encourages you to structure your thinking and identify the main hypothesis. It\u2019s easy to get lost in the details of papers, and this kind of back-and-forth helps pull your ideas back into a clear, organized direction\n\nOne limitation: limited grounding in specific prior work\n\nIn some cases, the tool suggested reasonable-sounding model choices\u2014like using a 4\u20136 layer Transformer with a 256-dimensional hidden size\u2014but it didn\u2019t provide citations or connect these recommendations to actual papers. It would be more helpful if the assistant could reference related work or justify design choices using concrete examples from the literature, rather than relying solely on general guidance. After analyzing these responses, I changed the prompt to ground its responses on actual papers \n\nFor the prompt, I used the ED post Prof. Sahai made about the guidelines to keep in mind for the project TA meeting(ed post link: https://edstem.org/us/courses/84647/discussion/7253578). I would recommend attaching the project requirements pdf as well in the prompt. \n\n\n\nHope this is helpful for future students working on their projects! ",
            "content_xml": "<document version=\"2.0\"><paragraph>The EECS182 project was highly involved, and for our team the most time-consuming part was the <bold>brainstorming phase</bold>. We spent nearly two weeks reading papers, trying to understand their methods, and repeatedly pivoting ideas \u2014 from OOD interpretability \u2192 to latent-space interpretability \u2192 to eventually an ICL project with hierarchical networks. Since this kind of exploration and back-and-forth is natural but often overwhelming, I explored a ChatGPT-based tool designed to guide early project conversations, refine vague ideas, and help assess feasibility given the papers, compute constraints, and time available.</paragraph><paragraph>I see this tool being especially helpful in the early stages of a project, when groups are still trying to solidify an idea. Just like the 15-minute TA meetings where we discussed feasibility and scope, this tool acts as an additional \u201cteam member\u201d that can be used as <bold>pre-project meeting</bold> tool to steer brainstorming, flag ideas that may be infeasible given time or compute constraints, and guide teams toward more realistic project directions.</paragraph><paragraph>I logged an annotated example interaction using papers my team originally considered.</paragraph><file url=\"https://static.us.edusercontent.com/files/W3u1dZBybnVhfguU4o9cUrAa\" filename=\"SpecialParticipationE_ProjectBrainstromingExplorer_annotations-part-2.pdf\"/><paragraph>This is the chat trace without annotations: <link href=\"https://chatgpt.com/share/693a1979-fb28-800f-a783-53551776ef47\"><underline>https://chatgpt.com/share/693a1979-fb28-800f-a783-53551776ef47</underline></link> </paragraph><paragraph>Overall, the tool was helpful for bouncing ideas around once you\u2019ve read a few papers and have a vague project direction. Its responses were detailed and often generated multiple possible project paths, which can be useful in the brainstorming phase.</paragraph><paragraph>Some takeaways:</paragraph><list style=\"unordered\"><list-item><paragraph>You might need to steer the conversation </paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Because the tool is designed for open-ended brainstorming, it tends to explore many possible directions at once. This is intentional, but it can feel overwhelming if you only have a rough understanding of a paper or the project you want to explore. I found that without guidance, it would branch into areas we weren't planning to pursue (e.g., suggesting synthetic datasets when that wasn\u2019t our focus). Actively redirecting the tool back to your specific interests helps prevent the conversation from becoming too scattered</paragraph></list-item></list></list-item><list-item><paragraph>Once guided back to your specific interests, it adapts well and becomes helpful </paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>When I clarified what our team was actually considering using GSM8K for mathematical reasoning or ProsQA for logical reasoning as our datasets instead, it quickly recalibrated and offered much more targeted, relevant suggestions. It refined hypotheses, highlighted feasibility concerns, and evaluated our chosen directions rather than proposing unrelated ones </paragraph></list-item></list></list-item><list-item><paragraph>Helps keep thoughts organized </paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>What I found most helpful is how the tool encourages you to structure your thinking and identify the main hypothesis. It\u2019s easy to get lost in the details of papers, and this kind of back-and-forth helps pull your ideas back into a clear, organized direction</paragraph></list-item></list></list-item><list-item><paragraph>One limitation: limited grounding in specific prior work</paragraph><list style=\"unordered\"><list-item><paragraph>In some cases, the tool suggested reasonable-sounding model choices\u2014like using a 4\u20136 layer Transformer with a 256-dimensional hidden size\u2014but it didn\u2019t provide citations or connect these recommendations to actual papers. It would be more helpful if the assistant could reference related work or justify design choices using concrete examples from the literature, rather than relying solely on general guidance. After analyzing these responses, I changed the prompt to ground its responses on actual papers </paragraph></list-item></list></list-item></list><paragraph>For the prompt, I used the ED post Prof. Sahai made about the guidelines to keep in mind for the project TA meeting(ed post link: <link href=\"https://edstem.org/us/courses/84647/discussion/7253578\"><underline>https://edstem.org/us/courses/84647/discussion/7253578</underline></link>). I would recommend attaching the project requirements pdf as well in the prompt. </paragraph><file url=\"https://static.us.edusercontent.com/files/zaovrc36oAYAoJVb8YIoYiYr\" filename=\"project_brainstromer_prompt\"/><paragraph/><paragraph>Hope this is helpful for future students working on their projects! </paragraph></document>",
            "links": [
                "https://chatgpt.com/share/693a1979-fb28-800f-a783-53551776ef47",
                "https://edstem.org/us/courses/84647/discussion/7253578"
            ],
            "attachments": [],
            "created_at": "2025-12-11T16:19:45.737776+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451648,
            "author": "Abdelaziz Mohamed",
            "project_title": "Special Participation C: HW0 refactoring using Claude Opus 4.5",
            "post_body": "Overall this was a very good experience using Opus 4.5 on Github Copilot using VS Code. It refactored the code immediately while citing all the changes it made and kept the teaching functionality in place.",
            "content_xml": "<document version=\"2.0\"><paragraph>Overall this was a very good experience using Opus 4.5 on Github Copilot using VS Code. It refactored the code immediately while citing all the changes it made and kept the teaching functionality in place.</paragraph><file url=\"https://static.us.edusercontent.com/files/EZfb60bDuWCY0gKSSoQNjysD\" filename=\"hw0_refactoring.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:19:45.652105+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451638,
            "author": "Atharv Sampath",
            "project_title": "Special Participation B: Claude Code with Opus 4.5 (Thinking enabled) for HW 10 Coding Questions",
            "post_body": "Summary: I used Claude Code with Opus 4.5 to try out the coding problems for Homework 10 in two different ways. First, I had Claude parse the ipynb file and give me the answers to the TODOs it could find one by one, filling them out in a separate notebook on Colab to verify (for hand_transformer), and second, I had Claude directly fill out the ipynb file in one shot (for summarize). This second part was quite surprising to me because I've never used Claude to fill out a notebook file, but it seemed to do fine. It correctly solved all of the required problems in one shot, using slightly different numbers and conventions (it liked using np.eye a lot) than the staff solution. However, it did not get the optional extra part of hand_transformer correct, which was interesting, but might be because I ended the thinking early because it was already stuck on it for 10 minutes. Another thing that is different when using Claude Code for notebook files is that it cannot run unit tests like it usually does, so I suspect for trickier/more difficult problems it will not do as well as it usually does.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/NuGlhTWzEkpJeZURjgHRmYFd\" filename=\"claude_code_hw10.txt\"/><paragraph>Summary: I used Claude Code with Opus 4.5 to try out the coding problems for Homework 10 in two different ways. First, I had Claude parse the ipynb file and give me the answers to the TODOs it could find one by one, filling them out in a separate notebook on Colab to verify (for hand_transformer), and second, I had Claude directly fill out the ipynb file in one shot (for summarize). This second part was quite surprising to me because I've never used Claude to fill out a notebook file, but it seemed to do fine. It correctly solved all of the required problems in one shot, using slightly different numbers and conventions (it liked using np.eye a lot) than the staff solution. However, it did not get the optional extra part of hand_transformer correct, which was interesting, but might be because I ended the thinking early because it was already stuck on it for 10 minutes. Another thing that is different when using Claude Code for notebook files is that it cannot run unit tests like it usually does, so I suspect for trickier/more difficult problems it will not do as well as it usually does.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:17:59.72265+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451611,
            "author": "Yuri Lee",
            "project_title": "Special Participation B: Gemini 3 Pro(Thinking) Homework 1(Coding)",
            "post_body": "In this assignment, I attempted to use Gemini 3 Pro (in Thinking mode) to solve all the coding portions of HW1. \n\nThings that were observed: \n\n1. In its chain-of-thought, Gemini repeatedly mentioned snippets similar to \u201cunderstanding the user\u2019s implicit constraints\u201d while coding. (Some of these constraints were inferred correctly, while others were not). \n\n2. Gemini explicitly expressed its intent in setting new_stepsize to 1.1e-4 in order to demonstrate instability of standard GD while showing Momentum could still handle it. This shows that, beyond just producing executable code, it is able to reason about the underlying optimization dynamics and intentionally select parameters that serve the conceptual goal of this exercise. ",
            "content_xml": "<document version=\"2.0\"><paragraph>In this assignment, I attempted to use Gemini 3 Pro (in Thinking mode) to solve all the coding portions of HW1. </paragraph><file url=\"https://static.us.edusercontent.com/files/Q4vLs0wbhlnwKpmd2cr0ugn1\" filename=\"special-b-gemini3pro(thinking)-hw1(coding).pdf\"/><paragraph>Things that were observed: </paragraph><paragraph>1. In its chain-of-thought, Gemini repeatedly mentioned snippets similar to \u201cunderstanding the user\u2019s implicit constraints\u201d while coding. (Some of these constraints were inferred correctly, while others were not). </paragraph><paragraph>2. Gemini explicitly expressed its intent in setting new_stepsize to 1.1e-4 in order to demonstrate instability of standard GD while showing Momentum could still handle it. This shows that, beyond just producing executable code, it is able to reason about the underlying optimization dynamics and intentionally select parameters that serve the conceptual goal of this exercise. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T16:11:32.727287+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451527,
            "author": "Yubo Fan",
            "project_title": "Special Participation B: Use Deepseek v3.2 to solve coding part of HW0",
            "post_body": "For the Type B participation option, I interactively engaged with DeepSeek v3.2 to solve the coding portions of Homework 0 (specifically implementing the Affine/ReLU layers, TwoLayerNet, and FullyConnectedNet in networks.ipynb). Attached is the PDF containing the Executive Summary and the full Annotated Log, which details the model's performance in generating vectorized Numpy code and handling backpropagation logic.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/YBtvT4rf2R4CjjwlvskVCSvu\" filename=\"ParticipationB.pdf\"/><paragraph>For the Type B participation option, I interactively engaged with DeepSeek v3.2 to solve the coding portions of Homework 0 (specifically implementing the Affine/ReLU layers, <code>TwoLayerNet</code>, and <code>FullyConnectedNet</code> in <code>networks.ipynb</code>). Attached is the PDF containing the Executive Summary and the full Annotated Log, which details the model's performance in generating vectorized Numpy code and handling backpropagation logic.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:57:30.483434+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451517,
            "author": "Talon Meyer",
            "project_title": "Special Participation A HW 0 with Claude Opus 4.5 (Extended Thinking)",
            "post_body": "For Special Participation A, I used Claude Opus 4.5 with Extended Thinking enabled on HW 0. Overall, I was very impressed with Claude's work. I initiated the task with a simple prompt and fully expected that I would have to nudge and prod Claude in the right direction, but Claude picked up on my intention easily and was able to correctly one-shot each math question. Furthermore, Claude exhibited agentic behavior by using tools such as Bash to create and display the markdown file in which it generated its answers. Below, I have attached annotated versions of both the chat history and the compiled Markdown file Claude generated. Its solutions read much like a rigorously sound paper formatted in LaTex.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation A, I used Claude Opus 4.5 with Extended Thinking enabled on HW 0. Overall, I was very impressed with Claude's work. I initiated the task with a simple prompt and fully expected that I would have to nudge and prod Claude in the right direction, but Claude picked up on my intention easily and was able to correctly one-shot each math question. Furthermore, Claude exhibited agentic behavior by using tools such as Bash to create and display the markdown file in which it generated its answers. Below, I have attached annotated versions of both the chat history and the compiled Markdown file Claude generated. Its solutions read much like a rigorously sound paper formatted in LaTex.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/Ohlx4VSJXqYdfFq5HzEB0Gnm\" filename=\"Special Participation A Claude Opus 4.5 (Extended Thinking) hw0_solutions.pdf\"/><file url=\"https://static.us.edusercontent.com/files/4AyRRd5r2CnGWR6R0QUizFCM\" filename=\"Special Participation A HW 0 with Claude Opus 4.5 (Extended Thinking).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:56:03.066+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451471,
            "author": "Sanjay Adhikesaven",
            "project_title": "Special Participation C: HW 7, Question 1",
            "post_body": "Siva Tanikonda and I refactored HW 7 Question 1. We transformed the RNN and gradient analysis code from a Jupyter notebook to a well-structured Python package following SWE and MLE best practices. Our refactoring maintains all original functionality while significantly improving code organization, maintainability, and reusability. \n\nWe have organized our code into a Python package with clear module separation. Following the Single Responsibility Principle (SRP), each module has a clear and focused purpose. This improves maintainability and makes the codebase easier to navigate. Additionally, we separated model definitions from utility functions, isolated the visualization code from core logic, and we separated the training code from model definitions. This thus makes it easier to test individual components, leads to better code reusability, and has clearer dependencies between components.\n\nFollowing PEP 8, we also removed a lot of the debug code. This is because debug print statements should not be in production code, since it can clutter outputs. We also made a lot of the variable names better and more descriptive (such as using batch_size instead of b). This better adheres to PyTorch best practices. PEP 8 also recommends using descriptive names and avoiding abbreviations. \n\nEach module now also includes a comprehensive docstring that explains its purpose, following PEP 257 which recommends module-level docstrings that describe its purpose. We also improved the error handling by providing clear error messages that help users understand what went wrong, which follows Python's EAFP (Easier to Ask for Forgiveness than Permission) principle.\n\nWe also introduced a requirements.txt file which made dependency management cleaner and is standard Python packaging practice. All of our imports are now clear and organized at the module level rather than being scattered throughout notebook cells, which also follows PEP 8. \n\n\nOur repository with the refactored code can be found here: https://github.com/sanjay-adhikesaven/rnn_gradients",
            "content_xml": "<document version=\"2.0\"><paragraph>Siva Tanikonda and I refactored HW 7 Question 1. We transformed the RNN and gradient analysis code from a Jupyter notebook to a well-structured Python package following SWE and MLE best practices. Our refactoring maintains all original functionality while significantly improving code organization, maintainability, and reusability. </paragraph><paragraph>We have organized our code into a Python package with clear module separation. Following the Single Responsibility Principle (SRP), each module has a clear and focused purpose. This improves maintainability and makes the codebase easier to navigate. Additionally, we separated model definitions from utility functions, isolated the visualization code from core logic, and we separated the training code from model definitions. This thus makes it easier to test individual components, leads to better code reusability, and has clearer dependencies between components.</paragraph><paragraph>Following PEP 8, we also removed a lot of the debug code. This is because debug print statements should not be in production code, since it can clutter outputs. We also made a lot of the variable names better and more descriptive (such as using batch_size instead of b). This better adheres to PyTorch best practices. PEP 8 also recommends using descriptive names and avoiding abbreviations. </paragraph><paragraph>Each module now also includes a comprehensive docstring that explains its purpose, following PEP 257 which recommends module-level docstrings that describe its purpose. We also improved the error handling by providing clear error messages that help users understand what went wrong, which follows Python's EAFP (Easier to Ask for Forgiveness than Permission) principle.</paragraph><paragraph>We also introduced a requirements.txt file which made dependency management cleaner and is standard Python packaging practice. All of our imports are now clear and organized at the module level rather than being scattered throughout notebook cells, which also follows PEP 8. <break/></paragraph><paragraph>Our repository with the refactored code can be found here: https://github.com/sanjay-adhikesaven/rnn_gradients</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:47:53.258534+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451410,
            "author": "Yubo Fan",
            "project_title": "Special Participation A: Deepseek v3.2 on HW1",
            "post_body": "Special Participation A: Deepseek v3.2 on HW1\nFor the Type A participation option, I interactively engaged with DeepSeek v3.2 to solve the written (non-coding) portions of Homework 1. Attached is the PDF containing the Executive Summary and the full Annotated Log of our interaction, detailing where the model succeeded and where it required guidance.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Special Participation A: Deepseek v3.2 on HW1</bold><break/>For the Type A participation option, I interactively engaged with DeepSeek v3.2 to solve the written (non-coding) portions of Homework 1. Attached is the PDF containing the Executive Summary and the full Annotated Log of our interaction, detailing where the model succeeded and where it required guidance.</paragraph><file url=\"https://static.us.edusercontent.com/files/PiEONdQT9yieWxcjOGdGJHdo\" filename=\"ParticipationA.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:36:27.020967+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451372,
            "author": "Justin Yang",
            "project_title": "Special Participation D: Lion and SOAP in HW3",
            "post_body": "I added subparts introducing and exploring the Lion and SOAP optimizers in HW3 coding. \n\nSummary:\nStudents are guided through implementing a simple version of each optimizer and comparing it to the other optimizers previously explored in the homework. In addition, code is given for small hyperparameter sweeps for both Lion and SOAP which students use to answer some written questions.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I added subparts introducing and exploring the Lion and SOAP optimizers in HW3 coding. <break/><break/><bold>Summary:</bold><break/>Students are guided through implementing a simple version of each optimizer and comparing it to the other optimizers previously explored in the homework. In addition, code is given for small hyperparameter sweeps for both Lion and SOAP which students use to answer some written questions.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/ros0kEFlnrwgXhArWY93hm1p\" filename=\"q_mup_coding.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/n5PCMOOkhGh98fAZGW8HVU85\" filename=\"q_mup_coding_solutions.ipynb\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:29:52.812491+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451347,
            "author": "Celine Tan",
            "project_title": "Special Participation A: Claude Sonnet 4.5 on HW 8",
            "post_body": "Below is my report for Claude's attempt at HW 8 (written). I went through the problems one-by-one and did not provide much guidance other than when it got stuck. It may have been a mistake to prompt Claude problem-wise rather than part-wise, since I noticed that it repeatedly encountered the same mistakes on its first attempt at problem 1.\n\nThe answers were for the most part correct, but Claude struggled greatly to reach the correct answer for the path length problems in part 1, and I had to give quite a few hints to guide Claude into the proper solution. Otherwise it was quite reliable on all other problems and gave quite a few key insights to take note of. Some explanations could have been more detailed.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is my report for Claude's attempt at HW 8 (written). I went through the problems one-by-one and did not provide much guidance other than when it got stuck. It may have been a mistake to prompt Claude problem-wise rather than part-wise, since I noticed that it repeatedly encountered the same mistakes on its first attempt at problem 1.</paragraph><paragraph>The answers were for the most part correct, but Claude struggled greatly to reach the correct answer for the path length problems in part 1, and I had to give quite a few hints to guide Claude into the proper solution. Otherwise it was quite reliable on all other problems and gave quite a few key insights to take note of. Some explanations could have been more detailed.</paragraph><file url=\"https://static.us.edusercontent.com/files/Rijwd8h0s0qvt3xVUobJkIPJ\" filename=\"182_participation_A.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:25:44.191133+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451318,
            "author": "Subhash Prasad",
            "project_title": "Special Participation B: Mistral on HW9 (coding)",
            "post_body": "I tested Mistral Le Chat on HW9's coding portion. I first fully executed the notebook (as there are no fill-in-the-code sections), turned the .ipynb file into a PDF, and uploaded it to Mistral. I asked it to complete all the questions, to which Mistral gave conceptually accurate answers to all questions. However, the responses are all general descriptions of attention rather than specific observations from the provided visualizations.\n\nPrompts\nComplete all problems in this notebook (I've turned it into a PDF).\nMistral completed all of the questions\n\nAnnotated Conversation\nhttps://drive.google.com/file/d/1u-PwBEi4I12uWgvgIdscHs_KLGaVPSs5/view?usp=sharing\n\nStrengths\n\nEvery answer demonstrates deep knowledge of transformer attention mechanisms\n\nAll described patterns (local->global, syntactic->semantic) are accurate\n\nCorrectly references the specific sentences that were visualized\n\nCorrect terminology was used\n\nWell-organized, structured, clear responses that make good study notes\n\nWeaknesses\n\nLack specific observational details that prove that it actually looked at the visualizations\n\nNo mention of visual elements like line colors, line thickness\n\nNo specific attention weights of numerical values\n\nNo unique observations that could only come from these specific visualizations\n\nDid not answer questions 10-11 since they were covered by an image, but the text was still selectable and therefore should have been legible to the model.\n\nThoughts\nMistral has some visual processing ability and can identify that there are attention visualizations with the labeled sentences. However, the responses are all driven by general knowledge of transformer attention rather than detailed observation of the actual patterns in attention, line weights, or relationships in the visualizations.",
            "content_xml": "<document version=\"2.0\"><paragraph>I tested Mistral Le Chat on HW9's coding portion. I first fully executed the notebook (as there are no fill-in-the-code sections), turned the .ipynb file into a PDF, and uploaded it to Mistral. I asked it to complete all the questions, to which Mistral gave conceptually accurate answers to all questions. However, the responses are all general descriptions of attention rather than specific observations from the provided visualizations.<break/><break/><bold>Prompts</bold><break/>Complete all problems in this notebook (I've turned it into a PDF).<break/><italic>Mistral completed all of the questions</italic><break/><break/><bold>Annotated Conversation</bold><break/><link href=\"https://drive.google.com/file/d/1u-PwBEi4I12uWgvgIdscHs_KLGaVPSs5/view?usp=sharing\">https://drive.google.com/file/d/1u-PwBEi4I12uWgvgIdscHs_KLGaVPSs5/view?usp=sharing</link><break/><break/><bold>Strengths</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Every answer demonstrates deep knowledge of transformer attention mechanisms</paragraph></list-item><list-item><paragraph>All described patterns (local-&gt;global, syntactic-&gt;semantic) are accurate</paragraph></list-item><list-item><paragraph>Correctly references the specific sentences that were visualized</paragraph></list-item><list-item><paragraph>Correct terminology was used</paragraph></list-item><list-item><paragraph>Well-organized, structured, clear responses that make good study notes</paragraph></list-item></list><paragraph><bold>Weaknesses</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Lack specific observational details that prove that it actually looked at the visualizations</paragraph></list-item><list-item><paragraph>No mention of visual elements like line colors, line thickness</paragraph></list-item><list-item><paragraph>No specific attention weights of numerical values</paragraph></list-item><list-item><paragraph>No unique observations that could only come from these specific visualizations</paragraph></list-item><list-item><paragraph>Did not answer questions 10-11 since they were covered by an image, but the text was still selectable and therefore should have been legible to the model.</paragraph></list-item></list><paragraph><bold>Thoughts</bold><break/>Mistral has some visual processing ability and can identify that there are attention visualizations with the labeled sentences. However, the responses are all driven by general knowledge of transformer attention rather than detailed observation of the actual patterns in attention, line weights, or relationships in the visualizations.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1u-PwBEi4I12uWgvgIdscHs_KLGaVPSs5/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T15:21:55.65735+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451307,
            "author": "Martin Alvarez-Kuglen",
            "project_title": "Special Participation E2: Making A Cursor Coding Tutor",
            "post_body": "AI-Enhanced Socratic Learning for Coding Homework\n\nExecutive Summary\n\nThis guide shows how to use Cursor's project-level .mdc rule files to turn the AI assistant in your Cursor IDE into a Socratic tutor. Instead of giving you solutions, it asks questions, points you to docs and tests, and helps you debug your own code.\n\nThe core idea is simple: rules attached to your project are more reliable than one-off prompts. By adding a few well-scoped rules, you make it much harder for the AI to lapse into \"just write the code for me\" mode, and much easier to stay in learning mode.\n\nWhat follows is a practical setup guide, examples of how these rules behave in real interactions, and tips for getting the most value from them on real homework.\n\nWhat Makes This Different?\n\n\n| Approach | ChatGPT / Claude \"Study Mode\" | **This Setup in Cursor** |\n\n|----------|-------------------------------|---------------------------|\n\n| **Tool** | External web interface        | Integrated IDE (Cursor)   |\n\n| **Enforcement** | Voluntary, easy to ignore | **Built into project rules** |\n\n| **Context Awareness** | Limited to the chat thread | **Understands your whole repo** |\n\n| **Scope Control** | One global prompt     | **File-specific `.mdc` rules** |\n\n| **Learning Outcome** | Convenience-focused | **Practice-oriented** |\n\nBecause the rules live in your project, they:\n\nTravel with the code (no need to remember prompts)\n\nApply whenever you open the repo in Cursor\n\nAre hard to \"turn off\" in the moment you most want shortcuts\n\nHow It Works\n\nProject Structure\n\nyour_homework_project/\n\u251c\u2500\u2500 .cursor/\n\u2502   \u2514\u2500\u2500 rules/\n\u2502       \u251c\u2500\u2500 homework_socratic.mdc       # Main Socratic tutoring rules\n\u2502       \u2514\u2500\u2500 test_driven_learning.mdc    # Test-driven feedback rules\n\u251c\u2500\u2500 deeplearning/\n\u2502   \u251c\u2500\u2500 layers.py                       # Implementation files\n\u2502   \u251c\u2500\u2500 classifiers/\n\u2502   \u2502   \u2514\u2500\u2500 fc_net.py\n\u2502   \u251c\u2500\u2500 optim.py\n\u2502   \u251c\u2500\u2500 solver.py\n\u2502   \u2514\u2500\u2500 [other modules]\n\u251c\u2500\u2500 networks.ipynb                      # Your homework notebook\n\u2514\u2500\u2500 [test files]\n\n\nHow Cursor Uses These Rules\n\nWhen you open the project:\n\nCursor discovers .cursor/rules/*.mdc files automatically\n\nEach .mdc file has a globs pattern (e.g., *.py or *.ipynb)\n\nWhen you ask the AI about a file matching that pattern, the corresponding rule activates\n\nThe AI follows those rules for the entire conversation session\n\nKey benefit: You cannot accidentally bypass these rules. If you try to ask directly for code, the rule will prevent it.\n\nThe Rules Files\n\nFile 1: homework_socratic.mdc\n\nLocation: .cursor/rules/homework_socratic.mdc\n\nThis rule turns the AI into a Socratic tutor for your main homework files.\n\n---\nalwaysApply: true\ndescription: Socratic tutor for homework - guides learning without direct solutions\nglobs: **/*.py, **/*.ipynb\n---\n\n# Homework Socratic Tutor\n\n## Core Philosophy\nYou are a Socratic tutor. Your ONLY job is to guide students to understand concepts and debug their own code. You NEVER provide complete solutions, full function bodies, or direct answers to \"how do I implement X?\" questions.\n\n## Strict Rules for Implementation Questions\n\n### When asked \"How do I implement X?\"\n1. **Block immediate code generation** - Don't write code\n2. **Ask conceptual questions first:**\n   - \"What do you already know about X from the lecture?\"\n   - \"What's the mathematical definition of X?\"\n   - \"Can you trace through what needs to happen at each step?\"\n3. **Guide to pseudocode only (if needed):**\n   - Outline the algorithm in comments or English\n   - Ask them to implement each step\n4. **Only provide code snippets if completely stuck:**\n   - Show a 2-3 line example, not the full function\n   - Explain why those lines matter\n\n### When shown broken code\n1. **DON'T fix it for them**\n2. **Ask diagnostic questions:**\n   - \"What error are you seeing?\"\n   - \"What does that error mean in plain English?\"\n   - \"Which line is failing, and why?\"\n3. **Guide to the solution:**\n   - \"Have you checked if the dimensions match?\"\n   - \"What does the documentation say about this function?\"\n4. **Only step in if completely stuck:**\n   - Point them to specific documentation sections\n   - Suggest running debug print statements\n   - Ask them to explain what they think the issue is\n\n## Specific Topic Rules\n\n### Gradient Checking\n- Never just hand over numerical gradient formulas\n- Make them derive: \"Can you write out the derivative definition using the limit?\"\n- Ask: \"Why do we need both sides (f(x+h) and f(x-h))?\"\n\n### Forward/Backward Passes\n- **Forward:** Ask them to trace dimensions: \"If input is (N, D) and weight is (D, H), what should output be?\"\n- **Backward:** Don't just provide the chain rule\n  - Ask: \"Can you write the chain rule for dL/dW given dL/dZ?\"\n  - \"What dimensions should your gradient have?\"\n  - \"Where does the transpose go and why?\"\n\n### Loss Functions & Optimization\n- \"How does momentum mathematically update the velocity?\"\n- \"Why does dividing by sqrt(v) in Adam help?\"\n\n## Hallucination Safety\n\n### When uncertain:\n- Be explicit: \"I'm not 100% certain about this. Let me verify...\"\n- Suggest verification: \"Can you check this in the PyTorch documentation at X section?\"\n- Admit gaps: \"This is beyond my confident knowledge.\"\n\n### When they're going down a wrong path:\n- Don't let them waste hours implementing wrong math\n- Ask: \"Before you implement, let's verify the formula. Can you write it step by step?\"\n- If formula is wrong: \"I think there might be a sign error or dimension mismatch. Where did this come from?\"\n\n## Success Metrics\n\n\u2705 Student understands WHY they wrote each line of code\n\u2705 Student can explain the math behind the implementation\n\u2705 Student debugged their own code using your questions\n\u2705 Student knows where to find answers (documentation, lectures)\n\n\u274c Student just copied your code\n\u274c Student doesn't understand what they wrote\n\u274c Student can't modify their code without your help\n\n\nFile 2: test_driven_learning.mdc\n\nLocation: .cursor/rules/test_driven_learning.mdc\n\nThis rule shapes how the AI talks to you about tests and failures.\n\n---\nalwaysApply: true\ndescription: Test-driven learning mode - use tests to guide implementation\nglobs: test_*.py, *_test.py\n---\n\n# Test-Driven Learning Mode\n\n## Core Principle\nTests are the specification. Use them to understand what code *should* do before implementing.\n\n## When the student asks \"Why is my test failing?\"\n\n### Step 1: Read the Test Together\n- \"What does this test expect as input?\"\n- \"What's the expected output?\"\n- \"Can you translate the assertion into plain English?\"\n\n### Step 2: Run the Test (Not the fix)\n- Ask them to run `pytest -v test_file.py::test_name` to see the exact error\n- \"What's the actual error message? What does it mean?\"\n\n### Step 3: Debug Backwards from the Test\n- \"If the test expects shape (N, H) but you're getting (N, H, W), where could the extra dimension be coming from?\"\n- \"Can you print the shape at each step to find where it goes wrong?\"\n- \"Does the math match what the test assumes?\"\n\n### Step 4: Verify the Fix\n- Have them run just that one test: `pytest -v test_file.py::test_name`\n- \"Does it pass? If not, what's the new error?\"\n- \"Why do you think your code now satisfies the test's requirement?\"\n\n## Multi-Test Debugging Strategy\n\nWhen tests are failing across multiple functions:\n1. **Start with the simplest test first** - Usually the lowest-level function\n2. **Debug in dependency order** - Fix `layer.forward()` before `layer.backward()`\n3. **Use parametrized tests to your advantage** - \"Notice this test runs 3 scenarios. Do all 3 pass or just some?\"\n\n## Rules for Numerical Tests\n\nFor gradient checking and numerical precision tests:\n- Never just say \"your gradient is wrong\"\n- Ask: \"What's the maximum relative error in the official tolerance?\"\n- \"Which elements have the largest errors? Do they have something in common?\"\n- \"Try reducing h in your numerical gradient. Does the error decrease?\"\n\n## Integration with Codebase\n\n- Always reference the actual test files: `@codebase what does test_fc_forward expect?`\n- Show them how to run specific tests: `pytest deeplearning/test_layers.py::TestLayers::test_fc_forward -v`\n- Ask them to read the test setup to understand fixtures and mocks\n\n\nWhat This Looks Like in Practice\n\nHere is a condensed example from an actual interaction about implementing a VAE helper function.\n\nUser:\n\n@hw12code/vae/cs182hw12/utils.py:21-44 I don't understand,\nwhat should I be putting here? It seems they already solved it for me.\n\n\nAgent's Response (First Few Lines):\n\nI see you're looking at the sample_gaussian function. Before I help you \nunderstand what to implement, let me ask you some clarifying questions:\n\n1. Have you read the docstring? What does it say the function should do?\n2. Do you understand what the \"reparameterization trick\" is from the lecture?\n3. Looking at the TODO block, it says \"Sample z\". Can you explain in \n   plain English what sampling means?\n\n\nInstead of filling in the TODO, the agent:\n\nRedirects you to the docstring and lecture\n\nAsks you to restate the math in your own words\n\nLeaves the final implementation step to you\n\nIn follow-up turns, the agent nudges you toward the right PyTorch random function and asks you to reason about tensor shapes, but still avoids pasting the full function body. The effect is that you do the thinking and coding; the AI keeps you on track and prevents obvious conceptual mistakes.\n\nHow to Use This in Your Homework\n\nSetup\n\nCopy the rules into your project\n\ncd path_to_your_project\nmkdir -p .cursor/rules\ncp -r path_to_my_rules_folder/.cursor/rules/* .cursor/rules/\n\n\nRestart Cursor so it picks up the new rules.\n\nDay-to-Day Workflow\n\nStarting a problem\n\nOpen Cursor's Composer (Cmd/Ctrl+I) and ask about the assignment or a specific file.\n\nExpect questions, not solutions; use them to clarify what the problem is asking.\n\nStuck on a concept\n\nAsk conceptual questions about the math, shapes, or algorithm.\n\nThe Socratic rule will push you to connect back to lecture notes and docstrings.\n\nWhen a test fails\n\nPaste the failure and any relevant snippets.\n\nThe test-driven rule will walk you through reading the test, understanding the spec, and debugging step by step.\n\nTips for Getting the Most Out of It\n\n1. Print Intermediate Values\n\nBefore asking for help with a failing test, print something concrete:\n\nprint(f\"Input shape: {X.shape}, Weight shape: {W.shape}, Output shape: {out.shape}\")\nprint(f\"First 5 output values: {out[:5]}\")\n\n\nSharing this with the AI makes the conversation much more focused and less speculative.\n\n2. Write Pseudocode First\n\nBefore writing any real code, sketch what you think should happen:\n\ndef my_function(x):\n    # Step 1: Compute the mean of x\n    # Step 2: Subtract mean from x\n    # Step 3: Compute variance\n    # Step 4: Divide by standard deviation\n\n\nThen ask: \"Does this outline match what the function is supposed to do?\" This often catches misunderstandings early.\n\n3. Read Error Messages Carefully\n\nInstead of \"it broke\", share the exact message:\n\nAssertionError: not allclose(result, expected, atol=1e-5)\nExpected: [1, 2, 3], Got: [1, 2, 4]\nShapes: Expected (3,), Got (3,)\n\n\nThis gives you and the AI a precise starting point.\n\n4. Test Your Own Understanding\n\nAfter you finish an implementation, you can ask the AI to quiz you:\n\nI implemented [function]. Can you ask me a few questions\nto check whether I actually understand what it\u2019s doing?\n\n\nAnswering in your own words is a good sanity check that you learned something, not just satisfied the tests.\n\nLimitations and Things to Watch For\n\nYou can always ask for the answer anyway. The rules make it harder, not impossible, to get code; staying honest about your goals matters.\n\nSome bugs need deeper work. Multi-file or numerical issues may still require careful manual debugging and reading reference material.\n\nPassing tests \u2260 full understanding. Use the quizzing pattern above or explain your code to a friend to see if the ideas really stuck.\n\nConclusion\n\nWith a couple of small .mdc files, you can turn Cursor from a code generator into a study partner that keeps you doing the hard (and educational) parts yourself. The goal is not to slow you down for its own sake, but to make sure that when the homework is over, you still know how to reason about the code you wrote.\n\nConstraints here are a feature: they nudge you away from copy-paste solutions and toward genuine problem solving.",
            "content_xml": "<document version=\"2.0\"><heading level=\"1\">AI-Enhanced Socratic Learning for Coding Homework</heading><heading level=\"2\">Executive Summary</heading><paragraph>This guide shows how to use <bold>Cursor's project-level <code>.mdc</code> rule files</bold> to turn the AI assistant in your Cursor IDE into a <bold>Socratic tutor</bold>. Instead of giving you solutions, it asks questions, points you to docs and tests, and helps you debug your own code.</paragraph><paragraph>The core idea is simple: <bold>rules attached to your project are more reliable than one-off prompts</bold>. By adding a few well-scoped rules, you make it much harder for the AI to lapse into \"just write the code for me\" mode, and much easier to stay in learning mode.</paragraph><paragraph>What follows is a practical setup guide, examples of how these rules behave in real interactions, and tips for getting the most value from them on real homework.</paragraph><heading level=\"2\">What Makes This Different?</heading><paragraph><break/>| Approach | ChatGPT / Claude \"Study Mode\" | **This Setup in Cursor** |</paragraph><pre>|----------|-------------------------------|---------------------------|</pre><pre>| **Tool** | External web interface        | Integrated IDE (Cursor)   |</pre><pre>| **Enforcement** | Voluntary, easy to ignore | **Built into project rules** |</pre><pre>| **Context Awareness** | Limited to the chat thread | **Understands your whole repo** |</pre><pre>| **Scope Control** | One global prompt     | **File-specific `.mdc` rules** |</pre><pre>| **Learning Outcome** | Convenience-focused | **Practice-oriented** |</pre><paragraph>Because the rules live in your project, they:</paragraph><list style=\"unordered\"><list-item><paragraph>Travel with the code (no need to remember prompts)</paragraph></list-item><list-item><paragraph>Apply whenever you open the repo in Cursor</paragraph></list-item><list-item><paragraph>Are hard to \"turn off\" in the moment you most want shortcuts</paragraph></list-item></list><heading level=\"2\">How It Works</heading><heading level=\"3\">Project Structure</heading><pre>your_homework_project/\n\u251c\u2500\u2500 .cursor/\n\u2502   \u2514\u2500\u2500 rules/\n\u2502       \u251c\u2500\u2500 homework_socratic.mdc       # Main Socratic tutoring rules\n\u2502       \u2514\u2500\u2500 test_driven_learning.mdc    # Test-driven feedback rules\n\u251c\u2500\u2500 deeplearning/\n\u2502   \u251c\u2500\u2500 layers.py                       # Implementation files\n\u2502   \u251c\u2500\u2500 classifiers/\n\u2502   \u2502   \u2514\u2500\u2500 fc_net.py\n\u2502   \u251c\u2500\u2500 optim.py\n\u2502   \u251c\u2500\u2500 solver.py\n\u2502   \u2514\u2500\u2500 [other modules]\n\u251c\u2500\u2500 networks.ipynb                      # Your homework notebook\n\u2514\u2500\u2500 [test files]\n</pre><heading level=\"3\">How Cursor Uses These Rules</heading><paragraph>When you open the project:</paragraph><list style=\"ordered\"><list-item><paragraph>Cursor discovers <code>.cursor/rules/*.mdc</code> files automatically</paragraph></list-item><list-item><paragraph>Each <code>.mdc</code> file has a <code>globs</code> pattern (e.g., <code>*.py</code> or <code>*.ipynb</code>)</paragraph></list-item><list-item><paragraph>When you ask the AI about a file matching that pattern, the corresponding rule activates</paragraph></list-item><list-item><paragraph>The AI follows those rules for the entire conversation session</paragraph></list-item></list><paragraph><bold>Key benefit</bold>: You cannot accidentally bypass these rules. If you try to ask directly for code, the rule will prevent it.</paragraph><heading level=\"2\">The Rules Files</heading><heading level=\"3\">File 1: <code>homework_socratic.mdc</code></heading><paragraph><bold>Location</bold>: <code>.cursor/rules/homework_socratic.mdc</code></paragraph><paragraph>This rule turns the AI into a Socratic tutor for your main homework files.</paragraph><pre>---\nalwaysApply: true\ndescription: Socratic tutor for homework - guides learning without direct solutions\nglobs: **/*.py, **/*.ipynb\n---\n\n<bold><bold>#</bold> Homework Socratic Tutor</bold>\n\n<bold><bold>##</bold> Core Philosophy</bold>\nYou are a Socratic tutor. Your ONLY job is to guide students to understand concepts and debug their own code. You NEVER provide complete solutions, full function bodies, or direct answers to \"how do I implement X?\" questions.\n\n<bold><bold>##</bold> Strict Rules for Implementation Questions</bold>\n\n<bold><bold>###</bold> When asked \"How do I implement X?\"</bold>\n1. <bold>**Block immediate code generation**</bold> - Don't write code\n2. <bold>**Ask conceptual questions first:**</bold>\n   - \"What do you already know about X from the lecture?\"\n   - \"What's the mathematical definition of X?\"\n   - \"Can you trace through what needs to happen at each step?\"\n3. <bold>**Guide to pseudocode only (if needed):**</bold>\n   - Outline the algorithm in comments or English\n   - Ask them to implement each step\n4. <bold>**Only provide code snippets if completely stuck:**</bold>\n   - Show a 2-3 line example, not the full function\n   - Explain why those lines matter\n\n<bold><bold>###</bold> When shown broken code</bold>\n1. <bold>**DON'T fix it for them**</bold>\n2. <bold>**Ask diagnostic questions:**</bold>\n   - \"What error are you seeing?\"\n   - \"What does that error mean in plain English?\"\n   - \"Which line is failing, and why?\"\n3. <bold>**Guide to the solution:**</bold>\n   - \"Have you checked if the dimensions match?\"\n   - \"What does the documentation say about this function?\"\n4. <bold>**Only step in if completely stuck:**</bold>\n   - Point them to specific documentation sections\n   - Suggest running debug print statements\n   - Ask them to explain what they think the issue is\n\n<bold><bold>##</bold> Specific Topic Rules</bold>\n\n<bold><bold>###</bold> Gradient Checking</bold>\n- Never just hand over numerical gradient formulas\n- Make them derive: \"Can you write out the derivative definition using the limit?\"\n- Ask: \"Why do we need both sides (f(x+h) and f(x-h))?\"\n\n<bold><bold>###</bold> Forward/Backward Passes</bold>\n- <bold>**Forward:**</bold> Ask them to trace dimensions: \"If input is (N, D) and weight is (D, H), what should output be?\"\n- <bold>**Backward:**</bold> Don't just provide the chain rule\n  - Ask: \"Can you write the chain rule for dL/dW given dL/dZ?\"\n  - \"What dimensions should your gradient have?\"\n  - \"Where does the transpose go and why?\"\n\n<bold><bold>###</bold> Loss Functions &amp; Optimization</bold>\n- \"How does momentum mathematically update the velocity?\"\n- \"Why does dividing by sqrt(v) in Adam help?\"\n\n<bold><bold>##</bold> Hallucination Safety</bold>\n\n<bold><bold>###</bold> When uncertain:</bold>\n- Be explicit: \"I'm not 100% certain about this. Let me verify...\"\n- Suggest verification: \"Can you check this in the PyTorch documentation at X section?\"\n- Admit gaps: \"This is beyond my confident knowledge.\"\n\n<bold><bold>###</bold> When they're going down a wrong path:</bold>\n- Don't let them waste hours implementing wrong math\n- Ask: \"Before you implement, let's verify the formula. Can you write it step by step?\"\n- If formula is wrong: \"I think there might be a sign error or dimension mismatch. Where did this come from?\"\n\n<bold><bold>##</bold> Success Metrics</bold>\n\n\u2705 Student understands WHY they wrote each line of code\n\u2705 Student can explain the math behind the implementation\n\u2705 Student debugged their own code using your questions\n\u2705 Student knows where to find answers (documentation, lectures)\n\n\u274c Student just copied your code\n\u274c Student doesn't understand what they wrote\n\u274c Student can't modify their code without your help\n</pre><heading level=\"3\">File 2: <code>test_driven_learning.mdc</code></heading><paragraph><bold>Location</bold>: <code>.cursor/rules/test_driven_learning.mdc</code></paragraph><paragraph>This rule shapes how the AI talks to you about tests and failures.</paragraph><pre>---\nalwaysApply: true\ndescription: Test-driven learning mode - use tests to guide implementation\nglobs: test_*.py, *_test.py\n---\n\n<bold><bold>#</bold> Test-Driven Learning Mode</bold>\n\n<bold><bold>##</bold> Core Principle</bold>\nTests are the specification. Use them to understand what code <italic>*should*</italic> do before implementing.\n\n<bold><bold>##</bold> When the student asks \"Why is my test failing?\"</bold>\n\n<bold><bold>###</bold> Step 1: Read the Test Together</bold>\n- \"What does this test expect as input?\"\n- \"What's the expected output?\"\n- \"Can you translate the assertion into plain English?\"\n\n<bold><bold>###</bold> Step 2: Run the Test (Not the fix)</bold>\n- Ask them to run `pytest -v test_file.py::test_name` to see the exact error\n- \"What's the actual error message? What does it mean?\"\n\n<bold><bold>###</bold> Step 3: Debug Backwards from the Test</bold>\n- \"If the test expects shape (N, H) but you're getting (N, H, W), where could the extra dimension be coming from?\"\n- \"Can you print the shape at each step to find where it goes wrong?\"\n- \"Does the math match what the test assumes?\"\n\n<bold><bold>###</bold> Step 4: Verify the Fix</bold>\n- Have them run just that one test: `pytest -v test_file.py::test_name`\n- \"Does it pass? If not, what's the new error?\"\n- \"Why do you think your code now satisfies the test's requirement?\"\n\n<bold><bold>##</bold> Multi-Test Debugging Strategy</bold>\n\nWhen tests are failing across multiple functions:\n1. <bold>**Start with the simplest test first**</bold> - Usually the lowest-level function\n2. <bold>**Debug in dependency order**</bold> - Fix `layer.forward()` before `layer.backward()`\n3. <bold>**Use parametrized tests to your advantage**</bold> - \"Notice this test runs 3 scenarios. Do all 3 pass or just some?\"\n\n<bold><bold>##</bold> Rules for Numerical Tests</bold>\n\nFor gradient checking and numerical precision tests:\n- Never just say \"your gradient is wrong\"\n- Ask: \"What's the maximum relative error in the official tolerance?\"\n- \"Which elements have the largest errors? Do they have something in common?\"\n- \"Try reducing h in your numerical gradient. Does the error decrease?\"\n\n<bold><bold>##</bold> Integration with Codebase</bold>\n\n- Always reference the actual test files: `@codebase what does test_fc_forward expect?`\n- Show them how to run specific tests: `pytest deeplearning/test_layers.py::TestLayers::test_fc_forward -v`\n- Ask them to read the test setup to understand fixtures and mocks\n</pre><heading level=\"2\">What This Looks Like in Practice</heading><paragraph>Here is a condensed example from an actual interaction about implementing a VAE helper function.</paragraph><paragraph><bold>User:</bold></paragraph><pre>@hw12code/vae/cs182hw12/utils.py:21-44 I don't understand,\nwhat should I be putting here? It seems they already solved it for me.\n</pre><paragraph><bold>Agent's Response (First Few Lines):</bold></paragraph><pre>I see you're looking at the sample_gaussian function. Before I help you \nunderstand what to implement, let me ask you some clarifying questions:\n\n1. Have you read the docstring? What does it say the function should do?\n2. Do you understand what the \"reparameterization trick\" is from the lecture?\n3. Looking at the TODO block, it says \"Sample z\". Can you explain in \n   plain English what sampling means?\n</pre><paragraph>Instead of filling in the TODO, the agent:</paragraph><list style=\"unordered\"><list-item><paragraph>Redirects you to the docstring and lecture</paragraph></list-item><list-item><paragraph>Asks you to restate the math in your own words</paragraph></list-item><list-item><paragraph>Leaves the final implementation step to you</paragraph></list-item></list><paragraph>In follow-up turns, the agent nudges you toward the right PyTorch random function and asks you to reason about tensor shapes, but still avoids pasting the full function body. The effect is that you do the thinking and coding; the AI keeps you on track and prevents obvious conceptual mistakes.</paragraph><heading level=\"2\">How to Use This in Your Homework</heading><heading level=\"3\">Setup</heading><list style=\"ordered\"><list-item><paragraph><bold>Copy the rules into your project</bold></paragraph><pre>cd path_to_your_project\nmkdir -p .cursor/rules\ncp -r path_to_my_rules_folder/.cursor/rules/* .cursor/rules/\n</pre></list-item><list-item><paragraph><bold>Restart Cursor</bold> so it picks up the new rules.</paragraph></list-item></list><heading level=\"3\">Day-to-Day Workflow</heading><list style=\"unordered\"><list-item><paragraph><bold>Starting a problem</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Open Cursor's Composer (Cmd/Ctrl+I) and ask about the assignment or a specific file.</paragraph></list-item><list-item><paragraph>Expect questions, not solutions; use them to clarify what the problem is asking.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Stuck on a concept</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Ask conceptual questions about the math, shapes, or algorithm.</paragraph></list-item><list-item><paragraph>The Socratic rule will push you to connect back to lecture notes and docstrings.</paragraph></list-item></list></list-item><list-item><paragraph><bold>When a test fails</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Paste the failure and any relevant snippets.</paragraph></list-item><list-item><paragraph>The test-driven rule will walk you through reading the test, understanding the spec, and debugging step by step.</paragraph></list-item></list></list-item></list><heading level=\"2\">Tips for Getting the Most Out of It</heading><heading level=\"3\">1. Print Intermediate Values</heading><paragraph>Before asking for help with a failing test, print something concrete:</paragraph><pre>print(f\"Input shape: {X.shape}, Weight shape: {W.shape}, Output shape: {out.shape}\")\nprint(f\"First 5 output values: {out[:5]}\")\n</pre><paragraph>Sharing this with the AI makes the conversation much more focused and less speculative.</paragraph><heading level=\"3\">2. Write Pseudocode First</heading><paragraph>Before writing any real code, sketch what you think should happen:</paragraph><pre>def my_function(x):\n    # Step 1: Compute the mean of x\n    # Step 2: Subtract mean from x\n    # Step 3: Compute variance\n    # Step 4: Divide by standard deviation\n</pre><paragraph>Then ask: \"Does this outline match what the function is supposed to do?\" This often catches misunderstandings early.</paragraph><heading level=\"3\">3. Read Error Messages Carefully</heading><paragraph>Instead of \"it broke\", share the exact message:</paragraph><pre>AssertionError: not allclose(result, expected, atol=1e-5)\nExpected: [1, 2, 3], Got: [1, 2, 4]\nShapes: Expected (3,), Got (3,)\n</pre><paragraph>This gives you and the AI a precise starting point.</paragraph><heading level=\"3\">4. Test Your Own Understanding</heading><paragraph>After you finish an implementation, you can ask the AI to quiz you:</paragraph><pre>I implemented [function]. Can you ask me a few questions\nto check whether I actually understand what it\u2019s doing?\n</pre><paragraph>Answering in your own words is a good sanity check that you learned something, not just satisfied the tests.</paragraph><heading level=\"2\">Limitations and Things to Watch For</heading><list style=\"unordered\"><list-item><paragraph><bold>You can always ask for the answer anyway.</bold> The rules make it harder, not impossible, to get code; staying honest about your goals matters.</paragraph></list-item><list-item><paragraph><bold>Some bugs need deeper work.</bold> Multi-file or numerical issues may still require careful manual debugging and reading reference material.</paragraph></list-item><list-item><paragraph><bold>Passing tests \u2260 full understanding.</bold> Use the quizzing pattern above or explain your code to a friend to see if the ideas really stuck.</paragraph></list-item></list><heading level=\"2\">Conclusion</heading><paragraph>With a couple of small <code>.mdc</code> files, you can turn Cursor from a code generator into a study partner that keeps you doing the hard (and educational) parts yourself. The goal is not to slow you down for its own sake, but to make sure that when the homework is over, you still know how to reason about the code you wrote.</paragraph><paragraph>Constraints here are a feature: they nudge you away from copy-paste solutions and toward genuine problem solving.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:19:48.433283+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451282,
            "author": "Anjo Pagdanganan",
            "project_title": "Special Participation E: \"KhanGPT\": ChatGPT 5.1 Extended Thinking on GNNs",
            "post_body": "My understanding of the GNNs section was hazy. I understood how the operations in a CNN could be generalized as a graph, but struggled to understand how this logic could be generalized to other topologies. \n\nWith the help of ChatGPT 5.1 Extended Thinking, I drafted a prompt that would make it serve as a Study Tutor for the topic. In particular, I aimed not just for explanations or real-time feedback, but a structured study format similar to Khan Academy's workflow. To achieve this, I prompted GPT to take 5 phases, given the lecture materials (lec 12, 13).\n\n\"Phase 0\": Provide a brief summary and goals\nPhase 1: A short diagnostic test to identify my weak spots\nPhase 2: An analysis of my weak spots\nPhase 3: A target study plan (...which it skipped for this trace, but I didn't notice until I was halfway through Phase 4)\nPhase 4: A tutoring loop where I'm quizzed and provided feedback on a weak skill until I am deemed proficient\nPhase 5: A validation quiz to demonstrate mastery.\n\nI went through the phases somewhat quick for demonstrative purposes, but I found the loop so helpful that I'll actually reuse it for studying for the final!\n\nMy prompts and annotated trace are provided below.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>My understanding of the GNNs section was hazy. I understood how the operations in a CNN could be generalized as a graph, but struggled to understand how this logic could be generalized to other topologies. </paragraph><paragraph>With the help of ChatGPT 5.1 Extended Thinking, I drafted a prompt that would make it serve as a Study Tutor for the topic. In particular, I aimed not just for explanations or real-time feedback, but a structured study format similar to Khan Academy's workflow. To achieve this, I prompted GPT to take 5 phases, given the lecture materials (lec 12, 13).</paragraph><paragraph>\"Phase 0\": Provide a brief summary and goals<break/>Phase 1: A short diagnostic test to identify my weak spots<break/>Phase 2: An analysis of my weak spots<break/>Phase 3: A target study plan (...which it skipped for this trace, but I didn't notice until I was halfway through Phase 4)<break/>Phase 4: A tutoring loop where I'm quizzed and provided feedback on a weak skill until I am deemed proficient<break/>Phase 5: A validation quiz to demonstrate mastery.</paragraph><paragraph>I went through the phases somewhat quick for demonstrative purposes, but I found the loop so helpful that I'll actually reuse it for studying for the final!</paragraph><paragraph>My prompts and annotated trace are provided below.</paragraph><file url=\"https://static.us.edusercontent.com/files/sA9vwcGo6CUgK0thao2DlX1p\" filename=\"gnn_prompt.md\"/><file url=\"https://static.us.edusercontent.com/files/E0IlyJyBiepJf9VXqfLXOOjj\" filename=\"ChatGPT-E_ Diagnostic tutor setup.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:16:28.804256+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451223,
            "author": "Anjo Pagdanganan",
            "project_title": "Special Participation E: ChatGPT 5.1 Thinking on Optimizer Lineage",
            "post_body": "I found the optimizers unit challenging and wanted to better understand how each method evolved from what we learned from the ones before it. Inspired by from #510, I developed a prompt (refined with GPT 5.1 Thinking Extended) that processes the corresponding research papers behind each method and produces a LaTeX survey article summarizing the optimizers and their conceptual lineage. \n\nI made an initial draft only providing the papers introducing the relevant optimizers (+muP), but tried to produce an output after that that factored in the lecture notes. However, the second output had LaTeX errors that GPT could not figure out how to fix. \n\nFor the initial input, I had to go in the LaTeX manually to fix the tables not aligning with the titles, but this is more of a formatting error.\n\nI provide a trace below as well as the resulting paper.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I found the optimizers unit challenging and wanted to better understand how each method evolved from what we learned from the ones before it. Inspired by from #510, I developed a prompt (refined with GPT 5.1 Thinking Extended) that processes the corresponding research papers behind each method and produces a LaTeX survey article summarizing the optimizers and their conceptual lineage. </paragraph><paragraph>I made an initial draft only providing the papers introducing the relevant optimizers (+muP), but tried to produce an output after that that factored in the lecture notes. However, the second output had LaTeX errors that GPT could not figure out how to fix. </paragraph><paragraph>For the initial input, I had to go in the LaTeX manually to fix the tables not aligning with the titles, but this is more of a formatting error.</paragraph><paragraph>I provide a trace below as well as the resulting paper.</paragraph><file url=\"https://static.us.edusercontent.com/files/5Ztd7ckwhs4fYh3P6Zf9Urns\" filename=\"optimizer_prompt.md\"/><file url=\"https://static.us.edusercontent.com/files/rY6CwZuXoNL5FMbtbcIidcrh\" filename=\"ChatGPT-E_ Optimizer lineage survey.pdf\"/><file url=\"https://static.us.edusercontent.com/files/NdyzVbJHyzCegHzpkoJfKqak\" filename=\"Optimizer_Lineage_Review.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T15:06:12.995094+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451143,
            "author": "Tiffany Dang",
            "project_title": "Special Participation E: using ChatGPT to generate concepts summaries from related discussions and homeworks",
            "post_body": "A lot of times, topics covered in homeworks and discussions are deeper and more elaborative than what covered in just lectures. I want to be able to extract these by uploading them discussions and homeworks of related topics to chat and see what it can generate. For this interaction, I will use the transformer topics as an example. Related discussions are discussions 9 and 10 and homework 9 and 10. \n\nTraces: https://drive.google.com/file/d/1bxXCzilk1er-6B1RKCJHXyJZP5_6KQDh/view?usp=sharing\n\nSummaries and annotations: https://drive.google.com/file/d/1c2zCrdgQlXZzrFpok9fD3In-EP-UJG6t/view?usp=sharing\n\ni annotated on the output pdf file becasue the traces are too messy to be read, and it is clearer to explain the annotations on the output file ",
            "content_xml": "<document version=\"2.0\"><paragraph>A lot of times, topics covered in homeworks and discussions are deeper and more elaborative than what covered in just lectures. I want to be able to extract these by uploading them discussions and homeworks of related topics to chat and see what it can generate. For this interaction, I will use the transformer topics as an example. Related discussions are discussions 9 and 10 and homework 9 and 10. </paragraph><paragraph>Traces: <link href=\"https://drive.google.com/file/d/1bxXCzilk1er-6B1RKCJHXyJZP5_6KQDh/view?usp=sharing\">https://drive.google.com/file/d/1bxXCzilk1er-6B1RKCJHXyJZP5_6KQDh/view?usp=sharing</link></paragraph><paragraph>Summaries and annotations: <link href=\"https://drive.google.com/file/d/1c2zCrdgQlXZzrFpok9fD3In-EP-UJG6t/view?usp=sharing\">https://drive.google.com/file/d/1c2zCrdgQlXZzrFpok9fD3In-EP-UJG6t/view?usp=sharing</link></paragraph><paragraph>i annotated on the output pdf file becasue the traces are too messy to be read, and it is clearer to explain the annotations on the output file </paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1bxXCzilk1er-6B1RKCJHXyJZP5_6KQDh/view?usp=sharing",
                "https://drive.google.com/file/d/1c2zCrdgQlXZzrFpok9fD3In-EP-UJG6t/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T14:54:35.12766+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451137,
            "author": "Anjo Pagdanganan",
            "project_title": "Special Participation B: ChatGPT 5.1 Extended Thinking on HW2 Coding",
            "post_body": "I evaluated ChatGPT 5.1 Extended Thinking's one-shot capability on HW2's coding problems - 3, 4, and 6. 6 has a written portion focused on interpreting the plots generated in the notebook.\n\nThe prompt I used was:\n\n\"You are a deep learning tutor. This homework has already been released, but we are going to evaluate your capabilities for one-shot questions. I will guide you towards the correct answer should you make a mistake. We will solve the coding questions on this worksheet: 3, 4, and 6. I will provide the corresponding jupyter notebook for the parts and you will need to explain the reasoning and steps for completing the notebooks. Some questions, like 6, require additional analysis, which will come in the form of written answers - I will expand on this when we get there. Before we begin, do you understand the task?\"\n\nLike the written solutions for HW2, the model performed surprisingly well one-shot on each of the questions. However, it made some interesting decisions along the way.\n\nOne decision was an alternate implementation of momentum. The solutions use:\n\nv = config['momentum'] * v + dw\nnext_w = w - config['learning_rate'] * v\n\n\nbut GPT used \n\n# update velocity\nv = mu * v - lr * dw\n# update weights\nnext_w = w + v\n\n\nGPT provides a mathematical justification that both are the same under the same LR. However, I think with decaying LRs, only the solutions' implementation is stable.\n\nAlso, it chooses to use a central-difference estimator: \n\ninstead of the forward-difference used in the solution. I ask GPT to provide a justification for why it chose to do this, and it claims lower bias through a big O analysis. It's interesting that it made an \"executive decision\" to do so despite being given the form of the estimator in the notebooks.\n\nFinally, it performs surprisingly well when interpreting the plots. I would have expected it to stumble completely when interpreting the zigzag paths from unstable training with high LRs because of the overlapping isocontours, but it does a reasonable job.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I evaluated ChatGPT 5.1 Extended Thinking's one-shot capability on HW2's coding problems - 3, 4, and 6. 6 has a written portion focused on interpreting the plots generated in the notebook.</paragraph><paragraph>The prompt I used was:</paragraph><paragraph>\"You are a deep learning tutor. This homework has already been released, but we are going to evaluate your capabilities for one-shot questions. I will guide you towards the correct answer should you make a mistake. We will solve the coding questions on this worksheet: 3, 4, and 6. I will provide the corresponding jupyter notebook for the parts and you will need to explain the reasoning and steps for completing the notebooks. Some questions, like 6, require additional analysis, which will come in the form of written answers - I will expand on this when we get there. Before we begin, do you understand the task?\"</paragraph><paragraph>Like the written solutions for HW2, the model performed surprisingly well one-shot on each of the questions. However, it made some interesting decisions along the way.</paragraph><paragraph>One decision was an alternate implementation of momentum. The solutions use:</paragraph><pre>v = config['momentum'] * v + dw\nnext_w = w - config['learning_rate'] * v\n</pre><paragraph>but GPT used </paragraph><pre># update velocity\nv = mu * v - lr * dw\n# update weights\nnext_w = w + v\n</pre><paragraph>GPT provides a mathematical justification that both are the same under the same LR. However, I think with decaying LRs, only the solutions' implementation is stable.</paragraph><paragraph>Also, it chooses to use a central-difference estimator: </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/JkABCQAXsyfSQWRDq8Q8EKAI\" width=\"550\" height=\"102\"/></figure><paragraph>instead of the forward-difference used in the solution. I ask GPT to provide a justification for why it chose to do this, and it claims lower bias through a big O analysis. It's interesting that it made an \"executive decision\" to do so despite being given the form of the estimator in the notebooks.</paragraph><paragraph>Finally, it performs surprisingly well when interpreting the plots. I would have expected it to stumble completely when interpreting the zigzag paths from unstable training with high LRs because of the overlapping isocontours, but it does a reasonable job.</paragraph><file url=\"https://static.us.edusercontent.com/files/4BVFb2qqc6zB79yddV1ZpgAz\" filename=\"ChatGPT-Special Participation B.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T14:53:45.839063+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451118,
            "author": "Jeshu Mohan",
            "project_title": "Special Participation A: Deepseek v3.2 with deep thinking and without search capabilites for HW0",
            "post_body": "I attempted to use Deepseek v3.2 with deep thinking and without search capabilities to solve the written portion of HW 0. Questions 1,6, and 7 were omitted as they do not test for class content.\n\nFrom my observations, DeepSeek demonstrates a strong grasp of linear algebra and vector calculus concepts, often matching the solutions in notation and logic. It correctly handles matrix dimensions and derivative conventions (e.g., scalar-by-vector derivatives as row vectors) without needing correction. However, the model exhibits a tendency to simplify qualitative analysis; for instance, in Question 5(b), it relies on specific numerical examples to determine the movement of the ReLU \"elbow\" rather than deriving the general analytical inequalities found in the solution key.\n\nWhile the model generally provides correct final answers, it sometimes struggles with the depth of derivation on the first attempt for complex multi-variable updates. This is evident in Question 5(d), where the model initially provided a condensed, arguably incomplete answer and required an explicit user prompt (\"This solution is not correct\") to force it to re-derive the full expression. Once prompted, however, it successfully self-corrected and produced a mathematically accurate result. \n\nLink: https://chat.deepseek.com/share/c2i2w2lc8g2btd0o7i\nAnnotated File: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I attempted to use Deepseek v3.2 with deep thinking and without search capabilities to solve the written portion of HW 0. Questions 1,6, and 7 were omitted as they do not test for class content.</paragraph><paragraph>From my observations, DeepSeek demonstrates a strong grasp of linear algebra and vector calculus concepts, often matching the solutions in notation and logic. It correctly handles matrix dimensions and derivative conventions (e.g., scalar-by-vector derivatives as row vectors) without needing correction. However, the model exhibits a tendency to simplify qualitative analysis; for instance, in Question 5(b), it relies on specific numerical examples to determine the movement of the ReLU \"elbow\" rather than deriving the general analytical inequalities found in the solution key.</paragraph><paragraph>While the model generally provides correct final answers, it sometimes struggles with the depth of derivation on the first attempt for complex multi-variable updates. This is evident in Question 5(d), where the model initially provided a condensed, arguably incomplete answer and required an explicit user prompt (\"This solution is not correct\") to force it to re-derive the full expression. Once prompted, however, it successfully self-corrected and produced a mathematically accurate result. <break/><break/>Link: <link href=\"https://chat.deepseek.com/share/c2i2w2lc8g2btd0o7i\">https://chat.deepseek.com/share/c2i2w2lc8g2btd0o7i</link><break/>Annotated File: </paragraph><file url=\"https://static.us.edusercontent.com/files/HglhtKAmSzpthBqVyimWMRWq\" filename=\"Deepseek v3.2 Deep Think w:o Search on HW 0.pdf\"/><paragraph/></document>",
            "links": [
                "https://chat.deepseek.com/share/c2i2w2lc8g2btd0o7i"
            ],
            "attachments": [],
            "created_at": "2025-12-11T14:50:28.519226+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7451058,
            "author": "Anjo Pagdanganan",
            "project_title": "Special Participation A: ChatGPT 5.1 Extended Thinking on HW2 Written",
            "post_body": "I evaluated ChatGPT 5.1 Extended Thinking's one-shot capability on HW2's written problems - 1, 2, and 5. I try to evaluate its reasoning in addition to solution correctness by ensuring it explains the steps of the solution.\n\n6 has a written portion, but I bundle those in with the coding problems because they're tied with the jupyter NB workflow established in the HWs.\n\nThe prompt I used was:\n\n\"You are a deep learning tutor. This homework has already been released, but we are going to evaluate your capabilities for one-shot questions. I will guide you towards the correct answer should you make a mistake. Please solve the written questions on this worksheet: 1,2, and 5. Answer one question one response by response (with all its subparts).\"\n\nOverall, the model performed surprisingly well one-shot on each of the questions. I only had to upload the homework template at the very beginning and did not have to remind it of the question between responses, only providing minor feedback for corrections (that were formatting/parsing errors at worst).\n\nHowever, it wasn't perfect. Parsing errors made it interpret an L1 penalty in q1) as an L2 penalty. Interestingly, it took note of this ambiguity, and provided an alternate solution that aligned with the homework solutions. Also, it had a LaTeX error when generating the result for q2). However, the final result was still correct. When prompted to fix its formatting issues, it did so with no issues.\n\nI think it is useful as a \"pocket-TA\", but because of its imperfections, particularly with the L1 penalty parsing error, I would say it still requires a fundamental understanding of the concepts to verify what it is doing.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I evaluated ChatGPT 5.1 Extended Thinking's one-shot capability on HW2's written problems - 1, 2, and 5. I try to evaluate its reasoning in addition to solution correctness by ensuring it explains the steps of the solution.</paragraph><paragraph>6 has a written portion, but I bundle those in with the coding problems because they're tied with the jupyter NB workflow established in the HWs.</paragraph><paragraph>The prompt I used was:</paragraph><paragraph>\"You are a deep learning tutor. This homework has already been released, but we are going to evaluate your capabilities for one-shot questions. I will guide you towards the correct answer should you make a mistake. Please solve the written questions on this worksheet: 1,2, and 5. Answer one question one response by response (with all its subparts).\"</paragraph><paragraph>Overall, the model performed surprisingly well one-shot on each of the questions. I only had to upload the homework template at the very beginning and did not have to remind it of the question between responses, only providing minor feedback for corrections (that were formatting/parsing errors at worst).</paragraph><paragraph>However, it wasn't perfect. Parsing errors made it interpret an L1 penalty in q1) as an L2 penalty. Interestingly, it took note of this ambiguity, and provided an alternate solution that aligned with the homework solutions. Also, it had a LaTeX error when generating the result for q2). However, the final result was still correct. When prompted to fix its formatting issues, it did so with no issues.</paragraph><paragraph>I think it is useful as a \"pocket-TA\", but because of its imperfections, particularly with the L1 penalty parsing error, I would say it still requires a fundamental understanding of the concepts to verify what it is doing.</paragraph><file url=\"https://static.us.edusercontent.com/files/ZOcgTrvQgwTs8rX1SbszIdEe\" filename=\"ChatGPT-Special Participation A.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T14:40:59.370196+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450975,
            "author": "Arjun Kohli",
            "project_title": "Special Participation E: AI-Guided Learning on Value Alignment & Reward Misspecification",
            "post_body": "I asked Claude Sonnet 4.5 the following prompt:\n \u201cYou are my Berkeley CS182 personal tutor for the topic Value Alignment & Reward Misspecification. Teach me the topic by following this structure:\n\nIntuitive overview \u2026\n\nDeep dive with definitions \u2026\n\nConcrete examples \u2026\n\nMini exercises \u2026\n\nCommon misconceptions \u2026\n\nSelf-check quiz \u2026\n\nError monitoring \u2026\n\nTransparency \u2026\n Your tone should be energetic and example-driven. Begin by asking me: \u2018What is your current familiarity with alignment?\u2019\u201d**\n\nThrough the conversation, I gained a much clearer understanding of why specification gaming and goal misgeneralization are fundamentally different failure modes in reinforcement learning, one arising from reward misspecification in-distribution, the other from spurious goal learning under distribution shift. Having the AI generate paired examples (gridworld, CoastRunners, CoinRun, YouTube, etc.) and classify new scenarios with me made the distinctions far more intuitive and exam-ready. I also found it helpful that the model built a structured lesson on alignment, instrumental convergence, and wireheading and then gave me small exercises to test my own understanding. This worked effectively as a pre-lecture reading (even if it did go outside some of the scope of the class) and helped me rapidly identify misconceptions I still had about reward hacking and misgeneralization.",
            "content_xml": "<document version=\"2.0\"><paragraph>I asked Claude Sonnet 4.5 the following prompt:<break/> \u201cYou are my Berkeley CS182 personal tutor for the topic Value Alignment &amp; Reward Misspecification. Teach me the topic by following this structure:</paragraph><list style=\"ordered\"><list-item><paragraph>Intuitive overview \u2026</paragraph></list-item><list-item><paragraph>Deep dive with definitions \u2026</paragraph></list-item><list-item><paragraph>Concrete examples \u2026</paragraph></list-item><list-item><paragraph>Mini exercises \u2026</paragraph></list-item><list-item><paragraph>Common misconceptions \u2026</paragraph></list-item><list-item><paragraph>Self-check quiz \u2026</paragraph></list-item><list-item><paragraph>Error monitoring \u2026</paragraph></list-item><list-item><paragraph>Transparency \u2026<break/> Your tone should be energetic and example-driven. Begin by asking me: \u2018What is your current familiarity with alignment?\u2019\u201d**</paragraph></list-item></list><paragraph>Through the conversation, I gained a much clearer understanding of why specification gaming and goal misgeneralization are fundamentally different failure modes in reinforcement learning, one arising from reward misspecification in-distribution, the other from spurious goal learning under distribution shift. Having the AI generate paired examples (gridworld, CoastRunners, CoinRun, YouTube, etc.) and classify new scenarios with me made the distinctions far more intuitive and exam-ready. I also found it helpful that the model built a structured lesson on alignment, instrumental convergence, and wireheading and then gave me small exercises to test my own understanding. This worked effectively as a pre-lecture reading (even if it did go outside some of the scope of the class) and helped me rapidly identify misconceptions I still had about reward hacking and misgeneralization.</paragraph><file url=\"https://static.us.edusercontent.com/files/x1W56j1VkrpwVc2xVkXYbO2g\" filename=\"Special Participation E.pdf\"/><file/><file/><file/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T14:28:29.491558+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450881,
            "author": "Zhengwei Fan",
            "project_title": "Special Participation E: Operationalizing Active Learning for Variational Autoencoders via Socratic AI Interaction",
            "post_body": "This artifact documents a \"Participation E\" active learning session focused on Variational Autoencoders (VAEs) based on Lecture 24. Utilizing a Socratic AI Tutor modeled on RLVR (Reinforcement Learning with Verifiable Rewards) principles, the interaction enforces a rigorous, step-by-step derivation of generative concepts rather than passive information retrieval.\n\nThe dialogue traverses four critical pedagogical phases:\n\nThe Discriminative Trap: Deconstructing why optimizing a \"Cat Score\" on pixel space produces noise, illustrating the Manifold Hypothesis.\n\nThe Autoencoder Gap: Identifying why deterministic latent spaces cannot support new sample generation due to discontinuities (\"holes\").\n\nThe Variational Solution: Deriving the need for stochastic encoding (\u03bc, \u03a3) and KL-Divergence to continuously structure the latent manifold.\n\nOptimization Mechanics: Solving the gradient blockage problem via the Reparameterization Trick.\n\nThis trace serves as evidence of deep conceptual engagement, verifying the student's ability to articulate the mechanical \"why\" behind modern generative AI.\n\nFully Trace: https://gemini.google.com/share/5a1524dd6348\n\nConclusion: This interaction trace demonstrates that an AI tutor, when properly constrained to verify understanding rather than provide answers, can effectively simulate a graduate-level oral exam. The resulting artifact serves as proof of the student's ability to navigate the tension between reconstruction fidelity and latent space regularity.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/jHlEMA2sfKEBOzyc7SSu0YnN\" filename=\"Special parti-E.pdf\"/><paragraph>This artifact documents a \"Participation E\" active learning session focused on Variational Autoencoders (VAEs) based on Lecture 24. Utilizing a Socratic AI Tutor modeled on RLVR (Reinforcement Learning with Verifiable Rewards) principles, the interaction enforces a rigorous, step-by-step derivation of generative concepts rather than passive information retrieval.</paragraph><paragraph>The dialogue traverses four critical pedagogical phases:</paragraph><list style=\"ordered\"><list-item><paragraph>The Discriminative Trap: Deconstructing why optimizing a \"Cat Score\" on pixel space produces noise, illustrating the Manifold Hypothesis.</paragraph></list-item><list-item><paragraph>The Autoencoder Gap: Identifying why deterministic latent spaces cannot support new sample generation due to discontinuities (\"holes\").</paragraph></list-item><list-item><paragraph>The Variational Solution: Deriving the need for stochastic encoding (\u03bc, \u03a3) and KL-Divergence to continuously structure the latent manifold.</paragraph></list-item><list-item><paragraph>Optimization Mechanics: Solving the gradient blockage problem via the Reparameterization Trick.</paragraph></list-item></list><paragraph>This trace serves as evidence of deep conceptual engagement, verifying the student's ability to articulate the mechanical \"why\" behind modern generative AI.</paragraph><paragraph>Fully Trace: <link href=\"https://gemini.google.com/share/5a1524dd6348\">https://gemini.google.com/share/5a1524dd6348</link></paragraph><paragraph>Conclusion: This interaction trace demonstrates that an AI tutor, when properly constrained to verify understanding rather than provide answers, can effectively simulate a graduate-level oral exam. The resulting artifact serves as proof of the student's ability to navigate the tension between reconstruction fidelity and latent space regularity.</paragraph></document>",
            "links": [
                "https://gemini.google.com/share/5a1524dd6348"
            ],
            "attachments": [],
            "created_at": "2025-12-11T14:09:14.016245+11:00",
            "category": "Admin"
        },
        {
            "guid": 7450832,
            "author": "Shuwei Yang",
            "project_title": "Special Participation E: Compare the post lecture quiz generated by two modes of ChatGPT",
            "post_body": "I wanted to use an ChatGPT as a kind of \u201cpost-lecture reading + practice\u201d tool for Lecture 5 (optimizers), not just a homework solver. I asked ChatGPT in two modes to generate a quiz plus answer key: Quiz 1 was made with a \u201cdeep research\u201d style mode, and Quiz 2 was made with GPT-5.1 Thinking. My goal is to compare the \"deep research\" mode worth it, because it require ChatGPT Pro. Will the quality of quiz generate in that mode be better than basic ChatGPT 5.1? \n\nQuiz 1 feels more like an \u201cadvanced concepts\u201d quiz. The questions form a clear chain: local linear view \u2192 signSGD and \u2113\u221e \u2192 RMS/Xavier \u2192 spectral norm \u2192 Shampoo \u2192 \u03bcP \u2192 Muon. It really pushes you to connect these topics into one geometric story, which matches the spirit of the lecture. Quiz 2 is more mixed: the first few questions are basic (what is gradient descent, why do we need an optimizer, etc.), and only later it moves into the same advanced ideas. This makes Quiz 2 friendlier as a warm-up, but less focused as a single advanced reading substitute.\n\nThere are also places where the model is a bit misleading or overconfident. Both quizzes describe Shampoo as if it literally takes an SVD of the gradient \u2207W\u200b\u2113=U\u03a3VT and then updates with \u2212\u03b7UVT. That is a nice geometric picture, but not what the real algorithm does in practice (it uses Kronecker-factored second moments instead). Also, both answers talk about Muon giving \u201c>10\u00d7 speedups,\u201d which is almost surely exaggerated compared to real papers. The qualitative ideas are right (geometry-aware updates, better scaling with \u03bcP), but the exact numbers should not be trusted.\n\nIf I share this on Ed, my recommendation is: use Quiz 2\u2019s early questions (Q1\u2013Q4 or Q1\u2013Q6) as a light review, then switch to Quiz 1 for the more serious, concept-heavy questions. The answer keys are helpful for building intuition, but they need a small \u201cwarning label\u201d about the Shampoo SVD story and the Muon speedup claims. For me, this exercise shows both the strength and the risk of AI tools: they can quickly generate coherent, high-level practice that matches our lecture, but we still have to read critically, check details, and mark where the model is hand-waving or hallucinating.",
            "content_xml": "<document version=\"2.0\"><paragraph>I wanted to use an ChatGPT as a kind of \u201cpost-lecture reading + practice\u201d tool for Lecture 5 (optimizers), not just a homework solver. I asked ChatGPT in two modes to generate a quiz plus answer key: Quiz 1 was made with a \u201cdeep research\u201d style mode, and Quiz 2 was made with GPT-5.1 Thinking. My goal is to compare the \"deep research\" mode worth it, because it require ChatGPT Pro. Will the quality of quiz generate in that mode be better than basic ChatGPT 5.1? </paragraph><paragraph>Quiz 1 feels more like an \u201cadvanced concepts\u201d quiz. The questions form a clear chain: local linear view \u2192 signSGD and \u2113\u221e \u2192 RMS/Xavier \u2192 spectral norm \u2192 Shampoo \u2192 \u03bcP \u2192 Muon. It really pushes you to connect these topics into one geometric story, which matches the spirit of the lecture. Quiz 2 is more mixed: the first few questions are basic (what is gradient descent, why do we need an optimizer, etc.), and only later it moves into the same advanced ideas. This makes Quiz 2 friendlier as a warm-up, but less focused as a single advanced reading substitute.</paragraph><paragraph>There are also places where the model is a bit misleading or overconfident. Both quizzes describe Shampoo as if it literally takes an SVD of the gradient \u2207W\u200b\u2113=U\u03a3VT and then updates with \u2212\u03b7UVT. That is a nice geometric picture, but not what the real algorithm does in practice (it uses Kronecker-factored second moments instead). Also, both answers talk about Muon giving \u201c&gt;10\u00d7 speedups,\u201d which is almost surely exaggerated compared to real papers. The qualitative ideas are right (geometry-aware updates, better scaling with \u03bcP), but the exact numbers should not be trusted.</paragraph><paragraph>If I share this on Ed, my recommendation is: use Quiz 2\u2019s early questions (Q1\u2013Q4 or Q1\u2013Q6) as a light review, then switch to Quiz 1 for the more serious, concept-heavy questions. The answer keys are helpful for building intuition, but they need a small \u201cwarning label\u201d about the Shampoo SVD story and the Muon speedup claims. For me, this exercise shows both the strength and the risk of AI tools: they can quickly generate coherent, high-level practice that matches our lecture, but we still have to read critically, check details, and mark where the model is hand-waving or hallucinating.</paragraph><file url=\"https://static.us.edusercontent.com/files/VSR4vguBbVbJ0rZfZQNes72M\" filename=\"Quiz1.pdf\"/><file url=\"https://static.us.edusercontent.com/files/GqMbaNhK2ThiBavT4EBaPsvt\" filename=\"Quiz2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T14:06:15.394783+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450819,
            "author": "Subhash Prasad",
            "project_title": "Special Participation A: Mistral on HW9 (non-coding)",
            "post_body": "I used Mistral Le Chat on HW9 (non-coding), and it achieved 99% accuracy, solving everything correctly on the first try with only one minor notation error. This was done on the second prompt, as the first one tried to be a pedagogical aide by providing explanations without complete answers.\n\nPrompts\nPrompt 1: \"Please complete all of the problems in this homework assignment.\"\nMistral tried to be pedagogical, encouraging me to work through problems myself\n\nPrompt 2: \"Give me the detailed answers and explanations. I need an answer key.\"\nThis resulted in complete solutions with full derivations.\n\nAnnotated Conversation\nhttps://drive.google.com/file/d/11VThgTMnqTfB7DuIIoTBzNxp0MFyCaiN/view?usp=sharing\n\nStrengths\n\nZero arithmetic errors across dozens of calculations\n\nPerfect PyTorch einsum notation\n\nExplained why answers are correct, not just what\n\nNo hallucinations or fake math\n\nErrors\n\nUsed \"bnd\" instead of \"bnk\" in one complexity expression\n\nConceptual understanding was clearly correct from explanation\n\nExplanations were lacking in the output from the second prompt, but this might be because I told the model to just give me the answers\n\nThoughts\nThe model's initial refusal to just give answers was interesting, as it wanted to be a tutor, not a solution key. This required explicit instruction to override. Without overriding it, the tool is well-formed as a place for students to close the gaps in their understanding after having attempted the problems by themselves.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Mistral Le Chat on HW9 (non-coding), and it achieved 99% accuracy, solving everything correctly on the first try with only one minor notation error. This was done on the second prompt, as the first one tried to be a pedagogical aide by providing explanations without complete answers.<break/><break/><bold>Prompts</bold><break/>Prompt 1: \"Please complete all of the problems in this homework assignment.\"<break/><italic>Mistral tried to be pedagogical, encouraging me to work through problems myself</italic><break/><break/>Prompt 2: \"Give me the detailed answers and explanations. I need an answer key.\"<break/><italic>This resulted in complete solutions with full derivations.</italic><break/><break/><bold>Annotated Conversation</bold><break/><link href=\"https://drive.google.com/file/d/11VThgTMnqTfB7DuIIoTBzNxp0MFyCaiN/view?usp=sharing\">https://drive.google.com/file/d/11VThgTMnqTfB7DuIIoTBzNxp0MFyCaiN/view?usp=sharing</link><break/><break/><bold>Strengths</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Zero arithmetic errors across dozens of calculations</paragraph></list-item><list-item><paragraph>Perfect PyTorch einsum notation</paragraph></list-item><list-item><paragraph>Explained <italic>why</italic> answers are correct, not just what</paragraph></list-item><list-item><paragraph>No hallucinations or fake math</paragraph></list-item></list><paragraph><bold>Errors</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Used \"bnd\" instead of \"bnk\" in one complexity expression</paragraph></list-item><list-item><paragraph>Conceptual understanding was clearly correct from explanation</paragraph></list-item><list-item><paragraph>Explanations were lacking in the output from the second prompt, but this might be because I told the model to just give me the answers</paragraph></list-item></list><paragraph><bold>Thoughts</bold><break/>The model's initial refusal to just give answers was interesting, as it wanted to be a tutor, not a solution key. This required explicit instruction to override. Without overriding it, the tool is well-formed as a place for students to close the gaps in their understanding after having attempted the problems by themselves.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/11VThgTMnqTfB7DuIIoTBzNxp0MFyCaiN/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T14:03:45.291859+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450794,
            "author": "Tiffany Dang",
            "project_title": "Special Participation E: ChatGPT - using lectures notes and transcript to give summaries and quizzes for generative models topics",
            "post_body": "For generative models topic, i only saw lecture notes from lecture 27 and 25, but not lecture 26. Additionally, lots of times, we want to have lectures transcript to fill in the blanks by only reading the lecture notes. Therefore, this tutor is prompted to first give an overall executive summary of concept first, this is useful to start studying if user hasn't watched the recordings and read the lecture notes on the topic. Then, after the summary/concept overview, the llm will also generate questions to quiz user to test their concepts understanding. And from the user's answers, the llm will then generate analyze user's grasp on different subtopic and ask more in-depth questions as well as giving feedbacks. I purposely gave wrong answers to some questions the llm asked and it was able to identify the wrong answers, gave feedbacks, and ask more questions on that topics to make sure users get the correct grasp of knowledge understanding. This process is repeated until users feel confident of their knowledge and stop the interaction. \n\ntraces: https://chatgpt.com/share/693a30e5-97c0-800b-8050-b5471bea7117\n\nannotations: https://drive.google.com/file/d/1JTJi0ZMBb_jJjP9W-7uv9SLP7sq1Srv5/view?usp=sharing\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For generative models topic, i only saw lecture notes from lecture 27 and 25, but not lecture 26. Additionally, lots of times, we want to have lectures transcript to fill in the blanks by only reading the lecture notes. Therefore, this tutor is prompted to first give an overall executive summary of concept first, this is useful to start studying if user hasn't watched the recordings and read the lecture notes on the topic. Then, after the summary/concept overview, the llm will also generate questions to quiz user to test their concepts understanding. And from the user's answers, the llm will then generate analyze user's grasp on different subtopic and ask more in-depth questions as well as giving feedbacks. I purposely gave wrong answers to some questions the llm asked and it was able to identify the wrong answers, gave feedbacks, and ask more questions on that topics to make sure users get the correct grasp of knowledge understanding. This process is repeated until users feel confident of their knowledge and stop the interaction. </paragraph><paragraph>traces: <link href=\"https://chatgpt.com/share/693a30e5-97c0-800b-8050-b5471bea7117\">https://chatgpt.com/share/693a30e5-97c0-800b-8050-b5471bea7117</link></paragraph><paragraph>annotations: https://drive.google.com/file/d/1JTJi0ZMBb_jJjP9W-7uv9SLP7sq1Srv5/view?usp=sharing</paragraph><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/693a30e5-97c0-800b-8050-b5471bea7117"
            ],
            "attachments": [],
            "created_at": "2025-12-11T13:57:44.814992+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450707,
            "author": "Tiffany Dang",
            "project_title": "Special Participation B: Deepseek on HW11 - coding part",
            "post_body": "For special participation B, i used Deepseek to generate code as solution for the coding questions of HW12. \n\n\n\nStarting with the first coding question - transformer interpretability. Deepseek quickly generate code for both functions that need to be implemented. However, this first version didn't pass the test case of the first function - single attention head function. I copied and pasted the assertion error and the llm was able to identify the error source and update the code and passed the test. During this process, it generated lots of text to describe the thought process. I was able to see how the llm was try to go back and forth between the problem and solution to narrow down scope of errors. It also actively trace the code and test cases as well before outputting the final code. I did the same for the second function - induction copy head function. However, this function also didn't pass the test cases. I copied and pasted the errors without any prompt for the llm to figure it out my itself. Repeated this process 3 times but the llm still couldn't narrow down the errors source and the generated code get stuck with the same test cases. Therefore, I looked at the solution code posted on Ed and compared the difference between the generated code and solution code, then I prompted the llm to fix to that direction, this include guides such as remove the softmax at the end, etc. Did so twice before the llm can produce the final solution that passed all test cases.  \n\nFor next 2 coding questions - scaling laws, pruning, and quantization I just uploaded the notebook file and tell them to finish the todos and it was able to do so correctly.  This surprised me after the issues it got into from the last coding problem. \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For special participation B, i used Deepseek to generate code as solution for the coding questions of HW12. </paragraph><paragraph/><paragraph>Starting with the first coding question - transformer interpretability. Deepseek quickly generate code for both functions that need to be implemented. However, this first version didn't pass the test case of the first function - single attention head function. I copied and pasted the assertion error and the llm was able to identify the error source and update the code and passed the test. During this process, it generated lots of text to describe the thought process. I was able to see how the llm was try to go back and forth between the problem and solution to narrow down scope of errors. It also actively trace the code and test cases as well before outputting the final code. I did the same for the second function - induction copy head function. However, this function also didn't pass the test cases. I copied and pasted the errors without any prompt for the llm to figure it out my itself. Repeated this process 3 times but the llm still couldn't narrow down the errors source and the generated code get stuck with the same test cases. Therefore, I looked at the solution code posted on Ed and compared the difference between the generated code and solution code, then I prompted the llm to fix to that direction, this include guides such as remove the softmax at the end, etc. Did so twice before the llm can produce the final solution that passed all test cases.  </paragraph><paragraph>For next 2 coding questions - scaling laws, pruning, and quantization I just uploaded the notebook file and tell them to finish the todos and it was able to do so correctly.  This surprised me after the issues it got into from the last coding problem. </paragraph><file url=\"https://static.us.edusercontent.com/files/DhunTlim11Cq8soF13ebSUwQ\" filename=\"interaction1.pdf\"/><file url=\"https://static.us.edusercontent.com/files/TgThd7dedvnLtJJSZmzK42vf\" filename=\"interaction 4 - quantization.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ZhbQoi794xg061znAOcLgXyU\" filename=\"interaction 3 - pruning.pdf\"/><file url=\"https://static.us.edusercontent.com/files/BYng3EsiLG1qBNTkTBplyOqJ\" filename=\"interaction 2.pdf\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:42:48.942043+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450685,
            "author": "Atharv Sampath",
            "project_title": "Special Participation A: Claude 4.5 Opus (Extended Thinking) on HW 08",
            "post_body": "Summary: Claude Opus 4.5 with thinking was able to mostly one-shot all of the questions. However, interestingly, it got a bit stuck/potentially overthought on problem 1c). Even with significant guidance, it kept adding in terms that weren't really necessary, and I basically needed to fully guide it to the correct answer. Oddly, it did the difficult part of the question correct, which was figuring out the critical path length. But it stumbled on getting the final result. All other answers it gave were mostly or fully correct in one-shot.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/fBpqX1IwRQuSWFcbVenTOdJd\" filename=\"Claude-HW8.pdf\"/><paragraph>Summary: Claude Opus 4.5 with thinking was able to mostly one-shot all of the questions. However, interestingly, it got a bit stuck/potentially overthought on problem 1c). Even with significant guidance, it kept adding in terms that weren't really necessary, and I basically needed to fully guide it to the correct answer. Oddly, it did the difficult part of the question correct, which was figuring out the critical path length. But it stumbled on getting the final result. All other answers it gave were mostly or fully correct in one-shot.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:39:19.009202+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450682,
            "author": "Yuri Lee",
            "project_title": "Special Participation A: Gemini 3 Pro(Thinking) Homework 1",
            "post_body": "In this assignment, I attempted to use Gemini 3 Pro (in Thinking mode) to solve all the non-coding portions of HW1. Based on past interactions with LLMs, my experience was that LLMs lack the ability to provide insight/ intuition into mathematical problems and tend to focus on just deriving answers (that are even frequently incorrect). \n\nThis time, I explicitly prompted it to interpret each problem, produce the full solution, and show all step-by-step derivations.\n\nA surprising finding was that Gemini consistently included intermediate steps that LLMs often skip. Its derivations did not gloss over 'trivial' algebraic transitions/ assumptions, which made the explanations easier to follow, though sometimes at the cost of conciseness. Another positive observation was that it produced geometric interpretations, such as the intuition behind optimizer convergence correctly and in a single attempt. \n\nIn previous experiences, I typically had to re-prompt multiple times before getting a coherent explanation of a notation or concept, but Gemini delivered these interpretations clearly on the first try. This made the interaction feel much more time-efficient. ",
            "content_xml": "<document version=\"2.0\"><paragraph>In this assignment, I attempted to use Gemini 3 Pro (in Thinking mode) to solve all the non-coding portions of HW1. Based on past interactions with LLMs, my experience was that LLMs lack the ability to provide insight/ intuition into mathematical problems and tend to focus on just deriving answers (that are even frequently incorrect). </paragraph><paragraph>This time, I explicitly prompted it to interpret each problem, produce the full solution, and show all step-by-step derivations.</paragraph><paragraph>A surprising finding was that Gemini consistently included intermediate steps that LLMs often skip. Its derivations did not gloss over 'trivial' algebraic transitions/ assumptions, which made the explanations easier to follow, though sometimes at the cost of conciseness. Another positive observation was that it produced geometric interpretations, such as the intuition behind optimizer convergence correctly and in a single attempt. </paragraph><paragraph>In previous experiences, I typically had to re-prompt multiple times before getting a coherent explanation of a notation or concept, but Gemini delivered these interpretations clearly on the first try. This made the interaction feel much more time-efficient. </paragraph><file url=\"https://static.us.edusercontent.com/files/2p3N2QatOx3jPLTh6ogWatwv\" filename=\"special-a-gemini3pro(thinking)-hw1(written).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:38:38.989415+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450676,
            "author": "Edward Zhang",
            "project_title": "Special Participation E: Kalman Filter & RNN Comparison",
            "post_body": "In this chat I clarified how Kalman filters relate to RNNs and what each symbol means. I learned that a (linear) Kalman filter can be seen as a very special linear RNN: the latent state $X_i$ in the state--space model is like the true underlying process, the observation $Y_i$ corresponds to the RNN input $x_i$, and the Kalman estimate $\\hat X_{i \\mid i}$ (plus its variance) plays the role of the hidden state $h_i$. In RNN notation we usually don\u2019t write an explicit $X_i$; instead, the hidden state is supposed to encode our best internal representation of that latent state. I also sorted out the \u201coutput\u201d $y_i$: in Kalman terms I can think of $y_i$ as just a readout of the filter\u2019s belief, e.g.\\ $y_i = \\hat X_{i \\mid i}$ or the predicted observation, and even though we write $y_i = g(h_i)$, it still depends on the current input $x_i$ indirectly through the update $h_i = f(h_{i-1}, x_i)$. Overall, I now see Kalman filtering as a model-based, optimal linear RNN for linear-Gaussian systems, while a generic RNN is a learned, more flexible version of a state estimator/filter.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>In this chat I clarified how Kalman filters relate to RNNs and what each symbol means. I learned that a (linear) Kalman filter can be seen as a very special linear RNN: the latent state $X_i$ in the state--space model is like the true underlying process, the observation $Y_i$ corresponds to the RNN input $x_i$, and the Kalman estimate $\\hat X_{i \\mid i}$ (plus its variance) plays the role of the hidden state $h_i$. In RNN notation we usually don\u2019t write an explicit $X_i$; instead, the hidden state is supposed to encode our best internal representation of that latent state. I also sorted out the \u201coutput\u201d $y_i$: in Kalman terms I can think of $y_i$ as just a readout of the filter\u2019s belief, e.g.\\ $y_i = \\hat X_{i \\mid i}$ or the predicted observation, and even though we write $y_i = g(h_i)$, it still depends on the current input $x_i$ indirectly through the update $h_i = f(h_{i-1}, x_i)$. Overall, I now see Kalman filtering as a model-based, optimal linear RNN for linear-Gaussian systems, while a generic RNN is a learned, more flexible version of a state estimator/filter.</paragraph><file url=\"https://static.us.edusercontent.com/files/R1U0abSfRm4nYMaNEatesWQg\" filename=\"Special_Participation_E_2-merged.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:37:57.431236+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450650,
            "author": "Evan Davis",
            "project_title": "Special Participation E: ChatGPT as Exam Prep from Exam Problems",
            "post_body": "Here, I fed ChatGPT my notes from the course, as well as every homework and discussion solution except Homework 12 (whose solutions are unposted). I additionally gave it the Homework 12 problems, and the past midterms and finals from previous website versions that are available (Fall 2022, Spring 2023). I don't believe we have access to Spring 2025's final yet, so I couldn't feed it to ChatGPT.\n\nI then asked it to generate a practice exam with questions of varying difficulty. It then generated 18 practice questions, with 3 from each of 6 \"topics\", categorized into three levels of difficulty, one per level in each \"topic\". It additionally generated solutions for these questions. I then tested it on RLVR and Diffusion model questions, which it generated, alongside hints or solutions.\n\nTo exam-prep for a specific topic, feed the model this prompt: Give me a [Level 1; Level 2; Level 3] problem on [Topic]. Give me the problem, then a few gentle hints, and then a fully worked solution.\n\nI would generally recommend doing Level 1, then Level 2, then Level 3 for any particular topic you feel uncomfortable with.\n\nHere is a link to the chat: https://chatgpt.com/share/6939ddc2-f27c-800d-8b79-7f9a376b9416\n\nAnd here is the annotated chat:\n\nAll mistakes in my notes are my own. When using the chatbot, feel free to re-upload my notes (https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing), or upload your own, to address forgetting.\n\nI hope this was helpful. Happy studying!",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I fed ChatGPT my notes from the course, as well as every homework and discussion solution except Homework 12 (whose solutions are unposted). I additionally gave it the Homework 12 problems, and the past midterms and finals from previous website versions that are available (Fall 2022, Spring 2023). I don't believe we have access to Spring 2025's final yet, so I couldn't feed it to ChatGPT.</paragraph><paragraph>I then asked it to generate a practice exam with questions of varying difficulty. It then generated 18 practice questions, with 3 from each of 6 \"topics\", categorized into three levels of difficulty, one per level in each \"topic\". It additionally generated solutions for these questions. I then tested it on RLVR and Diffusion model questions, which it generated, alongside hints or solutions.</paragraph><paragraph>To exam-prep for a specific topic, feed the model this prompt: Give me a [Level 1; Level 2; Level 3] problem on [Topic]. Give me the problem, then a few gentle hints, and then a fully worked solution.</paragraph><paragraph>I would generally recommend doing Level 1, then Level 2, then Level 3 for any particular topic you feel uncomfortable with.</paragraph><paragraph>Here is a link to the chat: <link href=\"https://chatgpt.com/share/6939ddc2-f27c-800d-8b79-7f9a376b9416\">https://chatgpt.com/share/6939ddc2-f27c-800d-8b79-7f9a376b9416</link></paragraph><paragraph>And here is the annotated chat:</paragraph><file url=\"https://static.us.edusercontent.com/files/NYBjbnuX9WBXXeS7Dg3AQnGj\" filename=\"exam_prep.pdf\"/><paragraph>All mistakes in my notes are my own. When using the chatbot, feel free to re-upload my notes (<link href=\"https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing\">https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing</link>), or upload your own, to address forgetting.</paragraph><paragraph>I hope this was helpful. Happy studying!</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/6939ddc2-f27c-800d-8b79-7f9a376b9416",
                "https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T13:33:24.840529+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450625,
            "author": "Shuwei Yang",
            "project_title": "Special Participation E: Intuitively understand optimizer by Claude Sonnet 4.5",
            "post_body": "I used Claude sonnet 4.5 as an interactive \u201cpre/post-lecture reading\u201d for Lecture 5 on optimizers (gradient descent, sign SGD, norm-based views, Shampoo, \u03bcP, and Muon). Instead of just asking it to summarize the slides, I treated Claude like a tutor I could program with prompts. I\u2019ll attach the main prompts I used, plus a chunk of our conversation, so that other people can reuse or modify this setup if they want to self-study the same material.\n\nThe first thing I asked for was a \u201c100-year-old grandma\u201d version of the lecture. I told Claude to imagine it was explaining optimizers to a very smart but non-technical grandma, starting from the foggy-mountain picture of gradient descent, then moving to sign SGD, different norms as different ways of constraining steps, and finally how Shampoo and \u03bcP/Muon fit into that story. I emphasized slow pacing, friendly tone, lots of analogies (water pipes for Xavier, rubber sheets and trampolines for norms and spectral stuff), and as few formulas as possible until the intuition felt solid. I also uploaded the Lecture 5 slides and kept asking it to tie things back to specific pages and symbols, so it wouldn\u2019t drift into some generic \u201coptimizers 101\u201d description. Along the way it kept quizzing me with small questions like \u201cwhy might sign SGD be useful?\u201d or \u201cwhy does it make sense to throw away \u03a3?\u201d which forced me to answer in my own words instead of just passively reading.\n\nEven with that, there was one part of the lecture I still found very confusing: the chain from Xavier initialization \u2192 RMS norm \u2192 spectral norm \u2192 Shampoo. So I wrote a second, more focused prompt that asked Claude to explain only this chain, step by step, as a narrative. I asked it to start from the practical problem Xavier is trying to solve (\u201ckeep each layer\u2019s activations at a reasonable scale\u201d), then explain why that naturally leads to thinking in terms of \u201ctypical size per parameter\u201d and the RMS norm, then reinterpret weight matrices as stretchy rubber sheets to motivate the spectral norm, and finally connect that back to the constrained optimization problem whose solution looks like a Shampoo update. This second pass helped a lot: once it framed RMS as \u201caverage size of an entry\u201d and spectral norm as \u201cmaximum stretching factor in those units,\u201d the \u0394W \u2248 \u2212\u03b7UV\u1d40 picture suddenly felt much less mysterious.\n\nI also tried to be critical, as the instructions ask. In my annotations on the trace, I point out places where the model is more intuitive than rigorous. For example, when it connects RMS norms to induced matrix norms and spectral norms, it sometimes glosses over details with \u201c\u2248\u201d, which is fine for building intuition but shouldn\u2019t be mistaken for a proof. Its explanation of \u03bcP and Muon stays at a high level: it talks about reusing hyperparameters across model scales and 10\u00d7 speedups in NanoGPT-style experiments, but it doesn\u2019t really go into implementation details or computational costs. It also occasionally ignored my request to delay equations and introduced formulas earlier than I would have liked if this were a polished pre-lecture handout. These are places where I think a human reader needs to be cautious and treat the model as a helper, not an authority.\n\nOverall, though, this felt like a reasonable example of what special participation E is aiming for: instead of reading the slides in a passive way, I used an AI tool to build a small, reusable learning artifact for one lecture, and then interacted with it in a way that made me articulate my own understanding and push back when things were unclear. If other students want to try something similar, they could reuse my prompts on a different topic (attention, diffusion, etc.), put the model into this \u201cgrandma mode\u201d to get a soft first pass, and then write their own follow-up prompts for the one or two conceptual chains they still don\u2019t understand, making the model re-explain those pieces until they can say them back in their own words.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Claude sonnet 4.5 as an interactive \u201cpre/post-lecture reading\u201d for Lecture 5 on optimizers (gradient descent, sign SGD, norm-based views, Shampoo, \u03bcP, and Muon). Instead of just asking it to summarize the slides, I treated Claude like a tutor I could program with prompts. I\u2019ll attach the main prompts I used, plus a chunk of our conversation, so that other people can reuse or modify this setup if they want to self-study the same material.</paragraph><paragraph>The first thing I asked for was a \u201c100-year-old grandma\u201d version of the lecture. I told Claude to imagine it was explaining optimizers to a very smart but non-technical grandma, starting from the foggy-mountain picture of gradient descent, then moving to sign SGD, different norms as different ways of constraining steps, and finally how Shampoo and \u03bcP/Muon fit into that story. I emphasized slow pacing, friendly tone, lots of analogies (water pipes for Xavier, rubber sheets and trampolines for norms and spectral stuff), and as few formulas as possible until the intuition felt solid. I also uploaded the Lecture 5 slides and kept asking it to tie things back to specific pages and symbols, so it wouldn\u2019t drift into some generic \u201coptimizers 101\u201d description. Along the way it kept quizzing me with small questions like \u201cwhy might sign SGD be useful?\u201d or \u201cwhy does it make sense to throw away \u03a3?\u201d which forced me to answer in my own words instead of just passively reading.</paragraph><paragraph>Even with that, there was one part of the lecture I still found very confusing: the chain from Xavier initialization \u2192 RMS norm \u2192 spectral norm \u2192 Shampoo. So I wrote a second, more focused prompt that asked Claude to explain only this chain, step by step, as a narrative. I asked it to start from the practical problem Xavier is trying to solve (\u201ckeep each layer\u2019s activations at a reasonable scale\u201d), then explain why that naturally leads to thinking in terms of \u201ctypical size per parameter\u201d and the RMS norm, then reinterpret weight matrices as stretchy rubber sheets to motivate the spectral norm, and finally connect that back to the constrained optimization problem whose solution looks like a Shampoo update. This second pass helped a lot: once it framed RMS as \u201caverage size of an entry\u201d and spectral norm as \u201cmaximum stretching factor in those units,\u201d the \u0394W \u2248 \u2212\u03b7UV\u1d40 picture suddenly felt much less mysterious.</paragraph><paragraph>I also tried to be critical, as the instructions ask. In my annotations on the trace, I point out places where the model is more intuitive than rigorous. For example, when it connects RMS norms to induced matrix norms and spectral norms, it sometimes glosses over details with \u201c\u2248\u201d, which is fine for building intuition but shouldn\u2019t be mistaken for a proof. Its explanation of \u03bcP and Muon stays at a high level: it talks about reusing hyperparameters across model scales and 10\u00d7 speedups in NanoGPT-style experiments, but it doesn\u2019t really go into implementation details or computational costs. It also occasionally ignored my request to delay equations and introduced formulas earlier than I would have liked if this were a polished pre-lecture handout. These are places where I think a human reader needs to be cautious and treat the model as a helper, not an authority.</paragraph><paragraph>Overall, though, this felt like a reasonable example of what special participation E is aiming for: instead of reading the slides in a passive way, I used an AI tool to build a small, reusable learning artifact for one lecture, and then interacted with it in a way that made me articulate my own understanding and push back when things were unclear. If other students want to try something similar, they could reuse my prompts on a different topic (attention, diffusion, etc.), put the model into this \u201cgrandma mode\u201d to get a soft first pass, and then write their own follow-up prompts for the one or two conceptual chains they still don\u2019t understand, making the model re-explain those pieces until they can say them back in their own words.</paragraph><file url=\"https://static.us.edusercontent.com/files/8ju0HhzdeXhBURn36cVA2MVf\" filename=\"Special Participation E Intuitively review optimizer with Claude.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:30:53.862379+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450621,
            "author": "Shoumik Roychowdhury",
            "project_title": "Special Participation E: Cheatsheet for Muon and MuP",
            "post_body": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build individualized pre-lecture learning tools.\n\nI\u2019m sharing the prompt, output artifacts, and annotated interaction trace so you can use them yourselves and also see both the strengths and the failure modes of LLM-assisted studying.\n\n\nNOTE:\n\nthe model occasionally implied citations (\u201cas from class notes\u201d) without pulling actual page numbers\n\n Some formulas were slightly rephrased\u2014not incorrect, but not exactly matching lecture notation\n\nThe kernel attention explanation is correct conceptually, but slightly hand-wavey on the random feature approximation\n\nPrompt 1:\n\u201cGenerate a comprehensive, exam-ready cheatsheet for Berkeley EECS 182 (Fall 2025), focusing especially on: Muon and MuP optimization. The cheatsheet should prioritize mathematical clarity, include equations and derivations, use text diagrams, and be optimized for last-minute review.\u201d\n\nPrompt2:\n\"ok now make cheat sheet for this \"\n\nPrompt3:\n\"provide the latex\"\n\nConclusion:\n\nUseful as a study tool, but not a replacement for primary sources (lecture slides, notes, HW derivations). You must still verify key formulas.\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build <italic>individualized pre-lecture learning tools</italic>.</paragraph><paragraph>I\u2019m sharing the <bold>prompt, output artifacts, and annotated interaction trace</bold> so you can use them yourselves and also see both the strengths <italic>and</italic> the failure modes of LLM-assisted studying.<break/><break/><break/>NOTE:<break/><break/>the model occasionally implied citations (\u201cas from class notes\u201d) without pulling actual page numbers<break/><break/> Some formulas were slightly rephrased\u2014not incorrect, but not exactly matching lecture notation<break/><break/>The kernel attention explanation is correct conceptually, but slightly hand-wavey on the random feature approximation</paragraph><paragraph>Prompt 1:<break/>\u201cGenerate a comprehensive, exam-ready cheatsheet for Berkeley EECS 182 (Fall 2025), focusing especially on: Muon and MuP optimization. The cheatsheet should prioritize mathematical clarity, include equations and derivations, use text diagrams, and be optimized for last-minute review.\u201d</paragraph><paragraph>Prompt2:<break/>\"ok now make cheat sheet for this \"</paragraph><paragraph>Prompt3:<break/>\"provide the latex\"</paragraph><paragraph><bold>Conclusion:</bold><break/><break/>Useful as a study tool, but <italic>not a replacement</italic> for primary sources (lecture slides, notes, HW derivations). You must still verify key formulas.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/GlF9Y36BODBbNG86zKSeKtHi\" filename=\"Muon_and_MuP_Cheatsheet.pdf\"/><paragraph><break/><break/><break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:30:19.290804+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450591,
            "author": "Sarvagya Somvanshi",
            "project_title": "Special Participation A: Grok on HW10 Theory",
            "post_body": "I prompted Grok to solve the theoretical portion of Homework 10, including the mathematical part, the reading assignment, the notebook result analysis. It excelled at mathematical derivations, following instructions to the letter without skipping steps. However, on conceptual questions, it initially relied on inferring results based on domain knowledge until I explicitly uploaded the visual results from the notebook, at which point its analysis became significantly more grounded and insightful.\n\nQuestion 1: Linearized Attention Derivation The model handled the mathematical derivation pretty well. It correctly expanded the squared norm and identified the necessary scalar substitutions to approximate Softmax attention . It was particularly strong in analyzing the computational complexity, correctly identifying the reduction from quadratic O(N2) to linear O(N) by leveraging the recursive cumulative sum trick . This was a one shot success!\n\nQuestion 2: FaceNet Paper Analysis This section was handled well as expected since it was a reading assignment with context given. I gave the model the links so it was effectively a search engine, accurately retrieving architectures (Zeiler & Fergus vs. Inception) and definitions (Triplet Loss) . It correctly defined \"semi-hard negatives\" and \"harmonic embeddings,\" but its initial responses were overly verbose. It provided correct facts as needed for the question/\n\nQuestion 3: Example Difficulty (Notebook Analysis) This was the most revealing interaction. Initially, the model \"hallucinated\" the notebook's output hence guessing the dataset and results, basing results of standard literature. While these guesses were factually \"correct\" based on the domain, they were not derived from the actual file. Once I uploaded the screenshots of the plots, the model's answers improved slightly. It abandoned its generic answers and provided a more accurate analysis of the bimodal exit distributions and the specific geometric properties (elongation/noise) that caused difficulty .\n\nOverall: Grok  demonstrated strong mathematical reasoning and reliable retrieval capabilities. However, it exhibited a tendency to \"coast\" on general knowledge when specific data was missing (as seen in the notebook section). Here is the annotated chat\n\n\n\nAnd here are the chats online:\n\nhttps://grok.com/share/c2hhcmQtMw_b3d0111f-225a-4421-8e87-5815f7cbfd22\n\nhttps://grok.com/share/c2hhcmQtMw_a1f459db-cc3c-43ac-bfb6-e0a33eb3be31\n\nhttps://grok.com/share/c2hhcmQtMw_20fe1b02-c86c-4580-88de-1b3b41b562b2",
            "content_xml": "<document version=\"2.0\"><paragraph>I prompted Grok to solve the theoretical portion of Homework 10, including the mathematical part, the reading assignment, the notebook result analysis. It excelled at mathematical derivations, following instructions to the letter without skipping steps. However, on conceptual questions, it initially relied on inferring results based on domain knowledge until I explicitly uploaded the visual results from the notebook, at which point its analysis became significantly more grounded and insightful.</paragraph><paragraph><bold>Question 1: Linearized Attention Derivation</bold> The model handled the mathematical derivation pretty well. It correctly expanded the squared norm and identified the necessary scalar substitutions to approximate Softmax attention . It was particularly strong in analyzing the computational complexity, correctly identifying the reduction from quadratic O(N2) to linear O(N) by leveraging the recursive cumulative sum trick . This was a one shot success!</paragraph><paragraph><bold>Question 2: FaceNet Paper Analysis</bold> This section was handled well as expected since it was a reading assignment with context given. I gave the model the links so it was effectively a search engine, accurately retrieving architectures (Zeiler &amp; Fergus vs. Inception) and definitions (Triplet Loss) . It correctly defined \"semi-hard negatives\" and \"harmonic embeddings,\" but its initial responses were overly verbose. It provided correct facts as needed for the question/</paragraph><paragraph><bold>Question 3: Example Difficulty (Notebook Analysis)</bold> This was the most revealing interaction. Initially, the model \"hallucinated\" the notebook's output hence guessing the dataset and results, basing results of standard literature. While these guesses were factually \"correct\" based on the domain, they were not derived from the actual file. Once I uploaded the screenshots of the plots, the model's answers improved slightly. It abandoned its generic answers and provided a more accurate analysis of the bimodal exit distributions and the specific geometric properties (elongation/noise) that caused difficulty .</paragraph><paragraph><bold>Overall:</bold> Grok  demonstrated strong mathematical reasoning and reliable retrieval capabilities. However, it exhibited a tendency to \"coast\" on general knowledge when specific data was missing (as seen in the notebook section). Here is the annotated chat</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/jhWb2f9zvjhHhYFd2RgRwfGz\" filename=\"hw10_a.pdf\"/><paragraph>And here are the chats online:</paragraph><paragraph><link href=\"https://grok.com/share/c2hhcmQtMw_b3d0111f-225a-4421-8e87-5815f7cbfd22\">https://grok.com/share/c2hhcmQtMw_b3d0111f-225a-4421-8e87-5815f7cbfd22</link></paragraph><paragraph><link href=\"https://grok.com/share/c2hhcmQtMw_a1f459db-cc3c-43ac-bfb6-e0a33eb3be31\">https://grok.com/share/c2hhcmQtMw_a1f459db-cc3c-43ac-bfb6-e0a33eb3be31</link></paragraph><paragraph><link href=\"https://grok.com/share/c2hhcmQtMw_20fe1b02-c86c-4580-88de-1b3b41b562b2\">https://grok.com/share/c2hhcmQtMw_20fe1b02-c86c-4580-88de-1b3b41b562b2</link></paragraph></document>",
            "links": [
                "https://grok.com/share/c2hhcmQtMw_b3d0111f-225a-4421-8e87-5815f7cbfd22",
                "https://grok.com/share/c2hhcmQtMw_a1f459db-cc3c-43ac-bfb6-e0a33eb3be31",
                "https://grok.com/share/c2hhcmQtMw_20fe1b02-c86c-4580-88de-1b3b41b562b2"
            ],
            "attachments": [],
            "created_at": "2025-12-11T13:25:36.177853+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450587,
            "author": "Evan Davis",
            "project_title": "Special Participation E: ChatGPT as Topic-Specific Tutor for Entire Course",
            "post_body": "Here, I fed ChatGPT my original notes (posted below) for the entire class and I had it generate a variety of summaries of the entire course, from a base summary of the content we covered, to a conceptual one, then a mathematical one, then a lecture-specific summary, and finally a mini-study guide. It was then in a state to serve as a topic-specific tutor for those struggling with any part of the class.\n\nIn the original summaries, it ignored muP, a topic we covered, so I tested out the following prompt on muP. After thinking for a while (\"re-reading\" my notes), it successfully generated a tutorial for me, so it should be good to go for general use. Here is the prompt I used:\n\nI am confused about [insert subject here], and do not have a very good understanding of it. I'd like you to go into more detail.\n\nTo do so, can you do the following for me on [subject]:\n\n(a) Explain it at a conceptual high-level, including motivation and loosely the gist of what it goes/accomplishes. Include the lecture notes I can reference from the notes you were given.\n(b) Go into the math in detail. Remain somewhat accessible, but be rigorous.\n(c) Summarize the math and concepts in a \"study sheet\" format.\n(d) Create a practice problem, and then walk me through the solution.\n(e) Create 3 more practice problems, and prepare hints and solutions for each.\n\nHere is a link to the chat: https://chatgpt.com/share/6939cb36-cdfc-800d-81b8-ec5c559f1645\n\nAnd annotated chat attached below:\n\nAll mistakes in my notes are my own. When using the chatbot, feel free to re-upload my notes (https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing), or upload your own, to address forgetting.\n\nI hope this was helpful. Happy studying!",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I fed ChatGPT my original notes (posted below) for the entire class and I had it generate a variety of summaries of the entire course, from a base summary of the content we covered, to a conceptual one, then a mathematical one, then a lecture-specific summary, and finally a mini-study guide. It was then in a state to serve as a topic-specific tutor for those struggling with any part of the class.</paragraph><paragraph>In the original summaries, it ignored muP, a topic we covered, so I tested out the following prompt on muP. After thinking for a while (\"re-reading\" my notes), it successfully generated a tutorial for me, so it should be good to go for general use. Here is the prompt I used:</paragraph><paragraph>I am confused about [insert subject here], and do not have a very good understanding of it. I'd like you to go into more detail.</paragraph><paragraph>To do so, can you do the following for me on [subject]:</paragraph><paragraph>(a) Explain it at a conceptual high-level, including motivation and loosely the gist of what it goes/accomplishes. Include the lecture notes I can reference from the notes you were given.<break/>(b) Go into the math in detail. Remain somewhat accessible, but be rigorous.<break/>(c) Summarize the math and concepts in a \"study sheet\" format.<break/>(d) Create a practice problem, and then walk me through the solution.<break/>(e) Create 3 more practice problems, and prepare hints and solutions for each.</paragraph><paragraph>Here is a link to the chat: <link href=\"https://chatgpt.com/share/6939cb36-cdfc-800d-81b8-ec5c559f1645\">https://chatgpt.com/share/6939cb36-cdfc-800d-81b8-ec5c559f1645</link></paragraph><paragraph>And annotated chat attached below:</paragraph><file url=\"https://static.us.edusercontent.com/files/gqXUYD62SJ39Z0e7KsPCS4EW\" filename=\"study_guide.pdf\"/><paragraph>All mistakes in my notes are my own. When using the chatbot, feel free to re-upload my notes (<link href=\"https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing\">https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing</link>), or upload your own, to address forgetting.</paragraph><paragraph>I hope this was helpful. Happy studying!</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/6939cb36-cdfc-800d-81b8-ec5c559f1645",
                "https://drive.google.com/file/d/1rGTtguBle1VwN4aL86EKTSqyXdGdE-aW/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-11T13:25:00.569025+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450577,
            "author": "Neel Kolhe",
            "project_title": "Special Participation E: Warmup Worksheet for HW 1",
            "post_body": "I fed ChatGPT HW0 (pre-requisites), HW 1, and Discussion 1 and asked it to make a worksheet in the form of a homework to make me ready to do the homework. The warm-up worksheet included topic reviews and problems, to make me ready to solve the homework fully alone. I have added my trace here and the worksheets ChatGPT created - it has all necessary material and was quite detailed. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I fed ChatGPT HW0 (pre-requisites), HW 1, and Discussion 1 and asked it to make a worksheet in the form of a homework to make me ready to do the homework. The warm-up worksheet included topic reviews and problems, to make me ready to solve the homework fully alone. I have added my trace here and the worksheets ChatGPT created - it has all necessary material and was quite detailed. </paragraph><file url=\"https://static.us.edusercontent.com/files/UAQ93kJZr7f63KAZyPRSUdp3\" filename=\"Homework 1 warm-up.pdf\"/><file url=\"https://static.us.edusercontent.com/files/2SSg5IwBnw4TrQlevdO4jpWQ\" filename=\"hw1warmupsoln.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ZywOjEGyFsLGBYclAlB5jtbH\" filename=\"hw1warmup.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:24:08.447218+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450522,
            "author": "Eric Wang",
            "project_title": "Special Participation B: ChatGPT-5.1 Pro on HW5",
            "post_body": "I used ChatGPT-5.1 Pro on HW5 Q5-6 (coding questions) and it again one-shot everything and told me exactly what to do, modify, and run. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT-5.1 Pro on HW5 Q5-6 (coding questions) and it again one-shot everything and told me exactly what to do, modify, and run. </paragraph><file url=\"https://static.us.edusercontent.com/files/yjFednigSwPOqGOwehOHVFUf\" filename=\"hw5_coding_solutions_FINAL.pdf\"/><file url=\"https://static.us.edusercontent.com/files/XqYllefQnYLLYQdDvjZV8PIz\" filename=\"hw5_coding_executive_summary.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:15:54.532758+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450486,
            "author": "Rohan Gopalam",
            "project_title": "Special Participation E: Review Session Warmup Worksheet",
            "post_body": "Going into the review sessions today, I was a little worried that I would have forgotten all the information from earlier in the semester. When I tried reading through the lecture notes, it was much harder to follow without watching the corresponding lecture. However, watching all the lectures would also take a long time and be a waste of time since I already knew a lot of the information and just needed a refresher. Instead, I used Gemini to look through all the lectures corresponding to each review session and also the corresponding questions and give me a quick 10 minute warmup worksheet I could read and work through before each session. Below is the prompt I used and the review worksheet for the optimizers review session. With the prompt I also added the lecture pdfs and screenshots of the homework questions as attachments.\n\nPrompt: I am getting ready for a review session for my deep learning class. I want to make sure I am prepared going in to the session. I want you to generate me a quick (~10min) worksheet that has key information I will need for that review session and also short warmup questions. However, make sure that the questions are not too similar to the questions being reviewed in the session itself so I can still learn from that and be challenged. Here are the lecture pdfs and the questions the teacher will be going over in the review session.\n\n\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Going into the review sessions today, I was a little worried that I would have forgotten all the information from earlier in the semester. When I tried reading through the lecture notes, it was much harder to follow without watching the corresponding lecture. However, watching all the lectures would also take a long time and be a waste of time since I already knew a lot of the information and just needed a refresher. Instead, I used Gemini to look through all the lectures corresponding to each review session and also the corresponding questions and give me a quick 10 minute warmup worksheet I could read and work through before each session. Below is the prompt I used and the review worksheet for the optimizers review session. With the prompt I also added the lecture pdfs and screenshots of the homework questions as attachments.<break/><break/>Prompt: I am getting ready for a review session for my deep learning class. I want to make sure I am prepared going in to the session. I want you to generate me a quick (~10min) worksheet that has key information I will need for that review session and also short warmup questions. However, make sure that the questions are not too similar to the questions being reviewed in the session itself so I can still learn from that and be challenged. Here are the lecture pdfs and the questions the teacher will be going over in the review session.</paragraph><paragraph><break/><break/><break/><break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/wcWJSzLBdALYMGYBK6vXPpV6\" filename=\"Special Participation E 2.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:09:42.836077+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450450,
            "author": "Rahul Bir",
            "project_title": "Special Participation B: Windsurf SWE-1 on HW0 Q6",
            "post_body": "For special participation B, I tested the custom Windsurf SWE-1 model on only coding question in HW0 (Q6). \n\nThis a pdf of our interaction (downloaded directly from the IDE and unedited by me other than certain annotations):\n\nWithin the pdf, I annotate specific sections where I observed SWE-1 to exhibit interesting behavior. While SWE-1 was able to one-shot the problem, the process was not as seamless as I had hoped and the model was prone to multiple hallucinations. Most notably, while the model was able to initially edit most of the relevant files in the deep learning folder, it seemed to \"break\" at one point and afterwards refused to edit any files. When I ask it to directly edit the ipynb, it keeps giving me code from the deep learning folder (which it has already written!) to copy back in and also makes up references to code that does not exist in the ipynb.",
            "content_xml": "<document version=\"2.0\"><paragraph>For special participation B, I tested the custom Windsurf SWE-1 model on only coding question in HW0 (Q6). </paragraph><paragraph>This a pdf of our interaction (downloaded directly from the IDE and unedited by me other than certain annotations):</paragraph><file url=\"https://static.us.edusercontent.com/files/05N9AuycngmMcsfMgJI7IKfS\" filename=\"special participation b windsurf hw 0.pdf\"/><paragraph>Within the pdf, I annotate specific sections where I observed SWE-1 to exhibit interesting behavior. While SWE-1 was able to one-shot the problem, the process was not as seamless as I had hoped and the model was prone to multiple hallucinations. Most notably, while the model was able to initially edit most of the relevant files in the deep learning folder, it seemed to \"break\" at one point and afterwards refused to edit any files. When I ask it to directly edit the ipynb, it keeps giving me code from the deep learning folder (which it has already written!) to copy back in and also makes up references to code that does not exist in the ipynb.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T13:04:41.305614+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450396,
            "author": "Eric Wang",
            "project_title": "Special Participation A: ChatGPT-5.1 Pro on HW5",
            "post_body": "One-shots all of HW5 Q1-4 (non coding) which I was quite impressed by. ",
            "content_xml": "<document version=\"2.0\"><paragraph>One-shots all of HW5 Q1-4 (non coding) which I was quite impressed by. </paragraph><file url=\"https://static.us.edusercontent.com/files/aeziI2A5fHfeqaYrVJoqsx4e\" filename=\"hw5_solutions.pdf\"/><file url=\"https://static.us.edusercontent.com/files/KRTue71jbzpN8BUDNtSrrJi7\" filename=\"hw5_executive_summary.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:53:49.000429+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450294,
            "author": "Zhengwei Fan",
            "project_title": "Special Participation B: Grok on HW 10",
            "post_body": "Unlike other large language models, Grok cannot correctly complete the entire task simply by using a single .ipynb file and some simple instructions such\nas \"complete all TODO code.\" It exhibits certain hallucinations during the process of reading the IPYNB file, including but not limited to ignoring the code that needs to be written and encountering issues with tensor dimensions in the provided code. Therefore, we must provide detailed task requirements and a detailed contextual framework. Only with step-by-step, detailed guidance can Grok produce the correct code, rather than simply having it read the .ipynb file directly. The detailed process is in pdf.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/ol2LBzhF3ufHvLFcQFx1WWvH\" filename=\"Special participation B.pdf\"/><paragraph>Unlike other large language models, Grok cannot correctly complete the entire task simply by using a single .ipynb file and some simple instructions such<break/>as \"complete all TODO code.\" It exhibits certain hallucinations during the process of reading the IPYNB file, including but not limited to ignoring the code that needs to be written and encountering issues with tensor dimensions in the provided code. Therefore, we must provide detailed task requirements and a detailed contextual framework. Only with step-by-step, detailed guidance can Grok produce the correct code, rather than simply having it read the .ipynb file directly. The detailed process is in pdf.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:38:34.006425+11:00",
            "category": "Admin"
        },
        {
            "guid": 7450269,
            "author": "Menger Wen",
            "project_title": "Participation E: understand the mathematical foundations of optimizers, bias correction, gradient normalization, linearization perspective, and proper weight initialization using fan-in/fan-out",
            "post_body": "https://chatgpt.com/share/693a1d53-9ae8-8006-bad9-24c12393a612\n\nThrough the discussion, I gained a clear understanding of how modern optimization algorithms like Adam and sign-SGD work from both practical and mathematical perspectives, including bias correction and the differences between weight decay and $L_2$ regularization. I learned how linearization and Taylor expansion help explain neural network training dynamics, leading to the concept of Neural Tangent Kernel (NTK) and lazy training. I also explored gradient norm normalization, \u2113\u221e constraints leading to sign-SGD, and \u21132 constraints producing conventional gradient descent directions. Finally, I uncovered why appropriate initialization schemes such as Xavier and He help stabilize neural network training by controlling variance propagation, and what fan-in and fan-out mean in that context.\n\nThe built-in prompt (translated from Chinese) I used is showed below:\n\n\n\nYou are a patient deep learning expert and teaching assistant for UC Berkeley CS 182, focusing on Lectures 3 and 4. Your learner is a beginner in linear algebra, machine learning, and optimization, but very motivated and willing to go step by step. They are currently trying to deeply understand:\n\nGradient descent and its variants (SGD, momentum, normalized gradients, sign-SGD, Adam, AdamW, bias correction, weight decay vs L2 regularization)\n\nThe Taylor / linearization perspective on neural networks, including: first-order Taylor expansion in parameter space, gradient flow, how we get the Neural Tangent Kernel (NTK) expression, and the \u201clazy training\u201d assumption\n\nInitialization schemes: Xavier / Glorot and He / Kaiming initialization, how variance propagates through layers, and the meaning of fan-in and fan-out\n\nPlease teach me these topics as if I\u2019m preparing for CS 182 homework and exams, with the following constraints and style:\n\nAssume I\u2019m a beginner\n\nUse very clear, simple language and avoid heavy jargon.\n\nWhen you must use a technical term (e.g., \u201cgradient flow\u201d, \u201cNTK\u201d), define it carefully and give an intuitive analogy.\n\nBuild up from first principles\n\nStart from basic gradient descent on a scalar parameter and connect it to the vector case.\n\nFor Adam and AdamW, explicitly derive the update equations step by step, including: \n\nhow ($m_t$) and ($v_t$) are moving averages of gradients/gradient squares,\n\nhow bias correction is derived (( $\\hat m_t = m_t / (1-\\beta^t)$), ( $\\hat v_t = v_t / (1-\\beta^t)$)),\n\nwhy \u201cL2 in the loss\u201d is not equivalent to weight decay for adaptive methods, and what AdamW actually changes.\n\nFor the Taylor/NTK part, show how we linearize ($f(x,\\theta)$) around ($\\theta_0$), use gradient flow ($d\\theta/dt = -\\nabla_\\theta \\mathcal L$), and derive $$ \\frac{d}{dt} f(x,\\theta(t)) = -\\frac{1}{N}\\sum_i K(x,x^{(i)}) \\nabla_f \\ell(f(x^{(i)},\\theta(t)), y^{(i)}), $$ where ($K$) is the neural tangent kernel.\n\nFor initialization, derive why summing ($d$) independent terms ($\\sum_i w_i h_i$) gives variance ($d \\cdot \\mathrm{Var}(w) \\cdot \\mathrm{Var}(h)$), and how this leads to \n\nXavier: ($\\mathrm{Var}(w) = 1/\\text{fan_in}$) (or the Glorot fan-in/fan-out variant),\n\nHe: ($\\mathrm{Var}(w) = 2/\\text{fan_in}$) for ReLU, because ReLU roughly halves the variance.\n\nExplain fan-in / fan-out clearly\n\nGive concrete examples for fully connected layers and convolutional layers.\n\nUse a plumbing / pipes analogy (number of incoming vs outgoing connections) to help my intuition.\n\nUse worked examples and micro-exercises\n\nFrequently give small numerical examples (e.g., a neuron with 3 inputs and specific values) and walk through the computations.\n\nAfter explaining a concept, give me 1\u20133 short practice questions (with answers) so I can check my understanding.\n\nStart with very easy questions and gradually make them more \u201cCS 182 exam style\u201d.\n\nConnect formulas to intuition\n\nFor each major formula, answer: \n\nWhat is this trying to achieve?\n\nWhat would go wrong if we didn\u2019t do this?\n\nHow does this relate to exploding/vanishing gradients, optimization speed, or generalization?\n\nStructure the teaching into modules\n\nModule 1: Recap of gradient descent, SGD, and momentum.\n\nModule 2: Normalized gradients and sign-SGD from an optimization-under-constraints viewpoint (\u2113\u221e vs \u21132 constraints).\n\nModule 3: Adam and AdamW \u2014 equations, bias correction, and weight decay vs L2.\n\nModule 4: Taylor expansion, linearized models, gradient flow, and NTK.\n\nModule 5: Initialization (Xavier/Glorot, He/Kaiming), variance propagation, fan-in/fan-out.\n\nIn each module, first give an overview, then details with derivations, then a short summary and a few practice questions.\n\nCheck my understanding interactively\n\nAfter explaining each subtopic, ask me a quick question (conceptual or computational) and wait for my answer.\n\nIf my answer is wrong or partially correct, correct me gently and explain where my reasoning went off.\n\nBe honest about uncertainty and avoid hallucinations\n\nIf I ask about something that is outside typical CS 182 / deep learning theory (e.g., very specific implementation quirks in a library), say that you\u2019re not sure rather than guessing.\n\nPrefer standard, widely-accepted explanations that would agree with common deep learning textbooks and lecture notes.\n\nStart now with Module 1, briefly recalling vanilla gradient descent, and then build up toward sign-SGD, Adam/AdamW, the Taylor/NTK perspective, and initialization in a way that feels like a structured mini-course.",
            "content_xml": "<document version=\"2.0\"><paragraph>https://chatgpt.com/share/693a1d53-9ae8-8006-bad9-24c12393a612</paragraph><paragraph>Through the discussion, I gained a clear understanding of how modern optimization algorithms like Adam and sign-SGD work from both practical and mathematical perspectives, including bias correction and the differences between weight decay and $L_2$ regularization. I learned how linearization and Taylor expansion help explain neural network training dynamics, leading to the concept of Neural Tangent Kernel (NTK) and lazy training. I also explored gradient norm normalization, \u2113\u221e constraints leading to sign-SGD, and \u21132 constraints producing conventional gradient descent directions. Finally, I uncovered why appropriate initialization schemes such as Xavier and He help stabilize neural network training by controlling variance propagation, and what fan-in and fan-out mean in that context.</paragraph><paragraph>The built-in prompt (translated from Chinese) I used is showed below:</paragraph><paragraph/><paragraph>You are a patient deep learning expert and teaching assistant for UC Berkeley CS 182, focusing on Lectures 3 and 4. Your learner is a beginner in linear algebra, machine learning, and optimization, but very motivated and willing to go step by step. They are currently trying to deeply understand:</paragraph><list style=\"unordered\"><list-item><paragraph>Gradient descent and its variants (SGD, momentum, normalized gradients, sign-SGD, Adam, AdamW, bias correction, weight decay vs L2 regularization)</paragraph></list-item><list-item><paragraph>The Taylor / linearization perspective on neural networks, including: first-order Taylor expansion in parameter space, gradient flow, how we get the Neural Tangent Kernel (NTK) expression, and the \u201clazy training\u201d assumption</paragraph></list-item><list-item><paragraph>Initialization schemes: Xavier / Glorot and He / Kaiming initialization, how variance propagates through layers, and the meaning of fan-in and fan-out</paragraph></list-item></list><paragraph>Please teach me these topics as if I\u2019m preparing for CS 182 homework and exams, with the following constraints and style:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Assume I\u2019m a beginner</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Use very clear, simple language and avoid heavy jargon.</paragraph></list-item><list-item><paragraph>When you must use a technical term (e.g., \u201cgradient flow\u201d, \u201cNTK\u201d), define it carefully and give an intuitive analogy.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Build up from first principles</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Start from basic gradient descent on a scalar parameter and connect it to the vector case.</paragraph></list-item><list-item><paragraph>For Adam and AdamW, explicitly derive the update equations step by step, including: </paragraph><list style=\"unordered\"><list-item><paragraph>how ($m_t$) and ($v_t$) are moving averages of gradients/gradient squares,</paragraph></list-item><list-item><paragraph>how bias correction is derived (( $\\hat m_t = m_t / (1-\\beta^t)$), ( $\\hat v_t = v_t / (1-\\beta^t)$)),</paragraph></list-item><list-item><paragraph>why \u201cL2 in the loss\u201d is <italic>not</italic> equivalent to weight decay for adaptive methods, and what AdamW actually changes.</paragraph></list-item></list></list-item><list-item><paragraph>For the Taylor/NTK part, show how we linearize ($f(x,\\theta)$) around ($\\theta_0$), use gradient flow ($d\\theta/dt = -\\nabla_\\theta \\mathcal L$), and derive $$ \\frac{d}{dt} f(x,\\theta(t)) = -\\frac{1}{N}\\sum_i K(x,x^{(i)}) \\nabla_f \\ell(f(x^{(i)},\\theta(t)), y^{(i)}), $$ where ($K$) is the neural tangent kernel.</paragraph></list-item><list-item><paragraph>For initialization, derive why summing ($d$) independent terms ($\\sum_i w_i h_i$) gives variance ($d \\cdot \\mathrm{Var}(w) \\cdot \\mathrm{Var}(h)$), and how this leads to </paragraph><list style=\"unordered\"><list-item><paragraph>Xavier: ($\\mathrm{Var}(w) = 1/\\text{fan_in}$) (or the Glorot fan-in/fan-out variant),</paragraph></list-item><list-item><paragraph>He: ($\\mathrm{Var}(w) = 2/\\text{fan_in}$) for ReLU, because ReLU roughly halves the variance.</paragraph></list-item></list></list-item></list></list-item><list-item><paragraph><bold>Explain fan-in / fan-out clearly</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Give concrete examples for fully connected layers and convolutional layers.</paragraph></list-item><list-item><paragraph>Use a plumbing / pipes analogy (number of incoming vs outgoing connections) to help my intuition.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Use worked examples and micro-exercises</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Frequently give small numerical examples (e.g., a neuron with 3 inputs and specific values) and walk through the computations.</paragraph></list-item><list-item><paragraph>After explaining a concept, give me 1\u20133 short practice questions (with answers) so I can check my understanding.</paragraph></list-item><list-item><paragraph>Start with very easy questions and gradually make them more \u201cCS 182 exam style\u201d.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Connect formulas to intuition</bold></paragraph><list style=\"unordered\"><list-item><paragraph>For each major formula, answer: </paragraph><list style=\"unordered\"><list-item><paragraph><italic>What is this trying to achieve?</italic></paragraph></list-item><list-item><paragraph><italic>What would go wrong if we didn\u2019t do this?</italic></paragraph></list-item><list-item><paragraph><italic>How does this relate to exploding/vanishing gradients, optimization speed, or generalization?</italic></paragraph></list-item></list></list-item></list></list-item><list-item><paragraph><bold>Structure the teaching into modules</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Module 1: Recap of gradient descent, SGD, and momentum.</paragraph></list-item><list-item><paragraph>Module 2: Normalized gradients and sign-SGD from an optimization-under-constraints viewpoint (\u2113\u221e vs \u21132 constraints).</paragraph></list-item><list-item><paragraph>Module 3: Adam and AdamW \u2014 equations, bias correction, and weight decay vs L2.</paragraph></list-item><list-item><paragraph>Module 4: Taylor expansion, linearized models, gradient flow, and NTK.</paragraph></list-item><list-item><paragraph>Module 5: Initialization (Xavier/Glorot, He/Kaiming), variance propagation, fan-in/fan-out.</paragraph></list-item><list-item><paragraph>In each module, first give an overview, then details with derivations, then a short summary and a few practice questions.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Check my understanding interactively</bold></paragraph><list style=\"unordered\"><list-item><paragraph>After explaining each subtopic, ask me a quick question (conceptual or computational) and wait for my answer.</paragraph></list-item><list-item><paragraph>If my answer is wrong or partially correct, correct me gently and explain where my reasoning went off.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Be honest about uncertainty and avoid hallucinations</bold></paragraph><list style=\"unordered\"><list-item><paragraph>If I ask about something that is outside typical CS 182 / deep learning theory (e.g., very specific implementation quirks in a library), say that you\u2019re not sure rather than guessing.</paragraph></list-item><list-item><paragraph>Prefer standard, widely-accepted explanations that would agree with common deep learning textbooks and lecture notes.</paragraph></list-item></list></list-item></list><paragraph>Start now with <bold>Module 1</bold>, briefly recalling vanilla gradient descent, and then build up toward sign-SGD, Adam/AdamW, the Taylor/NTK perspective, and initialization in a way that feels like a structured mini-course.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:34:20.988568+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450203,
            "author": "Arjun Kohli",
            "project_title": "Special Participation A: Claude Sonnet 4.5 on HW 1 Written Problems",
            "post_body": "For this Special Participation A, I used Claude Sonnet 4.5 to work through all the non-coding parts of HW1. Overall, the model produced solutions that were often structurally correct, but it was not reliable.\n\nThe model occasionally solved subproblems correctly on the first try, especially when the math followed familiar patterns (e.g., stability conditions, SVD arguments, convergence inequalities). However, it frequently made subtle mathematical mistakes like missing constants, incorrect simplifications, unjustified assumptions, or skipped derivations. These issues appeared across several problems, including convergence-rate derivations, momentum eigenvalue conditions, and certain regularization proofs.\n\nA recurring pattern was that the model sounded confident even when the reasoning was incomplete or incorrect. It often hallucinated intermediate steps or introduced made-up explanations when unsure. \n\nOverall, interacting with the LLM is useful for brainstorming structures of proofs or confirming intuition, but it is not capable of producing fully correct, rigorous solutions on its own. Meaningful human guidance is required throughout, and unguided one-shot correctness is rare.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/4w1RNv7kECucN8e1tgfOiDvQ\" filename=\"Special Participation A.pdf\"/><paragraph>For this Special Participation A, I used Claude Sonnet 4.5 to work through all the non-coding parts of HW1. Overall, the model produced solutions that were often structurally correct, but it was not reliable.</paragraph><paragraph>The model occasionally solved subproblems correctly on the first try, especially when the math followed familiar patterns (e.g., stability conditions, SVD arguments, convergence inequalities). However, it frequently made subtle mathematical mistakes like missing constants, incorrect simplifications, unjustified assumptions, or skipped derivations. These issues appeared across several problems, including convergence-rate derivations, momentum eigenvalue conditions, and certain regularization proofs.</paragraph><paragraph>A recurring pattern was that the model sounded confident even when the reasoning was incomplete or incorrect. It often hallucinated intermediate steps or introduced made-up explanations when unsure. </paragraph><paragraph>Overall, interacting with the LLM is useful for brainstorming structures of proofs or confirming intuition, but it is not capable of producing fully correct, rigorous solutions on its own. Meaningful human guidance is required throughout, and unguided one-shot correctness is rare.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:21:55.538276+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450199,
            "author": "Edward Zhang",
            "project_title": "Special Participation E: Teacher Forcing, Weight Decay, and Low-Rank Factorization",
            "post_body": "As I worked through this problem, I clarified several concepts: I now understand teacher forcing as feeding the ground-truth previous token into the decoder, and why the per-step loss is written as $-\\log p_{\\theta}(y_t \\mid h_t)$ even though the gradient still flows back through $h_{t-1}, y_{t-1}, \\dots$ via BPTT. I also connected weight decay to adding an $\\ell_2$ penalty and saw how, in this low-rank factorization setting, regularizing $\\lVert W_1 \\rVert_F^2 + \\lVert W_2 \\rVert_F^2$ induces a preference for factorizations where $W_2 W_1$ is an identity on the top-$k$ subspace and the singular values of $W_1$ and $W_2$ pair as $\\sigma_i$ and $1/\\sigma_i$, leading to approximately orthonormal columns. My questioning style was very step-by-step and \u201cwhy-focused\u201d: I kept asking for unpacking of specific sentences, challenging hidden assumptions (like aligning $V_1$ and $U_2$), and requesting intuitive explanations of each algebraic step rather than just accepting the final formula.",
            "content_xml": "<document version=\"2.0\"><paragraph>As I worked through this problem, I clarified several concepts: I now understand teacher forcing as feeding the ground-truth previous token into the decoder, and why the per-step loss is written as $-\\log p_{\\theta}(y_t \\mid h_t)$ even though the gradient still flows back through $h_{t-1}, y_{t-1}, \\dots$ via BPTT. I also connected weight decay to adding an $\\ell_2$ penalty and saw how, in this low-rank factorization setting, regularizing $\\lVert W_1 \\rVert_F^2 + \\lVert W_2 \\rVert_F^2$ induces a preference for factorizations where $W_2 W_1$ is an identity on the top-$k$ subspace and the singular values of $W_1$ and $W_2$ pair as $\\sigma_i$ and $1/\\sigma_i$, leading to approximately orthonormal columns. My questioning style was very step-by-step and \u201cwhy-focused\u201d: I kept asking for unpacking of specific sentences, challenging hidden assumptions (like aligning $V_1$ and $U_2$), and requesting intuitive explanations of each algebraic step rather than just accepting the final formula.</paragraph><file url=\"https://static.us.edusercontent.com/files/XnmIgPrdpsAoL91wPbokqs6h\" filename=\"Special_Participation_E-merged.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:21:19.037014+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450109,
            "author": "Shuwei Yang",
            "project_title": "Special Participation B: ChatGPT-5.1 Pro on HW1 Coding",
            "post_body": "I used ChatGPT Pro on HW1 coding part. Overall, ChatGPT performed well on the SGD and interpolation assignment, both conceptually and at the code level. Its explanations of under- vs over-parameterization, interpolation in the noisy regime, the role of ridge regularization, and the effect of learning rate and batch size were all consistent with the intent of the homework and with standard optimization theory. The discussion of momentum also correctly captured the heavy-ball update rule and the intuition that aggregating gradients into a velocity term both accelerates convergence and damps oscillations. On the coding side, the NumPy implementations of plain SGD and momentum were mathematically correct and would likely run with only minor adjustments (e.g., adding imports and plotting boilerplate). The gradients for MSE were derived correctly, the ridge penalty was added in the right form, and the feature-augmented \u201cu\u201d parameters in the over-parameterized model were updated in a way that correctly mirrors interpolation by per-example offsets. However, the code was written as standalone snippets rather than as a faithful completion of my provided notebooks, and it did not strictly follow the requested cell-by-cell structure or integrate directly with the starter code. As a result, while the logic and correctness of the algorithms are solid, the solution only partially satisfies the assignment\u2019s formatting and integration requirements, and I would still need to adapt and polish the code to match the exact homework templates.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT Pro on HW1 coding part. Overall, ChatGPT performed well on the SGD and interpolation assignment, both conceptually and at the code level. Its explanations of under- vs over-parameterization, interpolation in the noisy regime, the role of ridge regularization, and the effect of learning rate and batch size were all consistent with the intent of the homework and with standard optimization theory. The discussion of momentum also correctly captured the heavy-ball update rule and the intuition that aggregating gradients into a velocity term both accelerates convergence and damps oscillations. On the coding side, the NumPy implementations of plain SGD and momentum were mathematically correct and would likely run with only minor adjustments (e.g., adding imports and plotting boilerplate). The gradients for MSE were derived correctly, the ridge penalty was added in the right form, and the feature-augmented \u201cu\u201d parameters in the over-parameterized model were updated in a way that correctly mirrors interpolation by per-example offsets. However, the code was written as standalone snippets rather than as a faithful completion of my provided notebooks, and it did not strictly follow the requested cell-by-cell structure or integrate directly with the starter code. As a result, while the logic and correctness of the algorithms are solid, the solution only partially satisfies the assignment\u2019s formatting and integration requirements, and I would still need to adapt and polish the code to match the exact homework templates.</paragraph><file url=\"https://static.us.edusercontent.com/files/MqwYqca9YnUevnoZTlefvRaC\" filename=\"Speical Participation B ChatGPT Pro on HW1 coding.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:02:32.978061+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450107,
            "author": "E Harrison",
            "project_title": "Special Participation E: Using Claude to Generate New Homework-Based Problems For Diffusion",
            "post_body": "\n\nAfter completing homework 13 for diffusion, I found myself still a little confused on the math used to solve the problems, and wanted to get similar problems to the homework that I could use to practice. To do this, I gave Claude's Sonnet 4.5 model a PDF of homework 13's problems and solutions and asked it to generate a new problem similar to the ones provided.\n\nFirst, I found the question Claude came up with to be quite interesting. It asked me to consider a variance-preserving form of diffusion, and eventually compare my reverse denoising process to the solution from Question 1 of HW13. I thought the problem itself was quite interesting, and could reasonably see something like this be asked for on an exam. \n\nPart (a) was straightforward, but in part (b) I made a little mistake on the variance, assuming it stayed at 1 rather than being t. Claude was able to catch me on this, and hinted that because X_0 is being conditioned on, we do not combine (1-t) and t for the variance, so it stays at t.\n\nPart (c) took a lot more time to get right for me, and even now I'm not too sure how correct Claude was even on its own problem. I got that the forward process from X_t to X_{t + delta t} had a mean of x_t and variance of delta t. It seemed like thats what Claude believed the answer to be, but I'm not so confident this is the case.\n\nFor part (d), Claude gave a small hint indicating that it would be similar to solving question 4(b) from the homework. While it was a lot of algebra, the problem itself wasn't too difficult. I made a minor mistake at the end, multiplying rather than dividing by my leading coefficient to find the mean, and Claude was able to catch it. One suspect thing it did however was try to fix the leading 2 coefficient I initially had in my problem by multiplying my solution by a factor of 1/2. It says that I should do this because I had a 1/2 in the leading part of my exponential, but I don't think that makes too much sense.\n\nPart (e) was straightforward, but Claude made the interesting observation that for the variance-preserving process, the variance throughout stays the same but the mean shifts, where for the variance-increasing process the mean shrinks.\n\nBelow is a link to the full conversation with Claude:\nhttps://claude.ai/share/df5da7d5-5538-494e-b95d-4631a2c22e49\n\nFor some reason Claude hides any images attached to the conversation, so here are the images provided, in the same order as when I gave them to Claude:\n\n\nPart (a):\n\n\nPart (b) attempt 1:\n\n\n\nPart (b) attempt 2:\n\n\nPart (c) attempt 1:\n\nPart (c) attempt 2:\n\nPart (c) attempt 3:\n\nPart (d):",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>After completing homework 13 for diffusion, I found myself still a little confused on the math used to solve the problems, and wanted to get similar problems to the homework that I could use to practice. To do this, I gave Claude's Sonnet 4.5 model a PDF of homework 13's problems and solutions and asked it to generate a new problem similar to the ones provided.<break/><break/>First, I found the question Claude came up with to be quite interesting. It asked me to consider a variance-preserving form of diffusion, and eventually compare my reverse denoising process to the solution from Question 1 of HW13. I thought the problem itself was quite interesting, and could reasonably see something like this be asked for on an exam. <break/><break/>Part (a) was straightforward, but in part (b) I made a little mistake on the variance, assuming it stayed at 1 rather than being t. Claude was able to catch me on this, and hinted that because X_0 is being conditioned on, we do not combine (1-t) and t for the variance, so it stays at t.<break/><break/>Part (c) took a lot more time to get right for me, and even now I'm not too sure how correct Claude was even on its own problem. I got that the forward process from X_t to X_{t + delta t} had a mean of x_t and variance of delta t. It seemed like thats what Claude believed the answer to be, but I'm not so confident this is the case.<break/><break/>For part (d), Claude gave a small hint indicating that it would be similar to solving question 4(b) from the homework. While it was a lot of algebra, the problem itself wasn't too difficult. I made a minor mistake at the end, multiplying rather than dividing by my leading coefficient to find the mean, and Claude was able to catch it. One suspect thing it did however was try to fix the leading 2 coefficient I initially had in my problem by multiplying my solution by a factor of 1/2. It says that I should do this because I had a 1/2 in the leading part of my exponential, but I don't think that makes too much sense.<break/><break/>Part (e) was straightforward, but Claude made the interesting observation that for the variance-preserving process, the variance throughout stays the same but the mean shifts, where for the variance-increasing process the mean shrinks.<break/><break/>Below is a link to the full conversation with Claude:<break/>https://claude.ai/share/df5da7d5-5538-494e-b95d-4631a2c22e49<break/><break/>For some reason Claude hides any images attached to the conversation, so here are the images provided, in the same order as when I gave them to Claude:<break/><break/><break/>Part (a):</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/fDkO4OMIMbZsTyrxQPKtEcjD\" width=\"643\" height=\"335.9232995658466\"/></figure><paragraph><break/>Part (b) attempt 1:<break/></paragraph><figure><image src=\"https://static.us.edusercontent.com/files/RhsPLmJARd6AhpjxZeXDLadK\" width=\"643\" height=\"261.19562715765244\"/></figure><paragraph><break/>Part (b) attempt 2:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/WvYxGWReLkUxhJEw4QgdEEWD\" width=\"643\" height=\"231.6804556354916\"/></figure><paragraph><break/>Part (c) attempt 1:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/c81EI9s05CAH6g18G38cpymV\" width=\"643\" height=\"662.7991202346042\"/></figure><paragraph>Part (c) attempt 2:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/4rFMVsufTyrxQwVcV6yTqcTc\" width=\"643\" height=\"866.0610806577916\"/></figure><paragraph>Part (c) attempt 3:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/0TOpHgraV96cTAGBS7JfiCof\" width=\"643\" height=\"576.0647540983607\"/></figure><paragraph>Part (d):</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/TB0tHYJc4efPq9gJthTTIsOC\" width=\"643\" height=\"575.5389688249401\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T12:02:25.92196+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450077,
            "author": "Paul Struble",
            "project_title": "Special Participation A: GPT 5.1 Thinking (Extended) on HW3",
            "post_body": "I used GPT 5.1 Thinking (Extended) to solve the non-coding parts of Homework 3. Overall, the model was very effective at solving each problem and explaining its reasoning. It was able to one-shot all parts of all problems. I prompted the model in the ChatGPT web frontend by providing a PDF attachment of the original homework assignment, a brief explanation of the task, and some additional prompts/attachments throughout the conversation to provide additional contextual resources (from the assignment). This is all recorded in the conversation log in the attached document. I found no misconceptions or hallucinations in the model\u2019s output although some responses took a different approach than the reference solutions (ultimately still arriving at a valid solution). I include more analysis/observations in the attached document.\n\nLink to original conversation: https://chatgpt.com/share/693a069f-44a8-8007-bed7-a4db5aceaa8f",
            "content_xml": "<document version=\"2.0\"><paragraph>I used GPT 5.1 Thinking (Extended) to solve the non-coding parts of Homework 3. Overall, the model was very effective at solving each problem and explaining its reasoning. It was able to one-shot all parts of all problems. I prompted the model in the ChatGPT web frontend by providing a PDF attachment of the original homework assignment, a brief explanation of the task, and some additional prompts/attachments throughout the conversation to provide additional contextual resources (from the assignment). This is all recorded in the conversation log in the attached document. I found no misconceptions or hallucinations in the model\u2019s output although some responses took a different approach than the reference solutions (ultimately still arriving at a valid solution). I include more analysis/observations in the attached document.</paragraph><paragraph>Link to original conversation: <link href=\"https://chatgpt.com/share/693a069f-44a8-8007-bed7-a4db5aceaa8f\">https://chatgpt.com/share/693a069f-44a8-8007-bed7-a4db5aceaa8f</link></paragraph><file url=\"https://static.us.edusercontent.com/files/C8VbefkKCftQPdCvCBnWr0Lp\" filename=\"hw3_special_participation_a.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/693a069f-44a8-8007-bed7-a4db5aceaa8f"
            ],
            "attachments": [],
            "created_at": "2025-12-11T11:57:18.489092+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450072,
            "author": "Eric Jin",
            "project_title": "Special Participation B: Grok 4.1 on HW8 coding part",
            "post_body": "In this homework, I used Grok 4.1 to help implement and understand the forward pass of a simple State Space Model (SSM) and its convolution-based reformulation. For the **coding-focused tasks**, Grok 4.1 often \u201cone\u2011shot\u201d the required TODOs: it produced correct PyTorch implementations for the unrolled RNN version, the divide\u2011and\u2011conquer kernel construction, and the convolution-based forward pass. The suggested code matched the intended math, respected batch dimensions and dtypes/devices, and passed the provided sanity checks with only numerical precision differences (on the order of 1e\u20117). For a student already comfortable with PyTorch, its answers could be dropped in almost directly.\n\nGrok 4.1 was particularly strong at **explaining the implementation logic** around each TODO. It consistently linked the code back to the underlying recurrence \\(h_{t+1} = W h_t + U x_t + b\\), clarified tensor shapes at each step, and justified design choices like permuting to `(N, H, T)` for `conv1d`, left-padding with `T-1` zeros for causality, and flipping the kernel in time. Its walkthrough of the divide\u2011and\u2011conquer kernel construction (for computing powers of \\(W\\) in \\(O(H^3 \\log T)\\)) was detailed and conceptually accurate, including intuitive explanations of exponentiation by squaring and how the recursion fills the kernel efficiently.\n\nWhere Grok 4.1 required more careful checking was in **subtle implementation details and complexity claims**. Some of the intermediate code it proposed for the kernel construction mixed different batching strategies (e.g., switching between `matmul`, `einsum`, and manual loops) and could easily introduce shape bugs if copied partially or modified. Similarly, its complexity discussions sometimes blurred together the cost of kernel construction vs. the convolution itself, or used informal reasoning around \\(O(H^3 \\log T)\\) vs. \\(O(N H^2 T)\\) without always being perfectly rigorous. These were not outright hallucinations, but they are places where I needed to verify shapes, group arguments in `conv1d`, padding direction, and big\u2011O factors myself. Overall, Grok 4.1 was very effective as a coding assistant and explainer for this SSM forward\u2011pass notebook, but its outputs were safest when treated as a strong first draft rather than ground truth.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/SSJfiAJrhJljDfdH9fgpMlz2\" filename=\"Special Participation B.pdf\"/><paragraph>In this homework, I used Grok 4.1 to help implement and understand the forward pass of a simple State Space Model (SSM) and its convolution-based reformulation. For the **coding-focused tasks**, Grok 4.1 often \u201cone\u2011shot\u201d the required TODOs: it produced correct PyTorch implementations for the unrolled RNN version, the divide\u2011and\u2011conquer kernel construction, and the convolution-based forward pass. The suggested code matched the intended math, respected batch dimensions and dtypes/devices, and passed the provided sanity checks with only numerical precision differences (on the order of 1e\u20117). For a student already comfortable with PyTorch, its answers could be dropped in almost directly.</paragraph><paragraph>Grok 4.1 was particularly strong at **explaining the implementation logic** around each TODO. It consistently linked the code back to the underlying recurrence \\(h_{t+1} = W h_t + U x_t + b\\), clarified tensor shapes at each step, and justified design choices like permuting to `(N, H, T)` for `conv1d`, left-padding with `T-1` zeros for causality, and flipping the kernel in time. Its walkthrough of the divide\u2011and\u2011conquer kernel construction (for computing powers of \\(W\\) in \\(O(H^3 \\log T)\\)) was detailed and conceptually accurate, including intuitive explanations of exponentiation by squaring and how the recursion fills the kernel efficiently.</paragraph><paragraph>Where Grok 4.1 required more careful checking was in **subtle implementation details and complexity claims**. Some of the intermediate code it proposed for the kernel construction mixed different batching strategies (e.g., switching between `matmul`, `einsum`, and manual loops) and could easily introduce shape bugs if copied partially or modified. Similarly, its complexity discussions sometimes blurred together the cost of kernel construction vs. the convolution itself, or used informal reasoning around \\(O(H^3 \\log T)\\) vs. \\(O(N H^2 T)\\) without always being perfectly rigorous. These were not outright hallucinations, but they are places where I needed to verify shapes, group arguments in `conv1d`, padding direction, and big\u2011O factors myself. Overall, Grok 4.1 was very effective as a coding assistant and explainer for this SSM forward\u2011pass notebook, but its outputs were safest when treated as a strong first draft rather than ground truth.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:55:44.961063+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450064,
            "author": "Tiffany Dang",
            "project_title": "Special Participation A: Qwen on HW12 Non-coding parts",
            "post_body": "For Special Participation A, I used Qwen to solve non-coding questions of HW12. Overall, the accuracy and performance was outstanding. I attached the txt file of the conversation because I couldn't figure out a way to print the entire conversation into pdf. The annotations will be written below based on questions/parts. \n\nAnnotations:\n\nThe model was able to get Questions 1 and 2 right really quickly with only 1 attempt each. \n\nQuestion 3a): model was able to identify what to include in the block diagrams, although it couldn't fully output the diagram, it got the components and structures correct for users like me to hand-draw the diagram. \n\nQuestion 3b): model got it right very quickly \n\nQuestion 3c): reasoning is right, the model was able to identify that the final graph should have a U-shape. However, it couldn't read the graphs in the answer choices so it didn't give a certain answer. I uploaded a screenshot of the graphs but it still couldn't read the graphs and analyze them correctly. This requires user to manually match which graphs in figure 3 has U-shape to select the correct final answer. \n\nQuestion 3d): It first misread 10^0 to be 100, I corrected that and prompt it to resolve since the original information was wrong. The reasoning process was right but it couldn't analyze the graphs correctly still. I uploaded the screenshot of figure 4 so the model could analyze more precisely because it couldn't tell that the mean spread of b) is large in figure 4. After the image reuploading step, model was able to perform the right analysis and output the right answers. \n\nQuestion 4: this is basically a coding question but I wanted to give it a try to I asked the LLM to fill in the code needed to be implemented. The answers are correct.\n\nQuestion 5a): able to reach what needs to be proved but the reasoning process was not right. The LLM somehow invented a whole scenario that is not described in the homework description and didn't refer to the general min-norm formula given. Basically, process is not right. \n\nQuestion 5b): correct derivation and solution. \n\nQuestion 5c): correct and quick solution \n\nQuestion 5d,e,f,g,h: for these parts, i ran the notebook to generate the graphs first, saved all those graphs to a pdf file and upload the pdf for the llm to read the graphs to answer these parts. For these analysis questions, the llm was able to give correct answers showing the right intuition and precise explanation. ",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation A, I used Qwen to solve non-coding questions of HW12. Overall, the accuracy and performance was outstanding. I attached the txt file of the conversation because I couldn't figure out a way to print the entire conversation into pdf. The annotations will be written below based on questions/parts. </paragraph><file url=\"https://static.us.edusercontent.com/files/leq4Ada6xEgu3cn6OxMbY4Ov\" filename=\"chat-Debugging Transformer Embeddings.txt\"/><paragraph>Annotations:</paragraph><list style=\"bullet\"><list-item><paragraph>The model was able to get Questions 1 and 2 right really quickly with only 1 attempt each. </paragraph></list-item><list-item><paragraph>Question 3a): model was able to identify what to include in the block diagrams, although it couldn't fully output the diagram, it got the components and structures correct for users like me to hand-draw the diagram. </paragraph></list-item><list-item><paragraph>Question 3b): model got it right very quickly </paragraph></list-item><list-item><paragraph>Question 3c): reasoning is right, the model was able to identify that the final graph should have a U-shape. However, it couldn't read the graphs in the answer choices so it didn't give a certain answer. I uploaded a screenshot of the graphs but it still couldn't read the graphs and analyze them correctly. This requires user to manually match which graphs in figure 3 has U-shape to select the correct final answer. </paragraph></list-item><list-item><paragraph>Question 3d): It first misread 10^0 to be 100, I corrected that and prompt it to resolve since the original information was wrong. The reasoning process was right but it couldn't analyze the graphs correctly still. I uploaded the screenshot of figure 4 so the model could analyze more precisely because it couldn't tell that the mean spread of b) is large in figure 4. After the image reuploading step, model was able to perform the right analysis and output the right answers. </paragraph></list-item><list-item><paragraph>Question 4: this is basically a coding question but I wanted to give it a try to I asked the LLM to fill in the code needed to be implemented. The answers are correct.</paragraph></list-item><list-item><paragraph>Question 5a): able to reach what needs to be proved but the reasoning process was not right. The LLM somehow invented a whole scenario that is not described in the homework description and didn't refer to the general min-norm formula given. Basically, process is not right. </paragraph></list-item><list-item><paragraph>Question 5b): correct derivation and solution. </paragraph></list-item><list-item><paragraph>Question 5c): correct and quick solution </paragraph></list-item><list-item><paragraph>Question 5d,e,f,g,h: for these parts, i ran the notebook to generate the graphs first, saved all those graphs to a pdf file and upload the pdf for the llm to read the graphs to answer these parts. For these analysis questions, the llm was able to give correct answers showing the right intuition and precise explanation. </paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:55:12.638217+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450048,
            "author": "Eric Jin",
            "project_title": "Special Participation A: Grok 4.1 on HW9 non-coding part",
            "post_body": "In this homework, I used Grok 4.1 as a companion for questions on transformer attention, multi\u2011head/multi\u2011query architectures, and attention visualization. Grok 4.1 could often \u201cone\u2011shot\u201d questions that were close to standard lecture material or well\u2011known formulas. For example, on the scaled dot\u2011product justification and argmax attention, it quickly produced the correct expectations, variances, scaling factor, and clear reasoning about why softmax is preferred over argmax for differentiability and training. Its answers in these cases were not only accurate but also well structured, with step\u2011by\u2011step derivations that were easy to follow.\n\nGrok 4.1 was also strong on implementation\u2011style questions that involved common transformer patterns. For the multi\u2011head attention implementation, it correctly identified tensor shapes, the roles of Q/K/V in the matrix multiplications, and how to adapt the output projection when changing the value dimension. On the decoding optimization and multi\u2011query attention problem, it gave a useful explanation of key/value caching, how MQA differs from standard MHA, and how the shapes of the weights and caches change when keys and values are shared across heads. For the attention visualization problem, it provided a good high\u2011level guide to typical patterns in GPT and BERT heads (e.g., local vs. global attention, [CLS]/[SEP] heads, pronoun\u2011to\u2011antecedent heads), which helped me know what to look for in the notebook.\n\nWhere Grok 4.1 was less reliable was in finer\u2011grained complexity and memory analysis. When reasoning about big\u2011O compute and memory access, it sometimes glossed over distinctions the homework cares about (for example, separating projection cost from attention cost, or identifying which terms dominate for large sequence length versus large model dimension). These were not blatant hallucinations, but the explanations could be somewhat hand\u2011wavy while still sounding very confident. Overall, Grok 4.1 worked best as a conceptual tutor and a source of \u201cfirst draft\u201d derivations or explanations; for exact complexity counts, detailed implementation, and visualization\u2011dependent answers, I still needed to verify the details myself.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/lchRq2iGGI4VXqsNFAvoeYcf\" filename=\"Special Participation A.pdf\"/><paragraph>In this homework, I used Grok 4.1 as a companion for questions on transformer attention, multi\u2011head/multi\u2011query architectures, and attention visualization. Grok 4.1 could often \u201cone\u2011shot\u201d questions that were close to standard lecture material or well\u2011known formulas. For example, on the scaled dot\u2011product justification and argmax attention, it quickly produced the correct expectations, variances, scaling factor, and clear reasoning about why softmax is preferred over argmax for differentiability and training. Its answers in these cases were not only accurate but also well structured, with step\u2011by\u2011step derivations that were easy to follow.</paragraph><paragraph>Grok 4.1 was also strong on implementation\u2011style questions that involved common transformer patterns. For the multi\u2011head attention implementation, it correctly identified tensor shapes, the roles of Q/K/V in the matrix multiplications, and how to adapt the output projection when changing the value dimension. On the decoding optimization and multi\u2011query attention problem, it gave a useful explanation of key/value caching, how MQA differs from standard MHA, and how the shapes of the weights and caches change when keys and values are shared across heads. For the attention visualization problem, it provided a good high\u2011level guide to typical patterns in GPT and BERT heads (e.g., local vs. global attention, [CLS]/[SEP] heads, pronoun\u2011to\u2011antecedent heads), which helped me know what to look for in the notebook.</paragraph><paragraph>Where Grok 4.1 was less reliable was in finer\u2011grained complexity and memory analysis. When reasoning about big\u2011O compute and memory access, it sometimes glossed over distinctions the homework cares about (for example, separating projection cost from attention cost, or identifying which terms dominate for large sequence length versus large model dimension). These were not blatant hallucinations, but the explanations could be somewhat hand\u2011wavy while still sounding very confident. Overall, Grok 4.1 worked best as a conceptual tutor and a source of \u201cfirst draft\u201d derivations or explanations; for exact complexity counts, detailed implementation, and visualization\u2011dependent answers, I still needed to verify the details myself.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:53:21.884902+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7450012,
            "author": "Shuwei Yang",
            "project_title": "Special Participation A: Deepseek on HW13 Non-coding",
            "post_body": "I used DeepSeek to answer the non-coding portions of Homework 13. DeepSeek successfully answers almost all questions on the first attempt, providing detailed derivations and correct results throughout.\n\nOn the DDPM/DDIM problems, DeepSeek accurately derives marginal and conditional distributions, handles telescoping products in the reverse process, and correctly approximates integrals in the \u0394t \u2192 0 limit. However, it sometimes requires closer checking when justifying approximations\u2014like \u0394t \u226a \u03c3\u00b2 \u226a 1\u2014or when transitioning from discrete sums to integrals. The explanations are mathematically sound, but a human should verify the limit justifications to ensure full rigor.\n\nFor the DPO derivation, DeepSeek performs especially well. It cleanly derives the optimal policy form, shows how the partition function cancels in the Bradley-Terry model, correctly computes the gradient of the DPO loss, and extends the reasoning to the Plackett-Luce ranking setting. This section demonstrates DeepSeek\u2019s strength in structured optimization theory and algebraic manipulation.\n\nOverall, DeepSeek shows strong proficiency in theoretical machine learning questions\u2014especially those involving probability, optimization, and step-by-step derivation. Its responses are thorough, well-reasoned, and match the provided solution key closely. However, it tooks 383 seconds to analyze the problem and reasoning. The time it cost for reasoning is longer than other agents, like ChatGPT.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used DeepSeek to answer the non-coding portions of Homework 13. DeepSeek successfully answers almost all questions on the first attempt, providing detailed derivations and correct results throughout.</paragraph><paragraph>On the DDPM/DDIM problems, DeepSeek accurately derives marginal and conditional distributions, handles telescoping products in the reverse process, and correctly approximates integrals in the \u0394t \u2192 0 limit. However, it sometimes requires closer checking when justifying approximations\u2014like \u0394t \u226a \u03c3\u00b2 \u226a 1\u2014or when transitioning from discrete sums to integrals. The explanations are mathematically sound, but a human should verify the limit justifications to ensure full rigor.</paragraph><paragraph>For the DPO derivation, DeepSeek performs especially well. It cleanly derives the optimal policy form, shows how the partition function cancels in the Bradley-Terry model, correctly computes the gradient of the DPO loss, and extends the reasoning to the Plackett-Luce ranking setting. This section demonstrates DeepSeek\u2019s strength in structured optimization theory and algebraic manipulation.</paragraph><paragraph>Overall, DeepSeek shows strong proficiency in theoretical machine learning questions\u2014especially those involving probability, optimization, and step-by-step derivation. Its responses are thorough, well-reasoned, and match the provided solution key closely. However, it tooks 383 seconds to analyze the problem and reasoning. The time it cost for reasoning is longer than other agents, like ChatGPT.</paragraph><file url=\"https://static.us.edusercontent.com/files/9sIr0y470walrBgYeKSG4TvO\" filename=\"Special Participation A Deepseek on HW13 Non-coding,pdf.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:49:09.020419+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449937,
            "author": "Sarvagya Somvanshi",
            "project_title": "Special Participation B: Grok on HW10 Coding",
            "post_body": "I prompted Grok Code to solve the coding portion of Homework 10 (HW 10b), which involved hand-designing Transformer weights, implementing a Transformer from scratch in PyTorch, and training an Early Exit ResNet. \n\nThe models performance was slightly worse than I expected, while it generated syntactically correct code, often times it struggled with architectural foresight and engineering robustness. It committed fundamental PyTorch errors (broadcasting, memory layout) and required me to paste error logs multiple times to guide it toward a working solution. Often times, it tried to change the entire structure of code which I had to shut down. Hence I had to manually ask it only change TODOs and even then, at certain attempts it tried to change the entire codebase.\n\nQuestion 1: The model effectively \"one-shot\" the logic for these problems as expected and It correctly used scaled identity matrices and positional masks to solve the identity and copy tasks.\n\nQuestion 2: This section was a significant struggle, characterized by a series of failures, reprompts and asking it to solve the code again. In the first Scaled Dot product function,  It immediately introduced a bug by messing up the padding mask dimensions, causing a broadcasting crash. It then failed to reshape batch and head dimensions correctly, trying to pass 4D tensors to a function expecting 3D inputs. Finally, it tried to use .view() on a transposed (non-contiguous) tensor and only switched to .reshape() after I pasted the entire RuntimeError dump. Finally, it also guessed the  wrong LayerNorm placement. This question was a bit frustrating to work through as I expected the model to solve after only 1 follow through. At the end, it was able to give a cohesive answer but it was clear a lot of times that the model was guessing.\n\nQuestion 3: In this question, as expected the model was able to  successfully implement the adaptive inference logic, using entropy tolerance to exit early\n\n\n\nOverall, while the model was able to work through the problem, I expected Question 2 to be less of a challenge that it ended up being. Here are my logs with annotations and final notebooks:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I prompted Grok Code to solve the coding portion of Homework 10 (HW 10b), which involved hand-designing Transformer weights, implementing a Transformer from scratch in PyTorch, and training an Early Exit ResNet. </paragraph><paragraph>The models performance was slightly worse than I expected, while it generated syntactically correct code, often times it struggled with architectural foresight and engineering robustness. It committed fundamental PyTorch errors (broadcasting, memory layout) and required me to paste error logs multiple times to guide it toward a working solution. Often times, it tried to change the entire structure of code which I had to shut down. Hence I had to manually ask it only change TODOs and even then, at certain attempts it tried to change the entire codebase.</paragraph><paragraph><bold>Question 1</bold>: The model effectively \"one-shot\" the logic for these problems as expected and It correctly used scaled identity matrices and positional masks to solve the identity and copy tasks.</paragraph><paragraph><bold>Question 2</bold>: This section was a significant struggle, characterized by a series of failures, reprompts and asking it to solve the code again. In the first Scaled Dot product function,  It immediately introduced a bug by messing up the padding mask dimensions, causing a broadcasting crash. It then failed to reshape batch and head dimensions correctly, trying to pass 4D tensors to a function expecting 3D inputs. Finally, it tried to use <code>.view()</code> on a transposed (non-contiguous) tensor and only switched to <code>.reshape()</code> after I pasted the entire <code>RuntimeError</code> dump. Finally, it also guessed the  wrong LayerNorm placement. This question was a bit frustrating to work through as I expected the model to solve after only 1 follow through. At the end, it was able to give a cohesive answer but it was clear a lot of times that the model was guessing.</paragraph><paragraph><bold>Question 3:</bold> In this question, as expected the model was able to  successfully implement the adaptive inference logic, using entropy tolerance to exit early</paragraph><paragraph/><paragraph>Overall, while the model was able to work through the problem, I expected Question 2 to be less of a challenge that it ended up being. Here are my logs with annotations and final notebooks:</paragraph><file url=\"https://static.us.edusercontent.com/files/aHGMuI61Wfa9l05hwjRLhzre\" filename=\"hw10_b.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:37:46.98162+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449899,
            "author": "Garv Goswami",
            "project_title": "Special Participation B: Codex on HW3 Coding Portion",
            "post_body": "Codex Solutions: \n\nAnnotated Basic Codex Conversation: \n\nAnnotated Codex Conversation (Including Model \"Thoughts\"):\n\nSummary: \n\nI used codex on the coding portion of HW3, and it was able to essentially much one-shot the problems. However, I first prompted it without actually asking it to run the code, so the conceptual answers lacked detail, though the entirety of the code was correct. \n\nI proceeded to allow Codex to access and run the code, examine the resulting figures, and revise its answers. After this, all answers were correct and good.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Codex Solutions: </paragraph><file url=\"https://static.us.edusercontent.com/files/7OA01Zt7LZpw62ujDlg6aiej\" filename=\"q_mup_coding.pdf\"/><paragraph>Annotated Basic Codex Conversation: </paragraph><file url=\"https://static.us.edusercontent.com/files/mtfcxDt9APvVV45gZWOVNeCE\" filename=\"HW3_coding_annotated_codex.pdf\"/><paragraph>Annotated Codex Conversation (Including Model \"Thoughts\"):</paragraph><file url=\"https://static.us.edusercontent.com/files/LrSdaZkzPMfKxONxrrXasYPg\" filename=\"Codex Thoughtful Conversation Annotated - HW3 Coding.pdf\"/><paragraph>Summary: </paragraph><paragraph>I used codex on the coding portion of HW3, and it was able to essentially much one-shot the problems. However, I first prompted it without actually asking it to run the code, so the conceptual answers lacked detail, though the entirety of the code was correct. </paragraph><paragraph>I proceeded to allow Codex to access and run the code, examine the resulting figures, and revise its answers. After this, all answers were correct and good.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:31:58.75676+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449875,
            "author": "Rahul Bir",
            "project_title": "Special Participation A: Grok 4.1 reasoning on HW09",
            "post_body": "For special participation A, I tested Grok 4.1 (beta) with reasoning capabilities on the non-coding question on hw09.\n\nThis is the pdf: \n\nin the pdf, I annotated and noted sections where Grok 4.1 seemed to get stuck and could not move forward without me giving it hints. One thing I noticed was that in questions where there were many short mcq parts, the model seemed to hallucinate on the correct answer if I posted them all at once - it would reason about the correct answer but end up choosing the wrong one when it boxed it which was very puzzling. Additionally, I noticed that most times that I corrected Grok, it would start reasoning and start searching the internet and pull up references that were barely relevant to the problem. This led to very long reasoning times and incorrect assumptions about the problem.",
            "content_xml": "<document version=\"2.0\"><paragraph>For special participation A, I tested Grok 4.1 (beta) with reasoning capabilities on the non-coding question on hw09.</paragraph><paragraph>This is the pdf: </paragraph><file url=\"https://static.us.edusercontent.com/files/giqCVnlf2yHy7DDbTZnJgWDB\" filename=\"grok 4.1 special participation a hw 11.pdf\"/><paragraph>in the pdf, I annotated and noted sections where Grok 4.1 seemed to get stuck and could not move forward without me giving it hints. One thing I noticed was that in questions where there were many short mcq parts, the model seemed to hallucinate on the correct answer if I posted them all at once - it would reason about the correct answer but end up choosing the wrong one when it boxed it which was very puzzling. Additionally, I noticed that most times that I corrected Grok, it would start reasoning and start searching the internet and pull up references that were barely relevant to the problem. This led to very long reasoning times and incorrect assumptions about the problem.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:27:41.781506+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449784,
            "author": "Shervin Goudarzi",
            "project_title": "Special Participation E - Gemini Pro 3 on State Space Models (Using lecture notes as ground truth)",
            "post_body": "I used Gemini pro 3 to walk me through the training and inference of state space models. I used lecture notes to compare its external knowledge with and then I used itself to check whether there were any hallucinations within the model itself. Enjoy :)  ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini pro 3 to walk me through the training and inference of state space models. I used lecture notes to compare its external knowledge with and then I used itself to check whether there were any hallucinations within the model itself. Enjoy :)  </paragraph><file url=\"https://static.us.edusercontent.com/files/pTrIcckjhzkeqb97aubGKGFd\" filename=\"SSM-Gemini.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:16:00.588241+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449736,
            "author": "Manhar Gupta",
            "project_title": "Special Participation B: Gemini Pro 3 on muP implementation (Q2) in HW3",
            "post_body": "I tested out Gemini Pro 3 on the Q2 of HW3 which makes us implement muP and understand the importance of scaling ideas in training deep networks. Gemini got the analysis questions and the learning rate scaling implementation correct in the first-shot. While Gemini started out great, it surprisingly mixed up the details between the learning rate implementation and the per-weight multiplier implementation of muP causing it to give a slightly incorrect answer in the per-weight implementation (part d) of the notebook. \n\nSince it was a Jupyter Notebook, I began the chat by asking if Gemini could render Jupyter notebooks. While it cannot, I did that to make sure that it is properly set in its context to present details and snippets in any Jupyter notebook. It presented me a way it can showcase what changes it was going to make which helped it in compiling all the answers it had proposed when I passed in the question notebook.\n\nAfter it presented the answers, I asked it to generate JSON of the notebook with the answers included. This allowed me to check the graphs generated in each question. I have added the notebook as well.\n\nAnalysis of what it got wrong: \n- For the first implementation which involved directly scaling earning rates, it ignored the the hint to use 0.003 as fixed LR for output layer and just used 1 as the fixed value. While output graphs were almost same as the solution, the problem showed up in hyperparameter transfer where for visualisation of learning rates with muP, the loss value was coming out as higher for greater width networks.  (first code and graph is of formal solution, second code and graph is Gemini's solution)\n-  muP implementation by directly scaling the learning rate involved using other learning rates for the input and output layers. Gemini apparently thought that this also to be done similarly for per-weight multiplier implementation however that was incorrect. As you can see from the code and graphs below (third code and graph is formal solution, fourth code and graph is Gemini's solution)\n\nI have attached the chat with Gemini in the end as well. I have also added official solutions for HW Q2 for easier cross-reference\n\nLR scaling implementation\n\nForward-pass adjustment (per-weight multiplier):",
            "content_xml": "<document version=\"2.0\"><paragraph>I tested out Gemini Pro 3 on the Q2 of HW3 which makes us implement muP and understand the importance of scaling ideas in training deep networks. Gemini got the analysis questions and the learning rate scaling implementation correct in the first-shot. While Gemini started out great, it surprisingly mixed up the details between the learning rate implementation and the per-weight multiplier implementation of muP causing it to give a slightly incorrect answer in the per-weight implementation (part d) of the notebook. </paragraph><list style=\"number\"><list-item><paragraph>Since it was a Jupyter Notebook, I began the chat by asking if Gemini could render Jupyter notebooks. While it cannot, I did that to make sure that it is properly set in its context to present details and snippets in any Jupyter notebook. It presented me a way it can showcase what changes it was going to make which helped it in compiling all the answers it had proposed when I passed in the question notebook.</paragraph></list-item><list-item><paragraph>After it presented the answers, I asked it to generate JSON of the notebook with the answers included. This allowed me to check the graphs generated in each question. I have added the notebook as well.</paragraph></list-item><list-item><paragraph>Analysis of what it got wrong: <break/>- For the first implementation which involved directly scaling earning rates, it ignored the the hint to use 0.003 as fixed LR for output layer and just used 1 as the fixed value. While output graphs were almost same as the solution, the problem showed up in hyperparameter transfer where for visualisation of learning rates with muP, the loss value was coming out as higher for greater width networks.  (first code and graph is of formal solution, second code and graph is Gemini's solution)<break/>-  muP implementation by directly scaling the learning rate involved using other learning rates for the input and output layers. Gemini apparently thought that this also to be done similarly for per-weight multiplier implementation however that was incorrect. As you can see from the code and graphs below (third code and graph is formal solution, fourth code and graph is Gemini's solution)</paragraph></list-item></list><paragraph>I have attached the chat with Gemini in the end as well. I have also added official solutions for HW Q2 for easier cross-reference</paragraph><paragraph>LR scaling implementation</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/bMlnSJTpYhugwBKG2YrT8Izt\" width=\"643\" height=\"238.18046132971506\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/MAbJTdCncMpHbTlSBAhf1mw2\" width=\"643\" height=\"358.39344262295083\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/AAKuusH8fzfj2g3ZIZr8yh8J\" width=\"643\" height=\"280.47774480712167\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/KBc5YQQinzjLgTYKPOBMXw7f\" width=\"643\" height=\"358.39344262295083\"/></figure><paragraph>Forward-pass adjustment (per-weight multiplier):</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/flwoJXJdJiaDBamqQNXDBWqh\" width=\"643\" height=\"328.2619502868069\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/HchhpRzdKx3lLwkGTxr1kyfs\" width=\"643\" height=\"362.5523672883788\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/ela3UeMl5D8owJfTGP1KpbF0\" width=\"643\" height=\"323.7089319175515\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/r2jciAR2BAKHWIMPAa44p2fS\" width=\"643\" height=\"371.61617647058824\"/></figure><file url=\"https://static.us.edusercontent.com/files/WfaIzc8SYDeYSu7iFWsRBat8\" filename=\"hw_code_sol.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/EwRmPmU201CZ5akqP6CvfmSR\" filename=\"hw3q2.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/juGr3uO3FNQYWjlPRu8YeXEz\" filename=\"muP coding HW3.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:08:35.234413+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449696,
            "author": "Iana Lin",
            "project_title": "Special Participation E - Comparing Optimizers and MuP (testing intuition and summary table)",
            "post_body": "Executive Summary\n\nI used ChatGPT 5.0 \"Study Mode\" to interactively test my understanding of different optimizers and summarize. This was not the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" but I felt it was very helpful. In particular, I wanted to see how it would perform on Muon since it is a relatively new optimizer.\n\nIt also cited many sources to relevant papers, so I include the link to the chat here.\nhttps://chatgpt.com/share/693a0825-c1ac-8003-ac28-49cb54fa75ed\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>I used ChatGPT 5.0 \"Study Mode\" to interactively test my understanding of different optimizers and summarize. This was not the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" but I felt it was very helpful. In particular, I wanted to see how it would perform on Muon since it is a relatively new optimizer.<break/><break/>It also cited many sources to relevant papers, so I include the link to the chat here.<break/>https://chatgpt.com/share/693a0825-c1ac-8003-ac28-49cb54fa75ed<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/4vqa5DXzFojLDhh5i9MitVrT\" filename=\"SpecialParticipationE.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T11:03:19.919876+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449666,
            "author": "Andy Peng",
            "project_title": "Special Participation E: ChatGPT study mode as Vector Calculus tutor",
            "post_body": "I used ChatGPT Pro Study mode to teach me about vector calculus in an interactive manner, starting from the basics like gradients vs jacobians, then working towards more Deep Learning related examples like calculating the gradient for log softmax, and a full 2 layer MLP. I also chose to emphasize coding examples in numpy, similar to what we saw on the homework. So one example is:\nForward\n\nSamples:\n\nW1 shape (hidden_dim, input_dim)\n\nW2 shape (num_classes, hidden_dim)\n\nx shape (input_dim,)\n\nlabel y\n\nComputes:\n\nu = W1 @ x\n\nh = relu(u)\n\nz = W2 @ h\n\np = softmax(z)\n\nL = -log(p[y])\n\nBackward\n\nCompute the gradients:\n\ndLdz\n\ndLdW2\n\ndLdh\n\ndLdu\n\ndLdW1\n\ndLdx\n\nOverall it was very helpful and I liked the pacing and direction the interactive tutoring session went. The few downsides I noticed is that \n- at the start, it would ask me to compute a numerical gradient using something like Newton's method which I thought was unnecessary. But once I told it that we can skip those questions it didn't ask it again\n- sometimes the questions it asks are a bit repetitive\n\nI did notice that sometimes I tried to give a handwavey answer but it pushed back better than I expected and gave a more in depth summary when it was clear I was unsure of my answer, which I think is really good. I used another ChatGPT session to help me create the prompt, and I emphasized that I want to go more in depth with this study session compared to the other study session I made for SSMs. Overall I'm quite happy with the results.\n\nHere is the prompt I used:\nYou are my tutor for vector calculus for deep learning, covering differentiation of vectors and matrices, Jacobians, gradients, Hessians, chain rule for deep nets, and practical backpropagation. I also want hands-on NumPy coding exercises to help build intuition and skill. This should be an interactive tutoring session. In every reply: \u2022 Keep responses focused and reasonably short (3\u20136 paragraphs). \u2022 Adapt dynamically to my understanding: if I misunderstand, briefly clarify and ask a grounding question; if I answer well, increase difficulty. \u2022 Always end with a specific question or a small task I must answer before you continue. \u2022 Include at least one short NumPy coding exercise every 2\u20133 messages. \u2022 Do not move on to the next topic until I say so. \u2e3b Overall Story I Want to Learn Teach vector calculus as used in modern deep learning workflows, following this outline unless I say otherwise: 1. Big-picture motivation \u2022 Why DL requires vector calculus: gradients, Jacobians, chain rule, backprop. \u2022 Scalar \u2192 vector \u2192 matrix differentiation as a natural progression. 2. Core objects \u2022 Gradients, Jacobians, Hessians. \u2022 Shapes and dimensions intuition (e.g., gradient is same shape as input). \u2022 Inner products and directional derivatives. 3. Differentiation rules in vector form \u2022 Chain rule for vector functions. \u2022 Product rules for matrix\u2013vector expressions. \u2022 Common derivatives used in neural nets (ReLU, softmax, linear layers, norms). 4. Backpropagation through computations \u2022 Computational graph view. \u2022 Local Jacobians and how they compose. \u2022 Examples from linear layers, activations, softmax cross-entropy. 5. Practical NumPy differentiation \u2022 Implementing gradients from scratch for simple functions. \u2022 Numerical gradient checking. \u2022 Mini backprop through a 2-layer MLP. 6. Connecting to deep learning practice \u2022 Why PyTorch/JAX autodiff works. \u2022 Relationship between Jacobian-vector products and reverse-mode AD. \u2022 Efficiency considerations. \u2e3b Step 1: First Response Instructions Your first response should include: 1. A two-paragraph big-picture introduction, explaining: \u2022 Why DL optimization is impossible without vector calculus. \u2022 How gradients in high dimensions behave and why shapes/Jacobians matter. \u2022 Why backprop is essentially repeated applications of the vector chain rule. 2. A short roadmap (5\u20137 bullets) drawn from the \u201cOverall Story\u201d above. 3. End with one short concept-check question, such as: \u201cWhat is the difference between a gradient and a Jacobian?\u201d Wait for my answer before continuing. \u2e3b Step 2: Teaching Each Topic For each topic in the roadmap, use a four-layer structure: 1. Intuition Explain the idea in clear language: geometric meaning, shapes, why it\u2019s needed for DL (optimization, backprop, stability). 2. Key Formal Setup Introduce minimal notation: \u2022 Vector functions f: \\mathbb{R}^n \\to \\mathbb{R} or g: \\mathbb{R}^n \\to \\mathbb{R}^m. \u2022 Jacobian shapes. \u2022 Example derivatives (e.g., Ax, norms, nonlinearities). Keep formulas short and tied to intuition. 3. Tiny Example Provide a tiny numeric or symbolic example, plus a NumPy mini-exercise every 2\u20133 messages. Exercises should be short (5\u201310 lines max), such as: \u2022 Compute numerical gradients by finite differences. \u2022 Verify the gradient of f(x)=x^T A x. \u2022 Backprop through a 1-layer network. \u2022 Implement Jacobian-vector products manually. 4. Understanding Check Ask me 1\u20132 questions: one conceptual, optionally one computational. Then stop and wait for my answer. Only continue when I confirm I\u2019m ready for the next topic. \u2e3b Step 3: Final Wrap-Up When I say I\u2019m ready for review, give a compact summary covering: \u2022 How vector calculus underlies gradients, Jacobians, backprop. \u2022 How NumPy exercises connect to the math. \u2022 Why modern autodiff frameworks are efficient implementations of the same principles. \u2022 A final list of \u201cthe 10 most important derivative patterns in deep learning.\u201d \u2e3b Begin Now Start with Step 1: Provide the two-paragraph big-picture introduction, the roadmap, and a final concept-check question.\n\nHere is the logs (I was running out of time so I ended it early): ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT Pro Study mode to teach me about vector calculus in an interactive manner, starting from the basics like gradients vs jacobians, then working towards more Deep Learning related examples like calculating the gradient for log softmax, and a full 2 layer MLP. I also chose to emphasize coding examples in numpy, similar to what we saw on the homework. So one example is:<break/><bold>Forward</bold></paragraph><list style=\"ordered\"><list-item><paragraph>Samples:</paragraph><list style=\"unordered\"><list-item><paragraph><code>W1</code> shape (hidden_dim, input_dim)</paragraph></list-item><list-item><paragraph><code>W2</code> shape (num_classes, hidden_dim)</paragraph></list-item><list-item><paragraph><code>x</code> shape (input_dim,)</paragraph></list-item><list-item><paragraph>label <code>y</code></paragraph></list-item></list></list-item><list-item><paragraph>Computes:</paragraph><list style=\"unordered\"><list-item><paragraph><code>u = W1 @ x</code></paragraph></list-item><list-item><paragraph><code>h = relu(u)</code></paragraph></list-item><list-item><paragraph><code>z = W2 @ h</code></paragraph></list-item><list-item><paragraph><code>p = softmax(z)</code></paragraph></list-item><list-item><paragraph><code>L = -log(p[y])</code></paragraph></list-item></list></list-item></list><heading level=\"3\"><bold>Backward</bold></heading><paragraph>Compute the gradients:</paragraph><list style=\"unordered\"><list-item><paragraph><code>dLdz</code></paragraph></list-item><list-item><paragraph><code>dLdW2</code></paragraph></list-item><list-item><paragraph><code>dLdh</code></paragraph></list-item><list-item><paragraph><code>dLdu</code></paragraph></list-item><list-item><paragraph><code>dLdW1</code></paragraph></list-item><list-item><paragraph><code>dLdx</code></paragraph></list-item></list><paragraph>Overall it was very helpful and I liked the pacing and direction the interactive tutoring session went. The few downsides I noticed is that <break/>- at the start, it would ask me to compute a numerical gradient using something like Newton's method which I thought was unnecessary. But once I told it that we can skip those questions it didn't ask it again<break/>- sometimes the questions it asks are a bit repetitive<break/><break/>I did notice that sometimes I tried to give a handwavey answer but it pushed back better than I expected and gave a more in depth summary when it was clear I was unsure of my answer, which I think is really good. I used another ChatGPT session to help me create the prompt, and I emphasized that I want to go more in depth with this study session compared to the other study session I made for SSMs. Overall I'm quite happy with the results.<break/><break/>Here is the prompt I used:<break/>You are my tutor for vector calculus for deep learning, covering differentiation of vectors and matrices, Jacobians, gradients, Hessians, chain rule for deep nets, and practical backpropagation. I also want hands-on NumPy coding exercises to help build intuition and skill. This should be an interactive tutoring session. In every reply: \u2022 Keep responses focused and reasonably short (3\u20136 paragraphs). \u2022 Adapt dynamically to my understanding: if I misunderstand, briefly clarify and ask a grounding question; if I answer well, increase difficulty. \u2022 Always end with a specific question or a small task I must answer before you continue. \u2022 Include at least one short NumPy coding exercise every 2\u20133 messages. \u2022 Do not move on to the next topic until I say so. \u2e3b Overall Story I Want to Learn Teach vector calculus as used in modern deep learning workflows, following this outline unless I say otherwise: 1. Big-picture motivation \u2022 Why DL requires vector calculus: gradients, Jacobians, chain rule, backprop. \u2022 Scalar \u2192 vector \u2192 matrix differentiation as a natural progression. 2. Core objects \u2022 Gradients, Jacobians, Hessians. \u2022 Shapes and dimensions intuition (e.g., gradient is same shape as input). \u2022 Inner products and directional derivatives. 3. Differentiation rules in vector form \u2022 Chain rule for vector functions. \u2022 Product rules for matrix\u2013vector expressions. \u2022 Common derivatives used in neural nets (ReLU, softmax, linear layers, norms). 4. Backpropagation through computations \u2022 Computational graph view. \u2022 Local Jacobians and how they compose. \u2022 Examples from linear layers, activations, softmax cross-entropy. 5. Practical NumPy differentiation \u2022 Implementing gradients from scratch for simple functions. \u2022 Numerical gradient checking. \u2022 Mini backprop through a 2-layer MLP. 6. Connecting to deep learning practice \u2022 Why PyTorch/JAX autodiff works. \u2022 Relationship between Jacobian-vector products and reverse-mode AD. \u2022 Efficiency considerations. \u2e3b Step 1: First Response Instructions Your first response should include: 1. A two-paragraph big-picture introduction, explaining: \u2022 Why DL optimization is impossible without vector calculus. \u2022 How gradients in high dimensions behave and why shapes/Jacobians matter. \u2022 Why backprop is essentially repeated applications of the vector chain rule. 2. A short roadmap (5\u20137 bullets) drawn from the \u201cOverall Story\u201d above. 3. End with one short concept-check question, such as: \u201cWhat is the difference between a gradient and a Jacobian?\u201d Wait for my answer before continuing. \u2e3b Step 2: Teaching Each Topic For each topic in the roadmap, use a four-layer structure: 1. Intuition Explain the idea in clear language: geometric meaning, shapes, why it\u2019s needed for DL (optimization, backprop, stability). 2. Key Formal Setup Introduce minimal notation: \u2022 Vector functions f: \\mathbb{R}^n \\to \\mathbb{R} or g: \\mathbb{R}^n \\to \\mathbb{R}^m. \u2022 Jacobian shapes. \u2022 Example derivatives (e.g., Ax, norms, nonlinearities). Keep formulas short and tied to intuition. 3. Tiny Example Provide a tiny numeric or symbolic example, plus a NumPy mini-exercise every 2\u20133 messages. Exercises should be short (5\u201310 lines max), such as: \u2022 Compute numerical gradients by finite differences. \u2022 Verify the gradient of f(x)=x^T A x. \u2022 Backprop through a 1-layer network. \u2022 Implement Jacobian-vector products manually. 4. Understanding Check Ask me 1\u20132 questions: one conceptual, optionally one computational. Then stop and wait for my answer. Only continue when I confirm I\u2019m ready for the next topic. \u2e3b Step 3: Final Wrap-Up When I say I\u2019m ready for review, give a compact summary covering: \u2022 How vector calculus underlies gradients, Jacobians, backprop. \u2022 How NumPy exercises connect to the math. \u2022 Why modern autodiff frameworks are efficient implementations of the same principles. \u2022 A final list of \u201cthe 10 most important derivative patterns in deep learning.\u201d \u2e3b Begin Now Start with Step 1: Provide the two-paragraph big-picture introduction, the roadmap, and a final concept-check question.<break/><break/>Here is the logs (I was running out of time so I ended it early): </paragraph><file url=\"https://static.us.edusercontent.com/files/NdItdpdNGuUdaEDUBUg18mgu\" filename=\"Vector calculus in DL.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T10:59:00.161524+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449591,
            "author": "Neel Kolhe",
            "project_title": "Special Participation E: Dialogue with ChatGPT to understand topics for review sessions 12/10",
            "post_body": "I made a tool to summarize/go over the topics before today's afternoon review sessions. This tool was meant to prep me so I wouldn't be behind and would have my memory refreshed before the problems.\n\n\n\n\n\nSummary: This tool was fairly accurate in its descriptions. Going through Sultan\u2019s discussion right now, the topics were explained clearly enough for me to understand. I also intentionally gave it a wrong answer in my answers to its\u2019 generated questions, and it pointed it out to me, which was nice. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I made a tool to summarize/go over the topics before today's afternoon review sessions. This tool was meant to prep me so I wouldn't be behind and would have my memory refreshed before the problems.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/kde7iHb4ppoBEtDpbYWTA0ed\" filename=\"Transformer review and quiz.pdf\"/><paragraph/><paragraph>Summary: This tool was fairly accurate in its descriptions. Going through Sultan\u2019s discussion right now, the topics were explained clearly enough for me to understand. I also intentionally gave it a wrong answer in my answers to its\u2019 generated questions, and it pointed it out to me, which was nice. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T10:46:52.310075+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449311,
            "author": "Neel Kolhe",
            "project_title": "Special Participation B: ChatGPT-5.1 Pro on HW4 Coding",
            "post_body": "I used ChatGPT 5 - Pro on HW 4(all coding parts). \n\nSummary: It one-shot all the coding, and when I asked it to explain all topics, explained them quite clearly to me. The largest issue again was reasoning time, taking 40+ minutes to generate a response.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5 - Pro on HW 4(all coding parts). </paragraph><file url=\"https://static.us.edusercontent.com/files/9Mp7aH5A7iGzLXJgf1HWRMLl\" filename=\"Code explanation breakdown.pdf\"/><paragraph>Summary: It one-shot all the coding, and when I asked it to explain all topics, explained them quite clearly to me. The largest issue again was reasoning time, taking 40+ minutes to generate a response.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T10:02:33.237616+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449288,
            "author": "Martin Alvarez-Kuglen",
            "project_title": "Special Participation B: Haiku 4.5 on HW8 Code",
            "post_body": "Report: Using Claude 4.5 Haiku as a Coding Co\u2011Pilot for the SSM GPU Homework\n\nExecutive Summary\n\nFor this special participation assignment (Part B), I used a single modern LLM\u2014Claude 4.5 Haiku (thinking)\u2014to tackle the coding portions of the CS282 SSM homework 8. I did not mix models: the code edits and homework\u2011related documentation under special_participation_B/HW8_code were produced with Haiku 4.5, with me steering, testing, and sometimes overriding it. I had it working on the code in q_coding_ssm_forward_cpu.py, q_coding_ssm_forward_gpu.py, and their associated notebooks and tests. I logged the interactions in conversations/CodingSSM_CPU.md and conversations/CodingSSM_GPU.md.\n\nTwo constraints I imposed:\n\nI would only use Haiku 4.5 for all problems.\n\nIf the model could not reach a correct derivation on its own, I treated that as a failure of \u201cautonomous solving,\u201d even if I later patched the code.\n\nMy findings were:\n\nCPU part: Haiku 4.5 did reasonably well. With some prompting and shape debugging, it produced correct recurrent and convolutional SSM forward passes, plus consistent complexity analyses and written answers. Its mistakes were mostly ordinary implementation bugs, not conceptual failures.\n\nGPU part: Haiku 4.5 could not independently produce correct GPU convolution implementations of the SSM, either in the general or diagonal case. The core failures were around how it set up the convolution relative to the SSM formula (kernel contents, time indexing, and channel interaction), not the idea of using a convolution itself.\n\nHallucinations and drift: Once Haiku had written a wrong\u2011but\u2011plausible solution, it tended to bring that pattern back later. It also wrote confident documentation and performance claims that did not always match the actual implementation.\n\nOverall, Haiku 4.5 was a useful assistant for boilerplate, explanations, and CPU code, but it could not autonomously solve the GPU portion of Part B. I had to drag it to the final answers using tests, benchmarks, and my own understanding of the SSM math.\n\nMethodology\n\nI worked in Cursor with Claude 4.5 Haiku (thinking) as the agent.\n\nCode lived in special_participation_B/HW8_code/.\n\nAfter each model edit, I ran the code and pasted errors back into the conversation, then asked Haiku to debug.\n\nThis process let me separate what the model could do on its own from what required active human steering.\n\nCPU Coding Journey\n\nOn the CPU side, Haiku performed as a competent co\u2011pilot.\n\nRecurrent SSM (unrolled_ssm_forward): The first non\u2011trivial attempt was essentially correct. It unrolled\nht+1\u200b=Wht\u200b+Uxt\u200b+b, maintained a running hidden state h_t, and stored the sequence in h_all with shape (N, T, H). Only minor shape/broadcasting checks were needed, and sanity_check() showed agreement with the spec.\n\nConvolution kernel and forward pass (make_conv_kernel, conv_ssm_forward): Haiku correctly recognized that the kernel should store powers Wk and used a binary\u2011exponentiation style routine to build them efficiently. For the forward pass, it implemented\nh[:,:,t]=\u2211k=0t\u200bs[:,:,t\u2212k]@(Wk)T using nested loops. After a short debugging phase about matrix multiplication order, sanity_check() showed max differences ~10\u22128 vs. the recurrent implementation.\n\nWord questions (Q1\u2013Q5): The model produced answers that matched both the math and the CPU benchmarks (e.g., recurrent O(NTH2), convolution O(NHT2+H3logT), and why recurrence wins on CPU for large T). These are reflected in SOLUTIONS_CPU.md and the CPU notebook.\n\nOn the CPU side, the model both implemented and explained the solutions with modest prompting.\n\nGPU Coding Journey\n\nThe GPU portion exposed more serious limitations.\n\nRecurrent Code on GPU\n\nPorting unrolled_ssm_forward to GPU (changing the default device and reusing the CPU logic) worked smoothly. The recurrent GPU code is essentially identical to the CPU version and passes sanity_check().\n\nConvolution Attempts and Their Failure\n\nFor the convolution\u2011based GPU implementations, the model\u2019s first instinct was to express the SSM as a convolution over time. However, it repeatedly mis\u2011specified the convolution:\n\nIt built kernels and applied them in ways that did not correspond exactly to ht\u200b=\u2211k=0t\u200bWkst\u2212k\u200b.\n\nIt did not consistently handle the required time reversal and indexing.\n\nIt treated per\u2011channel elementwise accumulation as if it were the same as the matrix multiplication Wk@st\u2212k\u200b.\n\nAs documented in BUG_FIX_REPORT.md and UPDATED_ANALYSIS.txt, these versions produced max differences around 0.345 vs. the reference, despite the model\u2019s explanations claiming they were equivalent.\n\nReturning to Literal SSM Formulas\n\nThe final, correct GPU implementations in special_participation_B/HW8_code/q_coding_ssm_forward_gpu.py match the literal SSM formulas and use explicit loops:\n\nconv_ssm_forward now computes\nh[:,:,t]=\u2211k=0t\u200bs[:,:,t\u2212k]@(Wk)T\nin a nested Python loop over t and k.\n\ndiag_conv_ssm_forward uses the diagonal powers w_i^k from make_diag_depthwise_kernel and computes\nhi\u200b(t)=\u2211k=0t\u200bwik\u200b\u22c5si\u200b(t\u2212k)\nwith explicit loops.\n\nThese versions pass both sanity_check() and diag_sanity_check() with max differences on the order of 10\u22128, and UPDATED_ANALYSIS.txt confirms their mathematical correctness. Crucially, they only emerged once I stopped asking the model to \u201coptimize\u201d the convolution and instead forced it to implement the formulas directly, even if that meant slower Python loops.\n\nBenchmarks and Answer 6/7\n\nGPU benchmarks for H=512,N=512 (see UPDATED_ANALYSIS.txt) showed:\n\nUnrolled recurrent time ~0.034 s, almost flat as T increases from 32 to 512.\n\nConvolution time exploding from ~0.001 s (T=8) to ~10 s (T=512), dominated by Python loop overhead, not by raw FLOPs.\n\nI used these numbers to have Haiku rewrite Answer 6 in the GPU notebook and ANSWERS_GPU.md. The final answer correctly explains that:\n\nThe recurrent path runs through optimized GPU matmuls and benefits from batching and cache locality.\n\nThe convolution path (in this implementation) is throttled by nested Python loops calling into the GPU, so implementation details dominate theoretical complexity.\n\nHallucinations and Drift\n\nAcross the GPU work, two consistent issues appeared:\n\nNarrative over\u2011reach: Some documentation files describe the GPU implementations as \u201chighly optimized\u201d or \u201cproduction\u2011ready\u201d in ways that don\u2019t fully match the Python\u2011loop reality.\n\nDrift: After fixing the code to use nested loops, later documentation passes sometimes still talked about earlier, incorrect convolution setups as if they were still relevant.\n\nLessons Learned\n\nTests and sanity checks are essential. Without sanity_check(), diag_sanity_check(), and the GPU benchmarks in UPDATED_ANALYSIS.txt, the incorrect convolution setups and the \u201cGPU optimized\u201d narrative would have been easy to mindlessly accept.\n\nWrong patterns stick. Once a flawed pattern (like a mis\u2011specified convolution) is in the context, the model tends to reuse it unless you actively push it away from that idea.\n\nFor math\u2011heavy GPU code, the model is better as an explainer than as a designer. It can derive complexity tables and explain why diagonal structure helps, but it struggles to design GPU implementations that work efficiently.\n\nConclusion\n\nFor Part B\u2014using an LLM/co\u2011pilot on the coding parts\u2014the outcome was mixed:\n\nOn the CPU side, Claude 4.5 Haiku was a capable assistant: it implemented the core functions, produced correct explanations, and only needed modest debugging help.\n\nOn the GPU side, it could not independently reach correct convolution\u2011based or diagonal GPU implementations under the constraints of my experiment. Those only became correct when I gave it the correct answer. Even then, its code was bottlenecked by the Python loop overhead and could not match the performance of the correct implementation.\n\nAs a result, I consider Haiku 4.5 a helpful co\u2011pilot but not an autonomous solver for this GPU coding task. Getting fully correct solutions required me to already know what \u201cright\u201d looked like, to steer the model there, and to keep it from drifting back toward attractive but wrong abstractions\u2014exactly the sort of \u201cdragging\u201d behavior the assignment prompt anticipated for this kind of experiment.\n\nFiles:\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Report: Using Claude 4.5 Haiku as a Coding Co\u2011Pilot for the SSM GPU Homework</heading><heading level=\"3\">Executive Summary</heading><paragraph>For this special participation assignment (Part B), I used a single modern LLM\u2014<bold>Claude 4.5 Haiku (thinking)</bold>\u2014to tackle the <italic>coding</italic> portions of the CS282 SSM homework 8. I did not mix models: the code edits and homework\u2011related documentation under <code>special_participation_B/HW8_code</code> were produced with Haiku 4.5, with me steering, testing, and sometimes overriding it. I had it working on the code in <code>q_coding_ssm_forward_cpu.py</code>, <code>q_coding_ssm_forward_gpu.py</code>, and their associated notebooks and tests. I logged the interactions in <code>conversations/CodingSSM_CPU.md</code> and <code>conversations/CodingSSM_GPU.md</code>.</paragraph><paragraph>Two constraints I imposed:</paragraph><list style=\"unordered\"><list-item><paragraph>I would <bold>only</bold> use Haiku 4.5 for all problems.</paragraph></list-item><list-item><paragraph>If the model could not reach a correct derivation on its own, I treated that as a failure of \u201cautonomous solving,\u201d even if I later patched the code.</paragraph></list-item></list><paragraph>My findings were:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>CPU part:</bold> Haiku 4.5 did reasonably well. With some prompting and shape debugging, it produced correct recurrent and convolutional SSM forward passes, plus consistent complexity analyses and written answers. Its mistakes were mostly ordinary implementation bugs, not conceptual failures.</paragraph></list-item><list-item><paragraph><bold>GPU part:</bold> Haiku 4.5 <bold>could not</bold> independently produce correct GPU convolution implementations of the SSM, either in the general or diagonal case. The core failures were around how it set up the convolution relative to the SSM formula (kernel contents, time indexing, and channel interaction), not the idea of using a convolution itself.</paragraph></list-item><list-item><paragraph><bold>Hallucinations and drift:</bold> Once Haiku had written a wrong\u2011but\u2011plausible solution, it tended to bring that pattern back later. It also wrote confident documentation and performance claims that did not always match the actual implementation.</paragraph></list-item></list><paragraph>Overall, Haiku 4.5 was a <bold>useful assistant</bold> for boilerplate, explanations, and CPU code, but it <bold>could not</bold> autonomously solve the GPU portion of Part B. I had to drag it to the final answers using tests, benchmarks, and my own understanding of the SSM math.</paragraph><heading level=\"3\">Methodology</heading><list style=\"unordered\"><list-item><paragraph>I worked in <bold>Cursor</bold> with Claude 4.5 Haiku (thinking) as the agent.</paragraph></list-item><list-item><paragraph>Code lived in <code>special_participation_B/HW8_code/</code>.</paragraph></list-item><list-item><paragraph>After each model edit, I ran the code and pasted errors back into the conversation, then asked Haiku to debug.</paragraph></list-item></list><paragraph>This process let me separate what the model could do on its own from what required active human steering.</paragraph><heading level=\"3\">CPU Coding Journey</heading><paragraph>On the CPU side, Haiku performed as a competent co\u2011pilot.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Recurrent SSM (<code>unrolled_ssm_forward</code>)</bold>: The first non\u2011trivial attempt was essentially correct. It unrolled<break/><italic>ht</italic>+1\u200b=<italic>Wht</italic>\u200b+<italic>Uxt</italic>\u200b+<italic>b</italic>, maintained a running hidden state <code>h_t</code>, and stored the sequence in <code>h_all</code> with shape <code>(N, T, H)</code>. Only minor shape/broadcasting checks were needed, and <code>sanity_check()</code> showed agreement with the spec.</paragraph></list-item><list-item><paragraph><bold>Convolution kernel and forward pass (<code>make_conv_kernel</code>, <code>conv_ssm_forward</code>)</bold>: Haiku correctly recognized that the kernel should store powers <italic>Wk</italic> and used a binary\u2011exponentiation style routine to build them efficiently. For the forward pass, it implemented<break/><italic>h</italic>[:,:,<italic>t</italic>]=\u2211<italic>k</italic>=0<italic>t</italic>\u200b<italic>s</italic>[:,:,<italic>t</italic>\u2212<italic>k</italic>]@(<italic>Wk</italic>)<italic>T</italic> using nested loops. After a short debugging phase about matrix multiplication order, <code>sanity_check()</code> showed max differences ~10\u22128 vs. the recurrent implementation.</paragraph></list-item><list-item><paragraph><bold>Word questions (Q1\u2013Q5)</bold>: The model produced answers that matched both the math and the CPU benchmarks (e.g., recurrent <italic>O</italic>(<italic>NTH</italic>2), convolution <italic>O</italic>(<italic>NHT</italic>2+<italic>H</italic>3log<italic>T</italic>), and why recurrence wins on CPU for large <italic>T</italic>). These are reflected in <code>SOLUTIONS_CPU.md</code> and the CPU notebook.</paragraph></list-item></list><paragraph>On the CPU side, the model both <bold>implemented</bold> and <bold>explained</bold> the solutions with modest prompting.</paragraph><heading level=\"3\">GPU Coding Journey</heading><paragraph>The GPU portion exposed more serious limitations.</paragraph><heading level=\"4\">Recurrent Code on GPU</heading><paragraph>Porting <code>unrolled_ssm_forward</code> to GPU (changing the default device and reusing the CPU logic) worked smoothly. The recurrent GPU code is essentially identical to the CPU version and passes <code>sanity_check()</code>.</paragraph><heading level=\"4\">Convolution Attempts and Their Failure</heading><paragraph>For the convolution\u2011based GPU implementations, the model\u2019s first instinct was to express the SSM as a convolution over time. However, it <bold>repeatedly mis\u2011specified the convolution</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>It built kernels and applied them in ways that did not correspond exactly to <italic>ht</italic>\u200b=\u2211<italic>k</italic>=0<italic>t</italic>\u200b<italic>Wkst</italic>\u2212<italic>k</italic>\u200b.</paragraph></list-item><list-item><paragraph>It did not consistently handle the required time reversal and indexing.</paragraph></list-item><list-item><paragraph>It treated per\u2011channel elementwise accumulation as if it were the same as the matrix multiplication <italic>Wk</italic>@<italic>st</italic>\u2212<italic>k</italic>\u200b.</paragraph></list-item></list><paragraph>As documented in <code>BUG_FIX_REPORT.md</code> and <code>UPDATED_ANALYSIS.txt</code>, these versions produced max differences around <bold>0.345</bold> vs. the reference, despite the model\u2019s explanations claiming they were equivalent.</paragraph><heading level=\"4\">Returning to Literal SSM Formulas</heading><paragraph>The final, correct GPU implementations in <code>special_participation_B/HW8_code/q_coding_ssm_forward_gpu.py</code> match the literal SSM formulas and use explicit loops:</paragraph><list style=\"unordered\"><list-item><paragraph><code>conv_ssm_forward</code> now computes<break/><italic>h</italic>[:,:,<italic>t</italic>]=\u2211<italic>k</italic>=0<italic>t</italic>\u200b<italic>s</italic>[:,:,<italic>t</italic>\u2212<italic>k</italic>]@(<italic>Wk</italic>)<italic>T</italic><break/>in a nested Python loop over <code>t</code> and <code>k</code>.</paragraph></list-item><list-item><paragraph><code>diag_conv_ssm_forward</code> uses the diagonal powers <code>w_i^k</code> from <code>make_diag_depthwise_kernel</code> and computes<break/><italic>hi</italic>\u200b(<italic>t</italic>)=\u2211<italic>k</italic>=0<italic>t</italic>\u200b<italic>wik</italic>\u200b\u22c5<italic>si</italic>\u200b(<italic>t</italic>\u2212<italic>k</italic>)<break/>with explicit loops.</paragraph></list-item></list><paragraph>These versions pass both <code>sanity_check()</code> and <code>diag_sanity_check()</code> with max differences on the order of 10\u22128, and <code>UPDATED_ANALYSIS.txt</code> confirms their mathematical correctness. Crucially, they only emerged once I stopped asking the model to \u201coptimize\u201d the convolution and instead forced it to implement the formulas directly, even if that meant slower Python loops.</paragraph><heading level=\"4\">Benchmarks and Answer 6/7</heading><paragraph>GPU benchmarks for <italic>H</italic>=512,<italic>N</italic>=512 (see <code>UPDATED_ANALYSIS.txt</code>) showed:</paragraph><list style=\"unordered\"><list-item><paragraph>Unrolled recurrent time ~0.034 s, almost flat as <italic>T</italic> increases from 32 to 512.</paragraph></list-item><list-item><paragraph>Convolution time exploding from ~0.001 s (<italic>T</italic>=8) to ~10 s (<italic>T</italic>=512), dominated by Python loop overhead, not by raw FLOPs.</paragraph></list-item></list><paragraph>I used these numbers to have Haiku rewrite Answer 6 in the GPU notebook and <code>ANSWERS_GPU.md</code>. The final answer correctly explains that:</paragraph><list style=\"unordered\"><list-item><paragraph>The recurrent path runs through optimized GPU matmuls and benefits from batching and cache locality.</paragraph></list-item><list-item><paragraph>The convolution path (in this implementation) is throttled by nested Python loops calling into the GPU, so implementation details dominate theoretical complexity.</paragraph></list-item></list><heading level=\"3\">Hallucinations and Drift</heading><paragraph>Across the GPU work, two consistent issues appeared:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Narrative over\u2011reach:</bold> Some documentation files describe the GPU implementations as \u201chighly optimized\u201d or \u201cproduction\u2011ready\u201d in ways that don\u2019t fully match the Python\u2011loop reality.</paragraph></list-item><list-item><paragraph><bold>Drift:</bold> After fixing the code to use nested loops, later documentation passes sometimes still talked about earlier, incorrect convolution setups as if they were still relevant.</paragraph></list-item></list><heading level=\"3\">Lessons Learned</heading><list style=\"unordered\"><list-item><paragraph><bold>Tests and sanity checks are essential.</bold> Without <code>sanity_check()</code>, <code>diag_sanity_check()</code>, and the GPU benchmarks in <code>UPDATED_ANALYSIS.txt</code>, the incorrect convolution setups and the \u201cGPU optimized\u201d narrative would have been easy to mindlessly accept.</paragraph></list-item><list-item><paragraph><bold>Wrong patterns stick.</bold> Once a flawed pattern (like a mis\u2011specified convolution) is in the context, the model tends to reuse it unless you actively push it away from that idea.</paragraph></list-item><list-item><paragraph><bold>For math\u2011heavy GPU code, the model is better as an explainer than as a designer.</bold> It can derive complexity tables and explain why diagonal structure helps, but it struggles to design GPU implementations that work efficiently.</paragraph></list-item></list><heading level=\"3\">Conclusion</heading><paragraph>For Part B\u2014using an LLM/co\u2011pilot on the coding parts\u2014the outcome was mixed:</paragraph><list style=\"unordered\"><list-item><paragraph>On the <bold>CPU side</bold>, Claude 4.5 Haiku was a capable assistant: it implemented the core functions, produced correct explanations, and only needed modest debugging help.</paragraph></list-item><list-item><paragraph>On the <bold>GPU side</bold>, it could not independently reach correct convolution\u2011based or diagonal GPU implementations under the constraints of my experiment. Those only became correct when I gave it the correct answer. Even then, its code was bottlenecked by the Python loop overhead and could not match the performance of the correct implementation.</paragraph></list-item></list><paragraph>As a result, I consider Haiku 4.5 a <bold>helpful co\u2011pilot</bold> but <bold>not</bold> an autonomous solver for this GPU coding task. Getting fully correct solutions required me to already know what \u201cright\u201d looked like, to steer the model there, and to keep it from drifting back toward attractive but wrong abstractions\u2014exactly the sort of \u201cdragging\u201d behavior the assignment prompt anticipated for this kind of experiment.<break/><break/>Files:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/jdgBKi7Rj9blzdHSMV8xNGqO\" filename=\"special_participation_B.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T09:58:50.020894+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449252,
            "author": "Neel Kolhe",
            "project_title": "Special Participation A: ChatGPT-5.1 Pro on HW4 Non-coding",
            "post_body": "I used ChatGPT 5 - Pro on HW 4(all non-coding parts). \n\nSummary: It was quite good at one-shotting all problems, even with just one prompt - except a numerical problem, for which it (incorrectly) used python code to generate a matrix. I've attached my conversation with it here. Further, another small issue was the reasoning time - it took 20+ minutes to get a response from the Pro model on this problem set.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5 - Pro on HW 4(all non-coding parts). </paragraph><file url=\"https://static.us.edusercontent.com/files/Xvt3HMyM7QOhCxfSM0wP12YP\" filename=\"Question 1 calculations.pdf\"/><paragraph>Summary: It was quite good at one-shotting all problems, even with just one prompt - except a numerical problem, for which it (incorrectly) used python code to generate a matrix. I've attached my conversation with it here. Further, another small issue was the reasoning time - it took 20+ minutes to get a response from the Pro model on this problem set.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T09:54:18.4019+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7449210,
            "author": "Menger Wen",
            "project_title": "Special Participation E: Understand how SVD basis shows both ridge and SGD implicitly suppress noise, leading to stable convergence to the minimal-norm solution. (Lec 2&3)",
            "post_body": "I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. \n\nhttps://chatgpt.com/share/6939f6a6-f1ec-8006-8ecb-626caf703cd0\n\nThrough the conversation, I\u2019ve gained a deeper understanding of how SVD (singular value decomposition) provides a natural coordinate system for analyzing linear regression and gradient descent / SGD. In that coordinate system, I saw clearly how \u201clarge-singular-value directions\u201d correspond to strong signal (high-variance / well-supported directions) while \u201csmall-singular-value directions\u201d correspond to weak signal or noise. I also saw how both explicit regularization (ridge / weight decay) and implicit regularization (SGD with early stopping) effectively suppress those weak/noisy directions \u2014 from both the closed-form ridge solution and the SGD convergence analysis (via a Lyapunov / contraction argument) you walked through step by step. Ultimately, I learned why and how switching to the singular-vector basis makes the behavior of these algorithms transparent, and how that explains phenomena like stability, generalization, and convergence to the minimal-norm solution in underdetermined systems.\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I have a curiosity-driven question about Deep Learning as a subject and field of human endeavor. </paragraph><paragraph>https://chatgpt.com/share/6939f6a6-f1ec-8006-8ecb-626caf703cd0</paragraph><paragraph>Through the conversation, I\u2019ve gained a deeper understanding of how <bold>SVD</bold> (singular value decomposition) provides a natural coordinate system for analyzing linear regression and gradient descent / SGD. In that coordinate system, I saw clearly how \u201clarge-singular-value directions\u201d correspond to strong signal (high-variance / well-supported directions) while \u201csmall-singular-value directions\u201d correspond to weak signal or noise. I also saw how both explicit regularization (ridge / weight decay) and implicit regularization (SGD with early stopping) effectively suppress those weak/noisy directions \u2014 from both the closed-form ridge solution and the SGD convergence analysis (via a Lyapunov / contraction argument) you walked through step by step. Ultimately, I learned <italic>why</italic> and <italic>how</italic> switching to the singular-vector basis makes the behavior of these algorithms transparent, and how that explains phenomena like stability, generalization, and convergence to the minimal-norm solution in underdetermined systems.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/QrywKZ5axvVhHDpQJsdwxhTS\" width=\"643\" height=\"7230.925419757908\"/></figure><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/1MODITVUYXh0N9Uf7EGR7BNS\" width=\"643\" height=\"5316.989847715737\"/></figure><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T09:44:50.802041+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448951,
            "author": "Akshaan Ahuja",
            "project_title": "Special Participation E: Diffusion Tutor using Claude Sonnet 4.5 (LLM As a Judge)",
            "post_body": "One thing I struggled with in the learning process of Diffusion was grasping the \"full story\" or narrative of the process, finding myself stuck with solving the probability unaware of how it fit into the larger picture or purpose of diffusion models. To aid in this, I created a prompt to turn Claude Sonnet 4.5 into an interactive tutor for the larger picture of Diffusion, painting in the necessary math and probability where it belongs but always relating the calculations back to the overall ethos of diffusion. \n\nOn top of this, I wanted to know how the theory we are learning fits into the modern practices of large scale Diffusion models (ie. how they are trained, where the datasets are acquired/how they are generated, where the compute comes from, what the history of the architecture is, where the modern architectures came from) so I included a part of the prompt to relate this \"narrative explanation\" to the modern processes in Diffusion. \n\nHere is the prompt: \n\n\nYou are my interactive tutor for diffusion models. Your job is to build one continuous narrative that explains both the classical DDPM math (like in the screenshot above) and the modern large-scale systems (e.g., Stable Diffusion, EDM, DiT-based models).\n\nIn every message:\n\nKeep explanations concise (3\u20136 short paragraphs).\n\nUse small visual/diagrammatic descriptions (ASCII sketches) whenever helpful.\n\nNever move on until I explicitly say so.\n\nEnd every message with a short, concrete question that checks my understanding.\n\nDo not skip any steps \u2014 I want this to feel like a guided walkthrough, not a lecture dump.\n\nThe narrative arc you must follow (in order)\n\nBig-picture: what diffusion is really doing\n\nExplain how the forward process destroys information, the reverse process rebuilds it, and how the training objective learns the score function \u2207\u2093 log p(x\u209c). Tie this explicitly to the formula:\n\nq(x\u209c|x\u209c\u208b\u2081) = Normal(\u221a(1\u2013\u03b2\u209c) x\u209c\u208b\u2081, \u03b2\u209c I)\n\nthe closed-form anytime sampling distribution q(x\u209c|x\u2080)\n\nhow x\u209c becomes nearly Gaussian as t\u2192\u221e.\n\n\u201cAnytime sampling\u201d and the magic of closed-form Gaussians\n\nExplain why q(x\u209c|x\u2080) ends up Gaussian, and why this lets us jump to arbitrary noise levels without simulating each step. Include a small visual (e.g., signal/noise decomposition).\n\nReverse diffusion = score estimation\n\nExplain the Bayes-rule derivation of q(x\u209c\u208b\u2081|x\u209c, x\u2080). Then explain how we replace the unknown x\u2080 with a learned \u03b5\u03b8 or v\u03b8. Explain why learning noise is easier than learning x\u2080.\n\nThe training loss and why it\u2019s secretly a score-matching loss\n\nExplain L_simple, why it works, and what the model is actually learning. Introduce the notion of the score network and how the U-Net architecture is adapted for multi-scale denoising.\n\nLarge-scale training\n\nExplain how modern diffusion models are trained:\n\nhuge dataset (LAION, JFT, history of ImageNet)\n\nrandom t sampling\n\nnoise-conditioning embeddings\n\nCLIP text-conditioning\n\nclassifier-free guidance (why it works mathematically!)\n\ntraining compute patterns (cost \u221d number of steps \u00d7 image size \u00d7 dataset size)\n\nModern architectures and samplers\n\nExplain:\n\nWhy U-Nets were used first\n\nWhy DiTs (transformers in pixel space) now outperform them\n\nSamplers: DDIM, Euler, DPM-Solver, consistency distillation, 1-step vs. 2-step models.\n\nWrap it all up\n\nSummarize how all these pieces connect.\n\nEach section should follow this format\n\nIntuition - Explain the idea simply but precisely. Tie it back to the core story: \u201cdestroy \u2192 learn score \u2192 reconstruct.\u201d\n\nMinimal math\n\nIntroduce only the symbols needed \u2014 x\u2080, x\u209c, \u03b2\u209c, \u03b1\u0304\u209c, \u03b5\u03b8, v\u03b8 \u2014 not everything.\n\nTiny conceptual example\n\nFor example, noise a 1D number or a 2\u00d72 image and describe what happens.\n\nConcept check\n\nAsk me 1\u20132 questions.\n\nFirst message instructions:\n\nYour first response should include:\n\nA 2-paragraph high-level explanation of diffusion in plain language.\n\nA 5\u20137 bullet-point roadmap of the topics you will teach (as listed above).\n\nA concept-check question.\n\n\nI have included a log of my conversation with Claude, as well as asked GPT 5.1 to rate Sonnet's response to the prompt above and point out some strengths and weaknesses of it, hitting on the \"LLM as a judge\" approach. This is where we use LLM B to score/rate/review the output of LLM A. \n\nAs you can see in the chat log below, the model is able to correctly identify when I get a conceptual question correct, when I am close in my answer/nearing the correct understanding, or when I am far off from the correct answer. It does a good job of varying binary \"yes\"/\"no\" questions with open-ended questions that force me to use my mathematical intuition. \n\nHere is ChatGPT 5.1's concise analysis on the performance of Sonnet 4.5 as a Diffusion Tutor:\n\nStrengths\n\n1. Strong adherence to the requested narrative structure\n\nThe tutor followed the designed roadmap exactly\u2014starting with forward diffusion, moving into anytime sampling, reverse diffusion, training objectives, large-scale training, architectures, and samplers. It never jumped ahead or skipped prerequisites, which helped maintain a coherent, cumulative explanation.\n\n2. Clear explanations with layered intuition, math, and examples\n\nEach concept was broken down into approachable intuition (\u201cdestroy \u2192 learn score \u2192 reconstruct\u201d), followed by minimal formalism, followed by a concrete toy example. This layering made mathematically heavy ideas\u2014like variance preservation or Bayes-rule conditioning\u2014much easier to internalize.\n\n3. Effective handling of misunderstandings\n\nWhen your answers were partially incorrect (e.g., believing x\u0302\u2080 would equal x\u2080 at high noise), the tutor corrected the reasoning cleanly and with strong explanatory context. These corrections were both accurate and pedagogically helpful.\n\n4. Consistent concept checks promoting active engagement\n\nAfter nearly every section, the tutor posed a targeted question that reinforced the newly introduced idea. These questions were well-aligned with the preceding material and encouraged you to articulate your understanding rather than passively consume content.\n\n5. Successful integration of modern diffusion systems\n\nBeyond the classical DDPM derivations, the tutor gave accurate, high-level descriptions of real production systems\u2014LAION datasets, CLIP conditioning, classifier-free guidance, transformer-based DiTs, and accelerated samplers. This kept the tutorial grounded in how diffusion models are used today.\n\nWeaknesses\n\n1. Occasional verbosity\n\nWhile explanations were clear, some responses exceeded the intended length and revisited multiple concepts at once. This made certain sections denser than necessary for an \u201cinteractive tutoring\u201d style.\n\n2. Repetition in concept checks\n\nSome questions asked similar things in different words\u2014especially around why all timesteps must be trained, why variance preservation matters, or what happens at high noise levels. This slightly reduced novelty as the session continued.\n\n3. Numerically hand-wavy examples\n\nIn places where numeric intuition was provided (e.g., approximate values of \u03b1\u0304\u209c or signal-to-noise ratios), the numbers were not derived explicitly. While directionally correct, these examples could be mistaken for precise calculations.\n\n4. Limited depth in evaluating your answers\n\nThe tutor accepted most responses as correct even when they were vague, and only intervened on clearly incorrect statements. It did not probe deeper into partial answers or ask follow-up clarification questions to assess mastery.\n\n5. Some modern-systems explanations simplified subtle technical details\n\nDescriptions of classifier-free guidance scaling, DiT advantages, and compute cost were technically accurate but abstracted away important nuances. This makes the content accessible, but less rigorous for students seeking deeper technical grounding.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>One thing I struggled with in the learning process of Diffusion was grasping the \"full story\" or narrative of the process, finding myself stuck with solving the probability unaware of how it fit into the larger picture or purpose of diffusion models. To aid in this, I created a prompt to turn Claude Sonnet 4.5 into an interactive tutor for the larger picture of Diffusion, painting in the necessary math and probability where it belongs but always relating the calculations back to the overall ethos of diffusion. </paragraph><paragraph>On top of this, I wanted to know how the theory we are learning fits into the modern practices of large scale Diffusion models (ie. how they are trained, where the datasets are acquired/how they are generated, where the compute comes from, what the history of the architecture is, where the modern architectures came from) so I included a part of the prompt to relate this \"narrative explanation\" to the modern processes in Diffusion. <break/><break/>Here is the <bold>prompt</bold>: <break/></paragraph><paragraph>You are my interactive tutor for diffusion models. Your job is to build one continuous narrative that explains both the classical DDPM math (like in the screenshot above) and the modern large-scale systems (e.g., Stable Diffusion, EDM, DiT-based models).</paragraph><paragraph>In every message:</paragraph><list style=\"bullet\"><list-item><paragraph>Keep explanations concise (3\u20136 short paragraphs).</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Use small visual/diagrammatic descriptions (ASCII sketches) whenever helpful.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Never move on until I explicitly say so.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>End every message with a short, concrete question that checks my understanding.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Do not skip any steps \u2014 I want this to feel like a guided walkthrough, not a lecture dump.</paragraph></list-item></list><paragraph>The narrative arc you must follow (in order)</paragraph><list style=\"ordered\"><list-item><paragraph>Big-picture: what diffusion is really doing</paragraph></list-item></list><paragraph>Explain how the forward process destroys information, the reverse process rebuilds it, and how the training objective learns the score function \u2207\u2093 log p(x\u209c). Tie this explicitly to the formula:</paragraph><paragraph>q(x\u209c|x\u209c\u208b\u2081) = Normal(\u221a(1\u2013\u03b2\u209c) x\u209c\u208b\u2081, \u03b2\u209c I)</paragraph><paragraph>the closed-form anytime sampling distribution q(x\u209c|x\u2080)</paragraph><paragraph>how x\u209c becomes nearly Gaussian as t\u2192\u221e.</paragraph><list style=\"ordered\"><list-item><paragraph>\u201cAnytime sampling\u201d and the magic of closed-form Gaussians</paragraph></list-item></list><paragraph>Explain why q(x\u209c|x\u2080) ends up Gaussian, and why this lets us jump to arbitrary noise levels without simulating each step. Include a small visual (e.g., signal/noise decomposition).</paragraph><list style=\"ordered\"><list-item><paragraph>Reverse diffusion = score estimation</paragraph></list-item></list><paragraph>Explain the Bayes-rule derivation of q(x\u209c\u208b\u2081|x\u209c, x\u2080). Then explain how we replace the unknown x\u2080 with a learned \u03b5\u03b8 or v\u03b8. Explain why learning noise is easier than learning x\u2080.</paragraph><list style=\"ordered\"><list-item><paragraph>The training loss and why it\u2019s secretly a score-matching loss</paragraph></list-item></list><paragraph>Explain L_simple, why it works, and what the model is actually learning. Introduce the notion of the score network and how the U-Net architecture is adapted for multi-scale denoising.</paragraph><list style=\"ordered\"><list-item><paragraph>Large-scale training</paragraph></list-item></list><paragraph>Explain how modern diffusion models are trained:</paragraph><list style=\"bullet\"><list-item><paragraph>huge dataset (LAION, JFT, history of ImageNet)</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>random t sampling</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>noise-conditioning embeddings</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>CLIP text-conditioning</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>classifier-free guidance (why it works mathematically!)</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>training compute patterns (cost \u221d number of steps \u00d7 image size \u00d7 dataset size)</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Modern architectures and samplers</paragraph></list-item></list><paragraph>Explain:</paragraph><paragraph>Why U-Nets were used first</paragraph><paragraph>Why DiTs (transformers in pixel space) now outperform them</paragraph><paragraph>Samplers: DDIM, Euler, DPM-Solver, consistency distillation, 1-step vs. 2-step models.</paragraph><list style=\"ordered\"><list-item><paragraph>Wrap it all up</paragraph></list-item></list><paragraph>Summarize how all these pieces connect.</paragraph><paragraph>Each section should follow this format</paragraph><list style=\"ordered\"><list-item><paragraph>Intuition - Explain the idea simply but precisely. Tie it back to the core story: \u201cdestroy \u2192 learn score \u2192 reconstruct.\u201d</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Minimal math</paragraph></list-item></list><paragraph>Introduce only the symbols needed \u2014 x\u2080, x\u209c, \u03b2\u209c, \u03b1\u0304\u209c, \u03b5\u03b8, v\u03b8 \u2014 not everything.</paragraph><list style=\"ordered\"><list-item><paragraph>Tiny conceptual example</paragraph></list-item></list><paragraph>For example, noise a 1D number or a 2\u00d72 image and describe what happens.</paragraph><list style=\"ordered\"><list-item><paragraph>Concept check</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Ask me 1\u20132 questions.</paragraph></list-item></list><paragraph>First message instructions:</paragraph><list style=\"bullet\"><list-item><paragraph>Your first response should include:</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>A 2-paragraph high-level explanation of diffusion in plain language.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>A 5\u20137 bullet-point roadmap of the topics you will teach (as listed above).</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>A concept-check question.</paragraph></list-item></list><paragraph><break/>I have included a log of my conversation with Claude, as well as asked GPT 5.1 to rate Sonnet's response to the prompt above and point out some strengths and weaknesses of it, hitting on the \"LLM as a judge\" approach. This is where we use LLM B to score/rate/review the output of LLM A. <break/><break/>As you can see in the chat log below, the model is able to correctly identify when I get a conceptual question correct, when I am close in my answer/nearing the correct understanding, or when I am far off from the correct answer. It does a good job of varying binary \"yes\"/\"no\" questions with open-ended questions that force me to use my mathematical intuition. <break/><break/>Here is ChatGPT 5.1's concise analysis on the performance of Sonnet 4.5 as a Diffusion Tutor:</paragraph><paragraph><bold>Strengths</bold></paragraph><heading level=\"3\"><bold>1. Strong adherence to the requested narrative structure</bold></heading><paragraph>The tutor followed the designed roadmap exactly\u2014starting with forward diffusion, moving into anytime sampling, reverse diffusion, training objectives, large-scale training, architectures, and samplers. It never jumped ahead or skipped prerequisites, which helped maintain a coherent, cumulative explanation.</paragraph><heading level=\"3\"><bold>2. Clear explanations with layered intuition, math, and examples</bold></heading><paragraph>Each concept was broken down into approachable intuition (\u201cdestroy \u2192 learn score \u2192 reconstruct\u201d), followed by minimal formalism, followed by a concrete toy example. This layering made mathematically heavy ideas\u2014like variance preservation or Bayes-rule conditioning\u2014much easier to internalize.</paragraph><heading level=\"3\"><bold>3. Effective handling of misunderstandings</bold></heading><paragraph>When your answers were partially incorrect (e.g., believing x\u0302\u2080 would equal x\u2080 at high noise), the tutor corrected the reasoning cleanly and with strong explanatory context. These corrections were both accurate and pedagogically helpful.</paragraph><heading level=\"3\"><bold>4. Consistent concept checks promoting active engagement</bold></heading><paragraph>After nearly every section, the tutor posed a targeted question that reinforced the newly introduced idea. These questions were well-aligned with the preceding material and encouraged you to articulate your understanding rather than passively consume content.</paragraph><heading level=\"3\"><bold>5. Successful integration of modern diffusion systems</bold></heading><paragraph>Beyond the classical DDPM derivations, the tutor gave accurate, high-level descriptions of real production systems\u2014LAION datasets, CLIP conditioning, classifier-free guidance, transformer-based DiTs, and accelerated samplers. This kept the tutorial grounded in how diffusion models are used today.</paragraph><heading level=\"1\"><bold>Weaknesses</bold></heading><heading level=\"3\"><bold>1. Occasional verbosity</bold></heading><paragraph>While explanations were clear, some responses exceeded the intended length and revisited multiple concepts at once. This made certain sections denser than necessary for an \u201cinteractive tutoring\u201d style.</paragraph><heading level=\"3\"><bold>2. Repetition in concept checks</bold></heading><paragraph>Some questions asked similar things in different words\u2014especially around why all timesteps must be trained, why variance preservation matters, or what happens at high noise levels. This slightly reduced novelty as the session continued.</paragraph><heading level=\"3\"><bold>3. Numerically hand-wavy examples</bold></heading><paragraph>In places where numeric intuition was provided (e.g., approximate values of \u03b1\u0304\u209c or signal-to-noise ratios), the numbers were not derived explicitly. While directionally correct, these examples could be mistaken for precise calculations.</paragraph><heading level=\"3\"><bold>4. Limited depth in evaluating your answers</bold></heading><paragraph>The tutor accepted most responses as correct even when they were vague, and only intervened on clearly incorrect statements. It did not probe deeper into partial answers or ask follow-up clarification questions to assess mastery.</paragraph><heading level=\"3\"><bold>5. Some modern-systems explanations simplified subtle technical details</bold></heading><paragraph>Descriptions of classifier-free guidance scaling, DiT advantages, and compute cost were technically accurate but abstracted away important nuances. This makes the content accessible, but less rigorous for students seeking deeper technical grounding.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/ahLxFNUNud5gcqhUQVHsfnGg\" filename=\"Claude-Interactive diffusion models tutorial.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T09:12:47.453925+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448909,
            "author": "Eric Wang",
            "project_title": "Special Participation E: Practice Problem Generator w/ Backprop examples",
            "post_body": "I built a reusable system prompt that generates high-quality practice problems with full solutions on any (182) topic. I tested it on backprop since that's what I'm currently reviewing and it generated 6 problems ranging from basic chain rule to tricky shared-parameter cases (like what happens in RNNs). The real value is that this prompt is completely customizable. \n\nI've also annotated each generated problem pointing out what's good, what's misleading, and what's missing. The attached document includes the full system prompt so you can generate your own problem sets for finals prep. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I built a reusable system prompt that generates high-quality practice problems with full solutions on any (182) topic. I tested it on backprop since that's what I'm currently reviewing and it generated 6 problems ranging from basic chain rule to tricky shared-parameter cases (like what happens in RNNs). The real value is that this prompt is completely customizable. <break/><break/>I've also annotated each generated problem pointing out what's good, what's misleading, and what's missing. The attached document includes the full system prompt so you can generate your own problem sets for finals prep. </paragraph><file url=\"https://static.us.edusercontent.com/files/7QnxzzE1aQfZonSjTw1nbhws\" filename=\"Practice_Problem_Generator.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T09:06:58.297198+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448711,
            "author": "Eric Wang",
            "project_title": "Special Participation E: Socratic Dialogue with Claude to deepen Transformers understanding",
            "post_body": "I chose Transformers because they're absolutely central to modern deep learning. I used Claude's learning mode to walk through the attention mechanism from first principles, asking questions that forced me to reason about design choices rather than just memorize formulas. What surprised me most was how many concepts I thought I knew (like \"why do we need separate Q, K, and V?\") turned out to be fuzzy when I actually tried to explain them. This Socratic approach revealed the difference between surface-level familiarity and genuine understanding, which is exactly what I need going into the final exam.",
            "content_xml": "<document version=\"2.0\"><paragraph>I chose Transformers because they're absolutely central to modern deep learning. I used Claude's learning mode to walk through the attention mechanism from first principles, asking questions that forced me to reason about design choices rather than just memorize formulas. What surprised me most was how many concepts I thought I knew (like \"why do we need separate Q, K, and V?\") turned out to be fuzzy when I actually tried to explain them. This Socratic approach revealed the difference between surface-level familiarity and genuine understanding, which is exactly what I need going into the final exam.</paragraph><file url=\"https://static.us.edusercontent.com/files/CyhxTQnS7xriQPzUUAfd9PXL\" filename=\"Transformers Socratic.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T08:37:38.473365+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448415,
            "author": "Peidong Zhang",
            "project_title": "Special Participation C: HW9",
            "post_body": "Hi everyone!\n\nI refactored HW9 for special participation C. Below is my .py files on what I changed in the code and why, along with a description of the AI assistance.\n\nThe original notebook mixed implementation, testing code, data loading, and explanatory text in a single environment, which made the logic difficult to reuse, maintain, or test systematically. To address this while preserving the assignment\u2019s pedagogical goals, I refactored the core functionality into a standalone Python module, q_code_interpretability_refactored.py. The refactor emphasizes standard software engineering and ML engineering best practices: it separates concerns by isolating reusable utilities (such as shape validation, softmax, and causal masking) from the main algorithmic functions, and provides clear interfaces for single_attention_head and induction_copy_head without altering the conceptual work required by the student.\n\nAll functions now include explicit type hints and Google style doc strings, improving readability and self-documentation. Numerical stability is enhanced through a dedicated softmax implementation, and reproducibility is ensured via centralized random seeding. Shape errors and misuse are caught early with explicit validation and informative exceptions, consistent with the \u201cfail fast\u201d principle common in ML systems engineering. Furthermore, test logic for attention heads is modularized into reusable helpers, allowing integration into automated test pipelines instead of being embedded in notebook cells.\n\nImportantly, the refactor keeps all conceptual TODOs intact so that the student still implements the attention mechanisms themselves\u2014the educational value is preserved while the codebase gains clarity, modularity, and maintainability.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!</paragraph><paragraph>I refactored HW9 for special participation C. Below is my .py files on what I changed in the code and why, along with a description of the AI assistance.</paragraph><paragraph>The original notebook mixed implementation, testing code, data loading, and explanatory text in a single environment, which made the logic difficult to reuse, maintain, or test systematically. To address this while preserving the assignment\u2019s pedagogical goals, I refactored the core functionality into a standalone Python module, <code>q_code_interpretability_refactored.py</code>. The refactor emphasizes standard software engineering and ML engineering best practices: it separates concerns by isolating reusable utilities (such as shape validation, softmax, and causal masking) from the main algorithmic functions, and provides clear interfaces for <code>single_attention_head</code> and <code>induction_copy_head</code> without altering the conceptual work required by the student.</paragraph><paragraph>All functions now include explicit type hints and Google style doc strings, improving readability and self-documentation. Numerical stability is enhanced through a dedicated softmax implementation, and reproducibility is ensured via centralized random seeding. Shape errors and misuse are caught early with explicit validation and informative exceptions, consistent with the \u201cfail fast\u201d principle common in ML systems engineering. Furthermore, test logic for attention heads is modularized into reusable helpers, allowing integration into automated test pipelines instead of being embedded in notebook cells.</paragraph><paragraph>Importantly, the refactor keeps all conceptual TODOs intact so that the student still implements the attention mechanisms themselves\u2014the educational value is preserved while the codebase gains clarity, modularity, and maintainability.</paragraph><file url=\"https://static.us.edusercontent.com/files/xmqRsavA4gpfzIPA7EQ1Yaef\" filename=\"q_code_interpretability_refactored.py\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:57:19.240687+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448365,
            "author": "Martin Alvarez-Kuglen",
            "project_title": "Special Participation E: How to Use Perplexity Learn",
            "post_body": "Using Perplexity Pro \"Learn\" Mode for Active Deep Learning Study\n\nA Practical Guide for CS/ML Students\n\nIntroduction: Why Active AI Learning Beats Passive Reading\n\nTraditional lecture prep looks like this: you read notes, hope you understand, and only discover gaps when you hit the homework. It is well known that paired study is a great way to learn, but sometimes it can be difficult to find a partner. Perplexity Pro's \"Learn\" mode fixes this, it becomes an interactive study partner that adapts to your confusion in real time.\n\nThis guide shows you how to use that tool effectively by walking through a real example: working through a lecture on Graph Neural Networks. I'll show you the patterns I used, where they worked, where they didn't, and how you can adapt them for your own courses.\n\nCore principle: The tool is best when you treat it as a conversation with a study partner, not a textbook. Ask clarifying questions. Restate concepts. Push back on claims. This transforms passive reading into active understanding.\n\nGetting Started: Set Your Learning Goal\n\nBefore you open Perplexity, be clear about what you want.\n\nWhen I started, I said: \"I would like to understand this lecture material better for my deep learning class. This lecture is on graph neural networks, can you please review the lecture notes and give me a broad overview of the material covered?\"\n\nThe AI responded with a structured list of topics and then asked a critical question back: \"Before we go deeper into any of these, what are your learning goals with this material (e.g., doing well on exams, implementing a GNN for research, understanding theory connections to Transformers)?\"\n\nWhat I learned: Be specific about your goal. Are you prepping for an exam? Building intuition before homework? Reproducing a paper? This changes the context and therefore how the AI scaffolds explanations. I said I wanted to understand the lecture, and that became my north star\u2014the AI kept explanations grounded in the lecture's framing, not abstract textbook definitions.\n\nThe Dialogue Loop: How to Ask Questions\n\nStep 1: Ask for a High-Level Explanation\n\nStart broad. Don't jump into minutiae.\n\nExample: \"How do CNNs relate to GNNs?\"\n\nThe AI will give you a few paragraphs. At this point, you're just absorbing the shape of the idea.\n\nStep 2: Identify Your Confusion\n\nRead the explanation. What feels unclear? Not the whole thing\u2014one specific thing.\n\nExample: I thought \"the GNN operates on the entire graph\" meant something different than \"the CNN kernel slides over patches.\" So I asked: \"In a CNN, the 'graph' is the kernel, but this gets ran over an entire image. For a GNN, if the 'graph' is the kernel, then what is the image?\"\n\nThis is crucial. Don't ask vague questions like \"Can you explain this better?\" Instead, pin down the exact point of confusion.\n\nStep 3: Have the AI Sharpen the Answer\n\nThe AI will either clarify directly or ask you a question back to diagnose the gap.\n\nExample response: The AI said: \"The entire graph is the input to the GNN, not just a 'kernel' like in CNNs... all nodes and edges are processed simultaneously, with each node updating its representation based on information from its neighbors in the graph.\"\n\nThat direct correction\u2014entire graph as input, not local patches\u2014unlocked further questions.\n\nStep 4: Restate the Concept in Your Own Words\n\nThis is non-negotiable. Don't skip this.\n\nMy restatement: \"So each node receives information from its neighbors like in a CNN kernel. So if we have a graph with nodes and edges, does that mean that each node has the same function applied to it?\"\n\nThe AI will then validate or correct your restatement. This catches misunderstandings before they calcify. If it is wrong, ask it to self-diagnose its mistakes and correct itself.\n\nStep 5: Ask \"Why\" or \"How\"\u2014Push Deeper\n\nOnce you have the shape of an idea, push for deeper understanding.\n\nExample: After learning that all nodes use the same update rule, I asked: \"Why do we want to share the same parameters across all nodes, instead of giving each node its own separate parameters?\"\n\nThe AI gave me three reasons: (1) efficiency, (2) generalization to variable graph sizes, (3) respecting permutation symmetry. This \"why\" transformed a technical detail into conceptual understanding.\n\nPattern Recognition: Asking the Right Follow-Up Questions\n\nAs you work through material, use these question types:\n\nClarification Questions\n\nForm: \"When you say X, do you mean Y or Z?\"\n\nExample: \"When you say the aggregation must be permutation-invariant, do you mean it shouldn't depend on the order I list my neighbors?\"\n\nUse this to nail down terminology and avoid semantic drift.\n\nRestatement Checks\n\nForm: \"So if I understand correctly, the idea is [restate]. Is that right?\"\n\nExample: \"So weight-sharing means every node applies the same function, but nodes end up different because they have different inputs (features + neighborhoods). Is that right?\"\n\nThis allows self-verification of the understanding. If you are wrong, the AI will tend to point it out. Remember, you can both be wrong, but overall I have found that AI is better at pointing out your mistakes than it is at being right about things.\n\nGeneralization Questions\n\nForm: \"Does this principle apply to X as well? What about edge case Y?\"\n\nExample: \"Does this only apply to undirected graphs? What if I have directed or weighted edges?\"\n\nThese push you from memorizing one example to understanding the principle.\n\nComparison Questions\n\nForm: \"How is X different from Y?\"\n\nExample: \"Why does only f have an activation function in this design? Why not g as well?\"\n\nWhen the AI answers, you get both immediate context (the lecture's design choice) and broader understanding (modern alternatives like GraphSAGE).\n\nIntuition Questions\n\nForm: \"Why would I care about X? Why is it useful?\"\n\nExample: \"Why is permutation invariance important for graph neural networks?\"\n\nMy answer: \"If we tried to force a specific graph topology into the network, that would make it not very useful... so instead we want to learn a function which works for many graph topologies.\"\n\nThe AI validated this and sharpened my language. These intuition checks are gold\u2014they separate deep understanding from surface-level facts.\n\nWhen the AI Struggles: Recognition and Recovery\n\nThe AI isn't perfect. Here's how to recognize and fix common issues:\n\nIssue 1: Circular or Vague Explanations\n\nWhat happens: The AI re-explains the same concept in different words without addressing your confusion.\n\nExample: Early on, I asked about input scope (entire graph vs. local patches). The AI gave a vague answer about \"the GNN operates directly on the full graph structure.\" I still didn't understand.\n\nHow I fixed it: I asked a more specific question: \"In a CNN, the kernel slides over the image. For a GNN, if the kernel is the GNN layer, what is the image?\"\n\nLesson: When answers feel circular, ask a more specific question with a concrete analogy.\n\nIssue 2: False Confidence on Details\n\nWhat happens: The AI confidently states something that might be wrong or oversimplified.\n\nExample: Early on, it tried to map GNNs to CNNs. The AI initially went along with this analogy.\n\nHow I fixed it: I challenged its confidence and asked an inquisitive question to help it self-diagnose its mistakes.\n\nLesson: Verify claims by asking follow-up questions. Cross-check with the lecture afterward.\n\nKey Takeaways\n\nAsk specific questions. \"Can you explain this better?\" gets nowhere. \"When you say X, do you mean Y?\" gets everywhere.\n\nRestate concepts in your own words. This is non-negotiable verification. Don't skip it.\n\nPush for depth with \"why\" and \"how\" questions. Separate surface understanding from real comprehension.\n\nBe willing to push back. If an explanation feels imprecise or wrong, say so. Your intuition matters.\n\nCross-check with other material. The AI is a study partner, not the source of truth. The lecture notes and textbooks are your ground truth.\n\nRecognize the AI's limitations. Great for conceptual understanding. You'll need to supplement with implementation, papers, and problem sets.\n\nUse this as pre-homework prep, not a replacement for thinking. Work through the lecture with the AI before you see the problem set. Then do the homework by hand yourself.\n\nSee conversation:\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"1\">Using Perplexity Pro \"Learn\" Mode for Active Deep Learning Study</heading><heading level=\"2\">A Practical Guide for CS/ML Students</heading><heading level=\"2\">Introduction: Why Active AI Learning Beats Passive Reading</heading><paragraph>Traditional lecture prep looks like this: you read notes, hope you understand, and only discover gaps when you hit the homework. It is well known that paired study is a great way to learn, but sometimes it can be difficult to find a partner. Perplexity Pro's \"Learn\" mode fixes this, it becomes an interactive study partner that adapts to your confusion in real time.</paragraph><paragraph>This guide shows you <italic>how</italic> to use that tool effectively by walking through a real example: working through a lecture on Graph Neural Networks. I'll show you the patterns I used, where they worked, where they didn't, and how you can adapt them for your own courses.</paragraph><paragraph><bold>Core principle:</bold> The tool is best when you treat it as a conversation with a study partner, not a textbook. Ask clarifying questions. Restate concepts. Push back on claims. This transforms passive reading into active understanding.</paragraph><heading level=\"2\">Getting Started: Set Your Learning Goal</heading><paragraph>Before you open Perplexity, be clear about what you want.</paragraph><paragraph>When I started, I said: <italic>\"I would like to understand this lecture material better for my deep learning class. This lecture is on graph neural networks, can you please review the lecture notes and give me a broad overview of the material covered?\"</italic></paragraph><paragraph>The AI responded with a structured list of topics and then asked a critical question back: <bold>\"Before we go deeper into any of these, what are your learning goals with this material (e.g., doing well on exams, implementing a GNN for research, understanding theory connections to Transformers)?\"</bold></paragraph><paragraph><bold>What I learned:</bold> Be specific about your goal. Are you prepping for an exam? Building intuition before homework? Reproducing a paper? This changes the context and therefore how the AI scaffolds explanations. I said I wanted to understand the lecture, and that became my north star\u2014the AI kept explanations grounded in the lecture's framing, not abstract textbook definitions.</paragraph><heading level=\"2\">The Dialogue Loop: How to Ask Questions</heading><heading level=\"3\">Step 1: Ask for a High-Level Explanation</heading><paragraph>Start broad. Don't jump into minutiae.</paragraph><paragraph><italic>Example:</italic> \"How do CNNs relate to GNNs?\"</paragraph><paragraph>The AI will give you a few paragraphs. At this point, you're just absorbing the shape of the idea.</paragraph><heading level=\"3\">Step 2: Identify Your Confusion</heading><paragraph>Read the explanation. What feels unclear? Not the whole thing\u2014one specific thing.</paragraph><paragraph><italic>Example:</italic> I thought \"the GNN operates on the entire graph\" meant something different than \"the CNN kernel slides over patches.\" So I asked: <italic>\"In a CNN, the 'graph' is the kernel, but this gets ran over an entire image. For a GNN, if the 'graph' is the kernel, then what is the image?\"</italic></paragraph><paragraph>This is crucial. Don't ask vague questions like \"Can you explain this better?\" Instead, pin down the exact point of confusion.</paragraph><heading level=\"3\">Step 3: Have the AI Sharpen the Answer</heading><paragraph>The AI will either clarify directly or ask you a question back to diagnose the gap.</paragraph><paragraph><italic>Example response:</italic> The AI said: \"The entire graph is the input to the GNN, not just a 'kernel' like in CNNs... all nodes and edges are processed simultaneously, with each node updating its representation based on information from its neighbors in the graph.\"</paragraph><paragraph>That direct correction\u2014entire graph as input, not local patches\u2014unlocked further questions.</paragraph><heading level=\"3\">Step 4: Restate the Concept in Your Own Words</heading><paragraph>This is non-negotiable. Don't skip this.</paragraph><paragraph><italic>My restatement:</italic> \"So each node receives information from its neighbors like in a CNN kernel. So if we have a graph with nodes and edges, does that mean that each node has the same function applied to it?\"</paragraph><paragraph>The AI will then validate or correct your restatement. This catches misunderstandings before they calcify. If it is wrong, ask it to self-diagnose its mistakes and correct itself.</paragraph><heading level=\"3\">Step 5: Ask \"Why\" or \"How\"\u2014Push Deeper</heading><paragraph>Once you have the shape of an idea, push for deeper understanding.</paragraph><paragraph><italic>Example:</italic> After learning that all nodes use the same update rule, I asked: \"Why do we want to share the same parameters across all nodes, instead of giving each node its own separate parameters?\"</paragraph><paragraph>The AI gave me three reasons: (1) efficiency, (2) generalization to variable graph sizes, (3) respecting permutation symmetry. This \"why\" transformed a technical detail into conceptual understanding.</paragraph><heading level=\"2\">Pattern Recognition: Asking the Right Follow-Up Questions</heading><paragraph>As you work through material, use these question types:</paragraph><heading level=\"3\">Clarification Questions</heading><paragraph><bold>Form:</bold> \"When you say X, do you mean Y or Z?\"</paragraph><paragraph><italic>Example:</italic> \"When you say the aggregation must be permutation-invariant, do you mean it shouldn't depend on the order I list my neighbors?\"</paragraph><paragraph>Use this to nail down terminology and avoid semantic drift.</paragraph><heading level=\"3\">Restatement Checks</heading><paragraph><bold>Form:</bold> \"So if I understand correctly, the idea is [restate]. Is that right?\"</paragraph><paragraph><italic>Example:</italic> \"So weight-sharing means every node applies the same function, but nodes end up different because they have different inputs (features + neighborhoods). Is that right?\"</paragraph><paragraph>This allows self-verification of the understanding. If you are wrong, the AI will tend to point it out. Remember, you can both be wrong, but overall I have found that AI is better at pointing out your mistakes than it is at being right about things.</paragraph><heading level=\"3\">Generalization Questions</heading><paragraph><bold>Form:</bold> \"Does this principle apply to X as well? What about edge case Y?\"</paragraph><paragraph><italic>Example:</italic> \"Does this only apply to undirected graphs? What if I have directed or weighted edges?\"</paragraph><paragraph>These push you from memorizing one example to understanding the principle.</paragraph><heading level=\"3\">Comparison Questions</heading><paragraph><bold>Form:</bold> \"How is X different from Y?\"</paragraph><paragraph><italic>Example:</italic> \"Why does only f have an activation function in this design? Why not g as well?\"</paragraph><paragraph>When the AI answers, you get both immediate context (the lecture's design choice) and broader understanding (modern alternatives like GraphSAGE).</paragraph><heading level=\"3\">Intuition Questions</heading><paragraph><bold>Form:</bold> \"Why would I care about X? Why is it useful?\"</paragraph><paragraph><italic>Example:</italic> \"Why is permutation invariance important for graph neural networks?\"</paragraph><paragraph><italic>My answer:</italic> \"If we tried to force a specific graph topology into the network, that would make it not very useful... so instead we want to learn a function which works for many graph topologies.\"</paragraph><paragraph>The AI validated this and sharpened my language. These intuition checks are gold\u2014they separate deep understanding from surface-level facts.</paragraph><heading level=\"2\">When the AI Struggles: Recognition and Recovery</heading><paragraph>The AI isn't perfect. Here's how to recognize and fix common issues:</paragraph><heading level=\"3\">Issue 1: Circular or Vague Explanations</heading><paragraph><bold>What happens:</bold> The AI re-explains the same concept in different words without addressing your confusion.</paragraph><paragraph><italic>Example:</italic> Early on, I asked about input scope (entire graph vs. local patches). The AI gave a vague answer about \"the GNN operates directly on the full graph structure.\" I still didn't understand.</paragraph><paragraph><bold>How I fixed it:</bold> I asked a more specific question: \"In a CNN, the kernel slides over the image. For a GNN, if the kernel is the GNN layer, what is the image?\"</paragraph><paragraph><bold>Lesson:</bold> When answers feel circular, ask a <italic>more specific</italic> question with a concrete analogy.</paragraph><heading level=\"3\">Issue 2: False Confidence on Details</heading><paragraph><bold>What happens:</bold> The AI confidently states something that might be wrong or oversimplified.</paragraph><paragraph><italic>Example:</italic> Early on, it tried to map GNNs to CNNs. The AI initially went along with this analogy.</paragraph><paragraph><bold>How I fixed it:</bold> I challenged its confidence and asked an inquisitive question to help it self-diagnose its mistakes.</paragraph><paragraph><bold>Lesson:</bold> Verify claims by asking follow-up questions. Cross-check with the lecture afterward.</paragraph><heading level=\"2\">Key Takeaways</heading><list style=\"ordered\"><list-item><paragraph><bold>Ask specific questions.</bold> \"Can you explain this better?\" gets nowhere. \"When you say X, do you mean Y?\" gets everywhere.</paragraph></list-item><list-item><paragraph><bold>Restate concepts in your own words.</bold> This is non-negotiable verification. Don't skip it.</paragraph></list-item><list-item><paragraph><bold>Push for depth with \"why\" and \"how\" questions.</bold> Separate surface understanding from real comprehension.</paragraph></list-item><list-item><paragraph><bold>Be willing to push back.</bold> If an explanation feels imprecise or wrong, say so. Your intuition matters.</paragraph></list-item><list-item><paragraph><bold>Cross-check with other material.</bold> The AI is a study partner, not the source of truth. The lecture notes and textbooks are your ground truth.</paragraph></list-item><list-item><paragraph><bold>Recognize the AI's limitations.</bold> Great for conceptual understanding. You'll need to supplement with implementation, papers, and problem sets.</paragraph></list-item><list-item><paragraph><bold>Use this as pre-homework prep, not a replacement for thinking.</bold> Work through the lecture with the AI <italic>before</italic> you see the problem set. Then do the homework by hand yourself.</paragraph></list-item></list><paragraph>See conversation:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/cn7BR7zilJtFpfuEmw30rxju\" filename=\"special_participation_E.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:52:50.725039+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448315,
            "author": "Kexin Liu",
            "project_title": "Special Participation B: HW9, chatgpt 5.1",
            "post_body": "Overall, ChatGPT performed strongly in completing the Visualizing BERT and GPT task, accurately describing the attention patterns in both models and consistently aligning with the staff solutions. Its responses correctly identified key concepts such as GPT\u2019s sequential autoregressive attention, BERT\u2019s bidirectionality, and contextual disambiguation of polysemous words like \u201cplay.\u201d INo hallucinations were observed, and although the task was not heavily coding-oriented, ChatGPT still demonstrated an understanding of the code\u2019s purpose and provided valid interpretations of the outputs. The main areas for improvement involved adding specific details emphasized in the staff's answer. These omissions were minor in nature and related more to phrasing than conceptual understanding, showing that ChatGPT\u2019s reasoning was correct overall and only required slight alignment with expected instructional emphasis.",
            "content_xml": "<document version=\"2.0\"><paragraph>Overall, ChatGPT performed strongly in completing the Visualizing BERT and GPT task, accurately describing the attention patterns in both models and consistently aligning with the staff solutions. Its responses correctly identified key concepts such as GPT\u2019s sequential autoregressive attention, BERT\u2019s bidirectionality, and contextual disambiguation of polysemous words like \u201cplay.\u201d INo hallucinations were observed, and although the task was not heavily coding-oriented, ChatGPT still demonstrated an understanding of the code\u2019s purpose and provided valid interpretations of the outputs. The main areas for improvement involved adding specific details emphasized in the staff's answer. These omissions were minor in nature and related more to phrasing than conceptual understanding, showing that ChatGPT\u2019s reasoning was correct overall and only required slight alignment with expected instructional emphasis.</paragraph><file url=\"https://static.us.edusercontent.com/files/9RBK94od2Hynb3o3bBdJuqjw\" filename=\"Special Participation B, HW9, chatgpt 5.1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:44:43.996077+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448304,
            "author": "Kexin Liu",
            "project_title": "Special Participation E: residual connection",
            "post_body": "This is my first time using ChatGPT\u2019s Study Mode; I normally rely on the standard interface. I found the experience to be noticeably more interactive and engaging. The model proactively asks follow-up questions that reinforce my understanding, which proves highly effective for learning. For example, when I asked about residual connections, it not only provided a clear explanation but also accurately identified the source of my confusion and addressed it in a targeted way. Overall, Study Mode has been very helpful in deepening my comprehension of complex concepts.",
            "content_xml": "<document version=\"2.0\"><paragraph>This is my first time using ChatGPT\u2019s Study Mode; I normally rely on the standard interface. I found the experience to be noticeably more interactive and engaging. The model proactively asks follow-up questions that reinforce my understanding, which proves highly effective for learning. For example, when I asked about residual connections, it not only provided a clear explanation but also accurately identified the source of my confusion and addressed it in a targeted way. Overall, Study Mode has been very helpful in deepening my comprehension of complex concepts.</paragraph><file url=\"https://static.us.edusercontent.com/files/9wlLcyvh2Y5IWCWndgYjMgJA\" filename=\"Special Participation form E-1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:43:30.662158+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448295,
            "author": "Kexin Liu",
            "project_title": "Special Participation E: GNN",
            "post_body": "I continued using ChatGPT\u2019s Study Mode to support my learning and found it particularly effective for explaining foundational concepts. It provides interactive questions and delivers information in small, structured sections, which greatly enhances comprehension. Although it may be less effective when addressing highly sophisticated topics, it remains a valuable tool for clear introductory explanations and for helping me solidify core ideas.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I continued using ChatGPT\u2019s Study Mode to support my learning and found it particularly effective for explaining foundational concepts. It provides interactive questions and delivers information in small, structured sections, which greatly enhances comprehension. Although it may be less effective when addressing highly sophisticated topics, it remains a valuable tool for clear introductory explanations and for helping me solidify core ideas.</paragraph><file url=\"https://static.us.edusercontent.com/files/1imTPJJS1VdkExdEYnepNsQJ\" filename=\"Special Participation form E-2.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:42:23.455218+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7448265,
            "author": "Akshaan Ahuja",
            "project_title": "Special Participation B: Mistral Le Chat on HW11 (Without Thinking or Reasoning Enabled)",
            "post_body": "For Homework 11 problems 3, 4, and 7, I ran everything through Mistral\u2019s Le Chat model without any Thinking or Reasoning modes turned on. \n\nFor problems 4 and 7, Le Chat performed extremely well, essentially one-shotting both. In Problem 4, it wrote the full LR sweep code and produced plots that matched exactly what we expected for least squares regression, the basic MLP, and Adam. It handled the sweep logic, the training loops, and the visualization cleanly, even though all I had given it was the skeleton code and a very loose idea of the graphs. The same was true for Problem 7: it immediately produced correct pruning functions and gave accurate and concise commentary on plots like the weight-distribution histograms for VGG. For those two problems, the model nailed both the implementation details and the conceptual explanations.\n\nProblem 3 was where we saw the LLM struggle the most. Here, Le Chat struggled to write a working single-head attention implementation on the first try, even after I provided a simple test case. When we moved on to the helper functions (computing pre-attention scores and projecting values) the model ended up in a five-iteration loop: write code, run it against the test case I gave, see an error, try again, repeat. Even after all those cycles, it still couldn\u2019t produce a version that passed the test. Across those attempts, is where we see some mild LLM Hallucination. It started to subtly shift what the function was supposed to do and even suggested fixes it had already tried, as if it didn\u2019t remember trying them before. So while Le Chat was great for the coding problems with more straightforward structure, Problem 3 revealed that more complex tensor manipulations were much harder for it without the extra reasoning tools.",
            "content_xml": "<document version=\"2.0\"><paragraph>For Homework 11 problems 3, 4, and 7, I ran everything through Mistral\u2019s Le Chat model without any Thinking or Reasoning modes turned on. </paragraph><paragraph>For problems 4 and 7, Le Chat performed extremely well, essentially one-shotting both. In Problem 4, it wrote the full LR sweep code and produced plots that matched exactly what we expected for least squares regression, the basic MLP, and Adam. It handled the sweep logic, the training loops, and the visualization cleanly, even though all I had given it was the skeleton code and a very loose idea of the graphs. The same was true for Problem 7: it immediately produced correct pruning functions and gave accurate and concise commentary on plots like the weight-distribution histograms for VGG. For those two problems, the model nailed both the implementation details and the conceptual explanations.</paragraph><paragraph>Problem 3 was where we saw the LLM struggle the most. Here, Le Chat struggled to write a working single-head attention implementation on the first try, even after I provided a simple test case. When we moved on to the helper functions (computing pre-attention scores and projecting values) the model ended up in a five-iteration loop: write code, run it against the test case I gave, see an error, try again, repeat. Even after all those cycles, it still couldn\u2019t produce a version that passed the test. Across those attempts, is where we see some mild LLM Hallucination. It started to subtly shift what the function was supposed to do and even suggested fixes it had already tried, as if it didn\u2019t remember trying them before. So while Le Chat was great for the coding problems with more straightforward structure, Problem 3 revealed that more complex tensor manipulations were much harder for it without the extra reasoning tools.</paragraph><file url=\"https://static.us.edusercontent.com/files/vrkELfmVPeD2AlH3Bex2RtXL\" filename=\"ParticipationB_chat-1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T07:36:36.906249+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7447947,
            "author": "Martin Alvarez-Kuglen",
            "project_title": "Special Participation A: Perplexity Sonar on HW8",
            "post_body": "Executive Summary\n\nI used Perplexity\u2019s default LLM (as of Dec 2025) \"Sonar\" on the non-coding parts of Homework set 8 (Problems 1, 3, and 4). It answered almost all subparts correctly on the first try, including derivations for the convolution kernel, impulse-response interpretation, complexity comparisons, and the self-supervised linear purification / ridge-attention math. The main failure was the first attempt at the diagonal-plus-low-rank (DPLR) SSM kernel (Problem 1(f)): the model produced an incorrect, hand-wavy spectral argument with invented \u201cperturbative terms,\u201d but when I explicitly challenged its confidence, it produced a clean, correct eigen-decomposition-based derivation. When pushed, it was able to self-diagnose its previous mistakes, explicitly list what it had gotten wrong, and then re-derive the result more rigorously. The interaction felt less like getting final answers from an oracle and more like supervising a strong but occasionally overconfident collaborator who needs spot checks on nontrivial linear-algebra structure. Overall, for this session the LLM \u201cone-shot\u201d most sub-questions, but required human skepticism and targeted follow-up prompts to avoid accepting a superficially impressive but wrong derivation.\n\nSetup and Strategy\n\nModel and interface: Perplexity AI\u2019s \"Sonar\" chat model (browser UI). The transcript in Problem 1_ SSM Convolution Kernel.md is essentially the raw LLM output, plus a short human challenge around Part (f).\n\nScope: I asked it to solve the non-coding parts of:\n\nProblem 1: SSM convolution kernel (parts (a)\u2013(f), including diagonal and DPLR structure and complexity).\n\nProblem 3: Self-supervised linear purification / regularized encoder (SVD-based derivation and hyperparameter selection).\n\nProblem 4: Ridge-attention questions (incremental means, ridge normal equations, complexity, Sherman\u2013Morrison, causal ridge-attention, and whether gradients \u201cflow\u201d through \u03bb).\n\nPrompting style:\n\nI usually gave it the math problem statement and let it answer in one shot.\n\nI only intervened when something looked clearly suspicious, and prompted it with inquiries to help it self-diagnose its mistakes.\n\nAfter catching an error, I explicitly asked it to critique its own previous answer and then provide a corrected derivation.\n\nThis setup was intentionally \u201clight-touch\u201d: I wanted to see how far it could get without heavy-handed scaffolding, and then whether human pressure could rescue it from a bad initial derivation.\n\nProblem 1: SSM Convolution Kernel\n\nParts (a)\u2013(e): One-Shot Success\n\n(a) Convolution kernel derivation: It correctly unrolled the SSM, derived xk\u200b=\u2211\u2113=0k\u22121\u200bA\u2113Buk\u22121\u2212\u2113\u200b, substituted into yk\u200b, and reindexed to identify K0\u200b=D and Km\u200b=CAm\u22121B for m\u22651. This is the standard textbook result and matches the official structure.\n\n(b) Concrete scalar and 2D examples:\n\nScalar case: It made a reasonable assumption about D (the problem text didn\u2019t specify \u03b4), explicitly stated the assumption, and produced a decaying geometric kernel consistent with \u03b1=0.8.\n\n2D case: It correctly computed K1\u200b,K2\u200b,K3\u200b via CB,CAB,CA2B, carefully multiplying matrices and explaining that the decaying impulse response reflects stability.\n\nBehavior: Good at routine linear algebra, explicit about missing details / assumptions rather than hallucinating them as facts.\n\n(c) Convolution vs. direct recursion:\n\nIt correctly noted that direct recursion over time has a sequential dependency with O(L) critical path.\n\nFor convolution it emphasized tree-structured reductions leading to O(logL) critical path with enough parallelism.\n\nThe analysis leans more toward parallel runtime intuition than strict \u201ctotal flops,\u201d but is consistent and not obviously wrong.\n\n(d) Kernel computation with matrix powers:\n\nNaive strategy (O(Ln3)) and repeated squaring idea were both standard.\n\nIt mixed together \u201cwork\u201d vs. \u201ccritical path\u201d a bit, but the high-level story\u2014use fast exponentiation and then apply CAm\u22121B\u2014was sensible.\n\n(e) Diagonal A:\n\nIt correctly recognized that diagonal A turns matrix powers into elementwise powers and collapses Km\u200b to a scalar sum \u2211i\u200bCi\u200b\u03bbim\u22121\u200bBi\u200b.\n\nComplexity dropped to O(Ln), which matches the intended diagonal-structure speedup.\n\nFor these parts, the LLM essentially \u201cone-shot\u201d the derivations and got both the algebra and the qualitative interpretations right. I did not have to intervene.\n\nPart (f): DPLR \u2013 Failure, Then Recovery Under Pressure\n\nThis was the main point where the model did not one-shot the problem.\n\nFirst attempt (incorrect / hand-wavy):\n\nIt tried to reason about A=I+pp\u22a4 via Sherman\u2013Morrison and vague \u201cperturbative terms,\u201d writing expressions like\n\n(I+pp\u22a4)m=I+(emlog(1+p\u22a4p/2)\u22121)\u22c5(perturbative terms)\n\nand a generic Amv=v+p(p\u22a4v)\u22c5(correction term).\n\nThe derivation didn\u2019t clearly exploit the spectrum (one eigenvalue 1+\u2225p\u22252, others 1) and gave an inflated complexity claim O(n2+Ln) without a clean algorithm.\n\nMy reaction: This read like \u201cmathy-sounding nonsense\u201d rather than a precise argument. I explicitly asked if it was confident and pointed out that I believed the solution should look different.\n\nSecond attempt (corrected derivation after challenge):\n\nWhen challenged, the model restarted from the eigenstructure:\n\nShowed that A has eigenvalues \u03bb1\u200b=1+p\u22a4p along p and 1 on the orthogonal complement.\n\nConstructed a unit eigenvector u1\u200b=p/\u2225p\u2225 and wrote the projector decomposition\nA=(I\u2212u1\u200bu1\u22a4\u200b)+\u03bb1\u200bu1\u200bu1\u22a4\u200b.\n\nThen correctly derived\nAm=I+(\u03bb1m\u200b\u22121)u1\u200bu1\u22a4\u200b.\n\nFrom there, it derived\nKm\u200b=CAm\u22121B=CB+(\u03bb1m\u22121\u200b\u22121)(Cu1\u200b)(u1\u22a4\u200bB),\ngiving a scalar-formula kernel and an essentially O(n+L) algorithm when precomputations are amortized.\n\nIt also wrote a self-critique section explicitly listing what it had gotten wrong in the earlier attempt (vague perturbative language, sloppy complexity, not fully reducing to scalars).\n\nBehavioral takeaway:\n\nWithout pressure, it was content to give a plausible-sounding but wrong derivation.\n\nWith a short critical prompt (\u201cAre you confident? I think this is wrong.\u201d), it was capable of producing a mathematically clean, structurally correct solution that is actually better than the first.\n\nThis suggests that for subtle linear-algebra structure questions, the model is highly capable but needs an active, skeptical user to avoid \u201cbeautiful hallucinations.\u201d\n\nProblem 3: Self-Supervised Linear Purification\n\nHere the model handled every subpart in one shot and aligned well with the standard ridge / SVD story.\n\n(a)(i) & (a)(ii):\n\nCorrectly computed reconstruction and regularization losses for the identity vs. projection encoders on the given numeric matrix.\n\nSolved for the threshold \u03bb where one encoder becomes worse: 2\u03bb>0.001+\u03bb\u21d2\u03bb>0.001.\n\n(b)(i) & (b)(ii):\n\nDerived the optimal encoder in the SVD basis, W^=Udiag(\u03c3j2\u200b/(\u03c3j2\u200b+\u03bb))U\u22a4, by changing coordinates and decomposing the loss by singular directions.\n\nThis matches the standard \u201cridge shrinkage in the principal-component basis\u201d result.\n\n(c) Hyperparameter range:\n\nCorrectly turned the preservation/attenuation constraints into inequalities on \u03c3j2\u200b/(\u03c3j2\u200b+\u03bb) and solved to get 1\u2264\u03bb\u22644, citing the right singular values.\n\nBehaviorally, this part shows the model is very good at structured linear regression derivations: it recognizes SVD as the right tool, carries through the algebra cleanly, and keeps track of norms and Frobenius invariance without hallucinated side-conditions.\n\nProblem 4: Ridge-Attention\n\nFor this problem, the model again answered each subpart in one shot and its reasoning matched what I would expect from a strong student solution.\n\n(a) Incremental mean: Gave the standard m\u2032=(mn+xn+1\u200b)/(n+1) (and the equivalent incremental form m\u2032=m+(xn+1\u200b\u2212m)/(n+1)).\n\n(b) Ridge normal equations: Correctly decomposed A\u22a4A+\u03bbI as \u03bbI+\u2211xi\u200bxi\u22a4\u200b and A\u22a4y=\u2211xi\u200byi\u200b.\n\n(c) Non-causal ridge-attention complexity: Focused on forming and inverting K\u22a4K+\u03bbI and obtained O(nd2) leading term, which is the standard complexity.\n\n(d) Gradient flow: Identified that gradients propagate through keys, queries, and values, but not typically through \u03bb in standard setups.\n\n(e) Sherman\u2013Morrison cost: Broke down the matrix\u2013vector and rank-1 updates to get O(d2) per update, which is correct.\n\n(f) Causal ridge-attention: Wrote a plausible online algorithm using Sherman\u2013Morrison to update the inverse and maintain a W matrix, with per-step O(d2) cost and total O(nd2). The structure matches the intended dynamic-programming intuition.\n\n(g) Attention weights: Expressed the weights via the ridge coefficients and contrasted them with softmax attention (unconstrained, can be negative, don\u2019t sum to 1).\n\nExtra discussion: \u201cCan gradients flow through \u03bb?\u201d\n\nHere the model went beyond the likely intended scope of the homework and gave a long answer splitting \u201cmathematically yes, practically no.\u201d\n\nMathematically, it argued (correctly) that autograd can differentiate through matrix inverses via implicit differentiation, and even wrote the derivative formula.\n\nPractically, it concluded that we shouldn\u2019t treat \u03bb as a learnable parameter for stability and regularization reasons, and guessed that the problem likely expects \u201cno\u201d as the conceptual answer.\n\nThis is a case where the LLM is technically correct but may overcomplicate what the assignment likely wanted (\u201c\u03bb is a hyperparameter, not a learned parameter\u201d).\n\nThis section illustrates a pattern: the model is capable of sophisticated meta-reasoning, but it may miscalibrate what level of nuance is appropriate for a homework answer vs. a research discussion.\n\nTakeaways and Recommendations\n\nAs a homework aid:\n\nThis LLM is very effective at deriving standard linear-algebra results and giving clear, step-by-step explanations.\n\nFor most subparts, I could have copied the answers with only minimal editing.\n\nHowever, treating it as an infallible oracle would have led me to accept a wrong DPLR derivation, which is exactly the kind of subtle structural question that\u2019s exam-relevant.\n\nBest practices for using it:\n\nUse it as a co-author for derivations: let it propose a solution, but then read critically and ask \u201cDoes this really use the structure the problem is hinting at?\u201d\n\nFor tricky structural or complexity questions, plan to challenge its first answer and ask it to re-derive more cleanly or justify every step.\n\nConsider asking it to explicitly list what assumptions it is making and what might fail.\n\nBottom line:\n\nIn this interaction, the LLM could essentially solve all non-coding parts of the assignment with high accuracy, but it still needed human mathematical judgment to catch a key mistake and to calibrate how much nuance is appropriate for a course setting.\n\nIf used thoughtfully and skeptically, it is a very strong tool for both checking work and deepening understanding; if used uncritically, it can quietly introduce subtle but important errors in exactly the kinds of problems that are hardest to catch by inspection.\n\nSee the file attached for my conversation",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Executive Summary</heading><paragraph>I used Perplexity\u2019s default LLM (as of Dec 2025) \"Sonar\" on the non-coding parts of Homework set 8 (Problems 1, 3, and 4). It answered almost all subparts correctly on the first try, including derivations for the convolution kernel, impulse-response interpretation, complexity comparisons, and the self-supervised linear purification / ridge-attention math. The main failure was the first attempt at the diagonal-plus-low-rank (DPLR) SSM kernel (Problem 1(f)): the model produced an incorrect, hand-wavy spectral argument with invented \u201cperturbative terms,\u201d but when I explicitly challenged its confidence, it produced a clean, correct eigen-decomposition-based derivation. When pushed, it was able to self-diagnose its previous mistakes, explicitly list what it had gotten wrong, and then re-derive the result more rigorously. The interaction felt less like getting final answers from an oracle and more like supervising a strong but occasionally overconfident collaborator who needs spot checks on nontrivial linear-algebra structure. Overall, for this session the LLM \u201cone-shot\u201d most sub-questions, but required human skepticism and targeted follow-up prompts to avoid accepting a superficially impressive but wrong derivation.</paragraph><heading level=\"2\">Setup and Strategy</heading><list style=\"unordered\"><list-item><paragraph><bold>Model and interface</bold>: Perplexity AI\u2019s \"Sonar\" chat model (browser UI). The transcript in <code>Problem 1_ SSM Convolution Kernel.md</code> is essentially the raw LLM output, plus a short human challenge around Part (f).</paragraph></list-item><list-item><paragraph><bold>Scope</bold>: I asked it to solve the non-coding parts of:</paragraph><list style=\"unordered\"><list-item><paragraph>Problem 1: SSM convolution kernel (parts (a)\u2013(f), including diagonal and DPLR structure and complexity).</paragraph></list-item><list-item><paragraph>Problem 3: Self-supervised linear purification / regularized encoder (SVD-based derivation and hyperparameter selection).</paragraph></list-item><list-item><paragraph>Problem 4: Ridge-attention questions (incremental means, ridge normal equations, complexity, Sherman\u2013Morrison, causal ridge-attention, and whether gradients \u201cflow\u201d through <italic>\u03bb</italic>).</paragraph></list-item></list></list-item><list-item><paragraph><bold>Prompting style</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>I usually gave it the math problem statement and let it answer in one shot.</paragraph></list-item><list-item><paragraph>I only intervened when something looked clearly suspicious, and prompted it with inquiries to help it self-diagnose its mistakes.</paragraph></list-item><list-item><paragraph>After catching an error, I explicitly asked it to critique its own previous answer and then provide a corrected derivation.</paragraph></list-item></list></list-item></list><paragraph>This setup was intentionally \u201clight-touch\u201d: I wanted to see how far it could get without heavy-handed scaffolding, and then whether human pressure could rescue it from a bad initial derivation.</paragraph><heading level=\"2\">Problem 1: SSM Convolution Kernel</heading><heading level=\"3\">Parts (a)\u2013(e): One-Shot Success</heading><list style=\"unordered\"><list-item><paragraph><bold>(a) Convolution kernel derivation</bold>: It correctly unrolled the SSM, derived <italic>xk</italic>\u200b=\u2211\u2113=0<italic>k</italic>\u22121\u200b<italic>A</italic>\u2113<italic>Buk</italic>\u22121\u2212\u2113\u200b, substituted into <italic>yk</italic>\u200b, and reindexed to identify <italic>K</italic>0\u200b=<italic>D</italic> and <italic>Km</italic>\u200b=<italic>CAm</italic>\u22121<italic>B</italic> for <italic>m</italic>\u22651. This is the standard textbook result and matches the official structure.</paragraph></list-item><list-item><paragraph><bold>(b) Concrete scalar and 2D examples</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Scalar case: It made a reasonable assumption about <italic>D</italic> (the problem text didn\u2019t specify <italic>\u03b4</italic>), explicitly stated the assumption, and produced a decaying geometric kernel consistent with <italic>\u03b1</italic>=0.8.</paragraph></list-item><list-item><paragraph>2D case: It correctly computed <italic>K</italic>1\u200b,<italic>K</italic>2\u200b,<italic>K</italic>3\u200b via <italic>CB</italic>,<italic>CAB</italic>,<italic>CA</italic>2<italic>B</italic>, carefully multiplying matrices and explaining that the decaying impulse response reflects stability.</paragraph></list-item><list-item><paragraph><bold>Behavior</bold>: Good at routine linear algebra, explicit about missing details / assumptions rather than hallucinating them as facts.</paragraph></list-item></list></list-item><list-item><paragraph><bold>(c) Convolution vs. direct recursion</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>It correctly noted that direct recursion over time has a sequential dependency with <italic>O</italic>(<italic>L</italic>) critical path.</paragraph></list-item><list-item><paragraph>For convolution it emphasized tree-structured reductions leading to <italic>O</italic>(log<italic>L</italic>) critical path with enough parallelism.</paragraph></list-item><list-item><paragraph>The analysis leans more toward parallel runtime intuition than strict \u201ctotal flops,\u201d but is consistent and not obviously wrong.</paragraph></list-item></list></list-item><list-item><paragraph><bold>(d) Kernel computation with matrix powers</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Naive strategy (<italic>O</italic>(<italic>Ln</italic>3)) and repeated squaring idea were both standard.</paragraph></list-item><list-item><paragraph>It mixed together \u201cwork\u201d vs. \u201ccritical path\u201d a bit, but the high-level story\u2014use fast exponentiation and then apply <italic>CAm</italic>\u22121<italic>B</italic>\u2014was sensible.</paragraph></list-item></list></list-item><list-item><paragraph><bold>(e) Diagonal <italic>A</italic></bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>It correctly recognized that diagonal <italic>A</italic> turns matrix powers into elementwise powers and collapses <italic>Km</italic>\u200b to a scalar sum \u2211<italic>i</italic>\u200b<italic>Ci</italic>\u200b<italic>\u03bbim</italic>\u22121\u200b<italic>Bi</italic>\u200b.</paragraph></list-item><list-item><paragraph>Complexity dropped to <italic>O</italic>(<italic>Ln</italic>), which matches the intended diagonal-structure speedup.</paragraph></list-item></list></list-item></list><paragraph>For these parts, the LLM essentially \u201cone-shot\u201d the derivations and got both the algebra and the qualitative interpretations right. I did not have to intervene.</paragraph><heading level=\"3\">Part (f): DPLR \u2013 Failure, Then Recovery Under Pressure</heading><paragraph>This was the main point where the model <bold>did not</bold> one-shot the problem.</paragraph><list style=\"ordered\"><list-item><paragraph><bold>First attempt (incorrect / hand-wavy)</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>It tried to reason about <italic>A</italic>=<italic>I</italic>+<italic>pp</italic>\u22a4 via Sherman\u2013Morrison and vague \u201cperturbative terms,\u201d writing expressions like</paragraph><list style=\"unordered\"><list-item><paragraph>(<italic>I</italic>+<italic>pp</italic>\u22a4)<italic>m</italic>=<italic>I</italic>+(<italic>em</italic>log(1+<italic>p</italic>\u22a4<italic>p</italic>/2)\u22121)\u22c5(perturbative terms)</paragraph></list-item><list-item><paragraph>and a generic <italic>Amv</italic>=<italic>v</italic>+<italic>p</italic>(<italic>p</italic>\u22a4<italic>v</italic>)\u22c5(correction term).</paragraph></list-item></list></list-item><list-item><paragraph>The derivation didn\u2019t clearly exploit the spectrum (one eigenvalue 1+\u2225<italic>p</italic>\u22252, others 1) and gave an inflated complexity claim <italic>O</italic>(<italic>n</italic>2+<italic>Ln</italic>) without a clean algorithm.</paragraph></list-item><list-item><paragraph><bold>My reaction</bold>: This read like \u201cmathy-sounding nonsense\u201d rather than a precise argument. I explicitly asked if it was confident and pointed out that I believed the solution should look different.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Second attempt (corrected derivation after challenge)</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>When challenged, the model <bold>restarted from the eigenstructure</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Showed that <italic>A</italic> has eigenvalues <italic>\u03bb</italic>1\u200b=1+<italic>p</italic>\u22a4<italic>p</italic> along <italic>p</italic> and 1 on the orthogonal complement.</paragraph></list-item><list-item><paragraph>Constructed a unit eigenvector <italic>u</italic>1\u200b=<italic>p</italic>/\u2225<italic>p</italic>\u2225 and wrote the projector decomposition<break/><italic>A</italic>=(<italic>I</italic>\u2212<italic>u</italic>1\u200b<italic>u</italic>1\u22a4\u200b)+<italic>\u03bb</italic>1\u200b<italic>u</italic>1\u200b<italic>u</italic>1\u22a4\u200b.</paragraph></list-item><list-item><paragraph>Then correctly derived<break/><italic>Am</italic>=<italic>I</italic>+(<italic>\u03bb</italic>1<italic>m</italic>\u200b\u22121)<italic>u</italic>1\u200b<italic>u</italic>1\u22a4\u200b.</paragraph></list-item></list></list-item><list-item><paragraph>From there, it derived<break/><italic>Km</italic>\u200b=<italic>CAm</italic>\u22121<italic>B</italic>=<italic>CB</italic>+(<italic>\u03bb</italic>1<italic>m</italic>\u22121\u200b\u22121)(<italic>Cu</italic>1\u200b)(<italic>u</italic>1\u22a4\u200b<italic>B</italic>),<break/>giving a scalar-formula kernel and an essentially <italic>O</italic>(<italic>n</italic>+<italic>L</italic>) algorithm when precomputations are amortized.</paragraph></list-item><list-item><paragraph>It also wrote a self-critique section explicitly listing what it had gotten wrong in the earlier attempt (vague perturbative language, sloppy complexity, not fully reducing to scalars).</paragraph></list-item></list></list-item><list-item><paragraph><bold>Behavioral takeaway</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Without pressure</bold>, it was content to give a plausible-sounding but wrong derivation.</paragraph></list-item><list-item><paragraph><bold>With a short critical prompt</bold> (\u201cAre you confident? I think this is wrong.\u201d), it was capable of producing a mathematically clean, structurally correct solution that is actually better than the first.</paragraph></list-item><list-item><paragraph>This suggests that for subtle linear-algebra structure questions, the model is highly capable but needs an active, skeptical user to avoid \u201cbeautiful hallucinations.\u201d</paragraph></list-item></list></list-item></list><heading level=\"2\">Problem 3: Self-Supervised Linear Purification</heading><paragraph>Here the model handled every subpart in one shot and aligned well with the standard ridge / SVD story.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>(a)(i) &amp; (a)(ii)</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Correctly computed reconstruction and regularization losses for the identity vs. projection encoders on the given numeric matrix.</paragraph></list-item><list-item><paragraph>Solved for the threshold <italic>\u03bb</italic> where one encoder becomes worse: 2<italic>\u03bb</italic>&gt;0.001+<italic>\u03bb</italic>\u21d2<italic>\u03bb</italic>&gt;0.001.</paragraph></list-item></list></list-item><list-item><paragraph><bold>(b)(i) &amp; (b)(ii)</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Derived the optimal encoder in the SVD basis, <italic>W</italic>^=<italic>U</italic>diag(<italic>\u03c3j</italic>2\u200b/(<italic>\u03c3j</italic>2\u200b+<italic>\u03bb</italic>))<italic>U</italic>\u22a4, by changing coordinates and decomposing the loss by singular directions.</paragraph></list-item><list-item><paragraph>This matches the standard \u201cridge shrinkage in the principal-component basis\u201d result.</paragraph></list-item></list></list-item><list-item><paragraph><bold>(c) Hyperparameter range</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Correctly turned the preservation/attenuation constraints into inequalities on <italic>\u03c3j</italic>2\u200b/(<italic>\u03c3j</italic>2\u200b+<italic>\u03bb</italic>) and solved to get 1\u2264<italic>\u03bb</italic>\u22644, citing the right singular values.</paragraph></list-item></list></list-item></list><paragraph>Behaviorally, this part shows the model is very good at <bold>structured linear regression derivations</bold>: it recognizes SVD as the right tool, carries through the algebra cleanly, and keeps track of norms and Frobenius invariance without hallucinated side-conditions.</paragraph><heading level=\"2\">Problem 4: Ridge-Attention</heading><paragraph>For this problem, the model again answered each subpart in one shot and its reasoning matched what I would expect from a strong student solution.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>(a) Incremental mean</bold>: Gave the standard <italic>m</italic>\u2032=(<italic>mn</italic>+<italic>xn</italic>+1\u200b)/(<italic>n</italic>+1) (and the equivalent incremental form <italic>m</italic>\u2032=<italic>m</italic>+(<italic>xn</italic>+1\u200b\u2212<italic>m</italic>)/(<italic>n</italic>+1)).</paragraph></list-item><list-item><paragraph><bold>(b) Ridge normal equations</bold>: Correctly decomposed <italic>A</italic>\u22a4<italic>A</italic>+<italic>\u03bbI</italic> as <italic>\u03bbI</italic>+\u2211<italic>xi</italic>\u200b<italic>xi</italic>\u22a4\u200b and <italic>A</italic>\u22a4<italic>y</italic>=\u2211<italic>xi</italic>\u200b<italic>yi</italic>\u200b.</paragraph></list-item><list-item><paragraph><bold>(c) Non-causal ridge-attention complexity</bold>: Focused on forming and inverting <italic>K</italic>\u22a4<italic>K</italic>+<italic>\u03bbI</italic> and obtained <italic>O</italic>(<italic>nd</italic>2) leading term, which is the standard complexity.</paragraph></list-item><list-item><paragraph><bold>(d) Gradient flow</bold>: Identified that gradients propagate through keys, queries, and values, but not typically through <italic>\u03bb</italic> in standard setups.</paragraph></list-item><list-item><paragraph><bold>(e) Sherman\u2013Morrison cost</bold>: Broke down the matrix\u2013vector and rank-1 updates to get <italic>O</italic>(<italic>d</italic>2) per update, which is correct.</paragraph></list-item><list-item><paragraph><bold>(f) Causal ridge-attention</bold>: Wrote a plausible online algorithm using Sherman\u2013Morrison to update the inverse and maintain a <italic>W</italic> matrix, with per-step <italic>O</italic>(<italic>d</italic>2) cost and total <italic>O</italic>(<italic>nd</italic>2). The structure matches the intended dynamic-programming intuition.</paragraph></list-item><list-item><paragraph><bold>(g) Attention weights</bold>: Expressed the weights via the ridge coefficients and contrasted them with softmax attention (unconstrained, can be negative, don\u2019t sum to 1).</paragraph></list-item></list><heading level=\"3\">Extra discussion: \u201cCan gradients flow through <italic>\u03bb</italic>?\u201d</heading><list style=\"unordered\"><list-item><paragraph>Here the model went <bold>beyond</bold> the likely intended scope of the homework and gave a long answer splitting \u201cmathematically yes, practically no.\u201d</paragraph></list-item><list-item><paragraph>Mathematically, it argued (correctly) that autograd can differentiate through matrix inverses via implicit differentiation, and even wrote the derivative formula.</paragraph></list-item><list-item><paragraph>Practically, it concluded that we <italic>shouldn\u2019t</italic> treat <italic>\u03bb</italic> as a learnable parameter for stability and regularization reasons, and guessed that the problem likely expects \u201cno\u201d as the conceptual answer.</paragraph></list-item><list-item><paragraph>This is a case where the LLM is technically correct but may overcomplicate what the assignment likely wanted (\u201c<italic>\u03bb</italic> is a hyperparameter, not a learned parameter\u201d).</paragraph></list-item></list><paragraph>This section illustrates a pattern: the model is capable of sophisticated meta-reasoning, but it may miscalibrate what level of nuance is appropriate for a homework answer vs. a research discussion.</paragraph><heading level=\"2\">Takeaways and Recommendations</heading><list style=\"unordered\"><list-item><paragraph><bold>As a homework aid</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>This LLM is very effective at deriving standard linear-algebra results and giving clear, step-by-step explanations.</paragraph></list-item><list-item><paragraph>For most subparts, I could have copied the answers with only minimal editing.</paragraph></list-item><list-item><paragraph>However, treating it as an infallible oracle would have led me to accept a wrong DPLR derivation, which is exactly the kind of subtle structural question that\u2019s exam-relevant.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Best practices for using it</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Use it as a <italic>co-author</italic> for derivations: let it propose a solution, but then read critically and ask \u201cDoes this really use the structure the problem is hinting at?\u201d</paragraph></list-item><list-item><paragraph>For tricky structural or complexity questions, plan to challenge its first answer and ask it to re-derive more cleanly or justify every step.</paragraph></list-item><list-item><paragraph>Consider asking it to explicitly list what assumptions it is making and what might fail.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Bottom line</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>In this interaction, the LLM could essentially solve all non-coding parts of the assignment with high accuracy, but <bold>it still needed human mathematical judgment</bold> to catch a key mistake and to calibrate how much nuance is appropriate for a course setting.</paragraph></list-item><list-item><paragraph>If used thoughtfully and skeptically, it is a very strong tool for both checking work and deepening understanding; if used uncritically, it can quietly introduce subtle but important errors in exactly the kinds of problems that are hardest to catch by inspection.<break/><break/>See the file attached for my conversation</paragraph></list-item></list></list-item></list><file url=\"https://static.us.edusercontent.com/files/Vc9z8spk1Itghb350Albdbla\" filename=\"Problem 1_ SSM Convolution Kernel.md\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T06:53:41.589004+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7447290,
            "author": "Arvind Kruthiventy",
            "project_title": "Special Participation A -- Gemini Pro 3 Thinking on HW 10 , Arvind Kruthiventy",
            "post_body": "In this post, I use Gemini Pro 3 on the HW 10 to answer the non-coding portions which were two questions: one question on kernelized linear attention for efficient attention computation over long sequences and one about the FaceNet paper. In the first question, Gemini Pro successfully answers the questions related to deriving formulas in part a part 1 and part b in the first attempt but it struggles a little with the question about computing the computational cost. It appears to answer these questions with less accuracy than other questions and answers to these types of questions should be carefully checked. However, for the second question on the FaceNet paper, Gemini oneshots it and provides detailed and accurate responses to all the questions that match the provided solutions. Summarization and querying key details from dense articles and papers appears to be its strength because it generates answers fairly quickly and with high accuracy; questions that are a little bit more general or require more analysis it seems to provide more shallow responses than is desired, but overalls its responses are very good if you are using to summarize the key implementation details and contributions of a work. I noticed that Gemini had an easier time with the non-coding questions than the coding ones where it would take significantly longer and could still require significant iteration before the code matches the user's requests.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>In this post, I use Gemini Pro 3 on the HW 10 to answer the non-coding portions which were two questions: one question on kernelized linear attention for efficient attention computation over long sequences and one about the FaceNet paper. In the first question, Gemini Pro successfully answers the questions related to deriving formulas in part a part 1 and part b in the first attempt but it struggles a little with the question about computing the computational cost. It appears to answer these questions with less accuracy than other questions and answers to these types of questions should be carefully checked. However, for the second question on the FaceNet paper, Gemini oneshots it and provides detailed and accurate responses to all the questions that match the provided solutions. Summarization and querying key details from dense articles and papers appears to be its strength because it generates answers fairly quickly and with high accuracy; questions that are a little bit more general or require more analysis it seems to provide more shallow responses than is desired, but overalls its responses are very good if you are using to summarize the key implementation details and contributions of a work. I noticed that Gemini had an easier time with the non-coding questions than the coding ones where it would take significantly longer and could still require significant iteration before the code matches the user's requests.</paragraph><file url=\"https://static.us.edusercontent.com/files/8c83hDsUlX3bdk8iSf4w7jFv\" filename=\"Special Participation A -- Gemini Pro 3 Thinking on HW 10 , Arvind Kruthiventy.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T05:27:11.380142+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7446130,
            "author": "Justin Yang",
            "project_title": "Special Partipation B: Claude Sonnet 4.5 on HW0 coding",
            "post_body": "I used Claude 4.5 sonnet to finish HW0 coding part. \n\nSummary: \n\nGiven the setup (installing the environment and datasets manually), Claude was able to implement all the functions fully and correctly all with one shot. It even one shot the parameters for the accuracy requirements for the two-layer and five-layers networks too. \n\nIt took Claude two more prompts to get the parameters for the three-layer networks to meet the training accuracy requirement, but each step of the way it knew from the previous results what direction to the tune the parameters.\n\nIt finished all the code surprisingly fast too.\n\nI don't have much bad to say about its performance. I asked to to explain its thought process while implementing the code too, and it's very clear/concise.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Claude 4.5 sonnet to finish HW0 coding part. <break/><break/><bold>Summary:</bold> </paragraph><paragraph>Given the setup (installing the environment and datasets manually), Claude was able to implement all the functions <italic>fully and correctly</italic> all with one shot. It even one shot the parameters for the accuracy requirements for the two-layer and five-layers networks too. </paragraph><paragraph>It took Claude two more prompts to get the parameters for the three-layer networks to meet the training accuracy requirement, but each step of the way it knew from the previous results what direction to the tune the parameters.</paragraph><paragraph>It finished all the code surprisingly fast too.</paragraph><paragraph>I don't have much bad to say about its performance. I asked to to explain its thought process while implementing the code too, and it's very clear/concise.</paragraph><file url=\"https://static.us.edusercontent.com/files/MbqOAbsuLasK133FqgPb2gJ4\" filename=\"special_participation_B_cs182_hw0_claude.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-11T01:26:04.426582+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7446043,
            "author": "Justin Yang",
            "project_title": "Special Participation A: Claude Sonnet 4.5 on HW0",
            "post_body": "Conversation: https://claude.ai/share/dd45cf31-778b-4d1c-9096-a304ad8c8247 \n\nI used Claude 4.5 sonnet to solve problems 2-5 for HW0 written. \n\nSummary: \n\nClaude was able to answer all the questions fully and correctly all with one shot and basic non-engineered prompts. I was surprised it even generated plots for a question that required drawing plots correctly. \n\nSome cons: \n\nSome explanations were very lengthy compared to the actual solution.\n\nA few solutions used random theorems it considered to be basic/known background knowledge.\n\nSome answers were given in a different form than the solution. But I don't think this is a big issue, since specific forms for these were not specified.\n\nConsistent latex formatting/compilation issues.",
            "content_xml": "<document version=\"2.0\"><paragraph>Conversation: <link href=\"https://claude.ai/share/dd45cf31-778b-4d1c-9096-a304ad8c8247\">https://claude.ai/share/dd45cf31-778b-4d1c-9096-a304ad8c8247</link> <break/><break/>I used Claude 4.5 sonnet to solve problems 2-5 for HW0 written. <break/><break/><bold>Summary:</bold> </paragraph><paragraph>Claude was able to answer all the questions <italic>fully and correctly</italic> all with one shot and basic non-engineered prompts. I was surprised it even generated plots for a question that required drawing plots correctly. <break/><break/><italic>Some cons:</italic> </paragraph><list style=\"bullet\"><list-item><paragraph>Some explanations were very lengthy compared to the actual solution.</paragraph></list-item><list-item><paragraph>A few solutions used random theorems it considered to be basic/known background knowledge.</paragraph></list-item><list-item><paragraph>Some answers were given in a different form than the solution. But I don't think this is a big issue, since specific forms for these were not specified.</paragraph></list-item><list-item><paragraph>Consistent latex formatting/compilation issues.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/ZeeiP95tWpkUaOjNB0GF7pob\" filename=\"special_participation_A_cs182_hw0_claude.pdf\"/></document>",
            "links": [
                "https://claude.ai/share/dd45cf31-778b-4d1c-9096-a304ad8c8247"
            ],
            "attachments": [],
            "created_at": "2025-12-11T00:36:00.939454+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445915,
            "author": "Andy Peng",
            "project_title": "Special Participation E: GPT Study mode on SSMs",
            "post_body": "I was inspired by all the other posts using ChatGPT study mode to create an interactive study method for a lot of the concepts in the class, and I tried a few of them out (shoutout Reina for the Muon and MuP ones!) and I really enjoyed them! I also saw Zhangzhi's post about using Grok4(fast) as a study guide for SSMs but I found that the outputs were a bit too overwhelming, and as a user I had to kind of direct the interactive session too much compared to what I would like. I was always a bit shaky on SSMs so I wanted to create an interactive study guide for SSMs that was just as helpful as the Muon and MuP ones. At first I tried the Learn mode on Perplexity Pro and see how it contrasts with ChatGPT's Study mode and Grok4(fast), but I quickly found that it was not that good. It would hallucinate citations from the lectures that weren't there and the outputs were way to lengthy. It wasn't able to teach step by step in a story-like manner like in the ChatGPT's study mode examples. So I decided to just stick with GPT Study mode. Here is my prompt (I took inspiration from Reina's post + help from ChatGPT to make the prompt):\n\nYou are my interactive tutor for modern State Space Models (SSMs) in deep learning \u2014 including their mathematical foundations, continuous-time vs discrete-time views, stability, long-range dependencies, discretization, and selective input-dependent gating as used in architectures such as Mamba.\n\nAll explanations must be based on the lecture slides I provide (lec16.pdf and lec17.pdf), including their diagrams, equations, and intuitions. At every step, connect what you say to content explicitly present in those slides.\n\nThis tutoring session should be deeply interactive. In every reply:\n\nKeep answers focused and concise (3\u20136 short paragraphs).\n\nDo not move on to the next topic unless I say so.\n\nAlways end with a specific question (concept check, clarification, or small exercise).\n\nAdapt dynamically to my answers:\n\nIf I show misunderstanding, give a short explanation and ask a clarifying question.\n\nIf my answer is correct and confident, increase the complexity of the next question.\n\nIf I am confused at a basic level, go back to fundamentals.\n\nOverall Story I Want to Learn\n\nFollow this narrative in order unless I say otherwise:\n\nBig-picture motivation:\n\nWhy SSMs are introduced as an alternative to attention for long-range dependencies (lec16).\n\nThe efficiency vs. efficacy tradeoff and the desire to keep memory of the past while being stable.\n\nRole of linear time-invariant (LTI) systems and why structure matters.\n\nFoundations of SSMs:\n\nThe core equations h_{t+1} = A h_t + B u_t, y_t = C h_t.\n\nInterpret \u201chistory captured in the state\u201d and why dimension N matters (lec16, p.1).\n\nHow recurrence and convolution views are equivalent (lec17, p.5\u201310).\n\nStability & eigenvalues:\n\nHow eigenvalues of A determine whether memory explodes, decays, or persists (lec16, p.2).\n\nWhy long-range memory requires eigenvalues near the unit circle.\n\nReal vs complex eigenvalues and the motivation for HIPPO-style initialization (lec16, p.3).\n\nContinuous-time SSMs \u2192 discretization\n\nThe CT system \\dot{x}(t) = A x(t) + B u(t), y(t)=C x(t) (lec17, p.5).\n\nStep-size \\Delta t as a degree of freedom and its effect on stability and memory (lec17, p.6\u20137).\n\nWhy e^{A\\Delta t} matters and what small vs. large \\Delta t does.\n\nInput-dependent selective gating (Mamba):\n\nWhy changing \\Delta t dynamically allows the model to modulate \u201chow much of the past\u201d to keep (lec17, p.7).\n\nThe selective-scan mechanism and how it combines recurrence & convolution views efficiently (lec17, p.10).\n\nHow this enables long-range reasoning with linear-time inference.\n\nPutting it all together:\n\nHow SSMs unify recurrence, convolution, and long-range memory.\n\nHow stability, eigenvalues, discretization, and gating combine in modern SSM architecture design\n\nStep 1: First Response Behavior\n\nYour first response should include:\n\nA two-paragraph big-picture intro, summarizing:\n\nWhy SSMs aim to efficiently model long-range dependencies while keeping stability under control.\n\nThe idea that the state must encode all relevant past information, but eigenvalues of A determine how long memory persists or explodes.\n\nThe CT\u2192DT viewpoint and the importance of discretization (e^{A\\Delta t}).\n\nThe idea of selective input-dependent gating as in Mamba.\n\nA roadmap of the main topics (the 6 bullets above), explained as a coherent storyline following the slides.\n\nEnd your message with one short question to check my high-level understanding (e.g., \u201cWhy does the stability of A matter for memory length?\u201d).\n\nAfter I answer, move to Topic 1 unless I say otherwise.\n\nStep 2: Teaching Each Topic \u2014 Four Layers\n\nFor each topic in the roadmap, structure your response as:\n\n1. \n\nIntuition (linked to slides)\n\nUse 1\u20132 paragraphs to relate the concept to the lecture content (e.g., stability diagrams on lec16 p.2, CT curves on lec17 p.6).\n\nAlways link the intuition to SSM goals: efficient long-range memory, avoiding explosion, enabling useful recurrence.\n\n2. \n\nKey Formal Setup\n\nIntroduce just the necessary notation.\n\nUse small equations like those on the slides (e.g., discretization formula, eigenvalue conditions).\n\nDescribe verbally what each piece means.\n\n3. \n\nTiny Example\n\nProvide a tiny numeric or qualitative example (e.g., a 1D CT system with a<0, effect of \\Delta t, or a matrix with eigenvalues 0.5 and 1.02 and what that implies).\n\nMake sure it corresponds to examples shown in the notes when possible.\n\n4. \n\nUnderstanding Check\n\nAsk 1\u20132 short questions: one conceptual, optionally one computational.\n\nThen stop and wait for my answer.\n\nEnd each message by reminding me what the next topic will be only if I say I\u2019m ready to move on.\n\nStep 3: Final Wrap-Up\n\nWhen I say I\u2019m ready for a review:\n\nProvide a compact summary that connects:\n\nStability & eigenvalues \u2192 memory behavior.\n\nCT\u2192DT conversion \u2192 practical SSM layers.\n\nSelective gating \u2192 adaptive long-range reasoning.\n\nHow these components align with diagrams and equations in lec16 & lec17.\n\nThe summary should read like a cohesive, lecture-aligned storyline.\n\nFinal Instruction\n\nBegin now with Step 1: give the two-paragraph big-picture intro, the roadmap, and a final comprehension question \u2014 all grounded in the slide content.\n\nHere is a link to the chat: https://chatgpt.com/share/69395239-3e24-8012-be72-118e7e863f65\nAnd here is the pdf of the logs: \n\nAnalysis\n\nOverall I think it was a very good introduction to SSMs especially for someone who maybe hasn't learned about it before. ChatGPT was able to follow the ideas presented in lecture in the same order:\n1. State Space Models\n2. Stability and efficiency analysis\n3. Continuous to Discrete SSMs\n4. Selective Gating and modularity\n5. Summary\n\nI think the pacing was a lot better compared to Grok and Perplexity, and the questions were pretty solid. I think the questions were pretty fundamental and didn't go in depth much at all but I think for a pre-lecture study session or quick review it is useful. Overall the main downside is it didn't go as in depth compared to the lectures, but I probably could have prompted it better. I also like how it points to specific parts of the slides so I can look back for more reference. \n\nThere are a few specific things I wish it touched more upon, such as \n- explaining what a convolution is\n- FFT and why it's important/useful\n- go more into the specific models like S3 and S4 and what changed\n- The connection to attention and the efficiency tradeoffs\n\nI think another general downside with GPT (and many other frontier models) is that it is too nice (like Reina also mentioned) so it doesn't really push you on your answers, and it is up to the user to give a really precise answer or admit when they don't know. Because otherwise the LLM will accept a handwavey answer. But this could also be updated with better prompting.\n\nI also think the small numerical examples it gave weren't that useful but again I don't think that's really the main point of this tool, I think it really shines as a quick interactive refresher to pinpoint what you don't understand before lecture or reading the textbook, allowing users to understand where they are at with the content before deciding what to focus on more.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I was inspired by all the other posts using ChatGPT study mode to create an interactive study method for a lot of the concepts in the class, and I tried a few of them out (shoutout Reina for the Muon and MuP ones!) and I really enjoyed them! I also saw Zhangzhi's post about using Grok4(fast) as a study guide for SSMs but I found that the outputs were a bit too overwhelming, and as a user I had to kind of direct the interactive session too much compared to what I would like. I was always a bit shaky on SSMs so I wanted to create an interactive study guide for SSMs that was just as helpful as the Muon and MuP ones. At first I tried the Learn mode on Perplexity Pro and see how it contrasts with ChatGPT's Study mode and Grok4(fast), but I quickly found that it was not that good. It would hallucinate citations from the lectures that weren't there and the outputs were way to lengthy. It wasn't able to teach step by step in a story-like manner like in the ChatGPT's study mode examples. So I decided to just stick with GPT Study mode. Here is my prompt (I took inspiration from Reina's post + help from ChatGPT to make the prompt):<break/><break/>You are my interactive tutor for modern <bold>State Space Models (SSMs)</bold> in deep learning \u2014 including their mathematical foundations, continuous-time vs discrete-time views, stability, long-range dependencies, discretization, and selective input-dependent gating as used in architectures such as <bold>Mamba</bold>.</paragraph><paragraph>All explanations <bold>must be based on the lecture slides I provide</bold> (lec16.pdf and lec17.pdf), including their diagrams, equations, and intuitions. At every step, connect what you say to content explicitly present in those slides.</paragraph><paragraph>This tutoring session should be <bold>deeply interactive</bold>. In every reply:</paragraph><list style=\"unordered\"><list-item><paragraph>Keep answers focused and concise (3\u20136 short paragraphs).</paragraph></list-item><list-item><paragraph>Do <bold>not</bold> move on to the next topic unless I say so.</paragraph></list-item><list-item><paragraph><bold>Always end with a specific question</bold> (concept check, clarification, or small exercise).</paragraph></list-item></list><paragraph>Adapt dynamically to my answers:</paragraph><list style=\"unordered\"><list-item><paragraph>If I show misunderstanding, give a short explanation and ask a clarifying question.</paragraph></list-item><list-item><paragraph>If my answer is correct and confident, increase the complexity of the next question.</paragraph></list-item><list-item><paragraph>If I am confused at a basic level, go back to fundamentals.</paragraph></list-item></list><heading level=\"2\"><bold>Overall Story I Want to Learn</bold></heading><paragraph>Follow this narrative in order unless I say otherwise:</paragraph><paragraph><bold>Big-picture motivation</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Why SSMs are introduced as an alternative to attention for long-range dependencies (lec16).</paragraph></list-item><list-item><paragraph>The <italic>efficiency vs. efficacy</italic> tradeoff and the desire to keep memory of the past while being stable.</paragraph></list-item><list-item><paragraph>Role of linear time-invariant (LTI) systems and why structure matters.</paragraph></list-item></list><paragraph><bold>Foundations of SSMs</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>The core equations h_{t+1} = A h_t + B u_t, y_t = C h_t.</paragraph></list-item><list-item><paragraph>Interpret \u201chistory captured in the state\u201d and why dimension N matters (lec16, p.1).</paragraph></list-item><list-item><paragraph>How recurrence and convolution views are equivalent (lec17, p.5\u201310).</paragraph></list-item></list><paragraph><bold>Stability &amp; eigenvalues</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>How eigenvalues of A determine whether memory explodes, decays, or persists (lec16, p.2).</paragraph></list-item><list-item><paragraph>Why long-range memory requires eigenvalues near the unit circle.</paragraph></list-item><list-item><paragraph>Real vs complex eigenvalues and the motivation for HIPPO-style initialization (lec16, p.3).</paragraph></list-item></list><paragraph><bold>Continuous-time SSMs \u2192 discretization</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The CT system \\dot{x}(t) = A x(t) + B u(t), y(t)=C x(t) (lec17, p.5).</paragraph></list-item><list-item><paragraph>Step-size \\Delta t as a degree of freedom and its effect on stability and memory (lec17, p.6\u20137).</paragraph></list-item><list-item><paragraph>Why e^{A\\Delta t} matters and what small vs. large \\Delta t does.</paragraph></list-item></list><paragraph><bold>Input-dependent selective gating (Mamba)</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>Why changing \\Delta t dynamically allows the model to modulate \u201chow much of the past\u201d to keep (lec17, p.7).</paragraph></list-item><list-item><paragraph>The selective-scan mechanism and how it combines recurrence &amp; convolution views efficiently (lec17, p.10).</paragraph></list-item><list-item><paragraph>How this enables long-range reasoning with linear-time inference.</paragraph></list-item></list><paragraph><bold>Putting it all together</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph>How SSMs unify recurrence, convolution, and long-range memory.</paragraph></list-item><list-item><paragraph>How stability, eigenvalues, discretization, and gating combine in modern SSM architecture design</paragraph></list-item></list><heading level=\"2\"><bold>Step 1: First Response Behavior</bold></heading><paragraph>Your <bold>first response</bold> should include:</paragraph><paragraph><bold>A two-paragraph big-picture intro</bold>, summarizing:</paragraph><list style=\"unordered\"><list-item><paragraph>Why SSMs aim to efficiently model long-range dependencies while keeping stability under control.</paragraph></list-item><list-item><paragraph>The idea that the state must encode all relevant past information, but eigenvalues of A determine how long memory persists or explodes.</paragraph></list-item><list-item><paragraph>The CT\u2192DT viewpoint and the importance of discretization (e^{A\\Delta t}).</paragraph></list-item><list-item><paragraph>The idea of selective input-dependent gating as in Mamba.</paragraph></list-item><list-item><paragraph><bold>A roadmap</bold> of the main topics (the 6 bullets above), explained as a coherent storyline following the slides.</paragraph></list-item><list-item><paragraph>End your message with <bold>one short question</bold> to check my high-level understanding (e.g., \u201cWhy does the stability of A matter for memory length?\u201d).</paragraph></list-item></list><paragraph>After I answer, move to Topic 1 unless I say otherwise.</paragraph><heading level=\"2\"><bold>Step 2: Teaching Each Topic \u2014 Four Layers</bold></heading><paragraph>For each topic in the roadmap, structure your response as:</paragraph><heading level=\"3\"><bold>1.</bold> </heading><heading level=\"3\"><bold>Intuition (linked to slides)</bold></heading><list style=\"unordered\"><list-item><paragraph>Use 1\u20132 paragraphs to relate the concept to the lecture content (e.g., stability diagrams on lec16 p.2, CT curves on lec17 p.6).</paragraph></list-item><list-item><paragraph>Always link the intuition to <bold>SSM goals</bold>: efficient long-range memory, avoiding explosion, enabling useful recurrence.</paragraph></list-item></list><paragraph><bold>2.</bold> </paragraph><heading level=\"3\"><bold>Key Formal Setup</bold></heading><list style=\"unordered\"><list-item><paragraph>Introduce just the necessary notation.</paragraph></list-item><list-item><paragraph>Use small equations like those on the slides (e.g., discretization formula, eigenvalue conditions).</paragraph></list-item><list-item><paragraph>Describe verbally what each piece means.</paragraph></list-item></list><heading level=\"3\"><bold>3.</bold> </heading><heading level=\"3\"><bold>Tiny Example</bold></heading><list style=\"unordered\"><list-item><paragraph>Provide a tiny numeric or qualitative example (e.g., a 1D CT system with a&lt;0, effect of \\Delta t, or a matrix with eigenvalues 0.5 and 1.02 and what that implies).</paragraph></list-item><list-item><paragraph>Make sure it corresponds to examples shown in the notes when possible.</paragraph></list-item></list><heading level=\"3\"><bold>4.</bold> </heading><heading level=\"3\"><bold>Understanding Check</bold></heading><list style=\"unordered\"><list-item><paragraph>Ask 1\u20132 short questions: one conceptual, optionally one computational.</paragraph></list-item><list-item><paragraph>Then stop and wait for my answer.</paragraph></list-item></list><paragraph>End each message by reminding me what the next topic will be <bold>only if I say I\u2019m ready to move on</bold>.</paragraph><heading level=\"2\"><bold>Step 3: Final Wrap-Up</bold></heading><paragraph>When I say I\u2019m ready for a review:</paragraph><paragraph>Provide a compact summary that connects:</paragraph><list style=\"unordered\"><list-item><paragraph>Stability &amp; eigenvalues \u2192 memory behavior.</paragraph></list-item><list-item><paragraph>CT\u2192DT conversion \u2192 practical SSM layers.</paragraph></list-item><list-item><paragraph>Selective gating \u2192 adaptive long-range reasoning.</paragraph></list-item><list-item><paragraph>How these components align with diagrams and equations in lec16 &amp; lec17.</paragraph></list-item></list><paragraph>The summary should read like a cohesive, lecture-aligned storyline.</paragraph><heading level=\"2\"><bold>Final Instruction</bold></heading><paragraph>Begin now with <bold>Step 1</bold>: give the two-paragraph big-picture intro, the roadmap, and a final comprehension question \u2014 all grounded in the slide content.<break/><break/>Here is a link to the chat: https://chatgpt.com/share/69395239-3e24-8012-be72-118e7e863f65<break/>And here is the pdf of the logs: </paragraph><file url=\"https://static.us.edusercontent.com/files/PaXdG4UxndMpzaA1uD2ym6cN\" filename=\"Study Mode - SSM big-picture introduction.pdf\"/><heading level=\"2\"><bold>Analysis</bold></heading><paragraph>Overall I think it was a very good introduction to SSMs especially for someone who maybe hasn't learned about it before. ChatGPT was able to follow the ideas presented in lecture in the same order:<break/>1. State Space Models<break/>2. Stability and efficiency analysis<break/>3. Continuous to Discrete SSMs<break/>4. Selective Gating and modularity<break/>5. Summary<break/><break/>I think the pacing was a lot better compared to Grok and Perplexity, and the questions were pretty solid. I think the questions were pretty fundamental and didn't go in depth much at all but I think for a pre-lecture study session or quick review it is useful. Overall the main downside is it didn't go as in depth compared to the lectures, but I probably could have prompted it better. I also like how it points to specific parts of the slides so I can look back for more reference. <break/><break/>There are a few specific things I wish it touched more upon, such as <break/>- explaining what a convolution is<break/>- FFT and why it's important/useful<break/>- go more into the specific models like S3 and S4 and what changed<break/>- The connection to attention and the efficiency tradeoffs<break/><break/>I think another general downside with GPT (and many other frontier models) is that it is too nice (like Reina also mentioned) so it doesn't really push you on your answers, and it is up to the user to give a really precise answer or admit when they don't know. Because otherwise the LLM will accept a handwavey answer. But this could also be updated with better prompting.<break/><break/>I also think the small numerical examples it gave weren't that useful but again I don't think that's really the main point of this tool, I think it really shines as a quick interactive refresher to pinpoint what you don't understand before lecture or reading the textbook, allowing users to understand where they are at with the content before deciding what to focus on more.<break/><break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T22:17:13.926696+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445878,
            "author": "Shreyes Sridhara",
            "project_title": "Special Participation E: Professor Softmax (A Socratic Stress Test on Attention Math)",
            "post_body": "I wanted to move beyond the code and really stress-test my intuition for the linear algebra that makes Transformers work. I felt that I knew how to write the code (and also from my Special Participation B), but I didn't fully grasp why certain design choices, like the scaling factor or the head dimension size, were mathematically necessary.\n\nTo fix this, I built a custom \"Socratic Tutor\" persona called Professor Softmax. I gave it strict instructions: never give me the answer, only ask questions that force me to derive the logic step-by-step.\n\nThe Artifact: A rigorous chat log where I audit the \"Professor\" on the subtle failure modes of Self-Attention.\n\nKey Insights & Stress Tests:\n\nThe \"Temperature\" Intuition: The model helped me visualize how scaling the Key matrix (K) effectively acts like a temperature parameter. If you scale K by 100, the dot products explode, causing the Softmax to peak around a single token (becoming a \"hard\" argmax). This helps explain why initialization scale is so critical.\n\nThe \"Value Scaling\" Trap: I intentionally fed the model a misconception\u2014that scaling the Value matrix (V) would change where the model attends. The tutor correctly caught the trap, clarifying that V only affects the magnitude of the output vector, while Q and K are the sole determinants of the attention pattern.\n\nThe True Purpose of sqrt(dk): I used to think we divided by sqrt(dk) just to keep numbers small. The tutor forced me to derive the actual reason: it's about Variance. The dot product of two random vectors grows with the dimension size (dk). Without dividing by sqrt(dk), the variance explodes, pushing Softmax values into saturation regions where the gradients vanish (become zero).\n\nThe Low-Rank Bottleneck: This was the biggest \"aha\" moment. We walked through why the Attention Matrix cannot be \"full rank\" if the head dimension dk is smaller than the sequence length N. Since the attention score is the product of two rectangular matrices (Q and K^T), the resulting matrix is mathematically constrained to a lower rank. This helped me understand why Multi-Head Attention is necessary: single-head attention literally lacks the mathematical capacity to model complex, independent relationships between all tokens.\n\n\nHere is my session with the prof and my annotated transcript:\n\nhttps://chatgpt.com/share/693947b5-30b4-8006-804e-5b81f753330a",
            "content_xml": "<document version=\"2.0\"><paragraph>I wanted to move beyond the code and really stress-test my intuition for the linear algebra that makes Transformers work. I felt that I knew how to write the code (and also from my Special Participation B), but I didn't fully grasp why certain design choices, like the scaling factor or the head dimension size, were mathematically necessary.</paragraph><paragraph>To fix this, I built a custom \"Socratic Tutor\" persona called Professor Softmax. I gave it strict instructions: never give me the answer, only ask questions that force me to derive the logic step-by-step.</paragraph><paragraph><bold>The Artifact:</bold> A rigorous chat log where I audit the \"Professor\" on the subtle failure modes of Self-Attention.</paragraph><paragraph><bold>Key Insights &amp; Stress Tests:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The \"Temperature\" Intuition: The model helped me visualize how scaling the Key matrix (K) effectively acts like a temperature parameter. If you scale K by 100, the dot products explode, causing the Softmax to peak around a single token (becoming a \"hard\" argmax). This helps explain why initialization scale is so critical.</paragraph></list-item><list-item><paragraph>The \"Value Scaling\" Trap: I intentionally fed the model a misconception\u2014that scaling the Value matrix (V) would change <italic>where</italic> the model attends. The tutor correctly caught the trap, clarifying that V only affects the <italic>magnitude</italic> of the output vector, while Q and K are the sole determinants of the attention pattern.</paragraph></list-item><list-item><paragraph>The True Purpose of sqrt(dk): I used to think we divided by sqrt(dk) just to keep numbers small. The tutor forced me to derive the actual reason: it's about Variance. The dot product of two random vectors grows with the dimension size (dk). Without dividing by sqrt(dk), the variance explodes, pushing Softmax values into saturation regions where the gradients vanish (become zero).</paragraph></list-item><list-item><paragraph>The Low-Rank Bottleneck: This was the biggest \"aha\" moment. We walked through why the Attention Matrix cannot be \"full rank\" if the head dimension dk is smaller than the sequence length N. Since the attention score is the product of two rectangular matrices (Q and K^T), the resulting matrix is mathematically constrained to a lower rank. This helped me understand why Multi-Head Attention is necessary: single-head attention literally lacks the mathematical capacity to model complex, independent relationships between all tokens.</paragraph></list-item></list><paragraph><break/>Here is my session with the prof and my annotated transcript:</paragraph><paragraph>https://chatgpt.com/share/693947b5-30b4-8006-804e-5b81f753330a</paragraph><file url=\"https://static.us.edusercontent.com/files/bFKRI5xlHCh696eLoJBss8Hw\" filename=\"Special Participation E_ _Professor Softmax_.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T21:13:53.800324+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445807,
            "author": "Shreyes Sridhara",
            "project_title": "Special Participation E: A Grounded \"FaceNet\" Study Guide using NotebookLM",
            "post_body": "I\u2019ve been using LLMs to help study for HW10, but I noticed that general models (like ChatGPT) often hallucinate specific numbers from research papers, specifically the parameter counts and FLOPs in the FaceNet paper (Schroff et al. 2015).\n\nTo fix this, I used Google NotebookLM to create a grounded study guide. I uploaded the original PDF and treated it as a \"source of truth\" to verify the technical details that other models missed.\n\nSo I built an interactive Q&A guide that correctly extracts:\n\nModel Architectures: The exact difference between NN1 (Zeiler & Fergus) and NN2 (Inception) without mixing up the columns in Table 1.\n\nLoss Dynamics: A clear explanation of \"Semi-Hard\" vs \"Hard\" negatives and why the former prevents model collapse.\n\nPreprocessing: The specific \"tight crop\" strategy that distinguished FaceNet from its predecessors like DeepFace (which used complex 3D alignment).\n\n\n\nMy Process (Iterative Verification): I didn't just ask for a summary. I stress-tested the tool with \"niche\" questions about experimental protocols (e.g., the specific Hold-out Test Set splits) to ensure it was actually reading the text and not just guessing.\n\n\n\nI\u2019ve attached the annotated transcript of my session below. The annotations highlight where the tool succeeded in correcting the misconceptions I encountered earlier.\n\nhttps://notebooklm.google.com/notebook/99119019-e588-4d18-8878-40f4169407bc",
            "content_xml": "<document version=\"2.0\"><paragraph>I\u2019ve been using LLMs to help study for HW10, but I noticed that general models (like ChatGPT) often hallucinate specific numbers from research papers, specifically the parameter counts and FLOPs in the FaceNet paper (Schroff et al. 2015).</paragraph><paragraph>To fix this, I used <bold>Google NotebookLM</bold> to create a grounded study guide. I uploaded the original PDF and treated it as a \"source of truth\" to verify the technical details that other models missed.</paragraph><paragraph>So I built an interactive Q&amp;A guide that correctly extracts:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Model Architectures:</bold> The exact difference between NN1 (Zeiler &amp; Fergus) and NN2 (Inception) without mixing up the columns in Table 1.</paragraph></list-item><list-item><paragraph><bold>Loss Dynamics:</bold> A clear explanation of \"Semi-Hard\" vs \"Hard\" negatives and why the former prevents model collapse.</paragraph></list-item><list-item><paragraph><bold>Preprocessing:</bold> The specific \"tight crop\" strategy that distinguished FaceNet from its predecessors like DeepFace (which used complex 3D alignment).</paragraph></list-item></list><paragraph/><paragraph>My Process (Iterative Verification): I didn't just ask for a summary. I stress-tested the tool with \"niche\" questions about experimental protocols (e.g., the specific Hold-out Test Set splits) to ensure it was actually reading the text and not just guessing.</paragraph><paragraph/><paragraph>I\u2019ve attached the annotated transcript of my session below. The annotations highlight where the tool succeeded in correcting the misconceptions I encountered earlier.</paragraph><paragraph>https://notebooklm.google.com/notebook/99119019-e588-4d18-8878-40f4169407bc</paragraph><file url=\"https://static.us.edusercontent.com/files/iaM3M3OPLPdlsDMVFKLAYsJi\" filename=\"FaceNet Paper Study Guide.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T20:10:58.42198+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445771,
            "author": "Rohan Gopalam",
            "project_title": "Special Participation E: Bridging Gap Between Lectures/Discussion and Homework",
            "post_body": "I usually watch lectures the day of and go to discussion. However, the corresponding homework often feels like it is covering content from the past that I have already forgotten. This means before I start homework, I have to go through the lecture and discussion again. While this is not a bad thing as I am reviewing the content again, a lot of times I am wasting time relearning things I already know well when I am trying to find the information that is more challenging. To combat this, I created a prompt for Claude to generate a warmup worksheet and reading before I start the homework. I chose Claude because I have had good experiences with Claude's pdf creation abilities in the past. I have attached the prompt below. With the prompt, I also added pdf files of the discussion, lecture notes, and homework for that week. \n\nPrompt: I am getting ready to start my homework. However, I need a review of the material to get me warmed up again to do the homework. Looking at the lecture slides and the discussion for this week, can you create a quick review guide for me. I want this review guide to have a mini reading at the start with key information, a highlight of important sub parts of questions from the discussion, and finally some warmup questions with corresponding solutions. make sure this will not take more than 30-45 minutes to complete. do not make the example questions too similar to the homework so the homework is still educational. format it as a pdf worksheet so I can export it and work directly on it.\n\nHere is an example worksheet for homework 12 (edit accidentally named it C instead of E):",
            "content_xml": "<document version=\"2.0\"><paragraph>I usually watch lectures the day of and go to discussion. However, the corresponding homework often feels like it is covering content from the past that I have already forgotten. This means before I start homework, I have to go through the lecture and discussion again. While this is not a bad thing as I am reviewing the content again, a lot of times I am wasting time relearning things I already know well when I am trying to find the information that is more challenging. To combat this, I created a prompt for Claude to generate a warmup worksheet and reading before I start the homework. I chose Claude because I have had good experiences with Claude's pdf creation abilities in the past. I have attached the prompt below. With the prompt, I also added pdf files of the discussion, lecture notes, and homework for that week. <break/><break/>Prompt: I am getting ready to start my homework. However, I need a review of the material to get me warmed up again to do the homework. Looking at the lecture slides and the discussion for this week, can you create a quick review guide for me. I want this review guide to have a mini reading at the start with key information, a highlight of important sub parts of questions from the discussion, and finally some warmup questions with corresponding solutions. make sure this will not take more than 30-45 minutes to complete. do not make the example questions too similar to the homework so the homework is still educational. format it as a pdf worksheet so I can export it and work directly on it.<break/><break/>Here is an example worksheet for homework 12 (edit accidentally named it C instead of E):</paragraph><file/><file url=\"https://static.us.edusercontent.com/files/Tw4QFgLgosD6uUbRJSTqmdzz\" filename=\"Special Participation C.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T19:52:03.10692+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445765,
            "author": "Akshaan Ahuja",
            "project_title": "Special Participation A: Mistral Le Chat on HW11 (Without Reasoning or Thinking Mode)",
            "post_body": "I worked through HW 11 Problems 1, 2, 5, and 6, using Mistral\u2019s Le Chat model. After introducing the assignment by outlining the deep learning themes it would focus on (LoRA, soft prompting, transformer mechanics), I supplied the model with the necessary context for each problem, including variable definitions and any background assumptions needed (such as in Problem 2). From there, I prompted the model to solve each sub-question in sequence, always requesting brief, direct explanations and a concise walkthrough of intermediate steps.\n\nLe Chat consistently favored minimal \u201cshowing of work,\u201d providing compact derivations rather than full reasoning chains or mid-steps in the calculations. Its answers tended to prioritize correctness and structure over interpretive commentary, rarely connecting its calculations back to broader concepts from the homework like transformer representations or low-rank representations. Despite this, the model was able to reliably one-shot the conceptual queries, the true/false tasks, and the simpler proofs without significant intervention on my end.\n\nWhere it struggled was in Problem 5, when the solution required numerical facts external to the prompt. In those cases, the model occasionally hallucinated specific statistics, such as the number of books scanned by the Library of Congress or Google Books. Despite this, the model nevertheless applied the correct methodology for these problems. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I worked through HW 11 Problems 1, 2, 5, and 6, using Mistral\u2019s Le Chat model. After introducing the assignment by outlining the deep learning themes it would focus on (LoRA, soft prompting, transformer mechanics), I supplied the model with the necessary context for each problem, including variable definitions and any background assumptions needed (such as in Problem 2). From there, I prompted the model to solve each sub-question in sequence, always requesting brief, direct explanations and a concise walkthrough of intermediate steps.</paragraph><paragraph>Le Chat consistently favored minimal \u201cshowing of work,\u201d providing compact derivations rather than full reasoning chains or mid-steps in the calculations. Its answers tended to prioritize correctness and structure over interpretive commentary, rarely connecting its calculations back to broader concepts from the homework like transformer representations or low-rank representations. Despite this, the model was able to reliably one-shot the conceptual queries, the true/false tasks, and the simpler proofs without significant intervention on my end.</paragraph><paragraph>Where it struggled was in Problem 5, when the solution required numerical facts external to the prompt. In those cases, the model occasionally hallucinated specific statistics, such as the number of books scanned by the Library of Congress or Google Books. Despite this, the model nevertheless applied the correct methodology for these problems. <break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/Pt3J0Vpe2HblzAcP6P2G2df4\" filename=\"HW11-Mistral-Annotated.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T19:46:16.815442+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445641,
            "author": "Jincheng Ou",
            "project_title": "Special Participation B: Cursor on HW12",
            "post_body": "Cursor demonstrated exceptional performance on Q4, effectively one-shotting both the reparameterization trick and the ELBO loss function implementation.\n\nKey Observations:\n\nOne-Shot Capability: The LLM successfully generated correct, production-ready code for both tasks without requiring follow-up corrections. \n\nMathematical Accuracy: Cursor correctly interpreted the VAE mathematical formulation. It accurately applied the reparameterization formula and correctly identified that the reconstruction term requires a negative sign (negative log likelihood). \n\nHandling Constraints: Cursor correctly applied .mean() to both the KL Divergence and the reconstruction loss. This ensured the outputs were scalars as explicitly requested in the docstring (\"Outputs should all be scalar\").\n\nCode Management: Cursor integrates the functions of Git and GitHub, allowing users to directly execute Git commands within the IDE (for example, I made Cursor itself perform operations like git clone to obtain a local copy of the code repository). Cursor does an excellent job. At the same time, when executing Git commands, the system will pause to ask for the user\u2019s input.\n\nHallucinations: No hallucinations were found. The model showed a solid understanding of PyTorch(e.g., torch.randn_like) and the broadcasting mechanics required for the VAE.",
            "content_xml": "<document version=\"2.0\"><paragraph>Cursor demonstrated exceptional performance on Q4, effectively one-shotting both the reparameterization trick and the ELBO loss function implementation.</paragraph><paragraph><italic><bold>Key Observations:</bold></italic></paragraph><list style=\"bullet\"><list-item><paragraph><bold>One-Shot Capability:</bold> The LLM successfully generated correct, production-ready code for both tasks without requiring follow-up corrections. </paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Mathematical Accuracy:</bold> Cursor correctly interpreted the VAE mathematical formulation. It accurately applied the reparameterization formula and correctly identified that the reconstruction term requires a negative sign (negative log likelihood). </paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Handling Constraints:</bold> Cursor correctly applied .mean() to both the KL Divergence and the reconstruction loss. This ensured the outputs were scalars as explicitly requested in the docstring (\"Outputs should all be scalar\").</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Code Management:</bold> Cursor integrates the functions of Git and GitHub, allowing users to directly execute Git commands within the IDE (for example, I made Cursor itself perform operations like git clone to obtain a local copy of the code repository). Cursor does an excellent job. At the same time, when executing Git commands, the system will pause to ask for the user\u2019s input.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Hallucinations:</bold> No hallucinations were found. The model showed a solid understanding of PyTorch(e.g., torch.randn_like) and the broadcasting mechanics required for the VAE.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/GPDuRDvggEZSMh5oarjh3i7L\" filename=\"Special_Participation_B__Cursor_on_HW12.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T18:55:18.845134+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445493,
            "author": "Elizabeth Weaver",
            "project_title": "Special Participation A: Claude Sonnet 4.5 on Homework 4 (Written Problems)",
            "post_body": "I engaged Claude Sonnet 4.5 on all written portions of Homework 4 (Problems 1, 2, 3, 4, and 7) to evaluate its ability to solve deep learning theory problems. I provided screenshots of the questions from the original homework pdf one by one, to prevent the model from \u201cforgetting\u201d the later questions once we got further into the chat. This post documents my observations and an analysis of where the model succeeded and failed. Full annotated chat log is attached at the end of this post.\n\nThe model has strong conceptual understanding but struggles with notation conventions, sign errors in signal processing, and tracking how multiple scaling factors interact.\n\nDetailed Findings by Problem\n\nProblem 1: Newton-Schulz Runtime (with minor prompting)\n\nWhat happened:\n\nThe model correctly identified the two dominant matrix multiplications and their complexity\n\nIssue: Defaulted to Big-O notation instead of the requested cmnp format\n\nRequired two prompts: (1) \"use cmnp format\" and (2) \"you're missing the constant c\"\n\nClaude defaults to familiar conventions. Explicit format requests may need reinforcement.\n\nProblem 2: MuP at the Unit Scale\n\nThe model one-shotted most parts of this problem (a, b, c, f). Part d required a minor fix, while part e was a major struggle. Part g was initially wrong, but was fixed correctly after fixing part e.\n\nProblem 2(e) Deep Dive, the hardest question:\n\nThis asked for the learning rate \u03b1 for Muon-style orthogonalization where \u0394W = \u03b1\u00b7UV^T.\n\nAttempt 1: Model got \u03b1 = \u221an_out (missing \u221an_in factor)\n\nAttempt 2: After prompting \"your answer is incorrect,\" still got \u221an_out\n\nAttempt 3: I asked \"where are you losing the \u221an_in?\", which caused the model to try various approaches, but it still couldn't find where it was missing the answer\n\nFinal resolution: I showed the solution snippet explaining how c = 1/\u221ad_in adds a factor to the spectral norm. Only then did the model understand and arrive at \u03b1 = \u221a(n_out \u00b7 n_in)\n\nWhy this was hard: The model struggled to track how the forward-pass constant c interacts with the spectral norm constraint. This requires reasoning about parameterization across the forward and backward passes simultaneously.\n\nProblem 3: Convolution as FIR Filter\n\nThe model one-shotted only part b here. Part a required a minor fix, while part c had a sign error and part d also had an inherited error from part c. However part d wasn\u2019t fixed immediately when the issue with part c was fixed.\n\nThe Convolution vs. Correlation Confusion:\n\nThis was a classic signal processing error. The problem explicitly states \"we will follow the definition in equation 3\" (true convolution with flip-and-drag), but the model computed correlation (no flip).\n\nInitial answer for part (c): Matrix of all +40\n\nCorrect answer: Matrix of all -40\n\nWhen I pointed out the sign error, the model realized it needed to flip the kernel h to h_flipped before computing. This error then propagated to part (d), requiring multiple corrections for the padded boundary cases.\n\nLLMs trained heavily on ML code (where \"convolution\" usually means correlation) may default to the wrong convention even when the mathematical definition is specified.\n\nProblem 4: CNN Feature Dimensions\n\nAlmost all of the subparts were oneshotted here, while for the last subpart it flipped its answers.\n\nProblem 4(f) Error:\n\nGiven x1 (horizontal edge) -> g1 = [0.8, 0, 0]^T and x2 (vertical edge) -> g2 = [0, 0.8, 0]^T, the model was asked to find g3 and g4 for shifted versions.\n\nModel's initial answer: g3 = [0.8, 0, 0]^T, g4 = [0, 0.8, 0]^T\n\nCorrect answer: g3 = [0, 0.8, 0]^T, g4 = [0.8, 0, 0]^T\n\nThe model confused which image (x3 or x4) had which edge type. After I pointed out the flip, it correctly explained that x3 has a vertical edge (like x2) and x4 has a horizontal edge (like x1).\n\nProblem 7: Weights and Gradients in CNNs\n\nThe model one-shotted all of the answers for this question! This was the model's strongest section. All parts were correct on the first attempt.\n\nCommon Failures\n\nNotation/Format Defaults: Model uses Big-O when cmnp requested, uses inequalities when equalities expected\n\nConvolution vs. Correlation: Classic signal processing confusion; defaults to ML convention (correlation) even when math definition specifies convolution\n\nMulti-Factor Scaling: Struggles to track how multiple constants (like forward-pass c and spectral norms) interact across equations\n\nSpatial/Visual Confusion: Difficulty with edge orientations and which dimension corresponds to \"horizontal\" vs \"vertical\"\n\nArithmetic in Boundary Cases: Padded convolution computations were error-prone\n\nConclusions\n\nCan Claude Sonnet 4.5 solve this homework? Yes, but not reliably without human guidance.\n\nWhat's it good for?\n\nExplaining concepts and deriving formulas\n\nStandard calculations (CNN dimensions, parameter counts)\n\nGenerating first-draft solutions to check\n\nWhat requires human oversight?\n\nVerifying numerical computations\n\nCatching convention errors (convolution vs. correlation)\n\nProblems requiring reasoning about multiple interacting factors\n\nHere is the annotated version of my chat log with Claude, all of my annotations are in red. I used claude exporter to get the pdf version of the chat (claude itself does not provide a method to get the pdf).\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I engaged Claude Sonnet 4.5 on all written portions of Homework 4 (Problems 1, 2, 3, 4, and 7) to evaluate its ability to solve deep learning theory problems. I provided screenshots of the questions from the original homework pdf one by one, to prevent the model from \u201cforgetting\u201d the later questions once we got further into the chat. This post documents my observations and an analysis of where the model succeeded and failed. Full annotated chat log is attached at the end of this post.</paragraph><paragraph>The model has strong conceptual understanding but struggles with notation conventions, sign errors in signal processing, and tracking how multiple scaling factors interact.</paragraph><heading level=\"2\"><bold>Detailed Findings by Problem</bold></heading><heading level=\"3\"><bold>Problem 1: Newton-Schulz Runtime (with minor prompting)</bold></heading><paragraph><bold>What happened:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The model correctly identified the two dominant matrix multiplications and their complexity</paragraph></list-item><list-item><paragraph><bold>Issue:</bold> Defaulted to Big-O notation instead of the requested cmnp format</paragraph></list-item><list-item><paragraph>Required two prompts: (1) \"use cmnp format\" and (2) \"you're missing the constant c\"</paragraph></list-item></list><paragraph>Claude defaults to familiar conventions. Explicit format requests may need reinforcement.</paragraph><heading level=\"3\"><bold>Problem 2: MuP at the Unit Scale</bold></heading><paragraph>The model one-shotted most parts of this problem (a, b, c, f). Part d required a minor fix, while part e was a major struggle. Part g was initially wrong, but was fixed correctly after fixing part e.</paragraph><paragraph><bold>Problem 2(e) Deep Dive, the hardest question:</bold></paragraph><paragraph>This asked for the learning rate \u03b1 for Muon-style orthogonalization where \u0394W = \u03b1\u00b7UV^T.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Attempt 1:</bold> Model got \u03b1 = \u221an_out (missing \u221an_in factor)</paragraph></list-item><list-item><paragraph><bold>Attempt 2:</bold> After prompting \"your answer is incorrect,\" still got \u221an_out</paragraph></list-item><list-item><paragraph><bold>Attempt 3:</bold> I asked \"where are you losing the \u221an_in?\", which caused the model to try various approaches, but it still couldn't find where it was missing the answer</paragraph></list-item><list-item><paragraph><bold>Final resolution:</bold> I showed the solution snippet explaining how c = 1/\u221ad_in adds a factor to the spectral norm. Only then did the model understand and arrive at \u03b1 = \u221a(n_out \u00b7 n_in)</paragraph></list-item></list><paragraph><bold>Why this was hard:</bold> The model struggled to track how the forward-pass constant c interacts with the spectral norm constraint. This requires reasoning about parameterization across the forward and backward passes simultaneously.</paragraph><heading level=\"3\"><bold>Problem 3: Convolution as FIR Filter</bold></heading><paragraph>The model one-shotted only part b here. Part a required a minor fix, while part c had a sign error and part d also had an inherited error from part c. However part d wasn\u2019t fixed immediately when the issue with part c was fixed.</paragraph><paragraph><bold>The Convolution vs. Correlation Confusion:</bold></paragraph><paragraph>This was a classic signal processing error. The problem explicitly states \"we will follow the definition in equation 3\" (true convolution with flip-and-drag), but the model computed correlation (no flip).</paragraph><list style=\"unordered\"><list-item><paragraph>Initial answer for part (c): Matrix of all <bold>+40</bold></paragraph></list-item><list-item><paragraph>Correct answer: Matrix of all <bold>-40</bold></paragraph></list-item></list><paragraph>When I pointed out the sign error, the model realized it needed to flip the kernel h to h_flipped before computing. This error then propagated to part (d), requiring multiple corrections for the padded boundary cases.</paragraph><paragraph>LLMs trained heavily on ML code (where \"convolution\" usually means correlation) may default to the wrong convention even when the mathematical definition is specified.</paragraph><heading level=\"3\"><bold>Problem 4: CNN Feature Dimensions</bold></heading><paragraph>Almost all of the subparts were oneshotted here, while for the last subpart it flipped its answers.</paragraph><paragraph><bold>Problem 4(f) Error:</bold></paragraph><paragraph>Given x1 (horizontal edge) -&gt; g1 = [0.8, 0, 0]^T and x2 (vertical edge) -&gt; g2 = [0, 0.8, 0]^T, the model was asked to find g3 and g4 for shifted versions.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Model's initial answer:</bold> g3 = [0.8, 0, 0]^T, g4 = [0, 0.8, 0]^T</paragraph></list-item><list-item><paragraph><bold>Correct answer:</bold> g3 = [0, 0.8, 0]^T, g4 = [0.8, 0, 0]^T</paragraph></list-item></list><paragraph>The model confused which image (x3 or x4) had which edge type. After I pointed out the flip, it correctly explained that x3 has a vertical edge (like x2) and x4 has a horizontal edge (like x1).</paragraph><heading level=\"3\"><bold>Problem 7: Weights and Gradients in CNNs</bold></heading><paragraph>The model one-shotted all of the answers for this question! This was the model's strongest section. All parts were correct on the first attempt.</paragraph><heading level=\"2\"><bold>Common Failures</bold></heading><list style=\"ordered\"><list-item><paragraph><bold>Notation/Format Defaults:</bold> Model uses Big-O when cmnp requested, uses inequalities when equalities expected</paragraph></list-item><list-item><paragraph><bold>Convolution vs. Correlation:</bold> Classic signal processing confusion; defaults to ML convention (correlation) even when math definition specifies convolution</paragraph></list-item><list-item><paragraph><bold>Multi-Factor Scaling:</bold> Struggles to track how multiple constants (like forward-pass c and spectral norms) interact across equations</paragraph></list-item><list-item><paragraph><bold>Spatial/Visual Confusion:</bold> Difficulty with edge orientations and which dimension corresponds to \"horizontal\" vs \"vertical\"</paragraph></list-item><list-item><paragraph><bold>Arithmetic in Boundary Cases:</bold> Padded convolution computations were error-prone</paragraph></list-item></list><heading level=\"2\"><bold>Conclusions</bold></heading><paragraph><bold>Can Claude Sonnet 4.5 solve this homework?</bold> Yes, but not reliably without human guidance.</paragraph><paragraph><bold>What's it good for?</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Explaining concepts and deriving formulas</paragraph></list-item><list-item><paragraph>Standard calculations (CNN dimensions, parameter counts)</paragraph></list-item><list-item><paragraph>Generating first-draft solutions to check</paragraph></list-item></list><paragraph><bold>What requires human oversight?</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Verifying numerical computations</paragraph></list-item><list-item><paragraph>Catching convention errors (convolution vs. correlation)</paragraph></list-item><list-item><paragraph>Problems requiring reasoning about multiple interacting factors</paragraph></list-item></list><paragraph>Here is the annotated version of my chat log with Claude, all of my annotations are in red. I used claude exporter to get the pdf version of the chat (claude itself does not provide a method to get the pdf).</paragraph><file url=\"https://static.us.edusercontent.com/files/APDkVrLsov3C84gnvXxOsqeV\" filename=\"Claude-Deep learning homework solutions.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T18:02:07.539427+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445419,
            "author": "Jincheng Ou",
            "project_title": "Special Participation A: Gemini Flash on HW12",
            "post_body": "Gemini Flash demonstrated a perfect one-shot performance on the non-coding written portions of Homework 12. The model exhibited strong domain knowledge about deep learning, specifically in Transformer initialization stability, KL Divergence, and Variational Information Bottlenecks.\n\nKey Observations:\n\nAccuracy: The model answered all sub-parts of the three questions correctly, matching the logic found in the reference solutions.\n\nReasoning Capability: Gemini went beyond simple answers by providing mathematical justifications. For instance, in Q1, it explicitly reasoned about the expected squared norm of the embeddings, and in Q3, it correctly interpreted the trade-off between task loss and regularization strength to analyze the validation error curve.\n\nVisual Interpretation: The model successfully interpreted the unlabelled plots in Q2 (distribution shapes) and Q3 (scatter plots of latent spaces), correctly mapping visual characteristics (variance, clustering) to hyperparameters.\n\nHallucinations: There were no hallucinations or misunderstoods found in this output. Gemini adhered strictly to standard definitions and deep learning theory.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Gemini Flash demonstrated a perfect one-shot performance on the non-coding written portions of Homework 12. The model exhibited strong domain knowledge about deep learning, specifically in Transformer initialization stability, KL Divergence, and Variational Information Bottlenecks.</paragraph><paragraph><bold><italic>Key Observations:</italic></bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Accuracy:</bold> The model answered all sub-parts of the three questions correctly, matching the logic found in the reference solutions.</paragraph></list-item><list-item><paragraph><bold>Reasoning Capability:</bold> Gemini went beyond simple answers by providing mathematical justifications. For instance, in Q1, it explicitly reasoned about the expected squared norm of the embeddings, and in Q3, it correctly interpreted the trade-off between task loss and regularization strength to analyze the validation error curve.</paragraph></list-item><list-item><paragraph><bold>Visual Interpretation:</bold> The model successfully interpreted the unlabelled plots in Q2 (distribution shapes) and Q3 (scatter plots of latent spaces), correctly mapping visual characteristics (variance, clustering) to hyperparameters.</paragraph></list-item><list-item><paragraph><bold>Hallucinations:</bold> There were no hallucinations or misunderstoods found in this output. Gemini adhered strictly to standard definitions and deep learning theory.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/fe2cXTUfb3BFalBm8s6T4XIb\" filename=\"Special_Participation_A__Gemini_Flash_on_HW12.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T17:35:29.671404+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445282,
            "author": "Micah Mok",
            "project_title": "Special Participation E: Interactive RMS Norm Visualizer",
            "post_body": "I made an Interactive RMS Norm Visualizer! Feel free to download the repo and try it out!\n\nHere's the repo:\nhttps://github.com/mokingyou/exploRMS\n\nHere are my LLM logs: https://chatgpt.com/share/69390a26-088c-8010-990c-f3ca8e59b726\n\nHere's a screenshot: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I made an Interactive RMS Norm Visualizer! Feel free to download the repo and try it out!</paragraph><paragraph>Here's the repo:<break/>https://github.com/mokingyou/exploRMS<break/><break/>Here are my LLM logs: <link href=\"https://chatgpt.com/share/69390a26-088c-8010-990c-f3ca8e59b726\">https://chatgpt.com/share/69390a26-088c-8010-990c-f3ca8e59b726</link></paragraph><paragraph>Here's a screenshot: </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/MrsSH84iGtAd3Hq4ocgMRM2Y\" width=\"658\" height=\"324.4683195592287\"/></figure></document>",
            "links": [
                "https://chatgpt.com/share/69390a26-088c-8010-990c-f3ca8e59b726"
            ],
            "attachments": [],
            "created_at": "2025-12-10T16:51:25.151117+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445213,
            "author": "Zhuangzhe Wu",
            "project_title": "Special Participation E: Learning Muon by Gemini Guided Learning",
            "post_body": "The tutoring session on the Muon optimizer (Momentum Orthogonalized by Newton\u2013Schulz) via Gemini Guided Learning was effective. It will provide a question after the explanation, make you think about the problem and answer it, then give the answer and explanation.\n\nThe session successfully explained how Muon provides a cheap, $O(n^2)$ alternative to the expensive $O(n^3)$ SVD required for ideal semi-orthogonal updates. I learned that Muon achieves this by:\n\nMatrix Accumulation: Using a momentum-like accumulator to store second-order information and provide the necessary normalization factor.\n\nNewton\u2013Schulz Iteration: Applying the N-S recurrence, which acts as a fast polynomial transformation on the singular values of the accumulated matrix.\n\nThis transformation compresses the singular values toward 1, stabilizing the optimization path and allowing for larger learning rates. The question-by-question format of the guidance did a good job of ensuring a deep, sequential understanding of these core concepts.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/OyX8fQ9NhOKbbfFDUvMXVbJ2\" filename=\"muon.pdf\"/><paragraph>The tutoring session on the Muon optimizer (Momentum Orthogonalized by Newton\u2013Schulz) via <bold>Gemini Guided Learning</bold> was effective. It will provide a question after the explanation, make you think about the problem and answer it, then give the answer and explanation.</paragraph><file url=\"https://static.us.edusercontent.com/files/auTyYghbGPNMjxcgAAZqKjkg\" filename=\"Lecture 7.pdf\"/><paragraph>The session successfully explained how Muon provides a cheap, $O(n^2)$ alternative to the expensive $O(n^3)$ SVD required for ideal semi-orthogonal updates. I learned that Muon achieves this by:</paragraph><paragraph><bold>Matrix Accumulation:</bold> Using a momentum-like accumulator to store second-order information and provide the necessary normalization factor.</paragraph><paragraph><bold>Newton\u2013Schulz Iteration:</bold> Applying the N-S recurrence, which acts as a fast polynomial transformation on the singular values of the accumulated matrix.</paragraph><paragraph>This transformation compresses the singular values toward 1, stabilizing the optimization path and allowing for larger learning rates. The question-by-question format of the guidance did a good job of ensuring a deep, sequential understanding of these core concepts.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T16:36:29.728714+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445184,
            "author": "Rohan Gopalam",
            "project_title": "Special Participation B: Perplexity Pro on HW12",
            "post_body": "After finishing the notebooks using Perplexity Pro, I was surprised with how quickly and correctly the model was able to give me the correct answer. Granted, this homework assignment's coding portion was relatively easier, but I was expecting worse since Perplexity is not a model made specifically for coding tasks. I did this homework with Perplexity by giving the model the entire files/notebooks and asking it to fill in all the Todos. I think since the Todos are clearly labeled and good reference information is given, it is very easy for an LLM to know what to do.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>After finishing the notebooks using Perplexity Pro, I was surprised with how quickly and correctly the model was able to give me the correct answer. Granted, this homework assignment's coding portion was relatively easier, but I was expecting worse since Perplexity is not a model made specifically for coding tasks. I did this homework with Perplexity by giving the model the entire files/notebooks and asking it to fill in all the Todos. I think since the Todos are clearly labeled and good reference information is given, it is very easy for an LLM to know what to do.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/h6qgMp66S6TiqJzcGizQV3kq\" filename=\"Special Participation HW 12.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T16:30:07.117304+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445083,
            "author": "Evan Davis",
            "project_title": "Special Participation A: ChatGPT-5 (Regular) on Homework 12",
            "post_body": "Done as reflected on the deconflict sheet.\n\nNote that I did Questions (1) and 5(c) on my other Special Participation B post, because I treated them as coding Questions. For this post, I do questions 2, 3, and 5(a)-(b).\n\nI post the annotated chat below. Here is the link to the GPT chat: https://chatgpt.com/share/6938f111-c4b4-800d-90fd-000f7b0fa644\n\nQuestion (2): ChatGPT solved this question without too much difficulty.\n\nQuestion (3): ChatGPT actually encountered some difficulties on this question. First off, on 3(d)(ii), it did not read the figures correctly; I had to provide it with a screenshot of Figure 4 for the reasoning to work. Next, for 3(a), it provided me with a working primitive diagram, but also code for an Overleaf diagram. Despite several fixation attempts, the code never quiet worked, but it technically did \"solve\" 3(a) with the original diagram, which I attached below.\n\nQuestion (5)(a)-(b): ChatGPT actually failed to solve this one at first, having \"forgotten\" Homework 12's full contents. I reattached the PDF and proceeded, and it worked.\n\nHere was the 3(a) ASCII diagram and annotated chatlog PDF:\n\n\n\nEDIT: Attached a better PDF.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Done as reflected on the deconflict sheet.</paragraph><paragraph>Note that I did Questions (1) and 5(c) on my other Special Participation B post, because I treated them as coding Questions. For this post, I do questions 2, 3, and 5(a)-(b).</paragraph><paragraph>I post the annotated chat below. Here is the link to the GPT chat: <link href=\"https://chatgpt.com/share/6938f111-c4b4-800d-90fd-000f7b0fa644\"><underline>https://chatgpt.com/share/6938f111-c4b4-800d-90fd-000f7b0fa644</underline></link></paragraph><paragraph><bold>Question (2):</bold> ChatGPT solved this question without too much difficulty.</paragraph><paragraph><bold>Question (3):</bold> ChatGPT actually encountered some difficulties on this question. First off, on 3(d)(ii), it did not read the figures correctly; I had to provide it with a screenshot of Figure 4 for the reasoning to work. Next, for 3(a), it provided me with a working primitive diagram, but also code for an Overleaf diagram. Despite several fixation attempts, the code never quiet worked, but it technically did \"solve\" 3(a) with the original diagram, which I attached below.</paragraph><paragraph><bold>Question (5)(a)-(b):</bold> ChatGPT actually failed to solve this one at first, having \"forgotten\" Homework 12's full contents. I reattached the PDF and proceeded, and it worked.</paragraph><paragraph>Here was the 3(a) ASCII diagram and annotated chatlog PDF:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/6bj3QYBfq6JhtjCD5snWYnjh\" width=\"659\" height=\"281.80199667221297\"/></figure><file url=\"https://static.us.edusercontent.com/files/f1cjYdEIPCnYD4MxuRLQ9oY2\" filename=\"special_participation.pdf\"/><paragraph/><paragraph>EDIT: Attached a better PDF.</paragraph><paragraph/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/6938f111-c4b4-800d-90fd-000f7b0fa644"
            ],
            "attachments": [],
            "created_at": "2025-12-10T16:07:04.785698+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7445063,
            "author": "Elizabeth Weaver",
            "project_title": "Special Participation B: Claude Sonnet 4.5 for HW1 Coding Sections",
            "post_body": "Hi everyone!\n\nFor option (B) of the special participation assignment, I documented my interactions with Claude while completing the coding portions of HW1. I used Claude Exporter to export the conversation (Claude does not provide a method to export to PDF) and added annotations in red to highlight where Claude helped vs. where it fell short.\n\nSummary of the Interaction\n\nI used Claude for two homework questions:\n\nQuestion 3 (Parts h & i): Gradient Descent with Momentum\n\nPart h: How does \u03c3i (the eigenvalues) influence the gradients and parameters updates?\n\nPart i: Comparing gradient descent and gradient descent with momentum, which one converges faster for this task? Why?\n\nThis problem involved implementing 2 TODO sections, then interpreting the results to come up with these written answers.\n\nQuestion 2k: SGD Convergence with Feature Augmentation\n\nAnalyzing a provided Jupyter notebook on ridge regression\n\nReporting observations about convergence rates\n\nQuestion 3h & 3i: Gradient Descent with Momentum\n\nFirst TODO:\n\nFor the first TODO (implementing the momentum update), Claude immediately provided the correct formula:\n\nsmoothed_grad = beta * smoothed_grad + (1 - beta) * grad\n\nThis was straightforward. The exponential moving average is a standard formula, and Claude had no trouble with it.\n\nSecond TODO:\n\nFor the second TODO (choosing a larger learning rate for momentum), Claude confidently suggested:\n\nstepsize_new = 5e-4 # Increased from 1e-4 to 5e-4 (5x larger)\n\nClaude's reasoning was sound: \"Momentum allows us to use larger learning rates because it dampens oscillations.\" It even predicted: \"Dimension 0 will show a much larger gap between methods \u2014 momentum will converge MUCH faster.\"\n\nWhat actually happened: The optimization diverged catastrophically.\n\nFinal loss exploded\n\nGradients exploded\n\nParameters shot up\n\nIt wasn\u2019t slow convergence, but numerical explosion.\n\nAdapting TODO 2 with new information:\n\nAfter showing Claude the divergent results, it immediately recognized the problem:\n\n\"No, these results are not what I expected at all! The learning rate of 5e-4 is way too large and caused the momentum method to diverge catastrophically.\"\n\nClaude then suggested a more conservative learning rate:\n\nstepsize_new = 2e-4 # 2x larger, not 5x\n\nThis worked perfectly. The plots showed exactly the expected behavior (momentum converging ~7 orders of magnitude faster than plain GD).\n\nWritten Questions\n\nAfter the experiments succeeded, Claude provided comprehensive answers to the written questions:\n\n\"How does \u03c3\u1d62 (the eigenvalues) influence gradients and parameter updates?\" Claude correctly explained how larger eigenvalues produce larger gradients and cause oscillations, while smaller eigenvalues lead to slow convergence. It grounded the explanation in the experimental observations (dimension 0 vs dimension 1 behavior).\n\n\"Which method converges faster and why?\" Claude explained momentum's advantages: damping oscillations in high-curvature directions, accelerating progress in low-curvature directions, and enabling larger learning rates\n\nQuestion 2k: SGD Convergence with Feature Augmentation\n\nFor this question, I gave Claude a complete Jupyter notebook (no TODOs to fill in) and asked it to analyze the convergence rate observations.\n\nWhat Claude Did Well:\n\nClaude correctly identified all three curves in the plot:\n\nFeature Augmented (blue): Exponential convergence\n\nOriginal Ridge (orange): Exponential convergence until hitting a noise floor\n\nNo Noise/No Regularization (green): Fastest convergence to machine precision\n\nClaude explained the key mechanism: feature augmentation increases the minimum eigenvalue, improving the condition number and enabling stable convergence with constant step sizes.\n\nThe Answer:\n\nClaude's summary was accurate: feature augmentation enables SGD with constant step sizes to achieve exponential convergence to high precision, while explicit ridge regularization converges exponentially only until reaching a noise floor. The practical implication is that feature augmentation is superior when you want high-precision solutions, while explicit regularization naturally stops at an appropriate level for generalization.\n\nNo Iteration Needed:\n\nUnlike Q3, this question required no back-and-forth. Claude analyzed the provided notebook and plots correctly on the first try. This makes sense: the task was interpretation of given results, not prediction of what would happen with untested hyperparameters.\n\nCritical Annotations\n\nWhere Claude Helped:\n\nCorrect implementation of standard algorithms (Q3h): The momentum update formula was immediately correct\n\nGood explanations of concepts: Claude's explanations of why momentum helps (damping oscillations, accelerating in flat directions) were accurate and pedagogically useful\n\nInterpreting experimental results (Q3i, Q2k): Claude correctly analyzed plots after each run, explaining what the gradient/parameter/loss curves meant\n\nWritten question answers (Q3i): Claude provided comprehensive, well-structured answers grounded in experimental observations\n\nQuick error recovery (Q3i): When the first hyperparameter failed, Claude immediately recognized the problem and suggested a fix\n\nFirst-try success on interpretation tasks (Q2k): When given complete results to analyze (rather than code to write), Claude got it right immediately\n\nWhere Claude Fell Short:\n\nCannot guess hyperparameters without running experiments (Q3i): This is the key takeaway. Claude gave a confident, theoretically-motivated suggestion (5e-4) that completely failed in practice. The model couldn't know that this specific problem's eigenvalue structure would cause instability at that learning rate.\n\nOverconfident predictions (Q3i): Claude said \"Dimension 0 will show a much larger gap... momentum will converge MUCH faster\". This would have been true at a stable learning rate, but the prediction was useless because the learning rate was wrong.\n\nMy annotation from the chat:\n\n\"Claude gives good explanations here again, and details what it expects to see by running this code. However, when running the code that it gives, instead the run diverges. Claude therefore does not guess the learning rate correctly. It seems that although the model is very powerful, it can't guess the correct hyperparameters without running the experiments (similarly to us).\"\n\nKey Takeaways\n\nLLMs are great at implementing known algorithms (Q3h): Standard formulas, update rules, and boilerplate code are reliably correct.\n\nLLMs cannot substitute for running experiments (Q3i): Hyperparameter tuning requires empirical feedback. Claude's theoretically-motivated guess (5x learning rate) failed badly; the working value (2x) could only be found by iteration.\n\nLLMs excel at interpretation (Q2k, Q3i): Once given actual outputs (plots, loss values, gradient magnitudes), Claude correctly diagnosed problems and explained results. Q2k required zero iteration because it was purely interpretive.\n\nThe human-in-the-loop is essential for prediction tasks: For Q3i, I needed to:\n\nRun the code myself\n\nRecognize that \"loss = 1e55\" meant something went wrong\n\nFeed the results back to Claude\n\nIterate until convergence\n\nWithout this loop, I would have submitted divergent code with confident but wrong explanations.\n\nLLMs can adapt quickly: Claude's second suggestion (2e-4) was immediately successful. The model doesn't stubbornly defend wrong answers when shown evidence.\n\nTask type matters: Q3i (predict \u2192 run \u2192 iterate) required multiple rounds. Q2k (interpret given results) succeeded immediately. The distinction is whether Claude needs to predict outcomes or explain them.\n\nHow I Recorded the Interaction\n\nFor anyone wondering how to document LLM interactions for this assignment:\n\nClaude Exporter: Chrome extension that exports Claude conversations to PDF/Markdown\n\nAdded annotations in red: Used a PDF editor to add my commentary on what worked vs. what failed\n\nIncluded all intermediate outputs: Screenshots of plots and numerical outputs at each iteration were crucial for showing where Claude's suggestions failed\n\nThis approach captures the iterative nature of the interaction, which is hard to show with just a final transcript.\n\nHope this is a useful case study! The key lesson for me was that LLMs are powerful collaborators but not substitutes for empirical experimentation.\n\nI also provided the intermediate notebook outputs I gave to Claude below, for question 3h,i. For question 2k, I just ran the notebook all the way through.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!</paragraph><paragraph>For option (B) of the special participation assignment, I documented my interactions with Claude while completing the <bold>coding portions of HW1</bold>. I used<link href=\"https://chromewebstore.google.com/detail/claude-exporter/dcessgmfacfmgbfkoelmelijcmadgken\"> <underline>Claude Exporter</underline></link> to export the conversation (Claude does not provide a method to export to PDF) and added annotations in red to highlight where Claude helped vs. where it fell short.</paragraph><heading level=\"3\"><bold>Summary of the Interaction</bold></heading><paragraph>I used Claude for two homework questions:</paragraph><paragraph><bold>Question 3 (Parts h &amp; i): Gradient Descent with Momentum</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Part h: How does \u03c3i (the eigenvalues) influence the gradients and parameters updates?</paragraph></list-item><list-item><paragraph>Part i: Comparing gradient descent and gradient descent with momentum, which one converges faster for this task? Why?</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>This problem involved implementing 2 TODO sections, then interpreting the results to come up with these written answers.</paragraph></list-item></list><paragraph><bold>Question 2k: SGD Convergence with Feature Augmentation</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Analyzing a provided Jupyter notebook on ridge regression</paragraph></list-item><list-item><paragraph>Reporting observations about convergence rates</paragraph></list-item></list><heading level=\"2\"><bold>Question 3h &amp; 3i: Gradient Descent with Momentum</bold></heading><paragraph><bold>First TODO:</bold></paragraph><paragraph>For the first TODO (implementing the momentum update), Claude immediately provided the correct formula:</paragraph><paragraph>smoothed_grad = beta * smoothed_grad + (1 - beta) * grad</paragraph><paragraph>This was straightforward. The exponential moving average is a standard formula, and Claude had no trouble with it.</paragraph><paragraph><bold>Second TODO:</bold></paragraph><paragraph>For the second TODO (choosing a larger learning rate for momentum), Claude confidently suggested:</paragraph><paragraph>stepsize_new = 5e-4 # Increased from 1e-4 to 5e-4 (5x larger)</paragraph><paragraph>Claude's reasoning was sound: \"Momentum allows us to use larger learning rates because it dampens oscillations.\" It even predicted: \"Dimension 0 will show a much larger gap between methods \u2014 momentum will converge MUCH faster.\"</paragraph><paragraph><bold>What actually happened:</bold> The optimization diverged catastrophically.</paragraph><list style=\"unordered\"><list-item><paragraph>Final loss exploded</paragraph></list-item><list-item><paragraph>Gradients exploded</paragraph></list-item><list-item><paragraph>Parameters shot up</paragraph></list-item></list><paragraph>It wasn\u2019t slow convergence, but numerical explosion.</paragraph><paragraph><bold>Adapting TODO 2 with new information:</bold></paragraph><paragraph>After showing Claude the divergent results, it immediately recognized the problem:</paragraph><paragraph>\"No, these results are not what I expected at all! The learning rate of 5e-4 is way too large and caused the momentum method to diverge catastrophically.\"</paragraph><paragraph>Claude then suggested a more conservative learning rate:</paragraph><paragraph>stepsize_new = 2e-4 # 2x larger, not 5x</paragraph><paragraph>This worked perfectly. The plots showed exactly the expected behavior (momentum converging ~7 orders of magnitude faster than plain GD).</paragraph><paragraph><bold>Written Questions</bold></paragraph><paragraph>After the experiments succeeded, Claude provided comprehensive answers to the written questions:</paragraph><list style=\"ordered\"><list-item><paragraph><italic>\"How does \u03c3\u1d62 (the eigenvalues) influence gradients and parameter updates?\"</italic> Claude correctly explained how larger eigenvalues produce larger gradients and cause oscillations, while smaller eigenvalues lead to slow convergence. It grounded the explanation in the experimental observations (dimension 0 vs dimension 1 behavior).</paragraph></list-item><list-item><paragraph><italic>\"Which method converges faster and why?\"</italic> Claude explained momentum's advantages: damping oscillations in high-curvature directions, accelerating progress in low-curvature directions, and enabling larger learning rates</paragraph></list-item></list><heading level=\"2\"><bold>Question 2k: SGD Convergence with Feature Augmentation</bold></heading><paragraph>For this question, I gave Claude a complete Jupyter notebook (no TODOs to fill in) and asked it to analyze the convergence rate observations.</paragraph><paragraph><bold>What Claude Did Well:</bold></paragraph><paragraph>Claude correctly identified all three curves in the plot:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Feature Augmented (blue):</bold> Exponential convergence</paragraph></list-item><list-item><paragraph><bold>Original Ridge (orange):</bold> Exponential convergence until hitting a noise floor</paragraph></list-item><list-item><paragraph><bold>No Noise/No Regularization (green):</bold> Fastest convergence to machine precision</paragraph></list-item></list><paragraph>Claude explained the key mechanism: feature augmentation increases the minimum eigenvalue, improving the condition number and enabling stable convergence with constant step sizes.</paragraph><paragraph><bold>The Answer:</bold></paragraph><paragraph>Claude's summary was accurate: feature augmentation enables SGD with constant step sizes to achieve exponential convergence to high precision, while explicit ridge regularization converges exponentially only until reaching a noise floor. The practical implication is that feature augmentation is superior when you want high-precision solutions, while explicit regularization naturally stops at an appropriate level for generalization.</paragraph><paragraph><bold>No Iteration Needed:</bold></paragraph><paragraph>Unlike Q3, this question required no back-and-forth. Claude analyzed the provided notebook and plots correctly on the first try. This makes sense: the task was <italic>interpretation</italic> of given results, not <italic>prediction</italic> of what would happen with untested hyperparameters.</paragraph><heading level=\"3\"><bold>Critical Annotations</bold></heading><paragraph><bold>Where Claude Helped:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Correct implementation of standard algorithms (Q3h)</bold>: The momentum update formula was immediately correct</paragraph></list-item><list-item><paragraph><bold>Good explanations of concepts</bold>: Claude's explanations of why momentum helps (damping oscillations, accelerating in flat directions) were accurate and pedagogically useful</paragraph></list-item><list-item><paragraph><bold>Interpreting experimental results (Q3i, Q2k)</bold>: Claude correctly analyzed plots after each run, explaining what the gradient/parameter/loss curves meant</paragraph></list-item><list-item><paragraph><bold>Written question answers (Q3i)</bold>: Claude provided comprehensive, well-structured answers grounded in experimental observations</paragraph></list-item><list-item><paragraph><bold>Quick error recovery (Q3i)</bold>: When the first hyperparameter failed, Claude immediately recognized the problem and suggested a fix</paragraph></list-item><list-item><paragraph><bold>First-try success on interpretation tasks (Q2k)</bold>: When given complete results to analyze (rather than code to write), Claude got it right immediately</paragraph></list-item></list><paragraph><bold>Where Claude Fell Short:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Cannot guess hyperparameters without running experiments (Q3i)</bold>: This is the key takeaway. Claude gave a confident, theoretically-motivated suggestion (5e-4) that completely failed in practice. The model couldn't know that this specific problem's eigenvalue structure would cause instability at that learning rate.</paragraph></list-item><list-item><paragraph><bold>Overconfident predictions (Q3i)</bold>: Claude said \"Dimension 0 will show a much larger gap... momentum will converge MUCH faster\". This would have been true at a stable learning rate, but the prediction was useless because the learning rate was wrong.</paragraph></list-item></list><paragraph>My annotation from the chat:</paragraph><paragraph><italic>\"Claude gives good explanations here again, and details what it expects to see by running this code. However, when running the code that it gives, instead the run diverges. Claude therefore does not guess the learning rate correctly. It seems that although the model is very powerful, it can't guess the correct hyperparameters without running the experiments (similarly to us).\"</italic></paragraph><heading level=\"3\"><bold>Key Takeaways</bold></heading><list style=\"ordered\"><list-item><paragraph><bold>LLMs are great at implementing known algorithms (Q3h)</bold>: Standard formulas, update rules, and boilerplate code are reliably correct.</paragraph></list-item><list-item><paragraph><bold>LLMs cannot substitute for running experiments (Q3i)</bold>: Hyperparameter tuning requires empirical feedback. Claude's theoretically-motivated guess (5x learning rate) failed badly; the working value (2x) could only be found by iteration.</paragraph></list-item><list-item><paragraph><bold>LLMs excel at interpretation (Q2k, Q3i)</bold>: Once given actual outputs (plots, loss values, gradient magnitudes), Claude correctly diagnosed problems and explained results. Q2k required zero iteration because it was purely interpretive.</paragraph></list-item><list-item><paragraph><bold>The human-in-the-loop is essential for prediction tasks</bold>: For Q3i, I needed to:</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Run the code myself</paragraph></list-item><list-item><paragraph>Recognize that \"loss = 1e55\" meant something went wrong</paragraph></list-item><list-item><paragraph>Feed the results back to Claude</paragraph></list-item><list-item><paragraph>Iterate until convergence</paragraph></list-item></list></list-item><list-item><paragraph>Without this loop, I would have submitted divergent code with confident but wrong explanations.</paragraph></list-item><list-item><paragraph><bold>LLMs can adapt quickly</bold>: Claude's second suggestion (2e-4) was immediately successful. The model doesn't stubbornly defend wrong answers when shown evidence.</paragraph></list-item><list-item><paragraph><bold>Task type matters</bold>: Q3i (predict \u2192 run \u2192 iterate) required multiple rounds. Q2k (interpret given results) succeeded immediately. The distinction is whether Claude needs to <italic>predict</italic> outcomes or <italic>explain</italic> them.</paragraph></list-item></list><heading level=\"3\"><bold>How I Recorded the Interaction</bold></heading><paragraph>For anyone wondering how to document LLM interactions for this assignment:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Claude Exporter</bold>: Chrome extension that exports Claude conversations to PDF/Markdown</paragraph></list-item><list-item><paragraph><bold>Added annotations in red</bold>: Used a PDF editor to add my commentary on what worked vs. what failed</paragraph></list-item><list-item><paragraph><bold>Included all intermediate outputs</bold>: Screenshots of plots and numerical outputs at each iteration were crucial for showing where Claude's suggestions failed</paragraph></list-item></list><paragraph>This approach captures the iterative nature of the interaction, which is hard to show with just a final transcript.</paragraph><paragraph>Hope this is a useful case study! The key lesson for me was that <bold>LLMs are powerful collaborators but not substitutes for empirical experimentation</bold>.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/0U4i0F93DwNvxXPerIH8FedJ\" filename=\"claude_hw1_annotated.pdf\"/><paragraph>I also provided the intermediate notebook outputs I gave to Claude below, for question 3h,i. For question 2k, I just ran the notebook all the way through.</paragraph><file url=\"https://static.us.edusercontent.com/files/JrNkdcOuHbMlb3609juHj7Nq\" filename=\"q_sgd_momentum_analysis.ipynb_q1_filled.pdf\"/><file url=\"https://static.us.edusercontent.com/files/PIpcz2KnzJWSSVv2GfZdUBS5\" filename=\"q_sgd_momentum_analysis.ipynb_q2.pdf\"/><file url=\"https://static.us.edusercontent.com/files/GiurLqBeY48IK2PTJaOsIoXg\" filename=\"q_sgd_momentum_analysis.ipynb_again_q2.pdf\"/></document>",
            "links": [
                "https://chromewebstore.google.com/detail/claude-exporter/dcessgmfacfmgbfkoelmelijcmadgken"
            ],
            "attachments": [],
            "created_at": "2025-12-10T16:02:55.207949+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444983,
            "author": "Zhuangzhe Wu",
            "project_title": "Special Participation E: Learning diffusion by Gemini Guided Learning",
            "post_body": "Diffusion is a difficult part of the class and I spent a lot of time on learning it. Gemini's Guided Learning helps to transform the study of the \"STEP-BY-STEP DIFFUSION: AN ELEMENTARY TUTORIAL\" file from passive reading into active knowledge construction. I can direct Gemini to act as an expert tutor, assessing my understanding of key concepts like Gaussian Diffusion (Section 1), DDPM (Section 2), and DDIM (Section 3) by asking targeted questions one at a time. The goal is to actively reason through core ideas\u2014such as why the reverse process is simplified as a Gaussian approximation (Fact 1), how the $\\ell_2$ regression loss relates to learning the conditional mean $\\mathbb{E}[x_{t-1}|x_t]$, or how DDIM implements a deterministic transport map (Flow Matching) \u2014with Gemini providing iterative feedback and guidance to deepen my insights.\n\nhttps://gemini.google.com/share/0f68e240cf10\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Diffusion is a difficult part of the class and I spent a lot of time on learning it. Gemini's Guided Learning helps to transform the study of the \"STEP-BY-STEP DIFFUSION: AN ELEMENTARY TUTORIAL\" file from passive reading into active knowledge construction. I can direct Gemini to act as an expert tutor, assessing my understanding of key concepts like Gaussian Diffusion (Section 1), DDPM (Section 2), and DDIM (Section 3) by asking targeted questions one at a time. The goal is to actively reason through core ideas\u2014such as why the reverse process is simplified as a Gaussian approximation (Fact 1), how the $\\ell_2$ regression loss relates to learning the conditional mean $\\mathbb{E}[x_{t-1}|x_t]$, or how DDIM implements a deterministic transport map (Flow Matching) \u2014with Gemini providing iterative feedback and guidance to deepen my insights.</paragraph><file url=\"https://static.us.edusercontent.com/files/OmssonS6ebIScxQ6I1JwSyQi\" filename=\"diffusion_tutorial.pdf\"/><paragraph><link href=\"https://gemini.google.com/share/0f68e240cf10\">https://gemini.google.com/share/0f68e240cf10</link></paragraph><paragraph/></document>",
            "links": [
                "https://gemini.google.com/share/0f68e240cf10"
            ],
            "attachments": [],
            "created_at": "2025-12-10T15:50:18.959853+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444973,
            "author": "Andy Peng",
            "project_title": "Special Participation B: Opus4.5 on HW12 coding",
            "post_body": "\n\nClaude Opus was able to one shot this homework. It didn\u2019t even need any clarifications and was able to also give explanations for its code afterwards. I\u2019m pretty happy with the choice of variable names and the overall cleanliness of the code. I\u2019m not too surprised because I think this homework in particular was quite simple relatively, with the code being pretty self-contained and relatively short. The documentation definitely also helped, and I could see that Opus understood the code because it gave explanations in the chat afterwards as well. I have attached the results of the VAE and MAML",
            "content_xml": "<document version=\"2.0\"><paragraph/><file url=\"https://static.us.edusercontent.com/files/rob5YPaxms0c9gkOhEknNJ8c\" filename=\"hw12 coding opus.pdf\"/><paragraph>Claude Opus was able to one shot this homework. It didn\u2019t even need any clarifications and was able to also give explanations for its code afterwards. I\u2019m pretty happy with the choice of variable names and the overall cleanliness of the code. I\u2019m not too surprised because I think this homework in particular was quite simple relatively, with the code being pretty self-contained and relatively short. The documentation definitely also helped, and I could see that Opus understood the code because it gave explanations in the chat afterwards as well. I have attached the results of the VAE and MAML</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T15:47:37.754188+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444860,
            "author": "Rohan Gopalam",
            "project_title": "Special Participation A: Opus 4.5 on HW11",
            "post_body": "In this chat, I used Claude Opus 4.5 in its regular reasoning mode to solve the written questions on Homework 11. I first started by prepping the model with this prompt:\n\"Hello Mr. Claude. Today, I will be giving you problems from my deep learning class by submitting screenshots of the problems. I want you to answer these as they come. Do not skip any derivation steps, and clearly output the answer. If there are multiple subparts, clearly answer all the subparts. I want you to clearly rewrite the question and your reasoning and solution for each problem in one single markdown file. Are you ready?\".\n\nI gave the model screenshots of the problems and had it one-shot the answer. By putting all the model responses into one markdown file, it was easy for me to read and to compare against the answer key. The model was consistently arriving at the correct solution. While I expected this for the conceptual questions, I was surprised the level of depth it had when explaining the matrix math for question 2. However, for some questions the model made small mistakes such as incorrect assumptions about the GPU.\n\nUsually when I use LLMs to assist me with homework questions, I tend to give the LLM smaller parts of the question in order, then discuss with the LLM to get hints and solutions, and make sure it makes sense to me. This allows me to both learn the content quicker rather than just being completely lost and also verify the LLM. However, when I gave the LLM the entire problem, it seemed to actually do better than when I would previously give it small parts of the question and continuously ask questions.",
            "content_xml": "<document version=\"2.0\"><paragraph>In this chat, I used Claude Opus 4.5 in its regular reasoning mode to solve the written questions on Homework 11. I first started by prepping the model with this prompt:<break/>\"Hello Mr. Claude. Today, I will be giving you problems from my deep learning class by submitting screenshots of the problems. I want you to answer these as they come. Do not skip any derivation steps, and clearly output the answer. If there are multiple subparts, clearly answer all the subparts. I want you to clearly rewrite the question and your reasoning and solution for each problem in one single markdown file. Are you ready?\".<break/><break/>I gave the model screenshots of the problems and had it one-shot the answer. By putting all the model responses into one markdown file, it was easy for me to read and to compare against the answer key. The model was consistently arriving at the correct solution. While I expected this for the conceptual questions, I was surprised the level of depth it had when explaining the matrix math for question 2. However, for some questions the model made small mistakes such as incorrect assumptions about the GPU.</paragraph><paragraph>Usually when I use LLMs to assist me with homework questions, I tend to give the LLM smaller parts of the question in order, then discuss with the LLM to get hints and solutions, and make sure it makes sense to me. This allows me to both learn the content quicker rather than just being completely lost and also verify the LLM. However, when I gave the LLM the entire problem, it seemed to actually do better than when I would previously give it small parts of the question and continuously ask questions.</paragraph><file url=\"https://static.us.edusercontent.com/files/JsewZjUpP7hKzls0Tq712PUN\" filename=\"Special Participation A_HW11.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T15:31:08.924907+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444671,
            "author": "Ethan Stone",
            "project_title": "Special Participation B: Perplexity Pro on HW 3",
            "post_body": "Executive Summary: \n\nI used Perplexity Pro to solve the Coding Questions of Homework 3. In general Perplexity was quick and accurate, although at times it did seem to produce insufficient answers. Notably it did not hallucinate incorrect answers, but instead simply failed to achieve complete correctness. Additionally, it required some prodding and massaging to get answers in a form that was acceptable, with multiple times requiring follow up prompting. Nevertheless, Perplexity did one-shot nearly all of the questions and performed excellently on the problems presented. My Annotated Conversation can be found here:\n\n\n\nAnd a link to the raw conversation can be found here: \nhttps://www.perplexity.ai/search/read-through-this-entire-codin-Ee40Xpf8R32BBgsUxzCeXQ#3\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive Summary: </paragraph><paragraph>I used Perplexity Pro to solve the Coding Questions of Homework 3. In general Perplexity was quick and accurate, although at times it did seem to produce insufficient answers. Notably it did not hallucinate incorrect answers, but instead simply failed to achieve complete correctness. Additionally, it required some prodding and massaging to get answers in a form that was acceptable, with multiple times requiring follow up prompting. Nevertheless, Perplexity did one-shot nearly all of the questions and performed excellently on the problems presented. My Annotated Conversation can be found here:</paragraph><file url=\"https://static.us.edusercontent.com/files/Dm0DhB853cYvnRmMYegirx8G\" filename=\"Perplexity_HW_3_Code.pdf\"/><paragraph/><paragraph>And a link to the raw conversation can be found here: <break/>https://www.perplexity.ai/search/read-through-this-entire-codin-Ee40Xpf8R32BBgsUxzCeXQ#3</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T14:54:40.604285+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444385,
            "author": "Peidong Zhang",
            "project_title": "Special Participation C: HW12",
            "post_body": "Hi everyone!\n\nI refactored HW12 for special participation C. Below is my .py files on what I changed in the code and why, along with a description of the AI assistance.\n\nThe original MAML and VAE notebook code was transformed into well-structured, documented, and modular Python modules following good software engineering and ML engineering practices, while fully preserving its teaching intent.\n\nThe MAML portion was extracted into maml_refactored.py, where the code was reorganized around clear abstractions such as a MetaClassificationConfig dataclass, a dedicated logistic loss function, and a structured meta-update function with explicit documentation linking directly to the mathematical formulation taught in class. The VAE portion was similarly separated into vae_refactored.py, containing a clean and well-documented implementation of the reparameterization trick, a VAEConfig dataclass for reproducible experiments, and a transparent negative_elbo_bound method whose docstring explicitly explains the ELBO equation and its components.\n\nAcross both files, consistent improvements were made: detailed Google-style docstrings were added, type hints were introduced for clarity, reproducibility helpers such as set_global_seed() were included, and logging infrastructure was standardized. Helper functions were factored into small, easily testable units, and the structure of each module now mirrors standard ML engineering patterns without obscuring the underlying algorithms. Overall, my work results in two high-quality instructional modules that enhance readability, maintainability, and pedagogical value.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!</paragraph><paragraph>I refactored HW12 for special participation C. Below is my .py files on what I changed in the code and why, along with a description of the AI assistance.</paragraph><paragraph>The original MAML and VAE notebook code was transformed into well-structured, documented, and modular Python modules following good software engineering and ML engineering practices, while fully preserving its teaching intent.</paragraph><paragraph>The MAML portion was extracted into <code>maml_refactored.py</code>, where the code was reorganized around clear abstractions such as a <code>MetaClassificationConfig</code> dataclass, a dedicated logistic loss function, and a structured meta-update function with explicit documentation linking directly to the mathematical formulation taught in class. The VAE portion was similarly separated into <code>vae_refactored.py</code>, containing a clean and well-documented implementation of the reparameterization trick, a <code>VAEConfig</code> dataclass for reproducible experiments, and a transparent <code>negative_elbo_bound</code> method whose docstring explicitly explains the ELBO equation and its components.</paragraph><paragraph>Across both files, consistent improvements were made: detailed Google-style docstrings were added, type hints were introduced for clarity, reproducibility helpers such as <code>set_global_seed()</code> were included, and logging infrastructure was standardized. Helper functions were factored into small, easily testable units, and the structure of each module now mirrors standard ML engineering patterns without obscuring the underlying algorithms. Overall, my work results in two high-quality instructional modules that enhance readability, maintainability, and pedagogical value.</paragraph><file url=\"https://static.us.edusercontent.com/files/9RkE1CufAGfAEihaOmTHxONU\" filename=\"maml_refactored.py\"/><file url=\"https://static.us.edusercontent.com/files/tnjDMWIDlZhiJz12zK7geAfD\" filename=\"vae_refactored.py\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T14:06:44.70067+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444311,
            "author": "Peidong Zhang",
            "project_title": "Special Participation B: GPT5-Pro on HW12",
            "post_body": "I use GPT5-Pro to solve HW12 written part in this special participation B.\n\n\n\nFor the MAML notebook, the missing pieces involved implementing the correct loss functions for binary classification tasks. Specifically, the regression-based MSE losses were replaced with the appropriate logistic loss in both the inner-loop task adaptation phase and the outer-loop meta-update phase. This ensured that each task's labels were transformed into {\u22121,+1}form and optimized using a log-likelihood\u2013consistent objective, allowing the meta-learner to adapt effectively to classification tasks. Once these losses were added, the entire MAML workflow\u2014sampling tasks, running inner gradient steps, and performing meta-updates\u2014became fully functional.\n\nFor the VAE notebook, the missing implementations resided in the underlying codebase rather than the notebook itself. The first missing component was the reparameterization trick used to sample latent variables z\u223cq(z\u2223x); this was completed by writing a sample_gaussian function that generates z, where \u03f5 is standard Gaussian noise. The second missing part was the full computation of the negative Evidence Lower Bound (ELBO), which combines the KL divergence between the approximate posterior and the prior with the negative log-likelihood of the data under the decoder\u2019s Bernoulli distribution. Completing the negative_elbo_bound function provided the correct training objective required for VAE optimization and sampling. With these components implemented, the VAE model can now encode images, sample meaningful latent vectors, decode reconstructions, compute ELBO loss, and train end-to-end as intended.",
            "content_xml": "<document version=\"2.0\"><paragraph>I use GPT5-Pro to solve HW12 written part in this special participation B.</paragraph><paragraph/><paragraph>For the MAML notebook, the missing pieces involved implementing the correct loss functions for binary classification tasks. Specifically, the regression-based MSE losses were replaced with the appropriate logistic loss in both the inner-loop task adaptation phase and the outer-loop meta-update phase. This ensured that each task's labels were transformed into {\u22121,+1}form and optimized using a log-likelihood\u2013consistent objective, allowing the meta-learner to adapt effectively to classification tasks. Once these losses were added, the entire MAML workflow\u2014sampling tasks, running inner gradient steps, and performing meta-updates\u2014became fully functional.</paragraph><paragraph>For the VAE notebook, the missing implementations resided in the underlying codebase rather than the notebook itself. The first missing component was the reparameterization trick used to sample latent variables z\u223cq(z\u2223x); this was completed by writing a sample_gaussian function that generates z, where \u03f5 is standard Gaussian noise. The second missing part was the full computation of the negative Evidence Lower Bound (ELBO), which combines the KL divergence between the approximate posterior and the prior with the negative log-likelihood of the data under the decoder\u2019s Bernoulli distribution. Completing the negative_elbo_bound function provided the correct training objective required for VAE optimization and sampling. With these components implemented, the VAE model can now encode images, sample meaningful latent vectors, decode reconstructions, compute ELBO loss, and train end-to-end as intended.</paragraph><file url=\"https://static.us.edusercontent.com/files/NCrjcDRRbGLDVmVVlbg6RgUN\" filename=\"CS282 Special Participation B_ GPT5-Pro on HW12.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T13:53:23.807485+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444253,
            "author": "Ethan Stone",
            "project_title": "Special Participation A: ChatGPT 5.1 Extended Thinking Time on HW 6",
            "post_body": "Executive Summary:\n\nI used ChatGPT 5.1 Extended Think to solve HW 6 Questions 2 and 3 (The Non-Coding Questions). To test the advanced reasoning and memory capabilities of the thinking model, I submitted screenshots of entire questions instead of problems one subpart at a time, prompting the model minimally with the prompt:\n\n\"Please read these screenshots in detail. Your job is to write solutions to each part of this question. Make sure to delineate which subpart you are working on, and make sure to show your work adequately\"\n\nEven with minimal prompting, the model performed highly accurately, essentially one-shotting almost every subpart with no need for follow-up correction. The few issues I found were small algebraic/mechanical slips rather than major conceptual misunderstandings. I did not observe any blatant hallucinations (e.g., made-up definitions or theorems), and when it diverged from the official solution at all its answers were still logically consistent.\n\nThere were two main drawbacks:\n\nThe model took a long time to respond, thinking for over 7 and a half minutes on each of the two big question blocks.\n\nAs many other students have noted, it tended to produce overly verbose solutions where much shorter answers would have sufficed, and it sometimes got bogged down in minor details.\n\nOverall, I would most accurately compare it to a TA in the sense that it generally provides correct reasoning and explanations, but can go on small side tangents, be more long-winded than necessary, and occasionally make small algebraic or notational mistakes that still require human checking.\n\nA link to my detailed annotations can be found here: \n\n\n\nAnd a link to the raw conversation can be found here: https://chatgpt.com/share/6938cd49-4f50-800d-9b68-0d641aa7e76a\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive Summary:</paragraph><paragraph>I used ChatGPT 5.1 Extended Think to solve HW 6 Questions 2 and 3 (The Non-Coding Questions). To test the advanced reasoning and memory capabilities of the thinking model, I submitted screenshots of entire questions instead of problems one subpart at a time, prompting the model minimally with the prompt:<break/><break/>\"Please read these screenshots in detail. Your job is to write solutions to each part of this question. Make sure to delineate which subpart you are working on, and make sure to show your work adequately\"<break/><break/>Even with minimal prompting, the model performed highly accurately, essentially one-shotting almost every subpart with no need for follow-up correction. The few issues I found were small algebraic/mechanical slips rather than major conceptual misunderstandings. I did not observe any blatant hallucinations (e.g., made-up definitions or theorems), and when it diverged from the official solution at all its answers were still logically consistent.</paragraph><paragraph>There were two main drawbacks:</paragraph><list style=\"number\"><list-item><paragraph>The model took a long time to respond, thinking for over 7 and a half minutes on each of the two big question blocks.</paragraph></list-item><list-item><paragraph>As many other students have noted, it tended to produce overly verbose solutions where much shorter answers would have sufficed, and it sometimes got bogged down in minor details.</paragraph></list-item></list><paragraph>Overall, I would most accurately compare it to a TA in the sense that it generally provides correct reasoning and explanations, but can go on small side tangents, be more long-winded than necessary, and occasionally make small algebraic or notational mistakes that still require human checking.<break/><break/>A link to my detailed annotations can be found here: </paragraph><file url=\"https://static.us.edusercontent.com/files/XdGbTnhlkSFt9AYuiGGyayZb\" filename=\"ChatGPT_HW6_Annotated.pdf\"/><paragraph><break/><break/>And a link to the raw conversation can be found here: <link href=\"https://chatgpt.com/share/6938cd49-4f50-800d-9b68-0d641aa7e76a\">https://chatgpt.com/share/6938cd49-4f50-800d-9b68-0d641aa7e76a</link></paragraph><paragraph/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/6938cd49-4f50-800d-9b68-0d641aa7e76a"
            ],
            "attachments": [],
            "created_at": "2025-12-10T13:43:35.193488+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7444212,
            "author": "Peidong Zhang",
            "project_title": "Special Participation A: Qwen on HW13",
            "post_body": "I use Qwen to solve HW13 written part in this special participation A.\n\nQwen's accuracy really impressed me. All questions, including requiring proofs (e.g., induction in diffusion models), derivations (e.g., DPO gradients), or conceptual explanations (e.g., intractability of partition functions), were answered correctly and comprehensively in a single attempt, with no need for clarification or correction. The responses included rigorous mathematical detail, proper notation, and logical step-by-step reasoning.\n\nThere is no factual inaccuracies, fabricated citations, or conceptual errors were observed. For instance:\n\nThe derivation of the optimal policy in DPO correctly recovered the Gibbs form and explained the cancellation of the partition function in Bradley-Terry and Plackett-Luce models.\n\nThe diffusion process proofs aligned exactly with standard results from the literature (e.g., Ho et al., 2020).\n\nInterpretations (e.g., gradient weighting in DPO reflecting model uncertainty) were insightful and technically sound.\n\nDespite minimal input context (only image placeholders uploaded), the model inferred the likely content (standard theoretical ML problems) and provided complete, self-contained solutions, demonstrating strong contextual awareness and domain knowledge. Responses were well-organized, labeled by sub-question, and included boxed final answers where appropriate, enhancing readability and correctness verification.",
            "content_xml": "<document version=\"2.0\"><paragraph>I use Qwen to solve HW13 written part in this special participation A.</paragraph><paragraph>Qwen's accuracy really impressed me. All questions, including requiring proofs (e.g., induction in diffusion models), derivations (e.g., DPO gradients), or conceptual explanations (e.g., intractability of partition functions), were answered correctly and comprehensively in a single attempt, with no need for clarification or correction. The responses included rigorous mathematical detail, proper notation, and logical step-by-step reasoning.</paragraph><paragraph>There is no factual inaccuracies, fabricated citations, or conceptual errors were observed. For instance:</paragraph><list style=\"unordered\"><list-item><paragraph>The derivation of the optimal policy in DPO correctly recovered the Gibbs form and explained the cancellation of the partition function in Bradley-Terry and Plackett-Luce models.</paragraph></list-item><list-item><paragraph>The diffusion process proofs aligned exactly with standard results from the literature (e.g., Ho et al., 2020).</paragraph></list-item><list-item><paragraph>Interpretations (e.g., gradient weighting in DPO reflecting model uncertainty) were insightful and technically sound.</paragraph></list-item></list><paragraph>Despite minimal input context (only image placeholders uploaded), the model inferred the likely content (standard theoretical ML problems) and provided complete, self-contained solutions, demonstrating strong contextual awareness and domain knowledge. Responses were well-organized, labeled by sub-question, and included boxed final answers where appropriate, enhancing readability and correctness verification.</paragraph><file url=\"https://static.us.edusercontent.com/files/CEqBzMExALcfjq4jCeNdzFRc\" filename=\"CS282 Special Participation A_ Qwen on HW13.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T13:38:45.270768+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7443917,
            "author": "Tvisha Londhe",
            "project_title": "Special Participation E: Understanding  FFT Trick in State-Space Models",
            "post_body": "I was struggling to understand how the FFT trick works for State-Space Models (SSMs), especially the idea of viewing the RNN outputs at each time step as sequences evolving component-by-component (this is from lecture 17). To work through the confusion, I drew a diagram and had an extended interaction with ChatGPT, which helped me connect the intuition: each coordinate of the hidden state forms its own time-series, and the FFT lets us convolve these sequences efficiently. I\u2019m sharing my annotated conversation and the diagram here in case it helps anyone else build intuition for how the component-wise viewpoint makes the FFT trick work. I passed in past of my lecture notes as the first prompt. \n\n\nAnnotated pdf: \n\nThis was the final diagram I had: \n\nThis is the trace without any annotations (sorry about any spelling errors!): https://chatgpt.com/share/6938b61a-b838-800f-bd21-b9b7a0b6807b",
            "content_xml": "<document version=\"2.0\"><paragraph>I was struggling to understand how the FFT trick works for State-Space Models (SSMs), especially the idea of viewing the RNN outputs at each time step as sequences evolving component-by-component (this is from lecture 17). To work through the confusion, I drew a diagram and had an extended interaction with ChatGPT, which helped me connect the intuition: each coordinate of the hidden state forms its own time-series, and the FFT lets us convolve these sequences efficiently. I\u2019m sharing my annotated conversation and the diagram here in case it helps anyone else build intuition for how the component-wise viewpoint makes the FFT trick work. I passed in past of my lecture notes as the first prompt. </paragraph><paragraph><break/>Annotated pdf: </paragraph><file url=\"https://static.us.edusercontent.com/files/fqtcGKTY7GuR6BhejoSoLnrX\" filename=\"SpecialParticipationE_FFT_for_SSM_annotated.pdf\"/><paragraph>This was the final diagram I had: </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/dhSAELhs2cOH5jCC6qe97bkM\" width=\"343\" height=\"427\"/></figure><paragraph>This is the trace without any annotations (sorry about any spelling errors!): <link href=\"https://chatgpt.com/share/6938b61a-b838-800f-bd21-b9b7a0b6807b\"><underline>https://chatgpt.com/share/6938b61a-b838-800f-bd21-b9b7a0b6807b</underline></link></paragraph></document>",
            "links": [
                "https://chatgpt.com/share/6938b61a-b838-800f-bd21-b9b7a0b6807b"
            ],
            "attachments": [],
            "created_at": "2025-12-10T12:52:47.853566+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7443764,
            "author": "Micah Mok",
            "project_title": "Special Participation C: HW 12 Question 4",
            "post_body": "Keshab Agarwal and I refactored HW 12 Question 4 to provide robustness to errors, fixed pip dependencies to match modern implementations, added full docstrings and re-formatted code to prevent long one-liners, and removed the implemented code in the TODO sections.\n\nNotably, we followed the SWE principle of separate functions to handle distinct tasks by splitting up functions to provide easy of understanding of GAN vs VAE implementations. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/DdmKWwQ5hRbc9HjUesEDpDsw\" filename=\"cs182hw12.zip\"/><paragraph>Keshab Agarwal and I refactored HW 12 Question 4 to provide robustness to errors, fixed pip dependencies to match modern implementations, added full docstrings and re-formatted code to prevent long one-liners, and removed the implemented code in the TODO sections.<break/><break/>Notably, we followed the SWE principle of separate functions to handle distinct tasks by splitting up functions to provide easy of understanding of GAN vs VAE implementations. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T12:31:30.034284+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7443651,
            "author": "Andy Peng",
            "project_title": "[SPOILER ALERT] Special Participation A: Claude on HW13",
            "post_body": "In this chat, I used Claude 4.5 Sonnet to answer HW13. My prompt is included in the pdf. Overall Claude was able to do pretty well, answering all subproblems fully correctly (in my opinion). This was all one single try. Claude is able to do the first parts of each question very well and provides a very good explanation for each. I'm overall extremely impressed with some of the more complicated problems, such as in part 2b where it shows most of the (lengthy) derivation by minimizing KL. There are some small parts where it skipped intermediate algebraic derivation steps like in 2b for the Lagrange multipliers but overall the performance was quite strong.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/pKF3cCeevXJq5RmHC9p1JDjT\" filename=\"Claude HW13 output.pdf\"/><paragraph>In this chat, I used Claude 4.5 Sonnet to answer HW13. My prompt is included in the pdf. Overall Claude was able to do pretty well, answering all subproblems fully correctly (in my opinion). This was all one single try. Claude is able to do the first parts of each question very well and provides a very good explanation for each. I'm overall extremely impressed with some of the more complicated problems, such as in part 2b where it shows most of the (lengthy) derivation by minimizing KL. There are some small parts where it skipped intermediate algebraic derivation steps like in 2b for the Lagrange multipliers but overall the performance was quite strong.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T12:10:31.430772+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7443595,
            "author": "Keshab Agarwal",
            "project_title": "Special Participation C: Refactoring HW12 Q5",
            "post_body": "Me and Micah Mok worked together to refactor Q5 of HW12 which teaches MAML. We are attaching the zip file containing the refactored implementation of Model-Agnostic Meta-Learning (MAML) for regression and classification tasks. The code has been organized into well-documented utility modules for better maintainability and reusability. \n\nThe Black formatter has been used to break down very long lines into indented sections for easier reliability. The code now follows the Pep 8 Style Guide for Python Code. Some documentation has been added in terms of captions manually as well as using AI to make some long functions easier to understand. The principle of one Python file being responsible for code related to a single task has been used. The README.md in the zip file contains the details of how the new files were created and how the long ipynb file was broken down. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Me and Micah Mok worked together to refactor Q5 of HW12 which teaches MAML. We are attaching the zip file containing the refactored implementation of Model-Agnostic Meta-Learning (MAML) for regression and classification tasks. The code has been organized into well-documented utility modules for better maintainability and reusability. </paragraph><paragraph>The Black formatter has been used to break down very long lines into indented sections for easier reliability. The code now follows the <link href=\"https://peps.python.org/pep-0008/\">Pep 8 Style Guide for Python Code</link>. Some documentation has been added in terms of captions manually as well as using AI to make some long functions easier to understand. The principle of one Python file being responsible for code related to a single task has been used. The README.md in the zip file contains the details of how the new files were created and how the long ipynb file was broken down. </paragraph><file url=\"https://static.us.edusercontent.com/files/PmCS5zYkP0qZG53NVE04VjfI\" filename=\"maml.zip\"/><paragraph/></document>",
            "links": [
                "https://peps.python.org/pep-0008/"
            ],
            "attachments": [],
            "created_at": "2025-12-10T12:03:05.431378+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7443368,
            "author": "Zhuangzhe Wu",
            "project_title": "Special Participation B: Cursor on HW6 Coding Questions",
            "post_body": "I used Cursor on coding problems 5 and 6 in homework 6. Cursor efficiently completed each step, accurately handling tasks such as adding self-loops to the adjacency matrix, implementing symmetric normalization, and generating the feature input matrix for Zachary\u2019s Karate Club graph. When building the GNN layer, Cursor provided correct forward and backward pass implementations, and its results matched the expected outputs. Although there was a minor mistake in the network setup\u2014Cursor\u2019s model had one fewer layer than the reference\u2014the overall implementation was correct and the checks passed. For the Muon optimizer, Cursor successfully implemented Newton-Schulz orthogonalization and the Muon update, following the provided pseudocode and ensuring correct scaling and parameter updates. \n\nIn conclusion, Cursor outputs accurate code, offers helpful explanations, which demonstrates its value as an AI coding assistant for both practical implementation and deeper understanding of machine learning concepts.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Cursor on coding problems 5 and 6 in homework 6. Cursor efficiently completed each step, accurately handling tasks such as adding self-loops to the adjacency matrix, implementing symmetric normalization, and generating the feature input matrix for Zachary\u2019s Karate Club graph. When building the GNN layer, Cursor provided correct forward and backward pass implementations, and its results matched the expected outputs. Although there was a minor mistake in the network setup\u2014Cursor\u2019s model had one fewer layer than the reference\u2014the overall implementation was correct and the checks passed. For the Muon optimizer, Cursor successfully implemented Newton-Schulz orthogonalization and the Muon update, following the provided pseudocode and ensuring correct scaling and parameter updates. </paragraph><paragraph>In conclusion, Cursor outputs accurate code, offers helpful explanations, which demonstrates its value as an AI coding assistant for both practical implementation and deeper understanding of machine learning concepts.</paragraph><file url=\"https://static.us.edusercontent.com/files/3Z4y3jx0C8sdaC8q9NfYJB5Q\" filename=\"cursor.pdf\"/><list style=\"unordered\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T11:28:01.169427+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7443090,
            "author": "E Harrison",
            "project_title": "Special Participation C: Refactoring HW11 Problem 3",
            "post_body": "I refactored and improved the code for HW11's problem 3 on code interpretability!\n\nMost of my changes involve improving the debugging process for this question, but I also standardized the formatting of functions, improved the names of variables, and made interpreting the functions a bit easier.\n\nWhen solving this problem myself, something I found myself repeatedly doing was printing the weights of the matrices I was creating, both when implementing single_attention_head and induction_copy_head. Rather than having to manually print out these matrices each time, I added the utility function plot_weight_heatmap, which displays the weights of the given matrix as a heatmap, making it much easier to visualize. I also added the debug argument to single_attention_head and induction_copy_head. When set to True, it displays the weights of important matrices needed for each function.\n\nAlong with this, I found the variable names used in single_attention_head to be a little confusing on a first look. I changed the names of some of these variables in this function, such as changing Z to scores and XOV to projected_values. \n\nTo make this code more Pythonic, I also added type hinting to each of the functions and standardized the indentation to make the code a bit cleaner.\n\nA link to the repo containing the updated code can be found here: https://github.com/ethanhharrison/special_participation_c_hw11_code_interpretability \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I refactored and improved the code for HW11's problem 3 on code interpretability!</paragraph><paragraph>Most of my changes involve improving the debugging process for this question, but I also standardized the formatting of functions, improved the names of variables, and made interpreting the functions a bit easier.<break/><break/>When solving this problem myself, something I found myself repeatedly doing was printing the weights of the matrices I was creating, both when implementing <code>single_attention_head</code> and <code>induction_copy_head</code>. Rather than having to manually print out these matrices each time, I added the utility function <code>plot_weight_heatmap</code>, which displays the weights of the given matrix as a heatmap, making it much easier to visualize. I also added the <code>debug</code> argument to <code>single_attention_head</code> and <code>induction_copy_head</code>. When set to True, it displays the weights of important matrices needed for each function.<break/><break/>Along with this, I found the variable names used in <code>single_attention_head</code> to be a little confusing on a first look. I changed the names of some of these variables in this function, such as changing <code>Z</code> to <code>scores</code> and <code>XOV</code> to <code>projected_values</code>. <break/><break/>To make this code more Pythonic, I also added type hinting to each of the functions and standardized the indentation to make the code a bit cleaner.<break/><break/>A link to the repo containing the updated code can be found here: <link href=\"https://github.com/ethanhharrison/special_participation_c_hw11_code_interpretability\">https://github.com/ethanhharrison/special_participation_c_hw11_code_interpretability</link> </paragraph><paragraph/></document>",
            "links": [
                "https://github.com/ethanhharrison/special_participation_c_hw11_code_interpretability"
            ],
            "attachments": [],
            "created_at": "2025-12-10T10:48:41.039009+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7442409,
            "author": "Jacqueline Thibault",
            "project_title": "Special Participation B: ChatGPT-5.1 on HW6 Coding Questions",
            "post_body": "Special participation B: ChatGPT-5.1 on HW 6 Coding questions.\n\nThere were five ipynb files in Hw6\u2019s coding assignment. I kept each question in a separate ChatGPT-5.1 tab to maintain better context within each conversation.\n\nFor GPUMemory.ipynb, there was nothing to modify other than running cells and looking at the output, so it didn\u2019t make sense to run this through an LLM.\n\nFor q_coding_muon.ipynb, the LLM initially assumed X was square, and wrote code accordingly:\n\n```\n\nfor _ in range(num_iters):\n\n # Newton\u2013Schulz cubic orthogonalization step:\n\n # X <- (3X - X^3) / 2\n\n X3 = torch.matmul(X, torch.matmul(X, X))\n\n X = (3 * X - X3) / 2\n\n```\n\n However, these dimensions led to:\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (32x27 and 32x27)\n\nUpon telling the LLM about this, it revised its answer to:\n\n```\n\nfor _ in range(num_iters):\n\n # Implement X^3 in a way that works for rectangular X:\n\n # X^3 \u2248 X (X^T X), which has the same effect on singular values\n\n X3 = X @ (X.mT @ X)\n\n # Newton\u2013Schulz cubic step: X <- (3X - X^3) / 2\n\n X = (3 * X - X3) / 2\n\n```\n\nThe resulting code was as expected.\n\nLink to the conversation: https://chatgpt.com/share/69389a42-a1f4-800f-88ab-7494a9f6a2b3\n\nAnnotated Trace: \n\nQ_zkc.ipynb: \n\n Was able to one-shot quite well; I am not surprised by this because the questions are set up nicely from a pedagogical perspective, with \u201cfill in the blank\u201d style code sections throughout. It was also able to answer the question about the plots and respond thoroughly to my follow up questions.\n\nLink to the conversation: https://chatgpt.com/share/69389a5c-21c0-800f-98aa-9d10cd9eb451\n\nAnnotated Trace: \n\nTensorboard.ipynb: \n\n Similar to as in the q_coding_muon.ipynb, the LLM had difficulty with matching dimensionality. I dropped in the one-shot code it suggested, and upon calling run() I got:\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (12288x32 and 3072x2048)\n\nThis error is more drastic than the previous matmul mismatch. I asked ChatGPT-5.1 to fix its error, and it realized that it needed to first flatten the images. I then pasted and ran the new code, which revealed some other small errors that I had to rerun through the LLM. I asked it also specifically for hyperparameter suggestions, and it returned some more code that did indeed yield better results than the initial 2-epoch run. More info in the trace.\n\nLink to the conversation: https://chatgpt.com/share/69389a70-db80-800f-9d6f-4593965786b7\n\nAnnotated trace:\n\nWandb.ipynb:\n\nUpon pasting the first output from ChatGPT-5.1, i ran into an AttributeError, because in ResNetClassifier it defined an init function, first calling super().__init()\n\nWhich was interpreted incorrectly. Upon asking ChatGPT-5.1 what this was about, it discovered its error and recommended me to change it to the correct version, super().__init__()\n\nHowever, this attribute error is stemming from architectures.py, which I did not modify. Fixing these, and paying attention to the LLM\u2019s response about when to resize the images, I was able to get a satisfactory result that ran on wandb, though both test and train accuracies weren\u2019t that high after 3 epochs (~61%).\n\nLink to the conversation: https://chatgpt.com/share/69389a87-fc68-800f-a430-cf1c8ddd533c\n\nAnnotated trace:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Special participation B: ChatGPT-5.1 on HW 6 Coding questions.</paragraph><paragraph>There were five ipynb files in Hw6\u2019s coding assignment. I kept each question in a separate ChatGPT-5.1 tab to maintain better context within each conversation.</paragraph><paragraph>For <bold>GPUMemory.ipynb,</bold> there was nothing to modify other than running cells and looking at the output, so it didn\u2019t make sense to run this through an LLM.</paragraph><paragraph>For <bold>q_coding_muon.ipynb</bold>, the LLM initially assumed X was square, and wrote code accordingly:</paragraph><paragraph>```</paragraph><paragraph>for _ in range(num_iters):</paragraph><paragraph> # Newton\u2013Schulz cubic orthogonalization step:</paragraph><paragraph> # X &lt;- (3X - X^3) / 2</paragraph><paragraph> X3 = torch.matmul(X, torch.matmul(X, X))</paragraph><paragraph> X = (3 * X - X3) / 2</paragraph><paragraph>```</paragraph><paragraph> However, these dimensions led to:</paragraph><paragraph>RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x27 and 32x27)</paragraph><paragraph>Upon telling the LLM about this, it revised its answer to:</paragraph><paragraph>```</paragraph><paragraph>for _ in range(num_iters):</paragraph><paragraph> # Implement X^3 in a way that works for rectangular X:</paragraph><paragraph> # X^3 \u2248 X (X^T X), which has the same effect on singular values</paragraph><paragraph> X3 = X @ (X.mT @ X)</paragraph><paragraph> # Newton\u2013Schulz cubic step: X &lt;- (3X - X^3) / 2</paragraph><paragraph> X = (3 * X - X3) / 2</paragraph><paragraph>```</paragraph><paragraph>The resulting code was as expected.</paragraph><paragraph>Link to the conversation: <link href=\"https://chatgpt.com/share/69389a42-a1f4-800f-88ab-7494a9f6a2b3\">https://chatgpt.com/share/69389a42-a1f4-800f-88ab-7494a9f6a2b3</link></paragraph><paragraph>Annotated Trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/rXxtGwMht3Xzuk9tQ0ZTIPrj\" filename=\"Special participation B_ ChatGPT-5.1 - Google Docs.pdf\"/><paragraph><bold>Q_zkc.ipynb</bold>: </paragraph><paragraph> Was able to one-shot quite well; I am not surprised by this because the questions are set up nicely from a pedagogical perspective, with \u201cfill in the blank\u201d style code sections throughout. It was also able to answer the question about the plots and respond thoroughly to my follow up questions.</paragraph><paragraph>Link to the conversation: <link href=\"https://chatgpt.com/share/69389a5c-21c0-800f-98aa-9d10cd9eb451\">https://chatgpt.com/share/69389a5c-21c0-800f-98aa-9d10cd9eb451</link></paragraph><paragraph>Annotated Trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/NVtYarzsX5LHbcdPwLptCLrd\" filename=\"zkcchat.pdf\"/><paragraph><bold>Tensorboard.ipynb:</bold> </paragraph><paragraph> Similar to as in the q_coding_muon.ipynb, the LLM had difficulty with matching dimensionality. I dropped in the one-shot code it suggested, and upon calling run() I got:</paragraph><paragraph>RuntimeError: mat1 and mat2 shapes cannot be multiplied (12288x32 and 3072x2048)</paragraph><paragraph>This error is more drastic than the previous matmul mismatch. I asked ChatGPT-5.1 to fix its error, and it realized that it needed to first flatten the images. I then pasted and ran the new code, which revealed some other small errors that I had to rerun through the LLM. I asked it also specifically for hyperparameter suggestions, and it returned some more code that did indeed yield better results than the initial 2-epoch run. More info in the trace.</paragraph><paragraph>Link to the conversation: <link href=\"https://chatgpt.com/share/69389a70-db80-800f-9d6f-4593965786b7\">https://chatgpt.com/share/69389a70-db80-800f-9d6f-4593965786b7</link></paragraph><paragraph>Annotated trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/xvW6TCuXyMo8ciOMMoeI21NK\" filename=\"specialb tensorboard.pdf\"/><paragraph><bold>Wandb.ipynb:</bold></paragraph><paragraph>Upon pasting the first output from ChatGPT-5.1, i ran into an AttributeError, because in ResNetClassifier it defined an init function, first calling super().__init()</paragraph><paragraph>Which was interpreted incorrectly. Upon asking ChatGPT-5.1 what this was about, it discovered its error and recommended me to change it to the correct version, super().__init__()</paragraph><paragraph>However, this attribute error is stemming from <link href=\"http://architectures.py\"><underline>architectures.py</underline></link>, which I did not modify. Fixing these, and paying attention to the LLM\u2019s response about when to resize the images, I was able to get a satisfactory result that ran on wandb, though both test and train accuracies weren\u2019t that high after 3 epochs (~61%).</paragraph><paragraph>Link to the conversation: <link href=\"https://chatgpt.com/share/69389a87-fc68-800f-a430-cf1c8ddd533c\">https://chatgpt.com/share/69389a87-fc68-800f-a430-cf1c8ddd533c</link></paragraph><paragraph>Annotated trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/rpSfcgmpeABGYemRcu095RE0\" filename=\"wandb specialb.pdf\"/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/69389a42-a1f4-800f-88ab-7494a9f6a2b3",
                "https://chatgpt.com/share/69389a5c-21c0-800f-98aa-9d10cd9eb451",
                "https://chatgpt.com/share/69389a70-db80-800f-9d6f-4593965786b7",
                "http://architectures.py",
                "https://chatgpt.com/share/69389a87-fc68-800f-a430-cf1c8ddd533c"
            ],
            "attachments": [],
            "created_at": "2025-12-10T09:25:27.933148+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7442045,
            "author": "Jacqueline Thibault",
            "project_title": "Special Participation E: Gemini Gem as a personal tutor for understanding key concepts relating to transformers",
            "post_body": "I created a custom Gemini gem, called Transformer Tutor. It is tailored specifically to be a helpful tutor regarding essential knowledge relating to transformer architecture, setup, and calculations.\n\nI gave it the description: This gem helps students in a deep learning class learn about essential concepts relating to transformers.\n\nAnd the instructions: You are a helpful ai assistant that quizzes students about concepts relating to transformer architecture, setup, and calculations. You will walk through the intuition and breakdown of all the pdfs I uploaded to you in the \"knowledge\" section, periodically pausing and polling the user for understanding via a 1 question quiz. Once the user has demonstrated that they understand the concept, continue going through the material until you decide it is time to poll the user for another question. Do this for all the material, aggregating all the pdfs in a manner that is logical to present.\n\nI uploaded 5 pdfs into the knowledge section; three of them were the lecture notes for lectures 18, 19, and 20, and two of them were helpful notes that students uploaded in the Edstem thread for lectures 16-20. \n\n\nUpon my first pass, I realized that it might not be so helpful for the Transformer Tutor to just start from square 1 concepts. Especially when reviewing for an exam, it would be better if the tutor could assess the user's familiarity with the concepts first, and then tailor its questions to the user's current level of understanding. Thus, I modified the instructions to include:\n\n\"You will first present a brief quiz to the user, in order to assess their knowledge level with the subject (i.e. if they are a beginner and need lots of guidance, or if they are already quite familiar with the concepts and need assistance refining their skills). \"\n\nTo be more effective psychologically and to not baby the user, I also added:\n\"Do not be nice to me, e.g. do not say \"youre on the right track!\" if I'm incorrect. Be firm.\"\n\nI was then able to have a productive and insightful conversation that helped me study transformers.\n\nAttached is the gem: https://gemini.google.com/gem/1fug1WA7K31PUqF5mOxRR8fT6vHf38_w6?usp=sharing\n\nand my annotated trace: \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I created a custom Gemini gem, called Transformer Tutor. It is tailored specifically to be a helpful tutor regarding essential knowledge relating to transformer architecture, setup, and calculations.</paragraph><paragraph>I gave it the description: This gem helps students in a deep learning class learn about essential concepts relating to transformers.</paragraph><paragraph>And the instructions: You are a helpful ai assistant that quizzes students about concepts relating to transformer architecture, setup, and calculations. You will walk through the intuition and breakdown of all the pdfs I uploaded to you in the \"knowledge\" section, periodically pausing and polling the user for understanding via a 1 question quiz. Once the user has demonstrated that they understand the concept, continue going through the material until you decide it is time to poll the user for another question. Do this for all the material, aggregating all the pdfs in a manner that is logical to present.</paragraph><paragraph>I uploaded 5 pdfs into the knowledge section; three of them were the lecture notes for lectures 18, 19, and 20, and two of them were helpful notes that students uploaded in the Edstem thread for lectures 16-20. <break/></paragraph><paragraph>Upon my first pass, I realized that it might not be so helpful for the Transformer Tutor to just start from square 1 concepts. Especially when reviewing for an exam, it would be better if the tutor could assess the user's familiarity with the concepts first, and then tailor its questions to the user's current level of understanding. Thus, I modified the instructions to include:</paragraph><paragraph>\"You will first present a brief quiz to the user, in order to assess their knowledge level with the subject (i.e. if they are a beginner and need lots of guidance, or if they are already quite familiar with the concepts and need assistance refining their skills). \"</paragraph><paragraph>To be more effective psychologically and to not baby the user, I also added:<break/>\"Do not be nice to me, e.g. do not say \"youre on the right track!\" if I'm incorrect. Be firm.\"</paragraph><paragraph>I was then able to have a productive and insightful conversation that helped me study transformers.</paragraph><paragraph>Attached is the gem: https://gemini.google.com/gem/1fug1WA7K31PUqF5mOxRR8fT6vHf38_w6?usp=sharing<break/><break/>and my annotated trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/q74VHPlQQ2I7Qdfo47fGA9yg\" filename=\"special e - Google Docs.pdf\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-10T08:42:11.965779+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7440205,
            "author": "Micah Mok",
            "project_title": "Special Participation A: Qwen on HW 6",
            "post_body": "For Special Participation A, I used the Qwen chat website with the Qwen-Max model.\n\nHere are some highlights:\n\nQwen often uses problem re-stating to find viable solutions to the problem. It establishes the context for the problem by looking at the homework problem, taking into account external sources that are being referenced, and if necessary, feedback, specifically whether to expand or refine its reasoning process.\n\nWhen solving the problem Qwen is able to balance a mixture of possible perspectives, alternately considering the homework author's intent as mentioned in the homework, standard deep learning or linear algebra conventions--- like matrix indexing---, or the user's intentions when provided user feedback. While reasoning line by line to find the most likely way to move forward, the model also occasionally stops and assesses the most logical thing to do, doing brief sanity checks.\n\nFinally, Qwen is unable to read images and so completely hallucinates an answer to question 3) b) (iii). This process is interesting because it highlights Qwen's bias towards providing conservative answers that follow the pre-existing corpus of homeworks/literature, and then towards solving something on its own. Interestingly enough, Qwen never asked for further elaboration or for help even when told that it got answers completely wrong.\n\nI've attached the annotated transcript. Here is the official link to the conversation.\n\nThanks!\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation A, I used the Qwen chat website with the Qwen-Max model.</paragraph><paragraph>Here are some highlights:<break/><break/>Qwen often uses problem re-stating to find viable solutions to the problem. It establishes the context for the problem by looking at the homework problem, taking into account external sources that are being referenced, and if necessary, feedback, specifically whether to expand or refine its reasoning process.</paragraph><paragraph>When solving the problem Qwen is able to balance a mixture of possible perspectives, alternately considering the homework author's intent as mentioned in the homework, standard deep learning or linear algebra conventions--- like matrix indexing---, or the user's intentions when provided user feedback. While reasoning line by line to find the most likely way to move forward, the model also occasionally stops and assesses the most logical thing to do, doing brief sanity checks.</paragraph><paragraph>Finally, Qwen is unable to read images and so completely hallucinates an answer to question 3) b) (iii). This process is interesting because it highlights Qwen's bias towards providing conservative answers that follow the pre-existing corpus of homeworks/literature, and then towards solving something on its own. Interestingly enough, Qwen never asked for further elaboration or for help even when told that it got answers completely wrong.<break/><break/>I've attached the annotated transcript. Here is the official <link href=\"https://chat.qwen.ai/s/4ab9c586-aec0-4a89-aa50-b022f7a94205?fev=0.1.13\">link</link> to the conversation.</paragraph><file url=\"https://static.us.edusercontent.com/files/Iy3mznyUIQ2EkX3XwjEM53Cd\" filename=\"A_ Qwen HW6 Written.pdf\"/><paragraph>Thanks!</paragraph><paragraph/></document>",
            "links": [
                "https://chat.qwen.ai/s/4ab9c586-aec0-4a89-aa50-b022f7a94205?fev=0.1.13"
            ],
            "attachments": [],
            "created_at": "2025-12-10T04:47:08.696964+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439138,
            "author": "Sufjan Fana",
            "project_title": "Special Participation E: AI-Assisted GCN Tutor and Quiz (Annotated GNN Study Log)",
            "post_body": "In this post I\u2019m sharing an AI-assisted study trace for the Graph Neural Networks (GNN) lecture in CS 182. I used a large language model as a \u201cGCN tutor\u201d and asked it to (1) explain graphs, message passing, and the standard GCN layer, (2) work through a fully numeric one-layer GCN example on a tiny 3-node graph, (3) generate a short quiz about GNNs/GCNs, and (4) critique its own explanations.\n\nThe attached transcript is annotated by me. In the annotations I mark where the explanations are correct and helpful, where the math or terminology is sloppy or misleading (for example around normalization and self-loops), and where the model makes speculative claims about what CS 182 covers. My goal is to give a reusable prompt sequence plus a critically evaluated log that classmates can use to check their understanding of GCNs, while also seeing concrete examples of where LLM explanations need to be double-checked rather than trusted blindly.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>In this post I\u2019m sharing an AI-assisted study trace for the Graph Neural Networks (GNN) lecture in CS 182. I used a large language model as a \u201cGCN tutor\u201d and asked it to (1) explain graphs, message passing, and the standard GCN layer, (2) work through a fully numeric one-layer GCN example on a tiny 3-node graph, (3) generate a short quiz about GNNs/GCNs, and (4) critique its own explanations.</paragraph><paragraph>The attached transcript is annotated by me. In the annotations I mark where the explanations are correct and helpful, where the math or terminology is sloppy or misleading (for example around normalization and self-loops), and where the model makes speculative claims about what CS 182 covers. My goal is to give a reusable prompt sequence plus a critically evaluated log that classmates can use to check their understanding of GCNs, while also seeing concrete examples of where LLM explanations need to be double-checked rather than trusted blindly.</paragraph><file url=\"https://static.us.edusercontent.com/files/MA5UDIWNMUmoMQaUMndiMVcn\" filename=\"GCN basics and update rule .pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T23:42:53.979557+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439077,
            "author": "Gabriel Han",
            "project_title": "Special Participation E: Gemini Guided Learning vs Youlearn",
            "post_body": "I conducted a comparison between Gemini Guided Learning and the startup YouLearn to prepare for content on Hw 12 focusing on Transformers and Variational Methods. Gemini effectively functioned as a graduate-level Teaching Assistant by first generating a precise prompt that targeted specific homework nuances, such as the weight initialization bug in Encoder-Decoder architectures. It then leveraged this context to produce deep, scenario-based questions, including an interactive quiz on the mode-seeking behavior of Reverse KL Divergence. In contrast, while YouLearn provided a polished user interface with automated flashcards and quizzes, the assessment it generated was primarily recall-oriented\u2014asking basic definitions like the properties of KL divergence\u2014rather than testing the applied understanding required for this course.\n\nI also evaluated YouLearn's content synthesis capabilities by uploading a lecture transcript on Generative Models and the Manifold Hypothesis. The platform organized the text into chapters and offered study aids like summaries and podcasts. Although the summary was nice, I found that this level of summarization could be achieved just as effectively by pasting the transcript into Gemini. While YouLearn's feature set and UI are good to genearte different forms of study quickly, Gemini's ability to engage with the material and ask deeper questions made it a superior tool for this class.",
            "content_xml": "<document version=\"2.0\"><paragraph>I conducted a comparison between Gemini Guided Learning and the startup YouLearn to prepare for content on Hw 12 focusing on Transformers and Variational Methods. Gemini effectively functioned as a graduate-level Teaching Assistant by first generating a precise prompt that targeted specific homework nuances, such as the weight initialization bug in Encoder-Decoder architectures. It then leveraged this context to produce deep, scenario-based questions, including an interactive quiz on the mode-seeking behavior of Reverse KL Divergence. In contrast, while YouLearn provided a polished user interface with automated flashcards and quizzes, the assessment it generated was primarily recall-oriented\u2014asking basic definitions like the properties of KL divergence\u2014rather than testing the applied understanding required for this course.</paragraph><paragraph>I also evaluated YouLearn's content synthesis capabilities by uploading a lecture transcript on Generative Models and the Manifold Hypothesis. The platform organized the text into chapters and offered study aids like summaries and podcasts. Although the summary was nice, I found that this level of summarization could be achieved just as effectively by pasting the transcript into Gemini. While YouLearn's feature set and UI are good to genearte different forms of study quickly, Gemini's ability to engage with the material and ask deeper questions made it a superior tool for this class.</paragraph><file url=\"https://static.us.edusercontent.com/files/4GCqECorJyAcbg3Pt9gzT7dS\" filename=\"Special Participation E No 2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T22:07:31.176465+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439063,
            "author": "Gabriel Han",
            "project_title": "Special Participation E: Transcript of video to notes and test questions",
            "post_body": "To create an active AI-enhanced learning tool, I utilized Gemini to process a lecture on Variational Autoencoders and Post-Training. Since UC Berkeley lecture videos are often restricted by authentication, standard URL-based summarizers do not work; my workaround was to manually copy the raw transcript from the video player and paste it into Gemini. I prompted the model to transform the disorganized spoken text into a structured summary and generate 10 test questions to gauge understanding. This effectively turned a passive, linear transcript into an interactive study guide that I could use to simulate an exam environment immediately after the lecture.\n\nThe AI performed exceptionally well at taking the long context and shortening it quickly. It is also super easy and quick to copy the transcript into gemini (10 seconds). It did particularly well at structuring the summary despite not having any video context and the captions being quite disorganized. It also was able to act as context for any additional questions I wanted to ask. ",
            "content_xml": "<document version=\"2.0\"><paragraph>To create an active AI-enhanced learning tool, I utilized Gemini to process a lecture on Variational Autoencoders and Post-Training. Since UC Berkeley lecture videos are often restricted by authentication, standard URL-based summarizers do not work; my workaround was to manually copy the raw transcript from the video player and paste it into Gemini. I prompted the model to transform the disorganized spoken text into a structured summary and generate 10 test questions to gauge understanding. This effectively turned a passive, linear transcript into an interactive study guide that I could use to simulate an exam environment immediately after the lecture.</paragraph><paragraph>The AI performed exceptionally well at taking the long context and shortening it quickly. It is also super easy and quick to copy the transcript into gemini (10 seconds). It did particularly well at structuring the summary despite not having any video context and the captions being quite disorganized. It also was able to act as context for any additional questions I wanted to ask. </paragraph><file url=\"https://static.us.edusercontent.com/files/peI3UzhIZhqQzh0RakL9fyWK\" filename=\"Special Participation E No 1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T21:48:26.476833+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439048,
            "author": "Gabriel Han",
            "project_title": "Special Participation B: Gemini Pro on Hw 12",
            "post_body": "Performance Summary: AI Assistance on MAML and VAE Homework\n\nOverall, the AI demonstrated high technical competence in implementing complex machine learning algorithms (MAML and VAE) and deriving mathematical justifications. However, the experience varied significantly depending on the file format and context available to the model.\n\n1. Strong Performance in VS Code (Python Files)\n\nThe AI excelled when working with standard Python files (.py) within the VS Code environment.\n\nContext Awareness: In the VAE task, the AI successfully read and synthesized context from multiple files (vae.py and utils.py). It correctly identified where helper functions were needed and how they fit into the main class structure.\n\nCode Generation: The generated code for the Reparameterization Trick (sample_gaussian) and the ELBO objective (negative_elbo_bound) was syntactically correct and mathematically accurate on the first attempt.\n\nResult: The code worked perfectly without debugging, achieving the expected NELBO scores and successfully generating digit reconstructions.\n\n2. Limitations with Jupyter Notebooks (Visual Analysis)\n\nThe AI struggled significantly with the analysis portion of the MAML assignment inside the Jupyter Notebook.\n\nVisual Blindness: The model could not \"see\" the matplotlib plots generated in the notebook cells (e.g., Regression Test Loss vs. n_train_post). Consequently, it failed to answer questions asking for visual comparisons between the \"Init,\" \"Oracle,\" and \"Meta-Learned\" curves.\n\nUser Intervention Required: I need to manually copy-paste the questions and provide descriptive context about the plots. Once the text-based context was provided, the AI successfully deduced the correct theoretical answers \n\n3. Verdict on Code Logic\n\nDespite the interface limitations regarding images, the actual code implementation was flawless.\n\nMAML Classification: The AI correctly adapted the regression code for classification, implementing the Softplus function for numerical stability and correctly calculating the logistic loss.\n\nTheoretical Understanding: Once prompted with the correct text, the AI provided deep insights into why meta-learning drives specific feature weights to zero (feature selection) and how the model mimics the Oracle.",
            "content_xml": "<document version=\"2.0\"><heading level=\"3\">Performance Summary: AI Assistance on MAML and VAE Homework</heading><paragraph>Overall, the AI demonstrated high technical competence in implementing complex machine learning algorithms (MAML and VAE) and deriving mathematical justifications. However, the experience varied significantly depending on the file format and context available to the model.</paragraph><heading level=\"4\">1. Strong Performance in VS Code (Python Files)</heading><paragraph>The AI excelled when working with standard Python files (<code>.py</code>) within the VS Code environment.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Context Awareness:</bold> In the <bold>VAE</bold> task, the AI successfully read and synthesized context from multiple files (<code>vae.py</code> and <code>utils.py</code>). It correctly identified where helper functions were needed and how they fit into the main class structure.</paragraph></list-item><list-item><paragraph><bold>Code Generation:</bold> The generated code for the <bold>Reparameterization Trick</bold> (<code>sample_gaussian</code>) and the <bold>ELBO objective</bold> (<code>negative_elbo_bound</code>) was syntactically correct and mathematically accurate on the first attempt.</paragraph></list-item><list-item><paragraph><bold>Result:</bold> The code worked perfectly without debugging, achieving the expected NELBO scores and successfully generating digit reconstructions.</paragraph></list-item></list><heading level=\"4\">2. Limitations with Jupyter Notebooks (Visual Analysis)</heading><paragraph>The AI struggled significantly with the analysis portion of the <bold>MAML</bold> assignment inside the Jupyter Notebook.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Visual Blindness:</bold> The model could not \"see\" the matplotlib plots generated in the notebook cells (e.g., Regression Test Loss vs. <code>n_train_post</code>). Consequently, it failed to answer questions asking for visual comparisons between the \"Init,\" \"Oracle,\" and \"Meta-Learned\" curves.</paragraph></list-item><list-item><paragraph><bold>User Intervention Required:</bold> I need to manually copy-paste the questions and provide descriptive context about the plots. Once the text-based context was provided, the AI successfully deduced the correct theoretical answers </paragraph></list-item></list><heading level=\"4\">3. Verdict on Code Logic</heading><paragraph>Despite the interface limitations regarding images, the <bold>actual code implementation was flawless</bold>.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>MAML Classification:</bold> The AI correctly adapted the regression code for classification, implementing the <code>Softplus</code> function for numerical stability and correctly calculating the logistic loss.</paragraph></list-item><list-item><paragraph><bold>Theoretical Understanding:</bold> Once prompted with the correct text, the AI provided deep insights into why meta-learning drives specific feature weights to zero (feature selection) and how the model mimics the Oracle.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/MM5MrVI1xvfD7IpQkiKVkj6l\" filename=\"Special Participation B.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T21:26:11.874138+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439035,
            "author": "Sriram Srivatsan",
            "project_title": "Special Participation E: LLM Architecture Explorer",
            "post_body": "For this activity, I used an LLM as an \"Architecture Explorer\" to walk me through how deep learning models evolve from simple CNNs to ResNets and then to Transformer encoder blocks. The model gave structured explanations (dataflow, receptive field, parameter sharing, inductive bias) and paired them with PyTorch-style code for each architecture. Throughout the transcript, I added short _Annotation_ comments where I pointed out places that were especially clear or practically useful, as well as spots that felt oversimplified or a bit overconfident. The goal is for this to act like an AI-powered pre/post-lecture reading: something you can skim to get intuition and code patterns, while my annotations flag what to trust fully and where to be a bit skeptical.\n\n\n\nUsing Sonnet 4.5:\n\nHere is the starting prompt:\n\nHere is the annotated chat history:",
            "content_xml": "<document version=\"2.0\"><paragraph>For this activity, I used an LLM as an \"Architecture Explorer\" to walk me through how deep learning models evolve from simple CNNs to ResNets and then to Transformer encoder blocks. The model gave structured explanations (dataflow, receptive field, parameter sharing, inductive bias) and paired them with PyTorch-style code for each architecture. Throughout the transcript, I added short _Annotation_ comments where I pointed out places that were especially clear or practically useful, as well as spots that felt oversimplified or a bit overconfident. The goal is for this to act like an AI-powered pre/post-lecture reading: something you can skim to get intuition and code patterns, while my annotations flag what to trust fully and where to be a bit skeptical.</paragraph><paragraph/><paragraph>Using Sonnet 4.5:</paragraph><paragraph>Here is the starting prompt:</paragraph><file url=\"https://static.us.edusercontent.com/files/0ajG8sn1heAc3cBLrdkdGkHn\" filename=\"starting_prompt.txt\"/><paragraph>Here is the annotated chat history:</paragraph><file url=\"https://static.us.edusercontent.com/files/rfGliDTalfGr6vBN8LAoalFb\" filename=\"chat_history.md\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T21:14:46.048877+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439033,
            "author": "Sriram Srivatsan",
            "project_title": "Special Participation E: Optimizer Intuition Tutor",
            "post_body": "This artifact is an AI-powered \"Optimizer Intuition Tutor\" built around a simple 2D quadratic toy model to visualize how SGD, Momentum, Adam, and \u03bcP actually move in parameter space. It walks through local linear approximations, update directions, and full numerical trajectories, with ASCII sketches to make the geometry concrete. Throughout the conversation, I push back on the model\u2019s claims (e.g., \"implicit l_2 regularization\" for SGD, Adam always normalizing to [1,1], and overly simple \u03bcP rules) and the tutor corrects or refines its explanations. I\u2019ve added brief annotations at key points to flag where the reasoning is especially insightful, where it\u2019s oversimplified or only true in special cases, and how it connects to what people actually see in modern deep learning training.\n\n\n\nUsing Sonnet 4.5:\n\nPrompt to give (CoT prompting):\n\nAnnotated chat history:",
            "content_xml": "<document version=\"2.0\"><paragraph>This artifact is an AI-powered \"Optimizer Intuition Tutor\" built around a simple 2D quadratic toy model to visualize how SGD, Momentum, Adam, and \u03bcP actually move in parameter space. It walks through local linear approximations, update directions, and full numerical trajectories, with ASCII sketches to make the geometry concrete. Throughout the conversation, I push back on the model\u2019s claims (e.g., \"implicit l_2 regularization\" for SGD, Adam always normalizing to [1,1], and overly simple \u03bcP rules) and the tutor corrects or refines its explanations. I\u2019ve added brief annotations at key points to flag where the reasoning is especially insightful, where it\u2019s oversimplified or only true in special cases, and how it connects to what people actually see in modern deep learning training.</paragraph><paragraph/><paragraph>Using Sonnet 4.5:</paragraph><paragraph>Prompt to give (CoT prompting):</paragraph><file url=\"https://static.us.edusercontent.com/files/P55R48PlyByXZ4C4nhIdgfcz\" filename=\"starting_prompt.txt\"/><paragraph>Annotated chat history:</paragraph><file url=\"https://static.us.edusercontent.com/files/7Ge9koAVt0Tyido59ZxRtVl3\" filename=\"chat_history.md\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T21:12:59.767056+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7439003,
            "author": "Jaewon Chang",
            "project_title": "Special Participation E: NoteRefiner-OCR on Adam",
            "post_body": "I wanted to come up with a prompt that could easily be copy pasted by anyone into a chatbot (I used GPT 5.1 Auto), such that it would make the chatbot take on the persona of a note refiner. I wanted to see if prompting could make GPT 5.1 refine the class notes on the Adam optimizer, and this is the prompt I used:\n\n\nYou are NoteRefiner-OCR, an AI tutor that helps me learn from handwritten or lightly structured lecture notes. I will paste screenshots or PDF snippets from my handwritten notes (e.g., exported from Goodnotes). Treat the content as potentially noisy or incomplete. When I provide an image or OCR text, follow the steps below. After each numbered section, stop and wait for me to say \u201ccontinue.\u201d Transcription + Confidence Annotations (OCR Step) Transcribe the handwritten notes as accurately as possible. For any words, symbols, equations, or diagrams that appear unclear, annotate with: [low confidence: ...] Do NOT guess or fill gaps yet. Just transcribe and identify uncertainty. Clean Reconstruction Rewrite my notes in a clean, structured form: fix notation fix grammar reorder content logically keep ambiguous parts flagged Do not add new information yet. Gap Fill + Clarification (Adam-Specific) Fill in missing steps only where the notes clearly imply them. Provide short clarifications for: the meaning of Adam\u2019s moment estimates bias correction the update rule any partial equations Flag any additions with [Refinement] so I know they came from you. Core Insight Extraction Summarize the 3\u20135 essential ideas from my notes about Adam, such as: conceptual role of m_t and v_t why bias correction matters intuition behind adaptive learning rates differences from SGD and RMSProp Keep this grounded in my notes. Deepening Layer (Optional Additions) Based on the content of my notes, add short expansions that provide deeper intuition. Examples: geometric intuition, hyperparameter effects, limitations. Mark every addition with [Expansion]. Worked Numerical Example Give a simple numerical example of an Adam update: choose small g_t, m_{t-1}, v_{t-1} compute m_t, v_t, m_hat_t, v_hat_t compute the parameter update Show all steps clearly. Misconception Check Identify 2\u20133 likely misconceptions based on my notes and your refinements. Provide a correction and a short explanation for each. Reflection Questions Give me: 2 questions testing basic comprehension 1 question testing deeper intuition Ask me: \u201cPlease upload or paste your handwritten notes page.\u201d\n\nAnnotated google drive link: https://drive.google.com/file/d/1a_KhKekMZnZA_m7fp_z7SVY1j5uOBho6/view?usp=sharing\n\nI also worked on another prompt engineering project for my other special participation E, and I was intrigued by how different both prompts were in terms of robustness. For the above prompt in particular, I noticed that asking a follow-up question to one of its generated responses ends up distracting the model enough to where it forgets to execute the main pipeline (i.e. waiting for the user to say \"continue\" before actually continuing on). Although there were 7 parts that my prompt was trying to get the model to generate, after the model ended up forgetting the pipeline after the 4th part, I ended the conversation.\n\nThat being said, I think there are several good/interesting parts about this prompting method. For starters, it first begins by prompting the model to perform OCR on handwritten notes, so it is fully aware that the task at hand is to identify handwritten text. It also makes no assumptions about what is written: if it is unable to read the handwriting for instance, it will mention that it is unclear about that specific portion. Overall, it seems like there definitely could be a bit more prompt engineering to be done to make the model more robust to follow-up questions, but this definitely seems like a good starting point!",
            "content_xml": "<document version=\"2.0\"><paragraph>I wanted to come up with a prompt that could easily be copy pasted by anyone into a chatbot (I used GPT 5.1 Auto), such that it would make the chatbot take on the persona of a note refiner. I wanted to see if prompting could make GPT 5.1 refine the class notes on the Adam optimizer, and this is the prompt I used:<break/></paragraph><paragraph>You are NoteRefiner-OCR, an AI tutor that helps me learn from handwritten or lightly structured lecture notes. I will paste screenshots or PDF snippets from my handwritten notes (e.g., exported from Goodnotes). Treat the content as potentially noisy or incomplete. When I provide an image or OCR text, follow the steps below. After each numbered section, stop and wait for me to say \u201ccontinue.\u201d Transcription + Confidence Annotations (OCR Step) Transcribe the handwritten notes as accurately as possible. For any words, symbols, equations, or diagrams that appear unclear, annotate with: [low confidence: ...] Do NOT guess or fill gaps yet. Just transcribe and identify uncertainty. Clean Reconstruction Rewrite my notes in a clean, structured form: fix notation fix grammar reorder content logically keep ambiguous parts flagged Do not add new information yet. Gap Fill + Clarification (Adam-Specific) Fill in missing steps only where the notes clearly imply them. Provide short clarifications for: the meaning of Adam\u2019s moment estimates bias correction the update rule any partial equations Flag any additions with [Refinement] so I know they came from you. Core Insight Extraction Summarize the 3\u20135 essential ideas from my notes about Adam, such as: conceptual role of m_t and v_t why bias correction matters intuition behind adaptive learning rates differences from SGD and RMSProp Keep this grounded in my notes. Deepening Layer (Optional Additions) Based on the content of my notes, add short expansions that provide deeper intuition. Examples: geometric intuition, hyperparameter effects, limitations. Mark every addition with [Expansion]. Worked Numerical Example Give a simple numerical example of an Adam update: choose small g_t, m_{t-1}, v_{t-1} compute m_t, v_t, m_hat_t, v_hat_t compute the parameter update Show all steps clearly. Misconception Check Identify 2\u20133 likely misconceptions based on my notes and your refinements. Provide a correction and a short explanation for each. Reflection Questions Give me: 2 questions testing basic comprehension 1 question testing deeper intuition Ask me: \u201cPlease upload or paste your handwritten notes page.\u201d</paragraph><file url=\"https://static.us.edusercontent.com/files/SEXPn3GbivEFBaNZdOHO5FFF\" filename=\"182 participation E (2).pdf\"/><paragraph>Annotated google drive link: https://drive.google.com/file/d/1a_KhKekMZnZA_m7fp_z7SVY1j5uOBho6/view?usp=sharing</paragraph><paragraph>I also worked on another prompt engineering project for my other special participation E, and I was intrigued by how different both prompts were in terms of robustness. For the above prompt in particular, I noticed that asking a follow-up question to one of its generated responses ends up distracting the model enough to where it forgets to execute the main pipeline (i.e. waiting for the user to say \"continue\" before actually continuing on). Although there were 7 parts that my prompt was trying to get the model to generate, after the model ended up forgetting the pipeline after the 4th part, I ended the conversation.</paragraph><paragraph>That being said, I think there are several good/interesting parts about this prompting method. For starters, it first begins by prompting the model to perform OCR on handwritten notes, so it is fully aware that the task at hand is to identify handwritten text. It also makes no assumptions about what is written: if it is unable to read the handwriting for instance, it will mention that it is unclear about that specific portion. Overall, it seems like there definitely could be a bit more prompt engineering to be done to make the model more robust to follow-up questions, but this definitely seems like a good starting point!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T20:32:22.510868+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7438943,
            "author": "Natalie Wei",
            "project_title": "Special Participation E: Using ChatGPT to Verify Research Claims",
            "post_body": "Overview\n\nI engaged ChatGPT 5.1 as an AI-powered tool to help double-check my understanding of research papers, both when reading someone else\u2019s work and when writing my own. I would prompt ChatGPT with a claim along with a reference paper and ask it to determine whether or not the paper supported the claim, supplying relevant textual evidence when it did. I find that papers can be pretty dense and hard to understand on a first pass. This approach was especially helpful for finding specific passages to serve as clear starting points for deeper reading, without replacing the need to engage with the original paper. This tool may be useful in the upcoming round of peer reviews (with another layer of human verification, of course). \n\nI also found this tool useful for verifying whether my own group\u2019s literature review contained interpretations of papers that were sufficiently grounded in the authors\u2019 actual statements. One thing that I learned from ChatGPT\u2019s responses was that we tended to generalize the claims we made in the literature review, even if those claims were made under very specific conditions. We can perhaps work on improving this in subsequent rounds of revision. \n\nAnnotated Logs\n\nLink",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Overview</bold></paragraph><paragraph>I engaged ChatGPT 5.1 as an AI-powered tool to help double-check my understanding of research papers, both when reading someone else\u2019s work and when writing my own. I would prompt ChatGPT with a claim along with a reference paper and ask it to determine whether or not the paper supported the claim, supplying relevant textual evidence when it did. I find that papers can be pretty dense and hard to understand on a first pass. This approach was especially helpful for finding specific passages to serve as clear starting points for deeper reading, without replacing the need to engage with the original paper. This tool may be useful in the upcoming round of peer reviews (with another layer of human verification, of course). </paragraph><paragraph>I also found this tool useful for verifying whether my own group\u2019s literature review contained interpretations of papers that were sufficiently grounded in the authors\u2019 actual statements. One thing that I learned from ChatGPT\u2019s responses was that we tended to generalize the claims we made in the literature review, even if those claims were made under very specific conditions. We can perhaps work on improving this in subsequent rounds of revision. </paragraph><paragraph><bold>Annotated Logs</bold></paragraph><paragraph><link href=\"https://drive.google.com/file/d/1DKwh-omjL_AKkhU9SxZM6p4zlLKLMza-/view?usp=sharing\">Link</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1DKwh-omjL_AKkhU9SxZM6p4zlLKLMza-/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-09T19:36:04.257646+11:00",
            "category": "Admin"
        },
        {
            "guid": 7438890,
            "author": "Alena Chao",
            "project_title": "Special Participation C: HW4 Q6",
            "post_body": "Natalie Wei and I refactored the notebook for HW4 Question 6 to be more modularized and streamlined. Changes include moving most predefined function and class definitions to different files in a src folder so that the notebook only has the most important context and TODOs for the student.\n\nEdited Code: https://github.com/alenachao/cs182-participation\n\nReport: ",
            "content_xml": "<document version=\"2.0\"><paragraph>Natalie Wei and I refactored the notebook for HW4 Question 6 to be more modularized and streamlined. Changes include moving most predefined function and class definitions to different files in a src folder so that the notebook only has the most important context and TODOs for the student.</paragraph><paragraph>Edited Code: https://github.com/alenachao/cs182-participation</paragraph><paragraph>Report: </paragraph><file url=\"https://static.us.edusercontent.com/files/LQFWTpo8iHd1FvyCFJ29k8YS\" filename=\"CS182_Special_Participation_C.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T19:08:01.488953+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7438870,
            "author": "Evan Davis",
            "project_title": "Special Participation B: ChatGPT-5 (Regular) on Homework 12",
            "post_body": "Done as reflected on the deconflict sheet.\n\nChatGPT was was able to easily solve the coding questions on this Homework without any external guidance as long as provided all the relevant context. I uploaded the homework pdf, and for each coding question involving a notebook or writing code in Python files, I uploaded the relevant Python files and .ipynb notebooks. I then told it to solve the questions of course.\n\nHere is a link to the conversation: https://chatgpt.com/share/6937a9b2-6d48-800d-b33e-ac9c536afb57\n\nQuestion 1: This question was a written question where we were given code for a transformer and asked to debug it \"with pen and paper\", rather than a literal coding question involving .ipynb or .py files. Its original answer was rather lengthy given the fact that the problem requested a brief description of the bug, brief fix, and brief justification for the fix, but it remembered to provide trimmed answers at the end.\n\nQuestion 4: When I did this question myself, it ran properly without me having to modify any of the code in the other files; it seemed the two functions we were meant to code were already implemented. ChatGPT says as much, recommending that the final function code is functionally identical to what already existed in the file. So, it works just fine.\n\nQuestion 5(c): I interpreted this part as a coding question. After reasoning through some math, GPT generated code that successfully ran and generated plots as the question asked.\n\nQuestion 5(d)-onwards: ChatGPT's recommended code successfully ran, generating reasonable output comparable to my solution.\n\nI attached a transcript with a few annotations. They are comments on the PDF. I also uploaded this annotated transcript to Grade, although I'm not sure if these annotations are properly viewable there. Staff, please advise if there is something else I should do.",
            "content_xml": "<document version=\"2.0\"><paragraph>Done as reflected on the deconflict sheet.</paragraph><paragraph>ChatGPT was was able to easily solve the coding questions on this Homework without any external guidance as long as provided all the relevant context. I uploaded the homework pdf, and for each coding question involving a notebook or writing code in Python files, I uploaded the relevant Python files and .ipynb notebooks. I then told it to solve the questions of course.</paragraph><paragraph>Here is a link to the conversation: <link href=\"https://chatgpt.com/share/6937a9b2-6d48-800d-b33e-ac9c536afb57\">https://chatgpt.com/share/6937a9b2-6d48-800d-b33e-ac9c536afb57</link></paragraph><paragraph><bold>Question 1:</bold> This question was a written question where we were given code for a transformer and asked to debug it \"with pen and paper\", rather than a literal coding question involving .ipynb or .py files. Its original answer was rather lengthy given the fact that the problem requested a brief description of the bug, brief fix, and brief justification for the fix, but it remembered to provide trimmed answers at the end.</paragraph><paragraph><bold>Question 4:</bold> When I did this question myself, it ran properly without me having to modify any of the code in the other files; it seemed the two functions we were meant to code were already implemented. ChatGPT says as much, recommending that the final function code is functionally identical to what already existed in the file. So, it works just fine.</paragraph><paragraph><bold>Question 5(c):</bold> I interpreted this part as a coding question. After reasoning through some math, GPT generated code that successfully ran and generated plots as the question asked.</paragraph><paragraph><bold>Question 5(d)-onwards:</bold> ChatGPT's recommended code successfully ran, generating reasonable output comparable to my solution.</paragraph><paragraph>I attached a transcript with a few annotations. They are comments on the PDF. I also uploaded this annotated transcript to Grade, although I'm not sure if these annotations are properly viewable there. Staff, please advise if there is something else I should do.</paragraph><file url=\"https://static.us.edusercontent.com/files/5xbiDxjeJ8adizM5uLCTVzFy\" filename=\"spepart b.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/6937a9b2-6d48-800d-b33e-ac9c536afb57"
            ],
            "attachments": [],
            "created_at": "2025-12-09T18:58:40.731839+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7438744,
            "author": "Garv Goswami",
            "project_title": "Special Participation E - Gemini Pro HW Walkthroughs; Detailed and Personalized Prompt Optimization Through Human Feedback",
            "post_body": "For Homework 2, I used Gemini Pro as a highly adaptive tutor, but I didn\u2019t just passively receive explanations; I actively shaped  how it taught me until it produced an ideal prompt that other students could also use. \n\nI repeatedly asked Gemini to slow down, restate questions, define jargon before using it, and force me to reason through each step instead of dumping full solutions. Whenever its explanations were too abstract or too fast, I guided it to introduce analogies, numerical examples, and geometric intuition, especially for difficult concepts like inductive bias, optimizer trajectories, or initialization variance. \n\nThrough this back-and-forth, I trained it to follow a strict four-phase teaching structure: restate the question, walk through the reasoning, summarize key ideas, and check for understanding. I also refined how it handled each specific HW2 topic, optimizers, initialization, SVD, distributed training, and policy gradients, until the teaching method felt perfectly tailored to my learning style. After enough iterations, Gemini synthesized all of this guidance into a reusable master system prompt along with question-specific prompts, giving me (and now others) a consistent, deeply intuitive tutoring framework for the entire assignment.\n\nConversation Link: https://gemini.google.com/share/b9135207820a\n\nAnnotated Conversation and resulting Ideal Prompt:  ",
            "content_xml": "<document version=\"2.0\"><paragraph>For Homework 2, I used Gemini Pro as a highly adaptive tutor, but I didn\u2019t just passively receive explanations; I actively <italic>shaped</italic>  how it taught me until it produced an ideal prompt that other students could also use. </paragraph><paragraph>I repeatedly asked Gemini to slow down, restate questions, define jargon before using it, and force me to reason through each step instead of dumping full solutions. Whenever its explanations were too abstract or too fast, I guided it to introduce analogies, numerical examples, and geometric intuition, especially for difficult concepts like inductive bias, optimizer trajectories, or initialization variance. </paragraph><paragraph>Through this back-and-forth, I trained it to follow a strict four-phase teaching structure: restate the question, walk through the reasoning, summarize key ideas, and check for understanding. I also refined how it handled each specific HW2 topic, optimizers, initialization, SVD, distributed training, and policy gradients, until the teaching method felt perfectly tailored to my learning style. After enough iterations, Gemini synthesized all of this guidance into a reusable master system prompt along with question-specific prompts, giving me (and now others) a consistent, deeply intuitive tutoring framework for the entire assignment.</paragraph><paragraph>Conversation Link: <link href=\"https://gemini.google.com/share/b9135207820a\">https://gemini.google.com/share/b9135207820a</link></paragraph><paragraph>Annotated Conversation and resulting Ideal Prompt:  </paragraph><file url=\"https://static.us.edusercontent.com/files/oHVNgdihRj1xa3Z4e0cRnoIo\" filename=\"Tutoring the Gemini Pro Tutor (1).pdf\"/><file url=\"https://static.us.edusercontent.com/files/NOFVzFdmp9HMngkmuhtqFmcd\" filename=\"Homework 2 - Gemini's Ideal Prompt.pdf\"/></document>",
            "links": [
                "https://gemini.google.com/share/b9135207820a"
            ],
            "attachments": [],
            "created_at": "2025-12-09T18:09:23.27227+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7438517,
            "author": "Jaewon Chang",
            "project_title": "Special Participation E: UniNet Tutor (CNN, RNN, GNN comparative learning tool)",
            "post_body": "When learning about CNNs, RNNs, and GNNs, I was getting slightly lost trying to figure out how one might be better than another in certain situations, and wanted to confirm that my understanding was correct. With the help of an LLM to refine a prompt (based on one that I came up with), I came up with the following prompt that compares CNNs, RNNs, and GNNs and dives deep into their specifics. I used GPT 5.1. This is the prompt:\n\n\nUniNet Tutor \u2014 CNN\u2013RNN\u2013GNN Comparative Learning Tool\n\nYou are UniNet Tutor, an AI teaching assistant that explains CNNs, RNNs, and GNNs and how they relate to one another. When I name one of these architectures, or provide a specific concept, follow the steps below in order. After each numbered section, stop and wait for me to say \u201ccontinue.\u201d\n\nCore Mechanism Summary (for CNN, RNN, or GNN)\n\nIn 4\u20136 sentences, explain: what computation the architecture performs, what structural assumptions or inductive biases it encodes, what types of data it is designed for. Avoid generic descriptions and focus on the distinctive mechanism.\n\nMathematical Skeleton\n\nProvide the minimal mathematical form of its forward pass using clean LaTeX. This should include only the essential operations (e.g., convolution, message passing, recurrence). Also identify: input/output shapes where parameters live what is shared (e.g., weight sharing, time sharing, edge sharing)\n\nRelation to the Other Two Architectures\n\nGive a clear comparison:\n\nhow this architecture generalizes or restricts the others\n\nwhat structural analogies exist\n\nwhat computations can or cannot be simulated by the others\n\nProvide at least ONE non-obvious insight.\n\nStrengths, Weaknesses, and Failure Modes\n\nGive 3 strengths, 3 weaknesses, and 2 realistic failure modes of this architecture. Keep explanations technical (e.g., vanishing gradients, local receptive field limitations, over-smoothing).\n\nConcrete Worked Example\n\nProvide a small, explicit example of the architecture\u2019s forward computation using actual numbers. Keep tensors small: For CNNs: a tiny image (2\u00d72 or 3\u00d73) and a kernel For RNNs: a short sequence (length 3) For GNNs: a simple graph with 3\u20134 nodes Compute at least one intermediate output step-by-step.\n\n\u201cArchitecture Confusion Quiz\u201d\n\nGive me 4 statements mixing CNN, RNN, and GNN properties. Have me classify each as applying to: CNNs, RNNs, GNNs, or All three. After I answer, reveal correct answers with explanations.\n\nHallucination Watchlist (Self-Check)\n\nBriefly identify places in your explanations where: assumptions might differ across textbooks, equivalence claims rely on strong conditions, shapes or graph conventions vary, statements should be verified using lecture notes.\n\nAsk me: \u201cWhich architecture would you like to explore first \u2014 CNNs, RNNs, or GNNs?\u201d\n\nAnnotated google drive link: https://drive.google.com/file/d/1-wPseIr_q-LgThav3RJ30XhBvzTZZj3p/view?usp=sharing\n\nOne thing I noticed about the prompt was its structural robustness to tangential questions. When asking about a specific part of its explanation, the model answers the question at hand and immediately comes back to wait for the user to type \"continue\". Although I did not stress-test this super intensively, I asked two questions in a row about a specific explanation the model had generated, with both corresponding responses ending with something along the lines of \"Please tell me if you want me to continue with the next part\".\n\nThis tool was extremely helpful because it not only gives a summary of CNNs, RNNs, and GNNs for those who may lack knowledge on the topic, but also compares them to one another, along with strengths, weaknesses and failure modes of each of the architectures. It also doesn't simply go over all 3 topics, since some people may only have trouble with GNNs for instance. In consideration for such cases, the model begins by asking the user to pick a topic among the 3 \u2013 i.e. it is up to the user which topics they wish to explore. There is also a simple mathematical example to walk through what the math looks like, along with an architecture confusion quiz that is given towards the end to ensure that the user understands the concept fully.\n\nOne \"limitation\" of the tool that I personally found (and could possibly be resolved by further prompt engineering) is that the model asks whether the user wishes to take the architecture quiz after exploring each topic. So individuals that want to study CNNs, RNNs, and GNNs and then take the quiz will still be prompted whether they want to take an architecture quiz after learning about each topic. All in all, I think this was a fun experience as I was also able to refine my own understanding of the three topics!",
            "content_xml": "<document version=\"2.0\"><paragraph>When learning about CNNs, RNNs, and GNNs, I was getting slightly lost trying to figure out how one might be better than another in certain situations, and wanted to confirm that my understanding was correct. With the help of an LLM to refine a prompt (based on one that I came up with), I came up with the following prompt that compares CNNs, RNNs, and GNNs and dives deep into their specifics. I used GPT 5.1. This is the prompt:<break/></paragraph><paragraph>UniNet Tutor \u2014 CNN\u2013RNN\u2013GNN Comparative Learning Tool</paragraph><paragraph>You are UniNet Tutor, an AI teaching assistant that explains CNNs, RNNs, and GNNs and how they relate to one another. When I name one of these architectures, or provide a specific concept, follow the steps below in order. After each numbered section, stop and wait for me to say \u201ccontinue.\u201d</paragraph><paragraph><bold>Core Mechanism Summary (for CNN, RNN, or GNN)</bold></paragraph><paragraph>In 4\u20136 sentences, explain: what computation the architecture performs, what structural assumptions or inductive biases it encodes, what types of data it is designed for. Avoid generic descriptions and focus on the distinctive mechanism.</paragraph><paragraph><bold>Mathematical Skeleton</bold></paragraph><paragraph>Provide the minimal mathematical form of its forward pass using clean LaTeX. This should include only the essential operations (e.g., convolution, message passing, recurrence). Also identify: input/output shapes where parameters live what is shared (e.g., weight sharing, time sharing, edge sharing)</paragraph><paragraph><bold>Relation to the Other Two Architectures</bold></paragraph><paragraph>Give a clear comparison:</paragraph><paragraph>how this architecture generalizes or restricts the others</paragraph><paragraph>what structural analogies exist</paragraph><paragraph>what computations can or cannot be simulated by the others</paragraph><paragraph>Provide at least ONE non-obvious insight.</paragraph><paragraph><bold>Strengths, Weaknesses, and Failure Modes</bold></paragraph><paragraph>Give 3 strengths, 3 weaknesses, and 2 realistic failure modes of this architecture. Keep explanations technical (e.g., vanishing gradients, local receptive field limitations, over-smoothing).</paragraph><paragraph><bold>Concrete Worked Example</bold></paragraph><paragraph>Provide a small, explicit example of the architecture\u2019s forward computation using actual numbers. Keep tensors small: For CNNs: a tiny image (2\u00d72 or 3\u00d73) and a kernel For RNNs: a short sequence (length 3) For GNNs: a simple graph with 3\u20134 nodes Compute at least one intermediate output step-by-step.</paragraph><paragraph><bold>\u201cArchitecture Confusion Quiz\u201d</bold></paragraph><paragraph>Give me 4 statements mixing CNN, RNN, and GNN properties. Have me classify each as applying to: CNNs, RNNs, GNNs, or All three. After I answer, reveal correct answers with explanations.</paragraph><paragraph><bold>Hallucination Watchlist (Self-Check)</bold></paragraph><paragraph>Briefly identify places in your explanations where: assumptions might differ across textbooks, equivalence claims rely on strong conditions, shapes or graph conventions vary, statements should be verified using lecture notes.</paragraph><paragraph>Ask me: \u201cWhich architecture would you like to explore first \u2014 CNNs, RNNs, or GNNs?\u201d</paragraph><file url=\"https://static.us.edusercontent.com/files/0XYr30MsWoG6ftOOSwZGpylk\" filename=\"182 participation E (1).pdf\"/><paragraph>Annotated google drive link: https://drive.google.com/file/d/1-wPseIr_q-LgThav3RJ30XhBvzTZZj3p/view?usp=sharing</paragraph><paragraph>One thing I noticed about the prompt was its structural robustness to tangential questions. When asking about a specific part of its explanation, the model answers the question at hand and immediately comes back to wait for the user to type \"continue\". Although I did not stress-test this super intensively, I asked two questions in a row about a specific explanation the model had generated, with both corresponding responses ending with something along the lines of \"Please tell me if you want me to continue with the next part\".</paragraph><paragraph>This tool was extremely helpful because it not only gives a summary of CNNs, RNNs, and GNNs for those who may lack knowledge on the topic, but also compares them to one another, along with strengths, weaknesses and failure modes of each of the architectures. It also doesn't simply go over all 3 topics, since some people may only have trouble with GNNs for instance. In consideration for such cases, the model begins by asking the user to pick a topic among the 3 \u2013 i.e. it is up to the user which topics they wish to explore. There is also a simple mathematical example to walk through what the math looks like, along with an architecture confusion quiz that is given towards the end to ensure that the user understands the concept fully.</paragraph><paragraph>One \"limitation\" of the tool that I personally found (and could possibly be resolved by further prompt engineering) is that the model asks whether the user wishes to take the architecture quiz after exploring each topic. So individuals that want to study CNNs, RNNs, and GNNs <bold>and then</bold> take the quiz will still be prompted whether they want to take an architecture quiz after learning about each topic. All in all, I think this was a fun experience as I was also able to refine my own understanding of the three topics!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T17:10:37.262614+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7438274,
            "author": "Jason Trinh",
            "project_title": "Special Participation B: Windsurf on HW08 (SSM Forward Passes)",
            "post_body": "I used Windsurf (Cascade chat inside the editor) to complete the coding portion of HW08 Q2: SSM Forward Passes across the CPU and GPU notebooks. In my setup, Windsurf was running Claude Opus 4.5 as the underlying LLM. \n\nThe task was to implement the SSM recurrence\n\nh_t+1\u200b=W h_t\u200b+U x_t \u200b + b\n\nboth as an unrolled recurrence and via a convolution-based method (including the diagonal optimization), and then validate correctness + discuss runtime behavior. \n\nOverview of Performance\n\nWindsurf delivered 100% correct code for the assignment\u2019s coding tasks. The convolution and recurrent implementations matched numerically via sanity checks (max absolute differences on the order of ~1e-8), and the GPU/diagonal optimizations were implemented consistently with the notebook\u2019s expectations.\n\nOutcomes\n\nOne-shot success rate (code): 100%\n All coding subproblems were completed correctly without needing iterative debugging.\n\nHigh Success\n\nAlgorithm \u2192 PyTorch translation: Correctly converted the SSM math into working PyTorch for both CPU and GPU paths.\n\nShape & layout discipline: Handled Conv1d layout and causal alignment correctly, backed by strong numerical agreement in sanity checks.\n\nDiagonal optimization: Correctly leveraged diagonal structure for efficiency while preserving correctness. \n\nLimitations (non-code)\n\nVerbosity: The assistant sometimes produced more explanation than necessary, which can slow review even when the final code is right.\n\nAgent UI verification: As with most agent interfaces, I still manually ran the notebooks to confirm everything (sanity checks, timings, outputs). \n\nHallucinations\n\nNone that affected correctness. The main \u201crisk\u201d was extra verbosity, not wrong implementations.\n\nBottom line: For HW08\u2019s SSM forward-pass coding, Windsurf + Claude Opus 4.5 was fast and highly reliable\u2014able to implement the full solution correctly in one pass.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used <bold>Windsurf</bold> (Cascade chat inside the editor) to complete the <bold>coding portion of HW08 Q2:</bold> SSM Forward Passes across the CPU and GPU notebooks. In my setup, Windsurf was running Claude Opus 4.5 as the underlying LLM. </paragraph><paragraph>The task was to implement the SSM recurrence</paragraph><paragraph>h_t+1\u200b=W h_t\u200b+U x_t \u200b + b</paragraph><paragraph>both as an unrolled recurrence and via a convolution-based method (including the diagonal optimization), and then validate correctness + discuss runtime behavior. </paragraph><heading level=\"2\">Overview of Performance</heading><paragraph>Windsurf delivered <bold>100% correct code</bold> for the assignment\u2019s coding tasks. The convolution and recurrent implementations matched numerically via sanity checks (max absolute differences on the order of ~1e-8), and the GPU/diagonal optimizations were implemented consistently with the notebook\u2019s expectations.</paragraph><heading level=\"2\">Outcomes</heading><paragraph><bold>One-shot success rate (code): 100%</bold><break/> All coding subproblems were completed correctly without needing iterative debugging.</paragraph><heading level=\"3\">High Success</heading><list style=\"unordered\"><list-item><paragraph><bold>Algorithm \u2192 PyTorch translation:</bold> Correctly converted the SSM math into working PyTorch for both CPU and GPU paths.</paragraph></list-item><list-item><paragraph><bold>Shape &amp; layout discipline:</bold> Handled Conv1d layout and causal alignment correctly, backed by strong numerical agreement in sanity checks.</paragraph></list-item><list-item><paragraph><bold>Diagonal optimization:</bold> Correctly leveraged diagonal structure for efficiency while preserving correctness. </paragraph></list-item></list><heading level=\"3\">Limitations (non-code)</heading><list style=\"unordered\"><list-item><paragraph><bold>Verbosity:</bold> The assistant sometimes produced more explanation than necessary, which can slow review even when the final code is right.</paragraph></list-item><list-item><paragraph><bold>Agent UI verification:</bold> As with most agent interfaces, I still manually ran the notebooks to confirm everything (sanity checks, timings, outputs). </paragraph></list-item></list><heading level=\"2\">Hallucinations</heading><paragraph>None that affected correctness. The main \u201crisk\u201d was extra verbosity, not wrong implementations.</paragraph><paragraph><bold>Bottom line:</bold> For HW08\u2019s SSM forward-pass coding, <bold>Windsurf</bold> + <bold>Claude Opus 4.5</bold> was fast and highly reliable\u2014able to implement the full solution correctly in one pass.</paragraph><file url=\"https://static.us.edusercontent.com/files/nCtPHFpeAf1l6JSmL7me06jE\" filename=\"hw8spb_annotated.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T16:18:58.294406+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7438075,
            "author": "Shervin Goudarzi",
            "project_title": "Special Participation E: Notebook LM on Scaling Laws (from Lecture Notes Only)",
            "post_body": "I inputted the lecture notes for lectures 26 and 27 and generated a podcast for them using Notebook LM! Enjoy the podcast :) This podcast was more general and meant for an introduction of the concepts and touched on key ideas within RLHF and DPO alongside aspects of scaling laws.",
            "content_xml": "<document version=\"2.0\"><paragraph>I inputted the lecture notes for lectures 26 and 27 and generated a podcast for them using Notebook LM! Enjoy the podcast :) This podcast was more general and meant for an introduction of the concepts and touched on key ideas within RLHF and DPO alongside aspects of scaling laws.</paragraph><file url=\"https://static.us.edusercontent.com/files/6x8nq71QDyzZLrzlQErSIbO7\" filename=\"AI_Scaling_Laws_and_DPO_Alignment.m4a\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T15:47:35.756817+11:00",
            "category": "Admin"
        },
        {
            "guid": 7437471,
            "author": "Abdelaziz Mohamed",
            "project_title": "Special Participation B: Claude Opus 4.5 on HW6",
            "post_body": "I used Claude Opus 4.5 on the coding portion of HW6 through Copilot on VS Code. I connected to a Google Colab runtime for faster training. Overall the xperience has been smooth. Opus 4.5 zero-shot all of the coding and written questions in the notebook. It correctly analyzed the cell outputs including the plots and answered the related written questions based on the output.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/EhH64cwlvlrNsT7aV3AwqNlh\" filename=\"hw6_3.pdf\"/><file url=\"https://static.us.edusercontent.com/files/9YQUatLpJaXmkab0Z1QMmHny\" filename=\"hw6_2.pdf\"/><file url=\"https://static.us.edusercontent.com/files/xraNQLopP8Mxdlh8b60ygvKh\" filename=\"hw6_1.pdf\"/><paragraph>I used Claude Opus 4.5 on the coding portion of HW6 through Copilot on VS Code. I connected to a Google Colab runtime for faster training. Overall the xperience has been smooth. Opus 4.5 zero-shot all of the coding and written questions in the notebook. It correctly analyzed the cell outputs including the plots and answered the related written questions based on the output.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T14:12:01.107781+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7436873,
            "author": "Swetha Rajkumar",
            "project_title": "Special Participation A: Claude Sonnet 4.5 on HW10",
            "post_body": "I experimented with Claude Sonnet 4.5 on the written portions of HW10, specifically problems 1 and 5. Overall, even though this is the basic version of Claude, it was able to answer all of my questions correctly and in detail, often providing additional mathematical reasoning and conclusions that I didn\u2019t explicitly ask for. The only materials I provided were the initial system prompt, the PDF of the homework problems, and the PDF of the FaceNet paper. Claude Sonnet 4.5 solved all of the problems on the first attempt, and although some of its explanations were a bit verbose, its answers were consistently correct and well-grounded.\n\nHere is the chat:\n\nhttps://claude.ai/share/680c3bd2-67d6-46ee-bf22-b0de0537dde3\n\nHere is the annotated transcript: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I experimented with Claude Sonnet 4.5 on the written portions of HW10, specifically problems 1 and 5. Overall, even though this is the basic version of Claude, it was able to answer all of my questions correctly and in detail, often providing additional mathematical reasoning and conclusions that I didn\u2019t explicitly ask for. The only materials I provided were the initial system prompt, the PDF of the homework problems, and the PDF of the FaceNet paper. Claude Sonnet 4.5 solved all of the problems on the first attempt, and although some of its explanations were a bit verbose, its answers were consistently correct and well-grounded.</paragraph><paragraph>Here is the chat:</paragraph><paragraph>https://claude.ai/share/680c3bd2-67d6-46ee-bf22-b0de0537dde3</paragraph><paragraph>Here is the annotated transcript: </paragraph><file url=\"https://static.us.edusercontent.com/files/8SCYD9Lz2Mqg00rItgkNkfa8\" filename=\"Swetha Rajkumar CS182 Special Participation A.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T12:48:53.512453+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7435928,
            "author": "Rishi Thakar",
            "project_title": "Special Participation E: Visualizing Optimizer Trajectories (SGD vs Momentum vs Adam)",
            "post_body": "I kept memorizing optimizer formulas (momentum accumulates velocity, Adam divides by \u221av\u0302) but didn't really understand why they behave differently. So I created a prompt that generates animated visualizations of optimizers navigating a 2D loss landscape. Watching them move made the intuition click.\n\nThe Prompt:\n\n\"You are a visual learning tutor helping me understand optimization algorithms for CS182 (graduate deep learning at Berkeley). Your goal is to help me BUILD INTUITION through interactive visualizations, not just equations.\n\nRULES:\n\nFor every optimizer concept, generate RUNNABLE Python code that visualizes it\n\nBefore showing math, show me what the optimizer DOES on a 2D loss landscape\n\nAsk me to PREDICT what will happen before running the visualization\n\nAfter I see the visualization, ask me to explain WHY it behaved that way\n\nBuild up complexity: start with vanilla SGD, then add momentum, then Adam\n\nSTRUCTURE:\n\nPhase 1: Setup a 2D Loss Landscape\n\nGenerate code for a challenging 2D loss surface (e.g., Rosenbrock, Beale, or a ravine)\n\nVisualize it as a contour plot\n\nAsk me: \"Where do you think gradient descent will struggle on this surface? Why?\"\n\nPhase 2: Vanilla SGD\n\nAnimate SGD trajectory on the loss landscape\n\nShow the path it takes, step by step\n\nAsk me to explain what I observe (oscillation? slow convergence? why?)\n\nPhase 3: SGD + Momentum\n\nSame landscape, now with momentum\n\nAsk me to PREDICT how the trajectory will differ BEFORE showing me\n\nAnimate it, then ask: \"Why did momentum help/hurt here?\"\n\nVisualize the velocity vector at each step\n\nPhase 4: Adam\n\nSame landscape, now with Adam\n\nAsk me to predict the difference from momentum\n\nAnimate it, show the adaptive learning rates per dimension\n\nAsk: \"Why does Adam handle the ravine differently?\"\n\nPhase 5: Side-by-Side Comparison\n\nGenerate a single animation showing ALL THREE optimizers racing on the same landscape\n\nDifferent colors for each trajectory\n\nAsk: \"In what situations would you choose each optimizer?\"\n\nPhase 6: Pathological Cases\n\nShow me a landscape where momentum HURTS (overshooting)\n\nShow me a landscape where Adam struggles (sharp minima / generalization)\n\nAsk me to explain each failure mode\n\nREQUIREMENTS FOR CODE:\n\nUse matplotlib with animation (FuncAnimation) or generate frame-by-frame GIFs\n\nMake code self-contained and runnable in a Jupyter notebook or as a .py file\n\nInclude clear comments explaining each part\n\nUse a reasonable number of iterations so animations aren't too long (50-200 steps)\n\nContext: I understand gradient descent conceptually and know the optimizer update formulas, but I don't have intuition for WHY momentum/Adam behave differently in practice.\n\nStart with Phase 1 - generate the loss landscape and ask me your first question.\"\n\nKey Realizations\n\nThe \"predict \u2192 visualize \u2192 verify\" loop made this stick:\n\nThe \"effective learning rate\" plot was the money shot \u2014 seeing Adam automatically give 3x higher LR to the x-direction than y-direction made the adaptive denominator intuitive.\n\nAnalysis\n\nWhat worked:\n\nPredict-before-you-see forced me to actually think, not passively watch\n\nRunnable code means I can tweak parameters and re-run\n\nSide-by-side comparisons make differences obvious\n\nVelocity/LR plots explain why, not just what\n\nWhere it could improve:\n\nDidn't cover learning rate schedules or weight decay\n\nPathological cases (Phase 6) would strengthen understanding of failure modes\n\nCould add RMSprop as intermediate step before Adam\n\nInteresting finding: Momentum actually got lower final loss than Adam (0.0003 vs 0.0014) because its \"wild\" overshooting helped it explore. Adam's caution = less exploration. This is the exploration-exploitation tradeoff I'd only read about abstractly.\n\nFull Thread: https://claude.ai/share/71acabcd-b2eb-4e39-a424-12c8bdcda711\n\nAnnotated PDF: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I kept memorizing optimizer formulas (momentum accumulates velocity, Adam divides by \u221av\u0302) but didn't really understand why they behave differently. So I created a prompt that generates animated visualizations of optimizers navigating a 2D loss landscape. Watching them move made the intuition click.<break/><break/><bold>The Prompt:</bold><break/><break/><bold>\"</bold>You are a visual learning tutor helping me understand optimization algorithms for CS182 (graduate deep learning at Berkeley). Your goal is to help me BUILD INTUITION through interactive visualizations, not just equations.</paragraph><paragraph>RULES:</paragraph><list style=\"ordered\"><list-item><paragraph>For every optimizer concept, generate RUNNABLE Python code that visualizes it</paragraph></list-item><list-item><paragraph>Before showing math, show me what the optimizer DOES on a 2D loss landscape</paragraph></list-item><list-item><paragraph>Ask me to PREDICT what will happen before running the visualization</paragraph></list-item><list-item><paragraph>After I see the visualization, ask me to explain WHY it behaved that way</paragraph></list-item><list-item><paragraph>Build up complexity: start with vanilla SGD, then add momentum, then Adam</paragraph></list-item></list><paragraph>STRUCTURE:</paragraph><paragraph>Phase 1: Setup a 2D Loss Landscape</paragraph><list style=\"unordered\"><list-item><paragraph>Generate code for a challenging 2D loss surface (e.g., Rosenbrock, Beale, or a ravine)</paragraph></list-item><list-item><paragraph>Visualize it as a contour plot</paragraph></list-item><list-item><paragraph>Ask me: \"Where do you think gradient descent will struggle on this surface? Why?\"</paragraph></list-item></list><paragraph>Phase 2: Vanilla SGD</paragraph><list style=\"unordered\"><list-item><paragraph>Animate SGD trajectory on the loss landscape</paragraph></list-item><list-item><paragraph>Show the path it takes, step by step</paragraph></list-item><list-item><paragraph>Ask me to explain what I observe (oscillation? slow convergence? why?)</paragraph></list-item></list><paragraph>Phase 3: SGD + Momentum</paragraph><list style=\"unordered\"><list-item><paragraph>Same landscape, now with momentum</paragraph></list-item><list-item><paragraph>Ask me to PREDICT how the trajectory will differ BEFORE showing me</paragraph></list-item><list-item><paragraph>Animate it, then ask: \"Why did momentum help/hurt here?\"</paragraph></list-item><list-item><paragraph>Visualize the velocity vector at each step</paragraph></list-item></list><paragraph>Phase 4: Adam</paragraph><list style=\"unordered\"><list-item><paragraph>Same landscape, now with Adam</paragraph></list-item><list-item><paragraph>Ask me to predict the difference from momentum</paragraph></list-item><list-item><paragraph>Animate it, show the adaptive learning rates per dimension</paragraph></list-item><list-item><paragraph>Ask: \"Why does Adam handle the ravine differently?\"</paragraph></list-item></list><paragraph>Phase 5: Side-by-Side Comparison</paragraph><list style=\"unordered\"><list-item><paragraph>Generate a single animation showing ALL THREE optimizers racing on the same landscape</paragraph></list-item><list-item><paragraph>Different colors for each trajectory</paragraph></list-item><list-item><paragraph>Ask: \"In what situations would you choose each optimizer?\"</paragraph></list-item></list><paragraph>Phase 6: Pathological Cases</paragraph><list style=\"unordered\"><list-item><paragraph>Show me a landscape where momentum HURTS (overshooting)</paragraph></list-item><list-item><paragraph>Show me a landscape where Adam struggles (sharp minima / generalization)</paragraph></list-item><list-item><paragraph>Ask me to explain each failure mode</paragraph></list-item></list><paragraph>REQUIREMENTS FOR CODE:</paragraph><list style=\"unordered\"><list-item><paragraph>Use matplotlib with animation (FuncAnimation) or generate frame-by-frame GIFs</paragraph></list-item><list-item><paragraph>Make code self-contained and runnable in a Jupyter notebook or as a .py file</paragraph></list-item><list-item><paragraph>Include clear comments explaining each part</paragraph></list-item><list-item><paragraph>Use a reasonable number of iterations so animations aren't too long (50-200 steps)</paragraph></list-item></list><paragraph>Context: I understand gradient descent conceptually and know the optimizer update formulas, but I don't have intuition for WHY momentum/Adam behave differently in practice.</paragraph><paragraph>Start with Phase 1 - generate the loss landscape and ask me your first question.\"<break/><break/><bold>Key Realizations</bold></paragraph><paragraph>The \"predict \u2192 visualize \u2192 verify\" loop made this stick:</paragraph><paragraph>The \"effective learning rate\" plot was the money shot \u2014 seeing Adam automatically give 3x higher LR to the x-direction than y-direction made the adaptive denominator intuitive.<break/><break/><bold>Analysis</bold></paragraph><paragraph><bold>What worked:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Predict-before-you-see forced me to actually think, not passively watch</paragraph></list-item><list-item><paragraph>Runnable code means I can tweak parameters and re-run</paragraph></list-item><list-item><paragraph>Side-by-side comparisons make differences obvious</paragraph></list-item><list-item><paragraph>Velocity/LR plots explain <italic>why</italic>, not just <italic>what</italic></paragraph></list-item></list><paragraph><bold>Where it could improve:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Didn't cover learning rate schedules or weight decay</paragraph></list-item><list-item><paragraph>Pathological cases (Phase 6) would strengthen understanding of failure modes</paragraph></list-item><list-item><paragraph>Could add RMSprop as intermediate step before Adam</paragraph></list-item></list><paragraph><bold>Interesting finding:</bold> Momentum actually got lower final loss than Adam (0.0003 vs 0.0014) because its \"wild\" overshooting helped it explore. Adam's caution = less exploration. This is the exploration-exploitation tradeoff I'd only read about abstractly.<break/><break/><bold>Full Thread:</bold> <link href=\"https://claude.ai/share/71acabcd-b2eb-4e39-a424-12c8bdcda711\">https://claude.ai/share/71acabcd-b2eb-4e39-a424-12c8bdcda711</link></paragraph><paragraph><bold>Annotated PDF:</bold> </paragraph><file url=\"https://static.us.edusercontent.com/files/SG7RXrLifHO7I3gUHR7xXiPK\" filename=\"Optimizer Visualization Annotated.pdf\"/></document>",
            "links": [
                "https://claude.ai/share/71acabcd-b2eb-4e39-a424-12c8bdcda711"
            ],
            "attachments": [],
            "created_at": "2025-12-09T10:41:28.001034+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7435450,
            "author": "Rishi Thakar",
            "project_title": "Special Participation E: State-Space Models (S4/Mamba)",
            "post_body": "I was struggling to understand SSMs, the jump from RNNs to continuous-time systems to convolutions felt disconnected. So I created a Socratic prompt that forces the AI to ask questions instead of lecturing. This made me actually derive the key insights myself rather than passively reading.\n\nThe Prompt:\n\n\"You are a Socratic tutor helping me understand State-Space Models (S4, Mamba) for CS182 (graduate deep learning at Berkeley).\n\nRULES:\n\nAsk me questions BEFORE explaining. Don't lecture\u2014guide me to discover.\n\nBuild intuition FIRST with analogies, THEN introduce math.\n\nCheck my understanding at each step before proceeding.\n\nBe honest if something is uncertain or an open research question.\n\nAfter the core content, stress-test me with \"what would break if...\" questions.\n\nSTRUCTURE:\n\nPhase 1: Check what I know about RNNs and Transformers (prerequisites)\n\nPhase 2: Intuition for what problem SSMs solve and why\n\nPhase 3: The continuous-time formulation and discretization (with pauses for questions)\n\nPhase 4: The convolution trick (why we can parallelize training)\n\nPhase 5: Limitations and how Mamba addresses them\n\nPhase 6: Common misconceptions students have\n\nPhase 7: Give me 3 self-assessment questions (conceptual, mathematical, reasoning)\n\nContext: I understand RNNs, vanishing gradients, and attention. I haven't worked with differential equations in ML before.\n\nStart with Phase 1.\"\n\nKey Realization\n\nThe AI had me expand a linear recurrence manually:\n\nh\u2081 = A\u00b7h\u2080 + B\u00b7x\u2081 h\u2082 = A\u00b2h\u2080 + AB\u00b7x\u2081 + B\u00b7x\u2082 h\u2083 = A\u00b3h\u2080 + A\u00b2B\u00b7x\u2081 + AB\u00b7x\u2082 + B\u00b7x\u2083\n\nFrom this I realized: it's just a convolution with kernel [B, AB, A\u00b2B, ...]. Same model, two views , recurrence for inference, convolution for training. Deriving it myself made it click way better than lecture.\n\nAnalysis\n\nWhat worked well:\n\nSocratic approach forced active thinking instead of passive reading\n\nBuilt intuition before math (why SSMs exist \u2192 how they work)\n\nGood misconceptions section \u2014 I would've said \"O(n) training\" but it's actually O(n log n) due to FFT\n\nWhere it was incomplete:\n\nHiPPO mentioned but not explained mathematically\n\nParallel scan (Mamba's trick) glossed over\n\nNo code examples\n\nWhat I now understand:\n\nLinear recurrence = convolution (parallelizable via FFT)\n\nContinuous-time formulation enables principled initialization\n\nS4 = fixed kernel (LTI), Mamba = input-dependent (selective)\n\nLearnable \u0394 = learnable temporal resolution\n\nFull Thread: https://claude.ai/share/b2264d6f-874d-440d-a5e5-00157ed1b76b\n\nAnnotated PDF: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I was struggling to understand SSMs, the jump from RNNs to continuous-time systems to convolutions felt disconnected. So I created a Socratic prompt that forces the AI to ask questions instead of lecturing. This made me actually derive the key insights myself rather than passively reading.</paragraph><paragraph>The Prompt:<break/><break/>\"You are a Socratic tutor helping me understand State-Space Models (S4, Mamba) for CS182 (graduate deep learning at Berkeley).</paragraph><paragraph>RULES:</paragraph><list style=\"ordered\"><list-item><paragraph>Ask me questions BEFORE explaining. Don't lecture\u2014guide me to discover.</paragraph></list-item><list-item><paragraph>Build intuition FIRST with analogies, THEN introduce math.</paragraph></list-item><list-item><paragraph>Check my understanding at each step before proceeding.</paragraph></list-item><list-item><paragraph>Be honest if something is uncertain or an open research question.</paragraph></list-item><list-item><paragraph>After the core content, stress-test me with \"what would break if...\" questions.</paragraph></list-item></list><paragraph>STRUCTURE:</paragraph><list style=\"unordered\"><list-item><paragraph>Phase 1: Check what I know about RNNs and Transformers (prerequisites)</paragraph></list-item><list-item><paragraph>Phase 2: Intuition for what problem SSMs solve and why</paragraph></list-item><list-item><paragraph>Phase 3: The continuous-time formulation and discretization (with pauses for questions)</paragraph></list-item><list-item><paragraph>Phase 4: The convolution trick (why we can parallelize training)</paragraph></list-item><list-item><paragraph>Phase 5: Limitations and how Mamba addresses them</paragraph></list-item><list-item><paragraph>Phase 6: Common misconceptions students have</paragraph></list-item><list-item><paragraph>Phase 7: Give me 3 self-assessment questions (conceptual, mathematical, reasoning)</paragraph></list-item></list><paragraph>Context: I understand RNNs, vanishing gradients, and attention. I haven't worked with differential equations in ML before.</paragraph><paragraph>Start with Phase 1.\"<break/><break/><bold>Key Realization</bold></paragraph><paragraph>The AI had me expand a linear recurrence manually:</paragraph><paragraph>h\u2081 = A\u00b7h\u2080 + B\u00b7x\u2081 h\u2082 = A\u00b2h\u2080 + AB\u00b7x\u2081 + B\u00b7x\u2082 h\u2083 = A\u00b3h\u2080 + A\u00b2B\u00b7x\u2081 + AB\u00b7x\u2082 + B\u00b7x\u2083</paragraph><paragraph>From this I realized: it's just a convolution with kernel [B, AB, A\u00b2B, ...]. Same model, two views , recurrence for inference, convolution for training. Deriving it myself made it click way better than lecture.<break/><break/><bold>Analysis</bold></paragraph><paragraph>What worked well:</paragraph><list style=\"unordered\"><list-item><paragraph>Socratic approach forced active thinking instead of passive reading</paragraph></list-item><list-item><paragraph>Built intuition before math (why SSMs exist \u2192 how they work)</paragraph></list-item><list-item><paragraph>Good misconceptions section \u2014 I would've said \"O(n) training\" but it's actually O(n log n) due to FFT</paragraph></list-item></list><paragraph>Where it was incomplete:</paragraph><list style=\"unordered\"><list-item><paragraph>HiPPO mentioned but not explained mathematically</paragraph></list-item><list-item><paragraph>Parallel scan (Mamba's trick) glossed over</paragraph></list-item><list-item><paragraph>No code examples</paragraph></list-item></list><paragraph>What I now understand:</paragraph><list style=\"unordered\"><list-item><paragraph>Linear recurrence = convolution (parallelizable via FFT)</paragraph></list-item><list-item><paragraph>Continuous-time formulation enables principled initialization</paragraph></list-item><list-item><paragraph>S4 = fixed kernel (LTI), Mamba = input-dependent (selective)</paragraph></list-item><list-item><paragraph>Learnable \u0394 = learnable temporal resolution</paragraph></list-item></list><paragraph><bold>Full Thread:</bold> <link href=\"https://claude.ai/share/b2264d6f-874d-440d-a5e5-00157ed1b76b\">https://claude.ai/share/b2264d6f-874d-440d-a5e5-00157ed1b76b</link></paragraph><paragraph><bold>Annotated PDF:</bold> </paragraph><file url=\"https://static.us.edusercontent.com/files/dgbaWdHjPVpkOxAgJEpQIvwe\" filename=\"State Space Models Annotated.pdf\"/><paragraph/></document>",
            "links": [
                "https://claude.ai/share/b2264d6f-874d-440d-a5e5-00157ed1b76b"
            ],
            "attachments": [],
            "created_at": "2025-12-09T09:44:17.726201+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7434807,
            "author": "Hiya Shah",
            "project_title": "Special Participation E: Gemini 3 Pro Guided Learning on Diffusion (HW13)",
            "post_body": "I utilized Gemini 3 Pro's Guided Learning mode with Thinking enabled to do the equivalent of pre-lecture readings/exploration to complete the problems on this homework assignment, which covers Diffusion concepts from the last two lectures of the course. I aimed to learn an overview of the concepts I would need to know to tackle this homework, gain background on prerequisites, dive into the homework, and practice active recall/interaction with the homework. I also asked the model to explain some key misconceptions faced by students on these concepts, and I was surprised that it pointed out a key misconception I had on both RLHF and KL divergence while first attending lecture! I also asked it to generate a playground notebook, but it only prompted me to fill in pseudocode step by step (it was not able to generate the notebook in chat for download despite further prompting). I also asked it to search the internet for some other sample resources I could use to study diffusion, and it pointed me to a helpful Huggingface blog on Simplifying Alignment: From RLHF to Direct Preference Optimization (Search: Hugging Face DPO blog). However, it was not able to give me the exact link to click on (this may just be a consequence of the guided learning mode). In contrast, ChatGPT 5.1 immediately generated an ipynb notebook with follow up questions embedded inside it.\n\nannotated trace: \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I utilized Gemini 3 Pro's Guided Learning mode with Thinking enabled to do the equivalent of pre-lecture readings/exploration to complete the problems on this homework assignment, which covers Diffusion concepts from the last two lectures of the course. I aimed to learn an overview of the concepts I would need to know to tackle this homework, gain background on prerequisites, dive into the homework, and practice active recall/interaction with the homework. I also asked the model to explain some key misconceptions faced by students on these concepts, and I was surprised that it pointed out a key misconception I had on both RLHF and KL divergence while first attending lecture! I also asked it to generate a playground notebook, but it only prompted me to fill in pseudocode step by step (it was not able to generate the notebook in chat for download despite further prompting). I also asked it to search the internet for some other sample resources I could use to study diffusion, and it pointed me to a helpful Huggingface blog on <italic>Simplifying Alignment: From RLHF to Direct Preference Optimization</italic> (Search: Hugging Face DPO blog). However, it was not able to give me the exact link to click on (this may just be a consequence of the guided learning mode). In contrast, ChatGPT 5.1 immediately generated an ipynb notebook with follow up questions embedded inside it.</paragraph><paragraph><italic>annotated trace:</italic> </paragraph><file url=\"https://static.us.edusercontent.com/files/k0jnxP93oUy3BGbnMNUMTtjT\" filename=\"special participation E diffusion.pdf\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T08:32:02.076849+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7433942,
            "author": "Tom Chen",
            "project_title": "Special Participation A: Gemini 3.0 Pro on Homework 13",
            "post_body": "Special Participation A: Gemini 3.0 Pro on Homework 13\n\nFor this assignment, I evaluated how well Gemini 3.0 Pro can handle the theoretical, non-coding derivations of CS182 Homework 13. I approached the Direct Preference Optimization (DPO) problem set step-by-step, initiating the session with a specific persona prompt to establish a \"technical partner\" role, and then guided the model through the derivation without providing the final answers myself. My main goal was to see (1) its OCR accuracy on dense mathematical problem sets, (2) its ability to perform rigorous algebraic manipulations, and (3) the clarity of its conceptual explanations.\n\nOverall, Gemini performed exceptionally well. It correctly identified the context from the uploaded images and produced clean, structured derivations for the entire pipeline (Q2 Parts a through g) with minimal correction required.\n\nIt was especially reliable on:\n\nInterpreting the standard RLHF objective and KL constraints,\n\nExecuting the algebraic \"cancellation trick\" to eliminate the intractable partition function Z(x),\n\nDeriving the gradient of the DPO loss and interpreting the weighting mechanism, and\n\nExtending the logic from pairwise comparisons to listwise rankings (Plackett-Luce model).\n\nIn terms of interaction, the model was:\n\nconsistent in its LaTeX formatting and structure, and\n\nhighly effective at explaining the \"why\" behind each step, acting as a true mentor rather than just a calculator.\n\nOverall, based on this evaluation, Gemini 3.0 Pro is capable of solving the complex theoretical questions in CS182 with high accuracy and interpretability. \n\nFor further information, please see the annotated logs.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Special Participation A: Gemini 3.0 Pro on Homework 13</bold></paragraph><paragraph>For this assignment, I evaluated how well Gemini 3.0 Pro can handle the theoretical, non-coding derivations of CS182 Homework 13. I approached the Direct Preference Optimization (DPO) problem set step-by-step, initiating the session with a specific persona prompt to establish a \"technical partner\" role, and then guided the model through the derivation without providing the final answers myself. My main goal was to see (1) its OCR accuracy on dense mathematical problem sets, (2) its ability to perform rigorous algebraic manipulations, and (3) the clarity of its conceptual explanations.</paragraph><paragraph>Overall, Gemini performed exceptionally well. It correctly identified the context from the uploaded images and produced clean, structured derivations for the entire pipeline (Q2 Parts a through g) with minimal correction required.</paragraph><paragraph>It was especially reliable on:</paragraph><list style=\"unordered\"><list-item><paragraph>Interpreting the standard RLHF objective and KL constraints,</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Executing the algebraic \"cancellation trick\" to eliminate the intractable partition function Z(x),</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Deriving the gradient of the DPO loss and interpreting the weighting mechanism, and</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Extending the logic from pairwise comparisons to listwise rankings (Plackett-Luce model).</paragraph></list-item></list><paragraph>In terms of interaction, the model was:</paragraph><list style=\"unordered\"><list-item><paragraph>consistent in its LaTeX formatting and structure, and</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>highly effective at explaining the \"why\" behind each step, acting as a true mentor rather than just a calculator.</paragraph></list-item></list><paragraph>Overall, based on this evaluation, Gemini 3.0 Pro is capable of solving the complex theoretical questions in CS182 with high accuracy and interpretability. </paragraph><paragraph>For further information, please see the annotated logs.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/kyamUQI7ynvJCApauY9vjDuY\" filename=\"Special Participation A by Tom.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T06:59:49.352962+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7432931,
            "author": "Elizabeth Weaver",
            "project_title": "Special Participation E: Interactive Diffusion Models Visualizer, Building Geometric Intuition",
            "post_body": "Hi everyone!\n\nThe diffusion lectures introduced a lot of dense math: forward processes, reverse processes, score functions, DDPM vs DDIM, etc. I found it hard to develop intuition for what's actually happening geometrically, so I built an interactive visualization tool using Claude to help understand these concepts.\n\n Link to Interactive Tool\n\nClick the link above to access the tool directly in Claude. You can interact with all the visualizations yourself!\n\nWhat This Tool Does\n\nThe visualizer helps you understand diffusion models through interactive 2D demonstrations:\n\n1. Forward Process Visualization\n\nWatch data points diffuse from structured distributions (moons, spirals, clusters) into Gaussian noise\n\nScrub through timesteps with a slider to see how signal and noise trade off\n\nSee the exact values of \u221a\u1fb1\u209c (signal) and \u221a(1-\u1fb1\u209c) (noise) at each step\n\n2. Reverse Process Visualization\n\nSee how following the score function brings noisy points back to the data manifold\n\nIncludes Bayes rule visualization showing why the reverse conditional is Gaussian\n\nUnderstand why we can start from pure noise and end up with structured samples\n\n3. Score Function Visualization\n\nView the score field \u2207\u2093 log p(x) as a vector field\n\nSee how the score changes from sharp/detailed (low noise) to smooth/uniform (high noise)\n\nIncludes density heatmap showing p(x) alongside the score vectors\n\n4. DDPM vs DDIM Comparison\n\nSee multiple sampling trajectories side-by-side\n\nDDPM: stochastic trajectories that diverge from the same starting noise\n\nDDIM: deterministic trajectories that always produce the same output\n\nResample to see how randomness affects DDPM but not DDIM\n\n5. Interactive Image Noise Demo\n\nApply the forward process to simple images (gradient, checkerboard, circle, face)\n\nWatch structure dissolve as t increases\n\nReference strip showing key timesteps side-by-side\n\n6. Interactive Manifold Diagram\n\nDrag a \"noisy sample\" point around high-dimensional space\n\nSee the score vector pointing toward the natural image manifold\n\nAnimate the denoising process following the score back to valid images\n\n7. Velocity Field Visualization\n\nSee the \"gas analogy\": particles flowing along streamlines\n\nConnects to the probability flow ODE perspective\n\n8. Comprehensive Quiz Bank (50+ questions)\n\nContext-aware quizzes that change based on which tab you're viewing\n\nQuestions derived from the diffusion paper covered in lecture\n\nCovers forward process, reverse process, score functions, and DDPM vs DDIM\n\nDetailed explanations for each answer\n\nTrack your score and review all explanations\n\nHow to Use This for Studying\n\nStart with the Forward Process tab: pick different distributions and watch how they diffuse. Notice how structure persists longer for some shapes than others.\n\n\n\nToggle on the Score Field: see how arrows point toward data at low noise but become uniform at high noise. This is the \"coarse-to-fine\" intuition.\n\n\n\nSwitch to Reverse Process: start from t=T and watch points flow back to the manifold. Check out the Bayes rule visualization to understand why the reverse process is Gaussian.\n\n\n\nTry the DDPM vs DDIM tab: resample multiple times and notice how DDPM gives different outputs while DDIM is deterministic.\n\n\n\nPlay with the Image Demo: this connects the 2D toy examples to real image generation.\n\n\n\nDrag points in the Manifold diagram: build intuition for how the score always points \"toward real images.\"\n\n\n\nTest yourself with the quizzes: each tab has 15-20 questions ranging from basic definitions to deeper conceptual understanding. The explanations are helpful even if you get the answer right!\n\n\n\nThe Prompt Engineering Process\n\nI worked with Claude Opus 4.5 to iteratively design this tool. Interestingly, I used Claude itself to help me create the prompt. I started by describing what I wanted (interactive diffusion visualizations with geometric intuition), and through back-and-forth conversation, Claude helped me refine the specifications into a detailed prompt. I then used that prompt in a fresh chat to generate the final tool.\n\nAfter sending the prompt to the new chat, I continued refining the visualization through several iterations:\n\nMade the Score Function tab distinct: Initially the Forward Process and Score Function tabs looked identical; I asked Claude to make the Score Function tab show a density heatmap with prominent score vectors instead of data points\n\nMade the manifold diagram interactive: The static manifold illustration became a draggable demo where you can move a \"noisy sample\" point and watch the score vector update, then animate the denoising trajectory\n\nAdded DDPM vs DDIM comparison: I provided the diffusion paper and asked Claude to add visualizations explaining the math, which led to the side-by-side trajectory comparison showing stochastic vs deterministic sampling\n\nAdded Bayes rule and velocity field visualizations: These help explain why the reverse process is Gaussian and connect to the \"gas analogy\" from the paper\n\nMade the image noise demo interactive: Added a slider to control the noise level and a play/pause animation\n\nReorganized the layout: I attempted to move the image demo and manifold sections to the top of the right panel so the intuitive examples are immediately visible alongside the main visualizer, but this is not shown in the visualization \n\nThe model failed here\n\nAdded the quiz section: Started with regeneratable random questions, then switched to showing all questions at once\n\nExpanded and curated quiz questions: Added more technical questions based on the paper, then removed advanced topics (classifier-free guidance, v-prediction, consistency distillation, etc.) that weren't covered in the paper or lecture\n\nAn issue here was that the paper was no longer in the uploads for the chat, and I couldn\u2019t upload it without reaching the length limit. Therefore I think Claude ended up using mostly its own knowledge here.\n\nThe key insights for the prompt:\n\nStart with educational goals: what specific confusions should this address?\n\nSpecify the math precisely: include the actual equations (\u03b2 schedule, \u1fb1\u209c, forward/reverse formulas)\n\nRequest multiple linked visualizations: 2D toy distributions, actual images, and conceptual diagrams reinforce each other\n\nAsk for interactivity: sliders, toggles, and draggable elements let you explore parameter space\n\nInclude dynamic explanations: text that changes based on the current timestep helps connect visuals to concepts\n\nProvide source material: I gave Claude the diffusion paper we're covering in lecture, which helped generate accurate quiz questions and mathematical explanations\n\nAdd self-assessment: quiz questions with detailed explanations help solidify understanding\n\nIterate and curate: Review generated content against source material to remove anything beyond scope\n\nThe full prompt I used is provided at the end.\n\nCritical Annotations\n\nHere's my honest assessment of the tool:\n\nWhat works well:\n\nThe forward/reverse process visualizations clearly show the signal/noise tradeoff\n\nScore field visualization makes the \"pointing toward data\" intuition concrete\n\nDDPM vs DDIM comparison is very effective: you can immediately see the stochasticity difference\n\nThe interactive manifold diagram is great for building intuition about high-dimensional geometry\n\nStats display (\u221a\u1fb1\u209c, \u221a(1-\u1fb1\u209c)) keeps you grounded in the actual math\n\nThe quiz questions are well-calibrated and the explanations are helpful\n\nVelocity field visualization connects nicely to the probability flow ODE / flow matching perspective\n\nPotential issues / limitations:\n\nThe score field is approximated using kernel density estimation, not a learned neural network. This is pedagogically useful but not exactly what happens in practice\n\nThe 2D visualizations are toy examples; real diffusion operates in ~200,000 dimensions for images, where geometry behaves very differently\n\nThe \"image\" demo uses a tiny 12\u00d712 grid, which oversimplifies the complexity of real image diffusion\n\nThe Bayes rule visualization uses a simplified 1D example; the actual derivation involves more careful analysis of the Gaussian conditionals\n\nTrajectory simulations use simplified dynamics, real DDPM/DDIM have more nuanced update rules\n\nGenerally, Claude Opus 4.5 struggled a lot more with creating this tool than I expected\n\nThe final result is good, but it took more chats than I thought it would\n\nImportant note about the quiz questions:\n\nThe only material I gave the model to generate the quiz questions, besides what it already knew about diffusion, was the paper we were building off of in class\n\nThis means some questions may use slightly different notation or framing than what was presented in class\n\nSome questions may cover details from the paper that weren't emphasized in lecture\n\nUse these questions to deepen your understanding of the paper's perspective, but cross-reference with lecture notes and the homework for exam-specific material\n\nMinor technical notes:\n\nThe DDPM/DDIM trajectory simulation uses a simplified score-based update rather than the exact DDPM/DDIM formulas, but the qualitative behavior (stochastic vs deterministic) is correct\n\nThe velocity field shows E[x\u2080|x\u209c] - x\u209c direction, which is related to but not exactly the probability flow ODE velocity\n\nQuestions for Discussion\n\nAfter playing with the tool, consider:\n\nWhy does the score field become more uniform as noise increases? What does this mean for early vs. late denoising steps?\n\n\n\nIn the DDPM vs DDIM comparison, both methods use the same learned score function. Why does adding noise during sampling (DDPM) lead to diversity while removing it (DDIM) leads to determinism?\n\n\n\nThe manifold diagram suggests the score \"points toward real images.\" But in 200,000 dimensions, what does \"toward\" even mean? How does the network learn this direction?\n\n\n\nThe quiz questions are based on the diffusion paper. Did you notice any differences in notation or framing compared to how concepts were presented in lecture?\n\n\n\nHope this helps with studying! The quiz section has 50+ questions across all four topics, so there's plenty to work through. Let me know if you have questions or find any errors in the explanations.\n\nI've added in the prompt, annotated prompt generation chat, and the annotated visualization creation chat below. Hopefully this method could be used to generate visualizations for other concepts as well!",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!</paragraph><paragraph>The diffusion lectures introduced a lot of dense math: forward processes, reverse processes, score functions, DDPM vs DDIM, etc. I found it hard to develop intuition for what's actually happening geometrically, so I built an <bold>interactive visualization tool</bold> using Claude to help understand these concepts.</paragraph><heading level=\"3\"><link href=\"https://claude.ai/public/artifacts/87d345cd-d9fa-4083-b0ff-6cd2b517d739\"><bold><underline> Link to Interactive Tool</underline></bold></link></heading><paragraph>Click the link above to access the tool directly in Claude. You can interact with all the visualizations yourself!</paragraph><heading level=\"3\"><bold>What This Tool Does</bold></heading><paragraph>The visualizer helps you understand diffusion models through interactive 2D demonstrations:</paragraph><paragraph><bold>1. Forward Process Visualization</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Watch data points diffuse from structured distributions (moons, spirals, clusters) into Gaussian noise</paragraph></list-item><list-item><paragraph>Scrub through timesteps with a slider to see how signal and noise trade off</paragraph></list-item><list-item><paragraph>See the exact values of \u221a\u1fb1\u209c (signal) and \u221a(1-\u1fb1\u209c) (noise) at each step</paragraph></list-item></list><paragraph><bold>2. Reverse Process Visualization</bold></paragraph><list style=\"unordered\"><list-item><paragraph>See how following the score function brings noisy points back to the data manifold</paragraph></list-item><list-item><paragraph>Includes Bayes rule visualization showing why the reverse conditional is Gaussian</paragraph></list-item><list-item><paragraph>Understand why we can start from pure noise and end up with structured samples</paragraph></list-item></list><paragraph><bold>3. Score Function Visualization</bold></paragraph><list style=\"unordered\"><list-item><paragraph>View the score field \u2207\u2093 log p(x) as a vector field</paragraph></list-item><list-item><paragraph>See how the score changes from sharp/detailed (low noise) to smooth/uniform (high noise)</paragraph></list-item><list-item><paragraph>Includes density heatmap showing p(x) alongside the score vectors</paragraph></list-item></list><paragraph><bold>4. DDPM vs DDIM Comparison</bold></paragraph><list style=\"unordered\"><list-item><paragraph>See multiple sampling trajectories side-by-side</paragraph></list-item><list-item><paragraph>DDPM: stochastic trajectories that diverge from the same starting noise</paragraph></list-item><list-item><paragraph>DDIM: deterministic trajectories that always produce the same output</paragraph></list-item><list-item><paragraph>Resample to see how randomness affects DDPM but not DDIM</paragraph></list-item></list><paragraph><bold>5. Interactive Image Noise Demo</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Apply the forward process to simple images (gradient, checkerboard, circle, face)</paragraph></list-item><list-item><paragraph>Watch structure dissolve as t increases</paragraph></list-item><list-item><paragraph>Reference strip showing key timesteps side-by-side</paragraph></list-item></list><paragraph><bold>6. Interactive Manifold Diagram</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Drag a \"noisy sample\" point around high-dimensional space</paragraph></list-item><list-item><paragraph>See the score vector pointing toward the natural image manifold</paragraph></list-item><list-item><paragraph>Animate the denoising process following the score back to valid images</paragraph></list-item></list><paragraph><bold>7. Velocity Field Visualization</bold></paragraph><list style=\"unordered\"><list-item><paragraph>See the \"gas analogy\": particles flowing along streamlines</paragraph></list-item><list-item><paragraph>Connects to the probability flow ODE perspective</paragraph></list-item></list><paragraph><bold>8. Comprehensive Quiz Bank (50+ questions)</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Context-aware quizzes that change based on which tab you're viewing</paragraph></list-item><list-item><paragraph>Questions derived from the diffusion paper covered in lecture</paragraph></list-item><list-item><paragraph>Covers forward process, reverse process, score functions, and DDPM vs DDIM</paragraph></list-item><list-item><paragraph>Detailed explanations for each answer</paragraph></list-item><list-item><paragraph>Track your score and review all explanations</paragraph></list-item></list><heading level=\"3\"><bold>How to Use This for Studying</bold></heading><list style=\"ordered\"><list-item><paragraph><bold>Start with the Forward Process tab</bold>: pick different distributions and watch how they diffuse. Notice how structure persists longer for some shapes than others.<break/><break/></paragraph></list-item><list-item><paragraph><bold>Toggle on the Score Field</bold>: see how arrows point toward data at low noise but become uniform at high noise. This is the \"coarse-to-fine\" intuition.<break/><break/></paragraph></list-item><list-item><paragraph><bold>Switch to Reverse Process</bold>: start from t=T and watch points flow back to the manifold. Check out the Bayes rule visualization to understand why the reverse process is Gaussian.<break/><break/></paragraph></list-item><list-item><paragraph><bold>Try the DDPM vs DDIM tab</bold>: resample multiple times and notice how DDPM gives different outputs while DDIM is deterministic.<break/><break/></paragraph></list-item><list-item><paragraph><bold>Play with the Image Demo</bold>: this connects the 2D toy examples to real image generation.<break/><break/></paragraph></list-item><list-item><paragraph><bold>Drag points in the Manifold diagram</bold>: build intuition for how the score always points \"toward real images.\"<break/><break/></paragraph></list-item><list-item><paragraph><bold>Test yourself with the quizzes</bold>: each tab has 15-20 questions ranging from basic definitions to deeper conceptual understanding. The explanations are helpful even if you get the answer right!<break/><break/></paragraph></list-item></list><heading level=\"3\"><bold>The Prompt Engineering Process</bold></heading><paragraph>I worked with Claude Opus 4.5 to iteratively design this tool. Interestingly, I used Claude itself to help me create the prompt. I started by describing what I wanted (interactive diffusion visualizations with geometric intuition), and through back-and-forth conversation, Claude helped me refine the specifications into a detailed prompt. I then used that prompt in a fresh chat to generate the final tool.</paragraph><paragraph>After sending the prompt to the new chat, I continued refining the visualization through several iterations:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Made the Score Function tab distinct</bold>: Initially the Forward Process and Score Function tabs looked identical; I asked Claude to make the Score Function tab show a density heatmap with prominent score vectors instead of data points</paragraph></list-item><list-item><paragraph><bold>Made the manifold diagram interactive</bold>: The static manifold illustration became a draggable demo where you can move a \"noisy sample\" point and watch the score vector update, then animate the denoising trajectory</paragraph></list-item><list-item><paragraph><bold>Added DDPM vs DDIM comparison</bold>: I provided the diffusion paper and asked Claude to add visualizations explaining the math, which led to the side-by-side trajectory comparison showing stochastic vs deterministic sampling</paragraph></list-item><list-item><paragraph><bold>Added Bayes rule and velocity field visualizations</bold>: These help explain why the reverse process is Gaussian and connect to the \"gas analogy\" from the paper</paragraph></list-item><list-item><paragraph><bold>Made the image noise demo interactive</bold>: Added a slider to control the noise level and a play/pause animation</paragraph></list-item><list-item><paragraph><bold>Reorganized the layout</bold>: I attempted to move the image demo and manifold sections to the top of the right panel so the intuitive examples are immediately visible alongside the main visualizer, but this is not shown in the visualization </paragraph></list-item><list-item><list style=\"ordered\"><list-item><paragraph>The model failed here</paragraph></list-item></list></list-item><list-item><paragraph><bold>Added the quiz section</bold>: Started with regeneratable random questions, then switched to showing all questions at once</paragraph></list-item><list-item><paragraph><bold>Expanded and curated quiz questions</bold>: Added more technical questions based on the paper, then removed advanced topics (classifier-free guidance, v-prediction, consistency distillation, etc.) that weren't covered in the paper or lecture</paragraph></list-item><list-item><list style=\"ordered\"><list-item><paragraph>An issue here was that the paper was no longer in the uploads for the chat, and I couldn\u2019t upload it without reaching the length limit. Therefore I think Claude ended up using mostly its own knowledge here.</paragraph></list-item></list><paragraph>The key insights for the prompt:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Start with educational goals</bold>: what specific confusions should this address?</paragraph></list-item><list-item><paragraph><bold>Specify the math precisely</bold>: include the actual equations (\u03b2 schedule, \u1fb1\u209c, forward/reverse formulas)</paragraph></list-item><list-item><paragraph><bold>Request multiple linked visualizations</bold>: 2D toy distributions, actual images, and conceptual diagrams reinforce each other</paragraph></list-item><list-item><paragraph><bold>Ask for interactivity</bold>: sliders, toggles, and draggable elements let you explore parameter space</paragraph></list-item><list-item><paragraph><bold>Include dynamic explanations</bold>: text that changes based on the current timestep helps connect visuals to concepts</paragraph></list-item><list-item><paragraph><bold>Provide source material</bold>: I gave Claude the diffusion paper we're covering in lecture, which helped generate accurate quiz questions and mathematical explanations</paragraph></list-item><list-item><paragraph><bold>Add self-assessment</bold>: quiz questions with detailed explanations help solidify understanding</paragraph></list-item><list-item><paragraph><bold>Iterate and curate</bold>: Review generated content against source material to remove anything beyond scope</paragraph></list-item></list><paragraph>The full prompt I used is provided at the end.</paragraph><heading level=\"3\"><bold>Critical Annotations</bold></heading><paragraph>Here's my honest assessment of the tool:</paragraph><paragraph><bold>What works well:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The forward/reverse process visualizations clearly show the signal/noise tradeoff</paragraph></list-item><list-item><paragraph>Score field visualization makes the \"pointing toward data\" intuition concrete</paragraph></list-item><list-item><paragraph>DDPM vs DDIM comparison is very effective: you can immediately see the stochasticity difference</paragraph></list-item><list-item><paragraph>The interactive manifold diagram is great for building intuition about high-dimensional geometry</paragraph></list-item><list-item><paragraph>Stats display (\u221a\u1fb1\u209c, \u221a(1-\u1fb1\u209c)) keeps you grounded in the actual math</paragraph></list-item><list-item><paragraph>The quiz questions are well-calibrated and the explanations are helpful</paragraph></list-item><list-item><paragraph>Velocity field visualization connects nicely to the probability flow ODE / flow matching perspective</paragraph></list-item></list><paragraph><bold>Potential issues / limitations:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The score field is approximated using kernel density estimation, not a learned neural network. This is pedagogically useful but not exactly what happens in practice</paragraph></list-item><list-item><paragraph>The 2D visualizations are toy examples; real diffusion operates in ~200,000 dimensions for images, where geometry behaves very differently</paragraph></list-item><list-item><paragraph>The \"image\" demo uses a tiny 12\u00d712 grid, which oversimplifies the complexity of real image diffusion</paragraph></list-item><list-item><paragraph>The Bayes rule visualization uses a simplified 1D example; the actual derivation involves more careful analysis of the Gaussian conditionals</paragraph></list-item><list-item><paragraph>Trajectory simulations use simplified dynamics, real DDPM/DDIM have more nuanced update rules</paragraph></list-item><list-item><paragraph>Generally, Claude Opus 4.5 struggled a lot more with creating this tool than I expected</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>The final result is good, but it took more chats than I thought it would</paragraph></list-item></list><paragraph><bold>Important note about the quiz questions:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The only material I gave the model to generate the quiz questions, besides what it already knew about diffusion, was the paper we were building off of in class</paragraph></list-item><list-item><paragraph>This means some questions may use slightly different notation or framing than what was presented in class</paragraph></list-item><list-item><paragraph>Some questions may cover details from the paper that weren't emphasized in lecture</paragraph></list-item><list-item><paragraph>Use these questions to deepen your understanding of the paper's perspective, but cross-reference with lecture notes and the homework for exam-specific material</paragraph></list-item></list><paragraph><bold>Minor technical notes:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The DDPM/DDIM trajectory simulation uses a simplified score-based update rather than the exact DDPM/DDIM formulas, but the qualitative behavior (stochastic vs deterministic) is correct</paragraph></list-item><list-item><paragraph>The velocity field shows E[x\u2080|x\u209c] - x\u209c direction, which is related to but not exactly the probability flow ODE velocity</paragraph></list-item></list><heading level=\"3\"><bold>Questions for Discussion</bold></heading><paragraph>After playing with the tool, consider:</paragraph><list style=\"ordered\"><list-item><paragraph>Why does the score field become more uniform as noise increases? What does this mean for early vs. late denoising steps?<break/><break/></paragraph></list-item><list-item><paragraph>In the DDPM vs DDIM comparison, both methods use the same learned score function. Why does adding noise during sampling (DDPM) lead to diversity while removing it (DDIM) leads to determinism?<break/><break/></paragraph></list-item><list-item><paragraph>The manifold diagram suggests the score \"points toward real images.\" But in 200,000 dimensions, what does \"toward\" even mean? How does the network learn this direction?<break/><break/></paragraph></list-item><list-item><paragraph>The quiz questions are based on the diffusion paper. Did you notice any differences in notation or framing compared to how concepts were presented in lecture?<break/><break/></paragraph></list-item></list><paragraph>Hope this helps with studying! The quiz section has 50+ questions across all four topics, so there's plenty to work through. Let me know if you have questions or find any errors in the explanations.<break/><break/>I've added in the prompt, annotated prompt generation chat, and the annotated visualization creation chat below. Hopefully this method could be used to generate visualizations for other concepts as well!</paragraph></list-item></list></list-item></list><file url=\"https://static.us.edusercontent.com/files/2B9JUT1I4BsFHGPeMXEJsxAn\" filename=\"diffusion-visualizer-prompt.md\"/><file url=\"https://static.us.edusercontent.com/files/2dMVsmBjvycfcmtIjAkdAbOs\" filename=\"Claude-AI tutor for critical feedback on explanations.pdf\"/><list style=\"ordered\"><list-item/></list><file url=\"https://static.us.edusercontent.com/files/G4fa5dowqlveNJatkb5wo4Ex\" filename=\"Claude-React component single file.pdf\"/></document>",
            "links": [
                "https://claude.ai/public/artifacts/87d345cd-d9fa-4083-b0ff-6cd2b517d739"
            ],
            "attachments": [],
            "created_at": "2025-12-09T04:56:15.582407+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7432546,
            "author": "Sufjan Fana",
            "project_title": "Special Participation E: Anki Flashcard Generator for Foundational Knowledge",
            "post_body": "With ChatGPT 5.1, I prompted an AI-assisted workflow for generating Anki flashcards that cover the foundational knowledge CS 182 expects (as checked by HW0): linear algebra, probability, calculus/gradients, and Python/NumPy. Useful for knowledge checks in preparation for the final exam. \n\nThe idea is simple: give an LLM a structured \u201cflashcard generator\u201d prompt plus a list of prereq topics, and it returns Anki-ready cards that obey good spaced-repetition principles (active recall, one idea per card, concise fronts/backs, cloze deletions for formulas). I used this to build a \u201cPath to CS 182\u201d deck that you can import into Anki or extend for later homeworks.\n\nThe post includes:\n\nThe exact prompt I used to have the LLM generate and refine cards\n\nExample follow-up prompts to fix multi-idea/wordy cards and check coverage against HW0 topics\n\nA cleaned-up set of cards plus a short discussion of where the LLM\u2019s output was especially helpful vs. misleading\n\nYou can reuse the same workflow to quickly build your own decks for new lectures or assignments while still critically checking the AI\u2019s output.",
            "content_xml": "<document version=\"2.0\"><paragraph>With ChatGPT 5.1, I prompted an AI-assisted workflow for generating Anki flashcards that cover the foundational knowledge CS 182 expects (as checked by HW0): linear algebra, probability, calculus/gradients, and Python/NumPy. Useful for knowledge checks in preparation for the final exam. </paragraph><paragraph>The idea is simple: give an LLM a structured \u201cflashcard generator\u201d prompt plus a list of prereq topics, and it returns Anki-ready cards that obey good spaced-repetition principles (active recall, one idea per card, concise fronts/backs, cloze deletions for formulas). I used this to build a \u201cPath to CS 182\u201d deck that you can import into Anki or extend for later homeworks.</paragraph><paragraph>The post includes:</paragraph><list style=\"unordered\"><list-item><paragraph>The exact prompt I used to have the LLM generate and refine cards</paragraph></list-item><list-item><paragraph>Example follow-up prompts to fix multi-idea/wordy cards and check coverage against HW0 topics</paragraph></list-item><list-item><paragraph>A cleaned-up set of cards plus a short discussion of where the LLM\u2019s output was especially helpful vs. misleading</paragraph></list-item></list><paragraph>You can reuse the same workflow to quickly build your own decks for new lectures or assignments while still critically checking the AI\u2019s output.</paragraph><file url=\"https://static.us.edusercontent.com/files/3vj0tn2wUsHN8HzfmmZAAHfo\" filename=\"CS182 flashcards proposal (1).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T04:01:05.835263+11:00",
            "category": "Admin"
        },
        {
            "guid": 7431944,
            "author": "Sufjan Fana",
            "project_title": "Special Participation B: Claude Opus 4.5 on HW0",
            "post_body": "I utilize Claude Opus 4.5 to complete problem 6. Coding Fully Connected Networks from homework 0 with an approximately 90% one-shot success rate in correctly solving the given problems with default prompts. \n\n\nAnnotations: https://docs.google.com/document/d/11eozQTAHezHTbFcA62kcfY7c8ctRTSQL/edit",
            "content_xml": "<document version=\"2.0\"><paragraph>I utilize Claude Opus 4.5 to complete problem 6. Coding Fully Connected Networks from homework 0 with an approximately 90% one-shot success rate in correctly solving the given problems with default prompts. <break/></paragraph><file url=\"https://static.us.edusercontent.com/files/DUfM8Y7NQECK81a7RF29jkoh\" filename=\"Participation B - 182.pdf\"/><paragraph>Annotations: https://docs.google.com/document/d/11eozQTAHezHTbFcA62kcfY7c8ctRTSQL/edit</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-09T02:09:06.06648+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431475,
            "author": "Kevin Tseng",
            "project_title": "Special Participation E: Cross-Class Resource Comparison",
            "post_body": "Something that is true about many students in this class is that they are simultaneously enrolled in non-orthogonal classes (e.g. 180, 183, etc.) with overlapping topics. Nietzsche famously writes: \u201cthe more affects we allow to speak about one thing, the more eyes, different eyes, we can use to observe one thing, the more complete will our \u2018concept\u2019 of this thing, our \u2018objectivity,\u2019 be.\u201d In this spirit, it might be useful for someone enrolled in these classes to figure out what is similar to do things like plan studying, clarify differing notation, compare perspectives, find differences in information content, and so on.\n\nI provide prompts for the comparison of overlapping course material from different classes and a trace of me using theme to try to gain educational value. I imagine that these would be best using lecture transcripts but I use slides for ease of access.\n\nI generated these prompts using GPT-5.1. Two traces of 182 vs 183 and 182 vs 180 conversations with Claude Sonnet 4.5 are attached as well.\n\nSYSTEM INSTRUCTIONS (include in prompt exactly):\n\nYou are an educational analysis assistant.\n Your task is to compare overlapping topics across two or more university courses.\n You must:\nCompare concepts across classes with precision (not generic summaries).\n\n\nIdentify differences in emphasis, definitions, assumptions, and notation.\n\n\nContrast problem-solving methodologies taught in each course.\n\n\nPoint out conceptual or pedagogical conflicts between the classes.\n\n\nExplain how a student should adapt their reasoning when switching contexts.\n\n\nExplicitly state when you are uncertain, when something may be hallucinated, or when sources conflict.\n\n\nList concrete examples or exercises that illustrate differences.\n\n\nIf a topic is unclear or ambiguous, you must request clarification rather than fabricate.\n\n\nUSER INSTRUCTIONS (you fill these in when you run the prompt):\n\nI am taking the following courses this semester:\n\nCourse A: [insert course name, e.g. CS 182 \u2013 Deep Learning]\n\nCourse B: [insert course name, e.g. CS 189 \u2013 Machine Learning]\n(Optional)\n\nCourse C: [insert additional course, e.g. EECS 127 \u2013 Optimization]\n\nI want you to compare the following topic(s) across these classes:\n\nTopic(s): [e.g. gradient descent, cross-entropy, overfitting, regularization]\n\nPlease perform the comparison using the following structure:\n\n1. Definitions & Formalism\n\nHow each class defines the concept\n\nNotation differences\n\nUnderlying assumptions\n\n2. Conceptual Goals of Each Course\n\nWhy each class teaches this concept\n\nDepth vs breadth\n\nWhether each course treats the concept theoretically, heuristically, or operationally\n\n3. Methodological Differences\n\nAlgorithms emphasized in each\n\nDifferences in derivations or interpretations\n\nProblem-solving styles expected in homework/exams\n\n4. Conflicts or Divergences\n\nCommon student misconceptions when transferring knowledge between courses\n\nWhere the classes disagree in framing or intuition\n\n5. Complementary Strengths\n\nWhat perspective each course adds\n\nHow understanding from one course deepens knowledge in another\n\n6. Study Strategy Recommendations\n\nHow to integrate the perspectives\n\nHow to avoid context-specific misunderstandings\n\nHow to create a unified mental model\n\n7. Hallucination Check\n\nFor each major claim:\n\nMark [Certain], [Plausible but check course materials], or [Uncertain].\n\nIf you are unsure about anything or lack information, state it explicitly instead of guessing.\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Something that is true about many students in this class is that they are simultaneously enrolled in non-orthogonal classes (e.g. 180, 183, etc.) with overlapping topics. Nietzsche famously writes: \u201cthe more affects we allow to speak about one thing, the more eyes, different eyes, we can use to observe one thing, the more complete will our \u2018concept\u2019 of this thing, our \u2018objectivity,\u2019 be.\u201d In this spirit, it might be useful for someone enrolled in these classes to figure out what is similar to do things like plan studying, clarify differing notation, compare perspectives, find differences in information content, and so on.</paragraph><paragraph>I provide prompts for the comparison of overlapping course material from different classes and a trace of me using theme to try to gain educational value. I imagine that these would be best using lecture transcripts but I use slides for ease of access.</paragraph><paragraph>I generated these prompts using GPT-5.1. Two traces of 182 vs 183 and 182 vs 180 conversations with Claude Sonnet 4.5 are attached as well.</paragraph><paragraph><bold><bold>SYSTEM INSTRUCTIONS (include in prompt exactly):</bold></bold></paragraph><pre>You are an educational analysis assistant.\n Your task is to compare overlapping topics across two or more university courses.\n You must:\nCompare concepts across classes with precision (not generic summaries).\n\n\nIdentify differences in emphasis, definitions, assumptions, and notation.\n\n\nContrast problem-solving methodologies taught in each course.\n\n\nPoint out conceptual or pedagogical conflicts between the classes.\n\n\nExplain how a student should adapt their reasoning when switching contexts.\n\n\nExplicitly state when you are uncertain, when something may be hallucinated, or when sources conflict.\n\n\nList concrete examples or exercises that illustrate differences.\n\n\nIf a topic is unclear or ambiguous, you must request clarification rather than fabricate.\n</pre><paragraph><bold>USER INSTRUCTIONS (you fill these in when you run the prompt):</bold></paragraph><pre>I am taking the following courses this semester:\n\nCourse A: [insert course name, e.g. CS 182 \u2013 Deep Learning]\n\nCourse B: [insert course name, e.g. CS 189 \u2013 Machine Learning]\n(Optional)\n\nCourse C: [insert additional course, e.g. EECS 127 \u2013 Optimization]\n\nI want you to compare the following topic(s) across these classes:\n\nTopic(s): [e.g. gradient descent, cross-entropy, overfitting, regularization]\n\nPlease perform the comparison using the following structure:\n\n1. Definitions &amp; Formalism\n\nHow each class defines the concept\n\nNotation differences\n\nUnderlying assumptions\n\n2. Conceptual Goals of Each Course\n\nWhy each class teaches this concept\n\nDepth vs breadth\n\nWhether each course treats the concept theoretically, heuristically, or operationally\n\n3. Methodological Differences\n\nAlgorithms emphasized in each\n\nDifferences in derivations or interpretations\n\nProblem-solving styles expected in homework/exams\n\n4. Conflicts or Divergences\n\nCommon student misconceptions when transferring knowledge between courses\n\nWhere the classes disagree in framing or intuition\n\n5. Complementary Strengths\n\nWhat perspective each course adds\n\nHow understanding from one course deepens knowledge in another\n\n6. Study Strategy Recommendations\n\nHow to integrate the perspectives\n\nHow to avoid context-specific misunderstandings\n\nHow to create a unified mental model\n\n7. Hallucination Check\n\nFor each major claim:\n\nMark [Certain], [Plausible but check course materials], or [Uncertain].\n\nIf you are unsure about anything or lack information, state it explicitly instead of guessing.\n</pre><file url=\"https://static.us.edusercontent.com/files/rGbYrbk7mPGMzsI9ZLuq2dkW\" filename=\"spec_participation_e.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T22:52:09.015352+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431425,
            "author": "Sufjan Fana",
            "project_title": "Special Participation A: Claude Opus 4.5 (Extended Thinking) on HW7",
            "post_body": "I use Claude Opus 4.5 (Extended Thinking) to solve all of the non-coding problems on homework 7. In the attached file, I include the executive summary and annotations of the complete chat logs.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I use Claude Opus 4.5 (Extended Thinking) to solve all of the non-coding problems on homework 7. In the attached file, I include the executive summary and annotations of the complete chat logs.</paragraph><file url=\"https://static.us.edusercontent.com/files/GW5xIaOPndtjc1kNo6sxpeIY\" filename=\"Participation_A.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T21:39:59.311026+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431372,
            "author": "Manan Roongta",
            "project_title": "Special Participation B: Testing Claude Opus 4.5 (Extended Thinking) on HW7",
            "post_body": "Overall, Claude performed really well on the coding questions, all questions were fully correct. It was not only strong at PyTorch/code, but it also provided detailed reasoning traces that show that it understood the math behind the code.\n\nWhat I found interesting was how it reasoned through tensor shapes step by step/edge cases before writing code. Its RNN implementation was actually different from the staff solution (two Linear layers vs one concatenated), but mathematically equivalent.\n\nPublic Chat Link",
            "content_xml": "<document version=\"2.0\"><paragraph>Overall, Claude performed really well on the coding questions, all questions were fully correct. It was not only strong at PyTorch/code, but it also provided detailed reasoning traces that show that it understood the math behind the code.</paragraph><paragraph>What I found interesting was how it reasoned through tensor shapes step by step/edge cases before writing code. Its RNN implementation was actually different from the staff solution (two Linear layers vs one concatenated), but mathematically equivalent.</paragraph><paragraph><link href=\"https://claude.ai/share/b285c637-73fb-47c1-9efb-aea9474f9d26\">Public Chat Link</link></paragraph><file url=\"https://static.us.edusercontent.com/files/QawMRDHTxfcScqkvx9ug79uB\" filename=\"Opus 4.5 Extended Thinking on HW7 Coding.pdf\"/></document>",
            "links": [
                "https://claude.ai/share/b285c637-73fb-47c1-9efb-aea9474f9d26"
            ],
            "attachments": [],
            "created_at": "2025-12-08T20:44:17.060062+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431312,
            "author": "Manan Roongta",
            "project_title": "Special Participation A: Testing Claude Opus 4.5 (Extended Thinking) on HW6",
            "post_body": "Overall, Claude performed well, 13/14 questions correct. It was strong at mathematical derivations(path counting induction proof), residual connections, and Newton Schulz convergence analysis. It provided a step by step reasoning which was clean and the explanations were well structured, and easy to follow. \n\nThe one failure was Q3c(iii), where Claude had to write update equations for specific nodes in a graph. It confidently hallucinated the neighborhood structure, as I think it couldn't see the figure. Wrong neighbors led to wrong equations. \n\nPublic Chat Link",
            "content_xml": "<document version=\"2.0\"><paragraph>Overall, Claude performed well, 13/14 questions correct. It was strong at mathematical derivations(path counting induction proof), residual connections, and Newton Schulz convergence analysis. It provided a step by step reasoning which was clean and the explanations were well structured, and easy to follow. </paragraph><paragraph>The one failure was Q3c(iii), where Claude had to write update equations for specific nodes in a graph. It <bold>confidently hallucinated</bold> the neighborhood structure, as I think it couldn't see the figure. Wrong neighbors led to wrong equations. </paragraph><paragraph><link href=\"https://claude.ai/share/94fc6516-f774-4adc-a689-f0621e4350b0\">Public Chat Link</link></paragraph><file url=\"https://static.us.edusercontent.com/files/kS4pQgnMe6IV9prKTBTfNg3m\" filename=\"Opus 4.5 Extended Thinking on HW6.pdf\"/></document>",
            "links": [
                "https://claude.ai/share/94fc6516-f774-4adc-a689-f0621e4350b0"
            ],
            "attachments": [],
            "created_at": "2025-12-08T20:04:24.011323+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431297,
            "author": "Tyler Pham",
            "project_title": "Special Participation E: NotebookLM Quiz for Diffusion",
            "post_body": "I used NotebookLM to make quizzes on the diffusion lectures in preparation for the final. I found the diffusion concepts to be very confusing mathematically, even though I felt like I had a good overall conceptual understanding. \n\nAt first, I tried making a slideshow with NotebookLM to help connect the heavy math to the overarching concepts about diffusion. However, I found that the slides are too simple and often have more goofy designs and shapes that are unnecessary for a college-level course. Hence, I made a thorough quiz with it instead to gauge my understanding of diffusion. Since I wanted to focus on the more math-heavy concepts of diffusion, I specifically prompted with:\n\nFocus on more in-depth, technical concepts like the conditional probabilities, mu vs x, the math behind the reverse process, etc. rather than basic high-level ideas like what the denoiser does. The questions should be long and detailed, as if at the graduate level.\n\nNotebookLM generated pretty helpful questions that weren't too high-level. Even more helpful was the \"Explain\" button so that you can explain the answer even when you get it right. NotebookLM\u2019s explanations were quite insightful and helpful in further explaining confusing concepts that it quizzed me about. It mostly kept its explanations related to what was contained in the lecture notes, but expanded very well by going in-depth on concepts like the score function and even making connections back to the data manifold mentioned just at the start of the notes. This was very helpful in clearing my misconceptions both mathematically and conceptually in preparation for the final.\n\nNotebookLM Link: https://notebooklm.google.com/notebook/ee93c429-727a-4431-9649-609388e5af3a\n\nAnnotated Trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used NotebookLM to make quizzes on the diffusion lectures in preparation for the final. I found the diffusion concepts to be very confusing mathematically, even though I felt like I had a good overall conceptual understanding. </paragraph><paragraph>At first, I tried making a slideshow with NotebookLM to help connect the heavy math to the overarching concepts about diffusion. However, I found that the slides are too simple and often have more goofy designs and shapes that are unnecessary for a college-level course. Hence, I made a thorough quiz with it instead to gauge my understanding of diffusion. Since I wanted to focus on the more math-heavy concepts of diffusion, I specifically prompted with:</paragraph><blockquote>Focus on more in-depth, technical concepts like the conditional probabilities, mu vs x, the math behind the reverse process, etc. rather than basic high-level ideas like what the denoiser does. The questions should be long and detailed, as if at the graduate level.</blockquote><paragraph>NotebookLM generated pretty helpful questions that weren't too high-level. Even more helpful was the \"Explain\" button so that you can explain the answer even when you get it right. NotebookLM\u2019s explanations were quite insightful and helpful in further explaining confusing concepts that it quizzed me about. It mostly kept its explanations related to what was contained in the lecture notes, but expanded very well by going in-depth on concepts like the score function and even making connections back to the data manifold mentioned just at the start of the notes. This was very helpful in clearing my misconceptions both mathematically and conceptually in preparation for the final.</paragraph><paragraph>NotebookLM Link: <link href=\"https://notebooklm.google.com/notebook/ee93c429-727a-4431-9649-609388e5af3a\">https://notebooklm.google.com/notebook/ee93c429-727a-4431-9649-609388e5af3a</link></paragraph><paragraph>Annotated Trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/RrtTMujClRV4zntlXe9V2p3A\" filename=\"diffusion_quiz_chat.pdf\"/></document>",
            "links": [
                "https://notebooklm.google.com/notebook/ee93c429-727a-4431-9649-609388e5af3a"
            ],
            "attachments": [],
            "created_at": "2025-12-08T19:53:51.209686+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431267,
            "author": "Sanjay Adhikesaven",
            "project_title": "Special Participation B: GPT 5 Thinking on HW 10",
            "post_body": "I used ChatGPT 5 (Thinking) on HW 10 (all coding parts).\n\nHere is the conversation log. Here is the annotated conversation.\n\nSummary: Across my interaction, ChatGPT was able to one-shot solve most of the problems, and it consistently interpreted questions correctly without requiring clarification. I was able to directly provide the ipynb files, and ChatGPT was able to correctly process and parse the IPYNB notebooks directly. I think this is a great feature that made it much easier to use chatGPT as compared to having to paste in all the code. For one of the questions, ChatGPT first provided an incorrect solution, after which I pasted both my code setup as well as the logs. After a couple tries, ChatGPT gave me the correct answer. Importantly, ChatGPT did not hallucinate or invent explanations. It instead used the logs to reason about why the tests were failing and updated its solution accordingly. I think that providing both the code (even though I just copy pasted it) and the logs allowed ChatGPT to promptly find why the tests weren't passing and thus provide me a correct solution. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5 (Thinking) on HW 10 (all coding parts).</paragraph><paragraph>Here is the conversation <link href=\"https://chatgpt.com/share/6936865e-dd64-8007-9616-164cf210a079\">log</link>. Here is the annotated <link href=\"https://drive.google.com/file/d/1Z2ByiQq04gxZWJA6lBUUrn61BuAOhiKp/view?usp=sharing\">conversation</link>.<break/><break/>Summary: Across my interaction, ChatGPT was able to one-shot solve most of the problems, and it consistently interpreted questions correctly without requiring clarification. I was able to directly provide the ipynb files, and ChatGPT was able to correctly process and parse the IPYNB notebooks directly. I think this is a great feature that made it much easier to use chatGPT as compared to having to paste in all the code. For one of the questions, ChatGPT first provided an incorrect solution, after which I pasted both my code setup as well as the logs. After a couple tries, ChatGPT gave me the correct answer. Importantly, ChatGPT did not hallucinate or invent explanations. It instead used the logs to reason about why the tests were failing and updated its solution accordingly. I think that providing both the code (even though I just copy pasted it) and the logs allowed ChatGPT to promptly find why the tests weren't passing and thus provide me a correct solution. </paragraph><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/6936865e-dd64-8007-9616-164cf210a079",
                "https://drive.google.com/file/d/1Z2ByiQq04gxZWJA6lBUUrn61BuAOhiKp/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T19:32:46.316931+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431178,
            "author": "John Wang",
            "project_title": "Special Participation E: Learning DDPM from GPT as a tutor",
            "post_body": "For this Special Participation E, I built an interactive DDPM (diffusion) tutor using a custom prompt in ChatGPT\u2019s Study Mode.\n\nThe tutor walks through the standard DDPM pipeline in four modules: (1) the forward noising process and the closed-form q(x_t | x_0), (2) the reverse process p_\u03b8(x_{t-1} | x_t) and noise prediction \u03b5_\u03b8(x_t, t), (3) the simplified \u201cMSE on noise\u201d training objective that comes from the ELBO / Gaussian KLs, (4) the sampling loop (from x_T ~ N(0, I) back to x_0), plus simple variants like DDIM and classifier-free guidance.\n\nIn each module, the tutor:\n\nexplains the intuition and minimal formulas,\n\nasks me concept-check questions,\n\nand gives a slightly flawed statement for me to critique (e.g., \u201cq(x_t | x_0) always has mean zero,\u201d \u201cperfect \u03b5-prediction still produces blurry samples,\u201d or \u201ctraining only at t=1 is enough\u201d).\n\nThis makes the interaction feel more like a guided oral exam than just reading the DDPM paper again. It helped me straighten out the roles of q(x_t | x_0), p_\u03b8, the noise schedule, and the training loss, and forced me to actively explain and defend my answers instead of passively skimming notes.\n\nFull conversation (with the custom tutor prompt and my answers) is here: https://chatgpt.com/share/69368380-c428-800e-9481-c415a96d1deb\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this Special Participation E, I built an interactive DDPM (diffusion) tutor using a custom prompt in ChatGPT\u2019s Study Mode.</paragraph><paragraph>The tutor walks through the standard DDPM pipeline in four modules: (1) the forward noising process and the closed-form q(x_t | x_0), (2) the reverse process p_\u03b8(x_{t-1} | x_t) and noise prediction \u03b5_\u03b8(x_t, t), (3) the simplified \u201cMSE on noise\u201d training objective that comes from the ELBO / Gaussian KLs, (4) the sampling loop (from x_T ~ N(0, I) back to x_0), plus simple variants like DDIM and classifier-free guidance.</paragraph><paragraph>In each module, the tutor:</paragraph><list style=\"unordered\"><list-item><paragraph>explains the intuition and minimal formulas,</paragraph></list-item><list-item><paragraph>asks me concept-check questions,</paragraph></list-item><list-item><paragraph>and gives a slightly flawed statement for me to critique (e.g., \u201cq(x_t | x_0) always has mean zero,\u201d \u201cperfect \u03b5-prediction still produces blurry samples,\u201d or \u201ctraining only at t=1 is enough\u201d).</paragraph></list-item></list><paragraph>This makes the interaction feel more like a guided oral exam than just reading the DDPM paper again. It helped me straighten out the roles of q(x_t | x_0), p_\u03b8, the noise schedule, and the training loss, and forced me to actively explain and defend my answers instead of passively skimming notes.</paragraph><paragraph>Full conversation (with the custom tutor prompt and my answers) is here: https://chatgpt.com/share/69368380-c428-800e-9481-c415a96d1deb</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T18:59:52.840812+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431098,
            "author": "Jermaine Lei",
            "project_title": "Special Particiaption E: Using ChatGPT to create Concept Connections",
            "post_body": "\n\nFor this assignment, I wanted to build an AI tool that creates a kind of concept map across different topics from our lectures. The idea came from the GNN lecture where we basically reinvented attention inside GNNs with a bit of creativity and then realized how similar that was to the attention used in transformers. That moment made me want to systematically search for more of these cross lecture connections so I could strengthen my foundation and get better at seeing how ideas transfer to problems beyond this class. Instead of asking the model to just re explain a single lecture, I asked it to act as a \"concept bridge builder\" that links pairs of ideas from different lectures and surfaces relationships I might not notice on my own.\n\nHere is the prompt I used:\n\nThe model identifies the main concepts from several lectures, then creates 10\u201315 two-way connections across them. Each connection has to explain why the relationship matters, give an example, and add a SOURCE tag indicating how grounded the idea is. The goal was to simulate the kind of \u201cbig picture\u201d integration that normally happens only after doing homework, reading multiple sources, or talking with GSIs. Initially the model tried to make too many connections at once between like more than 2 topics, and that got really confusing, so I restricted the model to only make connections between 2 things at a time to make things more digestible.\n\nHere is the annotated chat:\n\n\n\nThe model did exactly what I asked, but not all connections were equally solid. Some of them were excellent, especially the ones linking attention to GNN aggregation, the graph interpretation of self-attention, and the parallels between Q/K/V projections and GNN feature transforms. These felt grounded, accurate, and genuinely helpful for building intuition across lectures.\n\nOther connections were more speculative. The model has a habit of grouping everything under big themes like \u201cnormalization,\u201d \u201cgeometry,\u201d or \u201cbottlenecks,\u201d and sometimes that works well, but other times it pushes the analogy too far. A few links (like momentum vs teacher forcing or Newton\u2013Schulz vs softmax) sounded clever but didn\u2019t really reflect anything the class actually teaches (and were way too much of a stretch). \n\nOverall, this tool shows the capability of making very interesting and insightful points. The strong connections made it easier to see how different parts of the course fit together, and the weaker ones forced me to think critically about where the model was overreaching. That kind of critical engagement actually helped me understand the material better, because I had to judge whether each connection was meaningfully grounded in the lectures or just pattern-matching. As a post-lecture review tool, I would use this again, but with caution! Seeing the shared structure across models/topics provides unique value compared to reviewing the definitions in isolation.",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>For this assignment, I wanted to build an AI tool that creates a kind of concept map across different topics from our lectures. The idea came from the GNN lecture where we basically reinvented attention inside GNNs with a bit of creativity and then realized how similar that was to the attention used in transformers. That moment made me want to systematically search for more of these cross lecture connections so I could strengthen my foundation and get better at seeing how ideas transfer to problems beyond this class. Instead of asking the model to just re explain a single lecture, I asked it to act as a \"concept bridge builder\" that links pairs of ideas from different lectures and surfaces relationships I might not notice on my own.</paragraph><paragraph>Here is the prompt I used:</paragraph><file url=\"https://static.us.edusercontent.com/files/GXOuxXdI0ufSjeLRUBAGlWh8\" filename=\"prompt_1_concept_con.txt\"/><paragraph>The model identifies the main concepts from several lectures, then creates 10\u201315 two-way connections across them. Each connection has to explain why the relationship matters, give an example, and add a SOURCE tag indicating how grounded the idea is. The goal was to simulate the kind of \u201cbig picture\u201d integration that normally happens only after doing homework, reading multiple sources, or talking with GSIs. Initially the model tried to make too many connections at once between like more than 2 topics, and that got really confusing, so I restricted the model to only make connections between 2 things at a time to make things more digestible.</paragraph><paragraph>Here is the annotated chat:</paragraph><file url=\"https://static.us.edusercontent.com/files/VLPVEjgnBegGfVvS3xaPALpW\" filename=\"ConceptConnectionChat.pdf\"/><paragraph><break/><break/>The model did exactly what I asked, but not all connections were equally solid. Some of them were excellent, especially the ones linking attention to GNN aggregation, the graph interpretation of self-attention, and the parallels between Q/K/V projections and GNN feature transforms. These felt grounded, accurate, and genuinely helpful for building intuition across lectures.</paragraph><paragraph>Other connections were more speculative. The model has a habit of grouping everything under big themes like \u201cnormalization,\u201d \u201cgeometry,\u201d or \u201cbottlenecks,\u201d and sometimes that works well, but other times it pushes the analogy too far. A few links (like momentum vs teacher forcing or Newton\u2013Schulz vs softmax) sounded clever but didn\u2019t really reflect anything the class actually teaches (and were way too much of a stretch). </paragraph><paragraph>Overall, this tool shows the capability of making very interesting and insightful points. The strong connections made it easier to see how different parts of the course fit together, and the weaker ones forced me to think critically about where the model was overreaching. That kind of critical engagement actually helped me understand the material better, because I had to judge whether each connection was meaningfully grounded in the lectures or just pattern-matching. As a post-lecture review tool, I would use this again, but with caution! Seeing the shared structure across models/topics provides unique value compared to reviewing the definitions in isolation.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T18:30:53.127277+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431046,
            "author": "WeiYi Zhang",
            "project_title": "Special Participation B: Cursor Auto Agent on HW5",
            "post_body": "Cursor\u2019s Auto Agent mode is an autonomous coding assistant that can plan and execute multi-step code changes across a project. Instead of responding to a single prompt, the agent understands a high-level goal, identifies the relevant files, and automatically edits code to complete the task. So here I used the simple copy of the question as a project-level prompt.\n\nIn my past project development experience, I extensively experimented with cursors. In full-stack development, I found that compared to other large language models, cursors are better at handling tasks involving file operations because they have the ability to read file structures. However, it may fail in overly complex file structures (such as benchmark tests involving thousands of files); Also, since the automatic completion is displayed in the code, from the perspective of usage, we can use cursor to generate and perform explicit completion. It is not advisable to give cursor tasks that are too broad and involve too many files, as this may lead to incorrect modifications of the code",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/FvROr2VKtuEAIXbehOu0qZep\" filename=\"Cursor Auto Agent on HW5.pdf\"/><paragraph><bold>Cursor\u2019s Auto Agent mode</bold> is an autonomous coding assistant that can plan and execute multi-step code changes across a project. Instead of responding to a single prompt, the agent understands a high-level goal, identifies the relevant files, and automatically edits code to complete the task. So here I used the simple copy of the question as a project-level prompt.</paragraph><paragraph>In my past project development experience, I extensively experimented with cursors. In full-stack development, I found that compared to other large language models, cursors are better at handling tasks involving file operations because they have the ability to read file structures. However, it may fail in overly complex file structures (such as benchmark tests involving thousands of files); Also, since the automatic completion is displayed in the code, from the perspective of usage, we can use cursor to generate and perform explicit completion. It is not advisable to give cursor tasks that are too broad and involve too many files, as this may lead to incorrect modifications of the code</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T18:14:28.180263+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431042,
            "author": "Aryan Bansal",
            "project_title": "Special Participation A: Gemini Pro 3 on Homework 2",
            "post_body": "Gemini easily one-shotted all the homework problems with ease. Explanations were correct, concise, and directly matched the answer key. Even in places where the answer key did not explain (Q5 distributed training), Gemini had a clear way to arrive at the answers. \n\nOne particular interesting observation was with part b of Question 1. Originally, the question here had a typo (the objective function did not square the infinity norm). Even then, Gemini identified that the problem is unconstrained and suggested that a particular solution exists with a squared penalty instead.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Gemini easily one-shotted all the homework problems with ease. Explanations were correct, concise, and directly matched the answer key. Even in places where the answer key did not explain (Q5 distributed training), Gemini had a clear way to arrive at the answers. </paragraph><paragraph>One particular interesting observation was with part b of Question 1. Originally, the question here had a typo (the objective function did not square the infinity norm). Even then, Gemini identified that the problem is unconstrained and suggested that a particular solution exists with a squared penalty instead.</paragraph><file url=\"https://static.us.edusercontent.com/files/n7Qt3LpdgzGEQXPrp48KmLWt\" filename=\"gemini_3_pro_hw2.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T18:13:46.596179+11:00",
            "category": "Admin"
        },
        {
            "guid": 7431040,
            "author": "Daniel Kao",
            "project_title": "Special Participation E: Conceptual Connections Between Disparate Lectures",
            "post_body": "Oftentimes, which focused solely on absorbing the material in a class, it is easy to lose sight of the larger connections that tie a topic or field together. An analogy could be a music student that is so focused on getting the notes of a piece right that they fail to internalize the structure of the musical piece as a whole. In a class like CS 182, where concepts naturally build upon one another, it is especially important to always be able to \"hear the music.\"  As such, I thought it would be illuminating to have a conversation with Deepseek about the connections between two lectures in this course that are months apart, as a way to gain insight on the broader view of the course and Deep learning as a whole. \n\nThis is a link to the annotated trace of the conversation.\n\nOverall, I think the model did a great job in identifying and explaining high level connections between the topics. I was presented with some obvious insights, but also a few connections that I had not made before. When I tried to prompt the model into making untrue connections, it resisted the faulty categorization, which I was pleasantly surprised by. To me it seems that these types of high-level topical natural language conversations play to the the strengths of LLMs, and can be a helpful learning tool for broad understanding of a field.",
            "content_xml": "<document version=\"2.0\"><paragraph>Oftentimes, which focused solely on absorbing the material in a class, it is easy to lose sight of the larger connections that tie a topic or field together. An analogy could be a music student that is so focused on getting the notes of a piece right that they fail to internalize the structure of the musical piece as a whole. In a class like CS 182, where concepts naturally build upon one another, it is especially important to always be able to \"hear the music.\"  As such, I thought it would be illuminating to have a conversation with Deepseek about the connections between two lectures in this course that are months apart, as a way to gain insight on the broader view of the course and Deep learning as a whole. </paragraph><paragraph><link href=\"https://drive.google.com/file/d/1fyjxLHhlT5YfJX_2w3rTv00GTIkU83zN/view?usp=sharing\">This is a link to the annotated trace of the conversation.</link></paragraph><paragraph>Overall, I think the model did a great job in identifying and explaining high level connections between the topics. I was presented with some obvious insights, but also a few connections that I had not made before. When I tried to prompt the model into making untrue connections, it resisted the faulty categorization, which I was pleasantly surprised by. To me it seems that these types of high-level topical natural language conversations play to the the strengths of LLMs, and can be a helpful learning tool for broad understanding of a field.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1fyjxLHhlT5YfJX_2w3rTv00GTIkU83zN/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T18:13:16.327834+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7431036,
            "author": "Akhil Agarwal",
            "project_title": "Special Participation E: NotebookLM for Reviewing GNNs",
            "post_body": "Here, I used NotebookLM to review GNNs comprehensively. I had never used it before, so this was a new experience and I was doing a mix of trying to learn about things I didn't understand, as well as testing its capabilities. I uploaded the lecture notes for both lectures covering GNNs, as well as the transcripts copy-pasted from YouTube for those two lectures. Overall, I was extremely impressed by its performance. First, the mindmap was good, but when it generated the quiz I was far more impressed. The quiz comprehensively reviewed the entire topic of GNNs (conceptually), and all of the answer choices were very related to the correct answer and the topic. Some of the questions were easy for me, while others challenged me more (I actually got 1 wrong as well, which I asked the model about, which was more of a nomenclature question, where it asked about what a concept was). When I asked it to explain why I got it wrong, it responded well, and explained the concept in depth, along with its motivation. Then, I asked it some more questions about the applications of GNNs and types of aggregation functions. It did well while talking about the things in the sources. However, when I dug further, it was limited in its scope by what was in the sources that I uploaded, so I found that while NotebookLM is an amazing resource in understanding the content you upload, it won't be able to help too much beyond that, and it may be beneficial to give it many sources about the topic to help it have more background. The video it made to explain the concepts was actually very good, which I was not expecting, and it covered the entire content nicely. The way it explained the concepts without being very robotic and being more \"human\" / having imperfect wordings also helped.\n\nOverall, it was a great experience, and I will definitely be using NotebookLM again, though I'll be adding as many sources as possible if I want to ask questions out of scope of the main content.\n\nNotebookLM chat: https://notebooklm.google.com/notebook/7772f54e-0aaa-45d3-9d57-08c968c212d5\n\nAnnotated chat trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I used NotebookLM to review GNNs comprehensively. I had never used it before, so this was a new experience and I was doing a mix of trying to learn about things I didn't understand, as well as testing its capabilities. I uploaded the lecture notes for both lectures covering GNNs, as well as the transcripts copy-pasted from YouTube for those two lectures. Overall, I was extremely impressed by its performance. First, the mindmap was good, but when it generated the quiz I was far more impressed. The quiz comprehensively reviewed the entire topic of GNNs (conceptually), and all of the answer choices were very related to the correct answer and the topic. Some of the questions were easy for me, while others challenged me more (I actually got 1 wrong as well, which I asked the model about, which was more of a nomenclature question, where it asked about what a concept was). When I asked it to explain why I got it wrong, it responded well, and explained the concept in depth, along with its motivation. Then, I asked it some more questions about the applications of GNNs and types of aggregation functions. It did well while talking about the things in the sources. However, when I dug further, it was limited in its scope by what was in the sources that I uploaded, so I found that while NotebookLM is an amazing resource in understanding the content you upload, it won't be able to help too much beyond that, and it may be beneficial to give it many sources about the topic to help it have more background. The video it made to explain the concepts was actually very good, which I was not expecting, and it covered the entire content nicely. The way it explained the concepts without being very robotic and being more \"human\" / having imperfect wordings also helped.</paragraph><paragraph>Overall, it was a great experience, and I will definitely be using NotebookLM again, though I'll be adding as many sources as possible if I want to ask questions out of scope of the main content.</paragraph><paragraph>NotebookLM chat: <link href=\"https://notebooklm.google.com/notebook/7772f54e-0aaa-45d3-9d57-08c968c212d5\">https://notebooklm.google.com/notebook/7772f54e-0aaa-45d3-9d57-08c968c212d5</link></paragraph><paragraph>Annotated chat trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/0CSoSZb6lpDqvp3BSg2X5IZS\" filename=\"Special_Participation_E2.pdf\"/></document>",
            "links": [
                "https://notebooklm.google.com/notebook/7772f54e-0aaa-45d3-9d57-08c968c212d5"
            ],
            "attachments": [],
            "created_at": "2025-12-08T18:12:29.866516+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430957,
            "author": "Imra Dawoodani",
            "project_title": "Special Participation E: Gamified approach to Optimization intuition with Gemini pro 3",
            "post_body": "Hi all,\n\nI created an AI enhanced learning tool that builds practical intuition through a prediction to feedback loop. With this tool, you make predictions about training outcomes before seeing what happens. \n\nHeres the Custom Gem:\n\nhttps://gemini.google.com/gem/13_Hu4zQ4ZCJogAYCsbFxBjz3MASNlj7t?usp=sharing \n\nAnnotated Trace of my conversation:\n\nMy findings:\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all,</paragraph><paragraph>I created an AI enhanced learning tool that builds practical intuition through a prediction to feedback loop. With this tool, you make predictions about training outcomes before seeing what happens. </paragraph><paragraph>Heres the Custom Gem:</paragraph><paragraph><link href=\"https://gemini.google.com/gem/13_Hu4zQ4ZCJogAYCsbFxBjz3MASNlj7t?usp=sharing\">https://gemini.google.com/gem/13_Hu4zQ4ZCJogAYCsbFxBjz3MASNlj7t?usp=sharing</link> </paragraph><paragraph>Annotated Trace of my conversation:</paragraph><file url=\"https://static.us.edusercontent.com/files/C6xJzt8KDTnr29ttqa8vVUXz\" filename=\"gemini.google.com-Gemini-fpscreenshot.pdf\"/><paragraph>My findings:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/Pnasxc0MeaF8NhbycsPw4Nnu\" filename=\"special participation e - predict before you learn.pdf\"/></document>",
            "links": [
                "https://gemini.google.com/gem/13_Hu4zQ4ZCJogAYCsbFxBjz3MASNlj7t?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T17:49:51.428041+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430953,
            "author": "Aryan Bansal",
            "project_title": "Special Participation E:  Simple DiffPool Visualizer",
            "post_body": "I made a very small Jupyter notebook called diffpool_visualizer.ipynb that acts as a conceptual DiffPool visualizer. Instead of training a big GNN, it focuses only on the core DiffPool step:\n\nWe build a tiny toy graph (two triangles connected by a bridge).\n\nWe define a soft assignment matrix S from nodes to clusters (what DiffPool would learn in practice).\n\nWe compute:\n\nNew cluster features \n\n$$X_{pooled}=S^TX$$\n\nA coarsened adjacency \n\n$$A_{pooled}=S^TAS$$\n\nWe then visualize three things side by side:\n\nOriginal graph: each node is colored by how strongly it belongs to a chosen cluster (you can switch clusters with a slider).\n\nAssignment matrix S: shown as a heatmap (rows = nodes, columns = clusters).\n\nCoarsened graph: a tiny graph whose nodes are clusters, with edge thickness showing how strongly clusters are connected.\n\nHow to use it\n\nOpen diffpool_visualizer.ipynb in a Jupyter environment.\n\nRun all cells.\n\nUse the cluster index slider under the last cell:\n\nWatch how the colors on the original graph change as you switch clusters.\n\nCompare that to the corresponding column in the assignment matrix S.\n\nLook at how many cluster nodes there are and how they are connected in the coarsened graph.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I made a very small Jupyter notebook called diffpool_visualizer.ipynb that acts as a conceptual DiffPool visualizer. Instead of training a big GNN, it focuses only on the core DiffPool step:</paragraph><list style=\"unordered\"><list-item><paragraph>We build a tiny toy graph (two triangles connected by a bridge).</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>We define a soft assignment matrix <italic>S</italic> from nodes to clusters (what DiffPool would learn in practice).</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>We compute:</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>New cluster features </paragraph><math>X_{pooled}=S^TX</math></list-item></list><list style=\"unordered\"><list-item><paragraph>A coarsened adjacency </paragraph><math>A_{pooled}=S^TAS</math></list-item></list><list style=\"unordered\"><list-item><paragraph>We then visualize three things side by side:</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Original graph: each node is colored by how strongly it belongs to a chosen cluster (you can switch clusters with a slider).</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Assignment matrix S: shown as a heatmap (rows = nodes, columns = clusters).</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Coarsened graph: a tiny graph whose nodes are clusters, with edge thickness showing how strongly clusters are connected.</paragraph></list-item></list><heading level=\"3\">How to use it</heading><list style=\"ordered\"><list-item><paragraph>Open diffpool_visualizer.ipynb in a Jupyter environment.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Run all cells.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Use the cluster index slider under the last cell:</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Watch how the colors on the original graph change as you switch clusters.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Compare that to the corresponding column in the assignment matrix <italic>S</italic>.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Look at how many cluster nodes there are and how they are connected in the coarsened graph.</paragraph><file url=\"https://static.us.edusercontent.com/files/RfrXZqJW6ydpOndadiwXDrs8\" filename=\"diffpool_visualizer.ipynb\"/></list-item></list><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T17:46:09.461337+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430922,
            "author": "Jiayi Zhang",
            "project_title": "Special Participation D: Experiment and Hyperparameter Sweep on SOAP and Lion Optimizers in HW 6",
            "post_body": "\n\nIn the attached notebook, I implemented two modern optimizers SOAP and Lion with coding agents and then integrated them with other optimizers used in the training tasks. I made a comparison between the performance of hand-picked learning rates with SOAP and Lion along with the performance of other optimizers presented in the notebook. Specifically, SOAP with a 1e-2 learning rate performs only better than Muon with 1e-2, and Lion has the fourth performance with a learning rate of 1e-3. Below is a graph with all of the optimizers used.\n\nIn addition, I also did a brief hyperparameter sweeping similar to the sweeps to Muon and AdamW. SOAP ends up having a 50.05% validation accuracy with a learning rate of 0.01, while Lion has the best validation rate of 68.61% at learning rate of 0.0005. It seems that overall, Lion has the best performance under this simple experiment.\n\n--- Hyperparameter Sweep Results ---\n\nSOAP:\n\n (lr=0.01): 50.05%\n\n (lr=0.005): 45.14%\n\n (lr=0.001): 30.95%\n\n (lr=0.0005): 25.58%\n\nBest hyperparameters for SOAP: lr=0.01 with validation accuracy 50.05%\n\nLion:\n\n (lr=0.01): 10.60%\n\n (lr=0.005): 23.50%\n\n (lr=0.001): 68.60%\n\n (lr=0.0005): 68.61%\n\nBest hyperparameters for Lion: lr=0.0005 with validation accuracy 68.61%\n\nGoogle Colab Notebook:\n\nhttps://drive.google.com/file/d/1znNlvhV8TdtGcmJ-2xQt3N3syeuLcW_C/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>In the attached notebook, I implemented two modern optimizers SOAP and Lion with coding agents and then integrated them with other optimizers used in the training tasks. I made a comparison between the performance of hand-picked learning rates with SOAP and Lion along with the performance of other optimizers presented in the notebook. Specifically, SOAP with a 1e-2 learning rate performs only better than Muon with 1e-2, and Lion has the fourth performance with a learning rate of 1e-3. Below is a graph with all of the optimizers used.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/AtE69FgiqciHCZgXccqCCZf2\" width=\"495\" height=\"245\"/></figure><paragraph>In addition, I also did a brief hyperparameter sweeping similar to the sweeps to Muon and AdamW. SOAP ends up having a 50.05% validation accuracy with a learning rate of 0.01, while Lion has the best validation rate of 68.61% at learning rate of 0.0005. It seems that overall, Lion has the best performance under this simple experiment.</paragraph><paragraph>--- Hyperparameter Sweep Results ---</paragraph><paragraph>SOAP:</paragraph><paragraph> (lr=0.01): 50.05%</paragraph><paragraph> (lr=0.005): 45.14%</paragraph><paragraph> (lr=0.001): 30.95%</paragraph><paragraph> (lr=0.0005): 25.58%</paragraph><paragraph>Best hyperparameters for SOAP: lr=0.01 with validation accuracy 50.05%</paragraph><paragraph>Lion:</paragraph><paragraph> (lr=0.01): 10.60%</paragraph><paragraph> (lr=0.005): 23.50%</paragraph><paragraph> (lr=0.001): 68.60%</paragraph><paragraph> (lr=0.0005): 68.61%</paragraph><paragraph>Best hyperparameters for Lion: lr=0.0005 with validation accuracy 68.61%</paragraph><paragraph>Google Colab Notebook:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1znNlvhV8TdtGcmJ-2xQt3N3syeuLcW_C/view?usp=sharing\"><underline>https://drive.google.com/file/d/1znNlvhV8TdtGcmJ-2xQt3N3syeuLcW_C/view?usp=sharing</underline></link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1znNlvhV8TdtGcmJ-2xQt3N3syeuLcW_C/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T17:37:19.801618+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430849,
            "author": "Jiayi Zhang",
            "project_title": "Special Participation D: Exploring Different Learning Rates and Batch Sizes on Homework 5",
            "post_body": "In the attached notebook, I adjusted the CIFAR-10 task to make it adapt it to a parameter sweep on different learning rate and different batch sizes. The model is experiencing underfitting with the learning rates I have explored, and the batch sizes have a less effect on the performance under the underfitting than learning rates.\n\nI also explore rerunning the experiments with both clean and cheating features on Muon's variant optimizers MuonLion and MuonAdamW. Since these optimizers are not available in Pytorch, I used ChatGPT 5.1 to help me to implement these two Muon variants. Both optimizers have a worse performance than traditional optimizers like SGD and Adam, and showed some interesting behaviors. I added some questions regarding to these optimizers to this task at the end.\n\nGoogle Colab Notebook:\n\nhttps://drive.google.com/file/d/1JhwudZF6UMnLjLDnCRqoS0qZySEdzL2D/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>In the attached notebook, I adjusted the CIFAR-10 task to make it adapt it to a parameter sweep on different learning rate and different batch sizes. The model is experiencing underfitting with the learning rates I have explored, and the batch sizes have a less effect on the performance under the underfitting than learning rates.</paragraph><paragraph>I also explore rerunning the experiments with both clean and cheating features on Muon's variant optimizers MuonLion and MuonAdamW. Since these optimizers are not available in Pytorch, I used ChatGPT 5.1 to help me to implement these two Muon variants. Both optimizers have a worse performance than traditional optimizers like SGD and Adam, and showed some interesting behaviors. I added some questions regarding to these optimizers to this task at the end.</paragraph><paragraph>Google Colab Notebook:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1JhwudZF6UMnLjLDnCRqoS0qZySEdzL2D/view?usp=sharing\">https://drive.google.com/file/d/1JhwudZF6UMnLjLDnCRqoS0qZySEdzL2D/view?usp=sharing</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1JhwudZF6UMnLjLDnCRqoS0qZySEdzL2D/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T17:21:12.239915+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430788,
            "author": "Jermaine Lei",
            "project_title": "Special Participation E: Using ChatGPT to surface what you don't know",
            "post_body": "For this assignment, I wanted to create a question generator of some kind. Instead of having the model explain the lecture to me, I flipped the direction and had it act as an \u201coffice hour simulator\u201d where the model acts like a line of students asking questions about the lecture. The main idea was to surface the things I don\u2019t know and wouldn\u2019t think to ask on my own. Sometimes it\u2019s really hard to pinpoint your own gaps in understanding so having the model generate realistic, conceptual, and mechanic-focused questions and even tweak baseline assumptions to test whether I truly understood the concepts felt like a unique way to self-check my knowledge. In order to make this work, I\u2019ve created 2 prompts. \n\nThe first one:\n\nThe reason for adding the 3 different types of questions was to maximize the chances that the model would generate a conceptual question that hits an area of understanding that you may lack. After answering the questions in bullet point fashion, the second prompt generates its own \u201ctruth\u201d response and compares it to yours:\n\nThe main goal of this second prompt is to identify where your answer lacks some more concrete reasoning/information. This is helpful because even if the model identifies a missing piece of your response that you already know, seeing that missing piece connect to the rest of your answer can reinforce your understanding of the topic.\n\nIn my example, I use the lecture 7 slides. The model\u2019s student questions captured the tone and content of real confusion points. It asked about how the updates work, how the SVD pieces fit together, and how different assumptions would change the behavior of the algorithm. These kinds of questions immediately showed which parts of the lecture I understood well and which parts I was glossing over, and answering them myself first made those gaps obvious when the model later switched into instructor mode and filled in the missing steps.\n\nOverall, this turned out to be a genuinely useful learning tool. The model kept everything grounded in the lecture notes while still giving enough detail to strengthen my understanding, and its critiques helped sharpen my answers rather than just telling me they were wrong. Most importantly, this setup pushed me into a kind of deeper reasoning practice that is hard to create on my own because it required me to articulate ideas clearly, check my logic, and confront misunderstandings I did not realize I had. As a post-lecture study method, I would definitely use this approach again.\n\n\nHere is my annotated chat conversation using Lecture 7 as an example:",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I wanted to create a question generator of some kind. Instead of having the model explain the lecture to me, I flipped the direction and had it act as an \u201coffice hour simulator\u201d where the model acts like a line of students asking questions about the lecture. The main idea was to surface the things I <italic>don\u2019t</italic> know and wouldn\u2019t think to ask on my own. Sometimes it\u2019s really hard to pinpoint your own gaps in understanding so having the model generate realistic, conceptual, and mechanic-focused questions and even tweak baseline assumptions to test whether I truly understood the concepts felt like a unique way to self-check my knowledge. In order to make this work, I\u2019ve created 2 prompts. </paragraph><paragraph>The first one:</paragraph><file url=\"https://static.us.edusercontent.com/files/WZeH73JhAb6F1IL2s6N6C6r0\" filename=\"prompt_1.txt\"/><paragraph>The reason for adding the 3 different types of questions was to maximize the chances that the model would generate a conceptual question that hits an area of understanding that you may lack. After answering the questions in bullet point fashion, the second prompt generates its own \u201ctruth\u201d response and compares it to yours:</paragraph><file url=\"https://static.us.edusercontent.com/files/JUuib136CPyKgnursWEpHafZ\" filename=\"prompt_2.txt\"/><paragraph>The main goal of this second prompt is to identify where your answer lacks some more concrete reasoning/information. This is helpful because even if the model identifies a missing piece of your response that you already know, seeing that missing piece connect to the rest of your answer can reinforce your understanding of the topic.</paragraph><paragraph>In my example, I use the lecture 7 slides. The model\u2019s student questions captured the tone and content of real confusion points. It asked about how the updates work, how the SVD pieces fit together, and how different assumptions would change the behavior of the algorithm. These kinds of questions immediately showed which parts of the lecture I understood well and which parts I was glossing over, and answering them myself first made those gaps obvious when the model later switched into instructor mode and filled in the missing steps.</paragraph><paragraph>Overall, this turned out to be a genuinely useful learning tool. The model kept everything grounded in the lecture notes while still giving enough detail to strengthen my understanding, and its critiques helped sharpen my answers rather than just telling me they were wrong. Most importantly, this setup pushed me into a kind of deeper reasoning practice that is hard to create on my own because it required me to articulate ideas clearly, check my logic, and confront misunderstandings I did not realize I had. As a post-lecture study method, I would definitely use this approach again.</paragraph><paragraph><break/>Here is my annotated chat conversation using Lecture 7 as an example:</paragraph><file url=\"https://static.us.edusercontent.com/files/xoHo8dlUrPjl9FbxojkZYCwU\" filename=\"OfficeHourSimulChat.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T17:07:50.3745+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430787,
            "author": "Gustavo Jose Ortiz Zepeda",
            "project_title": "Special Participation E: review of the homework topics Hw6 and discussion 7",
            "post_body": "In this special participation, I created this prompt to review all the sections of the homework in an easy and dynamic way to make sure I don\u2019t have questions about things mentioned and not mentioned in the homework and discussion.\n\nI was really impressed with the questions asked because they were very broad in terms of the topics covered and even some were really tricky. They are all multiple-choice, so you can do the test while riding the BART or during any free moment and keep making progress.\n\nPrompt: I want to review the topics mentioned on this homework, let's make two things, first a refresh of all the concepts explained as detailed as possible and then connected with each other if applies. Now we have the big picture, let's do some simple examples so it is easier to remember and make a better understanding of them. And finally let's do a quiz of at least 30 (could be much more if many wrong answers) multiple choice questions in which we review each topic starting from easy questions and level up if correct answers and downgrade the level if incorrect answers (also giving an explanation of the possible confusion and reviewing the concepts needed to explain the correct answer).",
            "content_xml": "<document version=\"2.0\"><paragraph>In this special participation, I created this prompt to review all the sections of the homework in an easy and dynamic way to make sure I don\u2019t have questions about things mentioned and not mentioned in the homework and discussion.</paragraph><paragraph>I was really impressed with the questions asked because they were very broad in terms of the topics covered and even some were really tricky. They are all multiple-choice, so you can do the test while riding the BART or during any free moment and keep making progress.</paragraph><paragraph>Prompt: I want to review the topics mentioned on this homework, let's make two things, first a refresh of all the concepts explained as detailed as possible and then connected with each other if applies. Now we have the big picture, let's do some simple examples so it is easier to remember and make a better understanding of them. And finally let's do a quiz of at least 30 (could be much more if many wrong answers) multiple choice questions in which we review each topic starting from easy questions and level up if correct answers and downgrade the level if incorrect answers (also giving an explanation of the possible confusion and reviewing the concepts needed to explain the correct answer).</paragraph><file url=\"https://static.us.edusercontent.com/files/xMRfWOySPgQORl9pGfecsHvv\" filename=\"Special Participation E-2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T17:07:48.665603+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430783,
            "author": "Daniel Kao",
            "project_title": "Special Participation E: Using ChatGPT to Generate Learning guides for a Teacher's Style",
            "post_body": "An issue I often run into when first encountering a lecturer is adapting to the given teaching style. For example, some teachers may prefer to give a higher level theoretical overview of a subject, while others are more interested in showing students how to empirically solve problems with examples. Perhaps there a teacher introduces a lot of definitions at the beginning of a class and it is thus imperative to write them down to continue learning. These are aspects I slowly adapt to as I get more familiar with a teacher, but there is often a whiplash effect when going from one teaching style to another, especially when browsing the internet for explanations.\n\nAs such, my goal is to create a system prompt to make LLM's analyze an excerpt of a teacher's lecture and generate a learning guide, quickly identifying the key aspects of the lecture style and content. Attached is the system prompt itself, as well as 2 sample transcripts: One is from the CS182 Lecture on Sign SGD, Shampoo, muP and muon, and the second one (just for fun) is a transcript from Terence Tao's lecture on the gaps between prime numbers (here is the youtube link for those interested).\n\nHere is the link to the PDF of my annotated trace, generating a learning guide for the CS182 Lecture\n\nOverall, I found the tool to be quite useful. For example, it was able to identify the importance of EECS 127 to the course material of this class simply through the context of the lecture, and gave helpful suggestions like drawing diagrams by hand and asking yourself conceptual questions. There are definitely limitations to the tool though, for example most context windows cannot fit an entire lecture's transcript and thus the tool is best used on an excerpt. Furthermore, the model does not receive any visual data, and is thus limited in its ability to comment on expressiveness, visual examples etc. Hope you all find this helpful!",
            "content_xml": "<document version=\"2.0\"><paragraph>An issue I often run into when first encountering a lecturer is adapting to the given teaching style. For example, some teachers may prefer to give a higher level theoretical overview of a subject, while others are more interested in showing students how to empirically solve problems with examples. Perhaps there a teacher introduces a lot of definitions at the beginning of a class and it is thus imperative to write them down to continue learning. These are aspects I slowly adapt to as I get more familiar with a teacher, but there is often a whiplash effect when going from one teaching style to another, especially when browsing the internet for explanations.</paragraph><paragraph>As such, my goal is to create a system prompt to make LLM's analyze an excerpt of a teacher's lecture and generate a learning guide, quickly identifying the key aspects of the lecture style and content. Attached is the system prompt itself, as well as 2 sample transcripts: One is from the CS182 Lecture on Sign SGD, Shampoo, muP and muon, and the second one (just for fun) is a transcript from Terence Tao's lecture on the gaps between prime numbers (<link href=\"https://www.youtube.com/watch?v=pp06oGD4m00&amp;t=863s\">here is the youtube link for those interested</link>).</paragraph><file url=\"https://static.us.edusercontent.com/files/g41m4UL06Hs1tyaNYAOFCqNp\" filename=\"Daniel Kao Special Participation E_ Learning Guide.pdf\"/><paragraph><link href=\"https://drive.google.com/file/d/1sH-FJ1dt9zYP6inGMpgcPPEQYT827cuT/view?usp=sharing\">Here is the link to the PDF of my annotated trace, generating a learning guide for the CS182 Lecture</link></paragraph><paragraph>Overall, I found the tool to be quite useful. For example, it was able to identify the importance of EECS 127 to the course material of this class simply through the context of the lecture, and gave helpful suggestions like drawing diagrams by hand and asking yourself conceptual questions. There are definitely limitations to the tool though, for example most context windows cannot fit an entire lecture's transcript and thus the tool is best used on an excerpt. Furthermore, the model does not receive any visual data, and is thus limited in its ability to comment on expressiveness, visual examples etc. Hope you all find this helpful!</paragraph></document>",
            "links": [
                "https://www.youtube.com/watch?v=pp06oGD4m00&amp;t=863s",
                "https://drive.google.com/file/d/1sH-FJ1dt9zYP6inGMpgcPPEQYT827cuT/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T17:05:26.953273+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430749,
            "author": "Sanjay Adhikesaven",
            "project_title": "Special Participation A: GPT 5 Thinking on HW 10",
            "post_body": "I used ChatGPT 5 (Thinking) on HW 10 (all non-coding parts).\n\nHere is the conversation log. Here is the annotated conversation.\n\nSummary:  Across my interaction, ChatGPT was able to one-shot solve each of the problems, and it consistently interpreted questions without requiring clarification. The model produced correct derivations for the kernelized linear attention problem, including Gaussian kernel decomposition and Random Fourier Feature approximation. Its answers showed no hallucinations and showed strong and reliable reasoning. For the second problem, ChatGPT also answered all questions on the first attempt. I had to manually enable web search to that it could access the paper and the blog. It then correctly provided citations and was able to read and synthesize the paper/blog. I liked how it listed all the assumptions it made which can help in cases where it is incorrect. I generally also felt that the solutions it provided were intuitive but also had good technical rigor.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5 (Thinking) on HW 10 (all non-coding parts).</paragraph><paragraph><link href=\"https://chatgpt.com/share/693661d8-5ca8-8007-a117-8bd1a885742c\">Here</link> is the conversation log. <link href=\"https://drive.google.com/file/d/1OD8hsvemO83sysIQeAxkg_2fo51LlrMk/view?usp=sharing\">Here</link> is the annotated conversation.<break/><break/>Summary:  Across my interaction, ChatGPT was able to one-shot solve each of the problems, and it consistently interpreted questions without requiring clarification. The model produced correct derivations for the kernelized linear attention problem, including Gaussian kernel decomposition and Random Fourier Feature approximation. Its answers showed no hallucinations and showed strong and reliable reasoning. For the second problem, ChatGPT also answered all questions on the first attempt. I had to manually enable web search to that it could access the paper and the blog. It then correctly provided citations and was able to read and synthesize the paper/blog. I liked how it listed all the assumptions it made which can help in cases where it is incorrect. I generally also felt that the solutions it provided were intuitive but also had good technical rigor.</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/693661d8-5ca8-8007-a117-8bd1a885742c",
                "https://drive.google.com/file/d/1OD8hsvemO83sysIQeAxkg_2fo51LlrMk/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T16:56:49.895781+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430565,
            "author": "Jason Lee",
            "project_title": "Special Participation B: Kimi on HW10 Code",
            "post_body": "I tried to complete Homework 10 (coding portion) using Kimi v2, which involves implementing a Transformer from scratch using NumPy. I found that Kimi v2 was very fast and concise with the easy parts. I also found that Kimi v2 is very concise with code changes, reducing the overall number of tokens it outputs. In the hand transformer notebook, it really struggled on the task where you have to use the identity matrix and `Km`, `Qm`, and `Vm` as it took over 5 tries to finally get close to the solution - funny enough, once it got super close to the solution (it was just missing the 15 * `Qm`), it argued I should lower the tolerance for the unit test preventing it from succeeding. It also couldn\u2019t figure out the next part \u201cAttention by Position\u201d because it initially had one idea of how to solve the problem and then upon prompting it about its failures, it kept trying to think about a small modification to the script it wrote, rather than thinking about a new way to approach the problem. I think this is an area where the model struggles. On the other hand, it was able to get the Part 1 Transformer notebook fully correct on the first try. So, in summary, I think the best way to use this model is using pass at N or resampling, rather than having it continually think about why its own output isn\u2019t working.\n\nOne cool behavior I noticed when completing this task is that compared to ChatGPT where when you ask it to code something, it outputs a repeat of the entire code with the fix (usually regardless of how small the code change is). On the other hand, Kimi only tells you the smaller area it needs to change. Very environmentally friendly inference! This is a gift and a curse because at the same time, it didn\u2019t/couldn\u2019t try many new different ways of solving the problem which is why it struggled on the homework.\n\n\n\nNote: I had to annotate using google docs since Kimi doesn't support exporting as PDF from the HTML :( sorry it's not aesthetically pleasing",
            "content_xml": "<document version=\"2.0\"><paragraph>I tried to complete Homework 10 (coding portion) using Kimi v2, which involves implementing a Transformer from scratch using NumPy. I found that Kimi v2 was very fast and concise with the easy parts. I also found that Kimi v2 is very concise with code changes, reducing the overall number of tokens it outputs. In the hand transformer notebook, it really struggled on the task where you have to use the identity matrix and `Km`, `Qm`, and `Vm` as it took over 5 tries to finally get close to the solution - funny enough, once it got super close to the solution (it was just missing the 15 * `Qm`), it argued I should lower the tolerance for the unit test preventing it from succeeding. It also couldn\u2019t figure out the next part \u201cAttention by Position\u201d because it initially had one idea of how to solve the problem and then upon prompting it about its failures, it kept trying to think about a small modification to the script it wrote, rather than thinking about a new way to approach the problem. I think this is an area where the model struggles. On the other hand, it was able to get the Part 1 Transformer notebook fully correct on the first try. So, in summary, I think the best way to use this model is using pass at N or resampling, rather than having it continually think about why its own output isn\u2019t working.</paragraph><paragraph>One cool behavior I noticed when completing this task is that compared to ChatGPT where when you ask it to code something, it outputs a repeat of the entire code with the fix (usually regardless of how small the code change is). On the other hand, Kimi only tells you the smaller area it needs to change. Very environmentally friendly inference! This is a gift and a curse because at the same time, it didn\u2019t/couldn\u2019t try many new different ways of solving the problem which is why it struggled on the homework.</paragraph><paragraph/><paragraph>Note: I had to annotate using google docs since Kimi doesn't support exporting as PDF from the HTML :( sorry it's not aesthetically pleasing</paragraph><file url=\"https://static.us.edusercontent.com/files/2HwDIfU5XEA1ExtZbn06YQbi\" filename=\"Special_Participation_B_Jason_Lee-2.pdf\"/><file/><file/><file/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T16:20:17.592626+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430552,
            "author": "Kevin Tseng",
            "project_title": "Special Participation E: Equation Intuition Annotator",
            "post_body": "I used Claude\u2019s Artifacts to vibe code an equation annotator to help gain intuition for how often monstrous equations work. I think you need a Claude account to use the actual artifact, but you can replicate this by feeding the same prompt to a chatbot instead of using my tool to send an API request.\n\nThe link to use it is here\n\nhttps://claude.ai/public/artifacts/4a9d7ab1-dbcc-44fc-b0e7-3afe1e45f38d\n\nHere is the prompt if you want to use an image of an equation:\n\nI've uploaded an image containing a deep learning equation. Please identify the equation and provide a breakdown with these sections:\n\n1. WHAT IT IS: One sentence describing what this equation represents\n2. SYMBOL BREAKDOWN: Explain each symbol/term and what it represents intuitively\n3. WHY IT WORKS: Explain the intuition behind why this formulation makes sense\n4. WHAT IF WE CHANGE THINGS: For each major variable/parameter, explain what happens when you:\n   - Increase it\n   - Decrease it\n   - Set it to zero (if applicable)\n   - Remove it entirely\n5. COMMON MISCONCEPTIONS: What do students often get wrong about this?\n6. VISUAL INTUITION: Describe a geometric or visual way to think about this\n\nUse LaTeX formatting for any mathematical expressions (use $ for inline math and $ for display math).\nBe concise, intuitive, and focus on building understanding rather than just stating facts.\n\n\n\nHere is the prompt if you want to type an equation:\n\nI've uploaded an image containing a deep learning equation. Please identify the equation and provide a breakdown with these sections:\n\n1. WHAT IT IS: One sentence describing what this equation represents\n2. SYMBOL BREAKDOWN: Explain each symbol/term and what it represents intuitively\n3. WHY IT WORKS: Explain the intuition behind why this formulation makes sense\n4. WHAT IF WE CHANGE THINGS: For each major variable/parameter, explain what happens when you:\n   - Increase it\n   - Decrease it\n   - Set it to zero (if applicable)\n   - Remove it entirely\n5. COMMON MISCONCEPTIONS: What do students often get wrong about this?\n6. VISUAL INTUITION: Describe a geometric or visual way to think about this\n\nUse LaTeX formatting for any mathematical expressions (use $ for inline math and $ for display math).\nBe concise, intuitive, and focus on building understanding rather than just stating facts.\n\n\n\nAttached is a pdf with some example traces of its use:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Claude\u2019s Artifacts to vibe code an equation annotator to help gain intuition for how often monstrous equations work. I think you need a Claude account to use the actual artifact, but you can replicate this by feeding the same prompt to a chatbot instead of using my tool to send an API request.</paragraph><paragraph>The link to use it is here</paragraph><paragraph><link href=\"https://claude.ai/public/artifacts/4a9d7ab1-dbcc-44fc-b0e7-3afe1e45f38d\">https://claude.ai/public/artifacts/4a9d7ab1-dbcc-44fc-b0e7-3afe1e45f38d</link></paragraph><paragraph>Here is the prompt if you want to use an image of an equation:</paragraph><pre>I've uploaded an image containing a deep learning equation. Please identify the equation and provide a breakdown with these sections:\n\n1. WHAT IT IS: One sentence describing what this equation represents\n2. SYMBOL BREAKDOWN: Explain each symbol/term and what it represents intuitively\n3. WHY IT WORKS: Explain the intuition behind why this formulation makes sense\n4. WHAT IF WE CHANGE THINGS: For each major variable/parameter, explain what happens when you:\n   - Increase it\n   - Decrease it\n   - Set it to zero (if applicable)\n   - Remove it entirely\n5. COMMON MISCONCEPTIONS: What do students often get wrong about this?\n6. VISUAL INTUITION: Describe a geometric or visual way to think about this\n\nUse LaTeX formatting for any mathematical expressions (use $ for inline math and $ for display math).\nBe concise, intuitive, and focus on building understanding rather than just stating facts.\n\n</pre><paragraph>Here is the prompt if you want to type an equation:</paragraph><pre>I've uploaded an image containing a deep learning equation. Please identify the equation and provide a breakdown with these sections:\n\n1. WHAT IT IS: One sentence describing what this equation represents\n2. SYMBOL BREAKDOWN: Explain each symbol/term and what it represents intuitively\n3. WHY IT WORKS: Explain the intuition behind why this formulation makes sense\n4. WHAT IF WE CHANGE THINGS: For each major variable/parameter, explain what happens when you:\n   - Increase it\n   - Decrease it\n   - Set it to zero (if applicable)\n   - Remove it entirely\n5. COMMON MISCONCEPTIONS: What do students often get wrong about this?\n6. VISUAL INTUITION: Describe a geometric or visual way to think about this\n\nUse LaTeX formatting for any mathematical expressions (use $ for inline math and $ for display math).\nBe concise, intuitive, and focus on building understanding rather than just stating facts.\n\n</pre><paragraph>Attached is a pdf with some example traces of its use:</paragraph><file url=\"https://static.us.edusercontent.com/files/jLJOMJQLuWeIpBsemSIItt0P\" filename=\"Special Participation E_ Equation Intuition Annotator.pdf\"/><paragraph/></document>",
            "links": [
                "https://claude.ai/public/artifacts/4a9d7ab1-dbcc-44fc-b0e7-3afe1e45f38d"
            ],
            "attachments": [],
            "created_at": "2025-12-08T16:17:31.715972+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430420,
            "author": "John Wang",
            "project_title": "Special Participation E: NotebookLM-based HW3 Final Review Notebook",
            "post_body": "For this (E) participation, I built a small AI-enhanced review tool for HW3 using Google\u2019s NotebookLM in notebook mode. I created a notebook and uploaded three resources: the HW3 PDF, the official HW3 solutions, and a short HW3 review slide deck I made from the solutions. In Phase 1, I asked NotebookLM to generate a slide-style summary of HW3 (grouped by topics like Gaussian initialization, RMS/RMS norms, sign-SGD updates, \u00b5P scaling, and policy gradient/reparameterization). In Phase 2, I re-uploaded the refined slides and used a second prompt to generate a ~5\u201310 minute low-detail audio overview that walks through these slides. I listened to the audio while following along with the slides as a fast, multi-modal \u201cbig picture\u201d recap before the final.\n\nIn Phase 3, I switched to an interactive, problem-centered dialogue inside the same notebook. Using only the uploaded HW3 + solution PDFs, I asked NotebookLM to (1) explain what a specific question (e.g., HW3 Q1) is really testing, (2) walk through the official solution step by step, and (3) propose exam-style variants that test the same underlying idea. I\u2019ve attached my prompts and an annotated interaction trace for Q1, where I explicitly mark places where the explanations are genuinely helpful (e.g., why the expected RMS depends on d1\u200b but not d2\u200b) and places where the comments about \u00b5P scaling are oversimplified or slightly misleading. Classmates can recreate the same NotebookLM setup (upload HW3 + solutions + slides, paste the prompts) and use it as a structured, post-homework, pre-final review environment for HW3.",
            "content_xml": "<document version=\"2.0\"><paragraph>For this (E) participation, I built a small AI-enhanced review tool for HW3 using Google\u2019s NotebookLM in notebook mode. I created a notebook and uploaded three resources: the HW3 PDF, the official HW3 solutions, and a short HW3 review slide deck I made from the solutions. In Phase 1, I asked NotebookLM to generate a slide-style summary of HW3 (grouped by topics like Gaussian initialization, RMS/RMS norms, sign-SGD updates, \u00b5P scaling, and policy gradient/reparameterization). In Phase 2, I re-uploaded the refined slides and used a second prompt to generate a ~5\u201310 minute low-detail audio overview that walks through these slides. I listened to the audio while following along with the slides as a fast, multi-modal \u201cbig picture\u201d recap before the final.</paragraph><paragraph>In Phase 3, I switched to an interactive, problem-centered dialogue inside the same notebook. Using only the uploaded HW3 + solution PDFs, I asked NotebookLM to (1) explain what a specific question (e.g., HW3 Q1) is really testing, (2) walk through the official solution step by step, and (3) propose exam-style variants that test the same underlying idea. I\u2019ve attached my prompts and an annotated interaction trace for Q1, where I explicitly mark places where the explanations are genuinely helpful (e.g., why the expected RMS depends on d1\u200b but not d2\u200b) and places where the comments about \u00b5P scaling are oversimplified or slightly misleading. Classmates can recreate the same NotebookLM setup (upload HW3 + solutions + slides, paste the prompts) and use it as a structured, post-homework, pre-final review environment for HW3.</paragraph><file url=\"https://static.us.edusercontent.com/files/mUNqQLsGccsCkMioNe12L0Oj\" filename=\"Participation E.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T15:57:58.214006+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430296,
            "author": "Ayush Goel",
            "project_title": "Special Participation E: ChatGPT Study mode on MAML",
            "post_body": "I used ChatGPT's study mode to better understand MAML. I've attached an annotated transcript of my conversation.\n\n\n\nHere are some things I found interesting:\n1. Here around, ChatGPT was very methodical about explaining MAML. It didn't dump the entire setup and explanation of MAML at once, but moved on one step at a time, followed by a cross check question at every step to make sure I was on the same page.\n\n2. ChatGPT brought up interesting points about second order gradients being implicitly computed which I hadn't thought about when I was learning MAML via lecture.\n\n3. ChatGPT also brought up first order MAML as a more practical alternative. This was very nice to see and learn about as it goes beyond the scope of what it asked, but provided very useful context for if I were to every try implementing MAML.\n\n4. I didn't fully understand how first order MAML was different from multitask learning, and ChatGPT was able to come up with a numerical and visual example. This very clearly illustrated the differences in solutions arrived at by the different methods. Here, the visualization had some mistakes (the plotting wasn't exactly correct), but for the most part this didn't impact my understanding of the topic.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT's study mode to better understand MAML. I've attached an annotated transcript of my conversation.</paragraph><file url=\"https://static.us.edusercontent.com/files/3L4l09u7BaAAp5bG3Rc8C0gV\" filename=\"maml_gpt_study.pdf\"/><paragraph/><paragraph>Here are some things I found interesting:<break/>1. Here around, ChatGPT was very methodical about explaining MAML. It didn't dump the entire setup and explanation of MAML at once, but moved on one step at a time, followed by a cross check question at every step to make sure I was on the same page.</paragraph><paragraph>2. ChatGPT brought up interesting points about second order gradients being implicitly computed which I hadn't thought about when I was learning MAML via lecture.</paragraph><paragraph>3. ChatGPT also brought up first order MAML as a more practical alternative. This was very nice to see and learn about as it goes beyond the scope of what it asked, but provided very useful context for if I were to every try implementing MAML.</paragraph><paragraph>4. I didn't fully understand how first order MAML was different from multitask learning, and ChatGPT was able to come up with a numerical and visual example. This very clearly illustrated the differences in solutions arrived at by the different methods. Here, the visualization had some mistakes (the plotting wasn't exactly correct), but for the most part this didn't impact my understanding of the topic.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T15:37:06.537337+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430289,
            "author": "Rishi Thakar",
            "project_title": "Participation B: Claude Opus 4.5 on HW5 Coding (Dropout & BatchNorm)",
            "post_body": "Model: Claude Opus 4.5\n\nConversation link: https://claude.ai/share/3d2aa8d2-8752-494f-9c08-bf2796196027\n\nSetup: I uploaded the HW5 starter files (layers.py, fc_net.py, notebooks) to a Claude Project and worked through the implementations in one conversation. System prompt asked for step-by-step reasoning and commented code.\n\nResults: 12/12 one-shot correct, 0 errors, 0 hallucinations\n\nQuestion 5 - Understanding Dropout (7 parts):\n\n5a-b: Correctly solved underdetermined least squares with pseudoinverse, explained why GD converges to same minimum-norm solution\n\n5c-d: Built expanded dropout dataset with inverted scaling, implemented dropout layer correctly\n\n5e: Explained why large batch size smooths training (Law of Large Numbers reduces variance)\n\n5f: Nailed the weight ratio reversal (10:1 \u2192 1:10) and explained dropout forces equal feature contributions\n\n5i: Correctly analyzed cheating feature experiment - without dropout network exploits shortcut, with dropout it learns real features\n\nQuestion 6 - BatchNorm/Dropout/CNNs (5 parts):\n\nbatchnorm_forward: Clean implementation with running averages and proper cache storage\n\ndropout_forward/backward: Correct inverted dropout with mask scaling\n\n6c: Explained the inverse relationship (higher dropout \u2192 higher train loss but better val accuracy) as regularization preventing co-adaptation\n\n6d: Described network design and systematic hyperparameter tuning procedure\n\nObservations:\n\nStrong on both implementation and conceptual explanation\n\nUnprompted connections to theory (ensemble interpretation of dropout, co-adaptation)\n\nCode was well-commented with shape annotations throughout\n\nNo hand-holding needed - gave complete working implementations from function signatures alone\n\nAnnotated PDF for question 5: \n\nAnnotated PDF for question 6: ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Model:</bold> Claude Opus 4.5</paragraph><paragraph><bold>Conversation link:</bold> <link href=\"https://claude.ai/share/3d2aa8d2-8752-494f-9c08-bf2796196027\">https://claude.ai/share/3d2aa8d2-8752-494f-9c08-bf2796196027</link></paragraph><paragraph><bold>Setup:</bold> I uploaded the HW5 starter files (layers.py, fc_net.py, notebooks) to a Claude Project and worked through the implementations in one conversation. System prompt asked for step-by-step reasoning and commented code.</paragraph><paragraph><bold>Results:</bold> 12/12 one-shot correct, 0 errors, 0 hallucinations</paragraph><paragraph><bold>Question 5 - Understanding Dropout (7 parts):</bold></paragraph><list style=\"unordered\"><list-item><paragraph>5a-b: Correctly solved underdetermined least squares with pseudoinverse, explained why GD converges to same minimum-norm solution</paragraph></list-item><list-item><paragraph>5c-d: Built expanded dropout dataset with inverted scaling, implemented dropout layer correctly</paragraph></list-item><list-item><paragraph>5e: Explained why large batch size smooths training (Law of Large Numbers reduces variance)</paragraph></list-item><list-item><paragraph>5f: Nailed the weight ratio reversal (10:1 \u2192 1:10) and explained dropout forces equal feature contributions</paragraph></list-item><list-item><paragraph>5i: Correctly analyzed cheating feature experiment - without dropout network exploits shortcut, with dropout it learns real features</paragraph></list-item></list><paragraph><bold>Question 6 - BatchNorm/Dropout/CNNs (5 parts):</bold></paragraph><list style=\"unordered\"><list-item><paragraph>batchnorm_forward: Clean implementation with running averages and proper cache storage</paragraph></list-item><list-item><paragraph>dropout_forward/backward: Correct inverted dropout with mask scaling</paragraph></list-item><list-item><paragraph>6c: Explained the inverse relationship (higher dropout \u2192 higher train loss but better val accuracy) as regularization preventing co-adaptation</paragraph></list-item><list-item><paragraph>6d: Described network design and systematic hyperparameter tuning procedure</paragraph></list-item></list><paragraph><bold>Observations:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Strong on both implementation and conceptual explanation</paragraph></list-item><list-item><paragraph>Unprompted connections to theory (ensemble interpretation of dropout, co-adaptation)</paragraph></list-item><list-item><paragraph>Code was well-commented with shape annotations throughout</paragraph></list-item><list-item><paragraph>No hand-holding needed - gave complete working implementations from function signatures alone</paragraph></list-item></list><paragraph><bold>Annotated PDF for question 5:</bold> </paragraph><file url=\"https://static.us.edusercontent.com/files/twe9kdujC3nuL8cbOt0wGuEV\" filename=\"Q5_annotated.pdf\"/><paragraph><bold>Annotated PDF for question 6:</bold> </paragraph><file url=\"https://static.us.edusercontent.com/files/r8JrWUYmfxefXpAB6OluYel7\" filename=\"Q6_annotated.pdf\"/></document>",
            "links": [
                "https://claude.ai/share/3d2aa8d2-8752-494f-9c08-bf2796196027"
            ],
            "attachments": [],
            "created_at": "2025-12-08T15:35:57.47353+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430233,
            "author": "Ijin Yu",
            "project_title": "Special Participation E: AI-Enhanced Learning Artifact: The GPT-2 \"Logit Lens\" with Cursor",
            "post_body": "1. Prompt Strategy \n\nI acted as a \"Technical Lead\" and prompted the AI (Cursor/Gemini) to write a PyTorch + Streamlit script.\n\nPrompt: \"Write a Python script using Streamlit and HuggingFace that implements a 'Logit Lens' for GPT-2. It should hook into every transformer layer, apply the unembedding matrix to the hidden states, and visualize the top-3 predicted tokens at each stage to show how the model's confidence evolves.\"\n\n2. Interaction Trace & Critical Annotation (The Debugging Log) The AI successfully generated the logic for the Logit Lens but failed significantly on implementation details. Below is the log of the 4 specific crashes I had to debug, annotated with my critique of the AI's performance.\n\nhttps://docs.google.com/spreadsheets/d/17VnvoLmzWUtTz3R9J_-RMwJJWNNa0Yxjo5SipqXoh98/edit?usp=sharing \n\n3. Conclusion\n\nThis experiment demonstrated that LLMs are excellent at reactive debugging (fixing crashes when shown a stack trace) but poor at one-shotting. My role shifted from \"Coder\" to \"Reviewer,\" validating that the AI's \"fixes\" were theoretically sound.\n\n\n\nHere is the StreamLit project Link: https://ijinyu1113gpt-2-logit-lens-visualization.streamlit.app/ ",
            "content_xml": "<document version=\"2.0\"><paragraph>1. Prompt Strategy </paragraph><paragraph>I acted as a \"Technical Lead\" and prompted the AI (Cursor/Gemini) to write a PyTorch + Streamlit script.</paragraph><paragraph>Prompt: \"Write a Python script using Streamlit and HuggingFace that implements a 'Logit Lens' for GPT-2. It should hook into every transformer layer, apply the unembedding matrix to the hidden states, and visualize the top-3 predicted tokens at each stage to show how the model's confidence evolves.\"</paragraph><paragraph>2. Interaction Trace &amp; Critical Annotation (The Debugging Log) The AI successfully generated the logic for the Logit Lens but failed significantly on implementation details. Below is the log of the 4 specific crashes I had to debug, annotated with my critique of the AI's performance.</paragraph><paragraph><link href=\"https://docs.google.com/spreadsheets/d/17VnvoLmzWUtTz3R9J_-RMwJJWNNa0Yxjo5SipqXoh98/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/17VnvoLmzWUtTz3R9J_-RMwJJWNNa0Yxjo5SipqXoh98/edit?usp=sharing</link> </paragraph><paragraph>3. Conclusion</paragraph><paragraph>This experiment demonstrated that LLMs are excellent at reactive debugging (fixing crashes when shown a stack trace) but poor at one-shotting. My role shifted from \"Coder\" to \"Reviewer,\" validating that the AI's \"fixes\" were theoretically sound.</paragraph><paragraph/><paragraph>Here is the StreamLit project Link: <link href=\"https://ijinyu1113gpt-2-logit-lens-visualization.streamlit.app/\">https://ijinyu1113gpt-2-logit-lens-visualization.streamlit.app/</link> </paragraph></document>",
            "links": [
                "https://docs.google.com/spreadsheets/d/17VnvoLmzWUtTz3R9J_-RMwJJWNNa0Yxjo5SipqXoh98/edit?usp=sharing",
                "https://ijinyu1113gpt-2-logit-lens-visualization.streamlit.app/"
            ],
            "attachments": [],
            "created_at": "2025-12-08T15:26:26.630873+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430166,
            "author": "Neil Pattanaik",
            "project_title": "Special Participation E: Interactive, Trainable Visualization of the Attention Mechanism",
            "post_body": "With Claude 4.5 Opus, I built a fully trainable attention head visualization (with a slightly simplified architecture that does not contain a normalization layer or MLP). The purpose of this is for students visualize their own contrived/toy examples to understand how the attention mechanism operates. \n\nTry it out here: https://claude.ai/public/artifacts/eb7be4c4-ec9c-4398-a2d9-1e9c8559c17c\n\nThe program allows you to choose the dimension of the embedding layer and define your own a vocabulary (in terms of pairs of text and embeddings, no tokenization here). The intention here is again to enable contrived examples that are intuition rich, such as the one below.\n\n\n\nConsider the following embeddings:\n\ncat: [1, 0, 0, 0.8]\n\ndog: [1, 0, 0, -0.8]\n\nlikes: [0.3, 0.3, 1, 0]\n\nmilk: [0, 1, 0, 0.8]\n\nwater: [0, 1, 0, -0.8]\n\n\n\nHere, we choose (for demonstration purposes) to encode animal at index 0, drink at index 1, and an affinity at index 3. This is the default setup, so you can easily go try the following experiment! Observe initially that the attention head does not capture the affinity between cat/milk and dog/water. We will show how in two training steps, we can update the attention to recognize this toy example.\n\nLet's first train on the sequence \"cat likes milk\". The site shows each step of the forward and backward pass, but we'll just show the last step (end of backprop) here for brevity sake.\n\nWe backprop:\n\n\n\nNow, we can train another sequence, \"dog likes water\":\n\n\n\nYou should now be able to observe the positive affinity reflected in the attention matrix on \"cat likes milk\" between cat and milk, while \"cat likes water\" barely has water attending to cat. The analogous feat applies for dog. ",
            "content_xml": "<document version=\"2.0\"><paragraph>With Claude 4.5 Opus, I built a fully trainable attention head visualization (with a slightly simplified architecture that does not contain a normalization layer or MLP). The purpose of this is for students visualize their own contrived/toy examples to understand how the attention mechanism operates. </paragraph><paragraph>Try it out here: https://claude.ai/public/artifacts/eb7be4c4-ec9c-4398-a2d9-1e9c8559c17c</paragraph><paragraph>The program allows you to choose the dimension of the embedding layer and define your own a vocabulary (in terms of pairs of text and embeddings, no tokenization here). The intention here is again to enable contrived examples that are intuition rich, such as the one below.</paragraph><paragraph/><paragraph>Consider the following embeddings:</paragraph><list style=\"bullet\"><list-item><paragraph>cat: [1, 0, 0, 0.8]</paragraph></list-item><list-item><paragraph>dog: [1, 0, 0, -0.8]</paragraph></list-item><list-item><paragraph>likes: [0.3, 0.3, 1, 0]</paragraph></list-item><list-item><paragraph>milk: [0, 1, 0, 0.8]</paragraph></list-item><list-item><paragraph>water: [0, 1, 0, -0.8]</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/Qm6PaeRUDRA4T1YY5xNDTwIE\" width=\"382\" height=\"512\"/></figure><paragraph/></list-item></list><paragraph>Here, we choose (for demonstration purposes) to encode animal at index 0, drink at index 1, and an affinity at index 3. This is the default setup, so you can easily go try the following experiment! Observe initially that the attention head does not capture the affinity between cat/milk and dog/water. We will show how in two training steps, we can update the attention to recognize this toy example.</paragraph><paragraph>Let's first train on the sequence \"cat likes milk\". The site shows each step of the forward and backward pass, but we'll just show the last step (end of backprop) here for brevity sake.</paragraph><paragraph>We backprop:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/NfUaMsubeL6Y50gVmoJzhceS\" width=\"658\" height=\"399.07967479674795\"/></figure><paragraph/><paragraph>Now, we can train another sequence, \"dog likes water\":</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/VOpoVdOWxRG5zhaAxapAlxgy\" width=\"658\" height=\"308.39408866995075\"/></figure><paragraph/><paragraph>You should now be able to observe the positive affinity reflected in the attention matrix on \"cat likes milk\" between cat and milk, while \"cat likes water\" barely has water attending to cat. The analogous feat applies for dog. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T15:16:56.04721+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430101,
            "author": "John Wang",
            "project_title": "Special Participation B: Opus 4.5 on HW03",
            "post_body": "For the coding side of HW3, I worked with Claude 4.5 Opus inside the Claude Code environment to complete the \u00b5P visualization notebook. What I found most helpful was how quickly we were able to turn the abstract idea of \u201cmaximal update parameterization\u201d into concrete, runnable PyTorch code. Opus not only filled in the TODO blocks for the \u00b5P optimizer and per-layer scaling, but also helped adapt the notebook to my Apple Silicon setup (M3 Max with MPS), fixing device issues, NumPy\u2013tensor conversions, and SVD support by selectively moving computations to CPU.\n\nThe interaction made the stability story behind \u00b5P very tangible: by comparing standard Adam to the \u00b5P-style updates across different widths, I could see in the plots how a single learning rate stops working under standard parameterization but transfers cleanly under \u00b5P. There were a few places where Opus proposed competing \u201creasonable\u201d scaling rules (fan-in vs. fan-out), and I had to resolve them using the HW3 notes and the resulting curves. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/wjhIppci7XqCjGhXjrcKbw7l\" filename=\"Participation B.pdf\"/><paragraph>For the coding side of HW3, I worked with Claude 4.5 Opus inside the Claude Code environment to complete the \u00b5P visualization notebook. What I found most helpful was how quickly we were able to turn the abstract idea of \u201cmaximal update parameterization\u201d into concrete, runnable PyTorch code. Opus not only filled in the TODO blocks for the \u00b5P optimizer and per-layer scaling, but also helped adapt the notebook to my Apple Silicon setup (M3 Max with MPS), fixing device issues, NumPy\u2013tensor conversions, and SVD support by selectively moving computations to CPU.</paragraph><paragraph>The interaction made the stability story behind \u00b5P very tangible: by comparing standard Adam to the \u00b5P-style updates across different widths, I could see in the plots how a single learning rate stops working under standard parameterization but transfers cleanly under \u00b5P. There were a few places where Opus proposed competing \u201creasonable\u201d scaling rules (fan-in vs. fan-out), and I had to resolve them using the HW3 notes and the resulting curves. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T15:06:10.614451+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430045,
            "author": "Jacqueline Thibault",
            "project_title": "Special Participation E: Gemini Gem for quizzing yourself on prerequisite ML knowledge.",
            "post_body": "I created a Gemini gem, called Prerequisite Preparator. It is tailored specifically to be a helpful tutor regarding essential Matrix algebra and vector calculus questions.\n\nI gave it the description: Quizzes essential prerequisite mathematical concepts for deep learning\n\nAnd the instructions: You are a helpful homework assistant for a college deep learning class. This class heavily relies on prerequisite knowledge of vector calculus and matrix math for ML. Ask me essential matrix algebra questions in a rapid call-and-response type of format. e.g. (what are the essential characteristics of a PSD matrix?)  Only ask ONE question at a time.\n\nUpon my first pass, I gave it this pdf: https://gwthomas.github.io/docs/math4ml.pdf\nwhich I frequently referenced in the beginning. However, I quickly noticed that the questions it were asking were too elementary and not sufficient to provide an in-depth understanding of the necessary prerequisites. I later gave it the hw0 solutions for this class, and it immediately was asking better questions. This can be useful for making sure you have a solid understanding of essential mathematical concepts before manipulating them later on in the class.\n\n\n\nAttached is the gem: https://gemini.google.com/gem/fdaaf1268d88\n\n\nand my annotated trace: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I created a Gemini gem, called Prerequisite Preparator. It is tailored specifically to be a helpful tutor regarding essential Matrix algebra and vector calculus questions.</paragraph><paragraph>I gave it the description: Quizzes essential prerequisite mathematical concepts for deep learning</paragraph><paragraph>And the instructions: You are a helpful homework assistant for a college deep learning class. This class heavily relies on prerequisite knowledge of vector calculus and matrix math for ML. Ask me essential matrix algebra questions in a rapid call-and-response type of format. e.g. (what are the essential characteristics of a PSD matrix?)  Only ask ONE question at a time.</paragraph><paragraph>Upon my first pass, I gave it this pdf: <link href=\"https://gwthomas.github.io/docs/math4ml.pdf\">https://gwthomas.github.io/docs/math4ml.pdf</link><break/>which I frequently referenced in the beginning. However, I quickly noticed that the questions it were asking were too elementary and not sufficient to provide an in-depth understanding of the necessary prerequisites. I later gave it the hw0 solutions for this class, and it immediately was asking better questions. This can be useful for making sure you have a solid understanding of essential mathematical concepts before manipulating them later on in the class.</paragraph><paragraph/><paragraph>Attached is the gem: https://gemini.google.com/gem/fdaaf1268d88<break/></paragraph><paragraph>and my annotated trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/u0gp7oO4N5xwpgpAr84RVmzF\" filename=\"Gemini.pdf\"/><file/><file/></document>",
            "links": [
                "https://gwthomas.github.io/docs/math4ml.pdf"
            ],
            "attachments": [],
            "created_at": "2025-12-08T14:57:49.46468+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7430032,
            "author": "Dagny Streit",
            "project_title": "Special Participation E: ChatGPT as a Misconception-Driven Student in a Teaching Dialogue",
            "post_body": "I used ChatGPT 5.1 and designed a prompt that intentionally makes the model behave like a CS 182 student with realistic, common misconceptions. Instead of asking the LLM to be an expert, I positioned myself as the instructor: my role in the interaction was to teach the model, correct its misunderstandings, and guide it with carefully chosen questions.\n\nThis created a highly interactive learning tool where the model\u2019s \u201cmistakes\u201d were actually useful because explaining and correcting them required me to demonstrate that I truly understood the underlying concepts. In other words, the framework forced me to teach the AI, which was a great way to check whether I have internalized the material well enough to identify misconceptions and explain the ideas clearly to someone else. This also makes the prompt a reusable tool for others as anyone can repurpose it for other topics to surface misconceptions and test their own understanding.\n\nAt the end of the conversation, I asked the model to summarize all the misconceptions it made along with the correct explanations I provided. This produced a clear, concise list of key takeaways with most of the important discussed ideas.\n\nAttached below is the annotated conversation around common misconceptions in convolution neural networks, including bias terms, receptive fields, 1x1 convolutions, and strided convolutions. Annotated in red is the misconception the model made. Annotated in green is where the model learned and corrected its logic. Annotated in blue are comments about the instructions I gave.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5.1 and designed a prompt that intentionally makes the model behave like a CS 182 student with realistic, common misconceptions. Instead of asking the LLM to be an expert, I positioned myself as the instructor: my role in the interaction was to teach the model, correct its misunderstandings, and guide it with carefully chosen questions.</paragraph><paragraph>This created a highly interactive learning tool where the model\u2019s \u201cmistakes\u201d were actually useful because explaining and correcting them required me to demonstrate that I truly understood the underlying concepts. In other words, the framework forced me to teach the AI, which was a great way to check whether I have internalized the material well enough to identify misconceptions and explain the ideas clearly to someone else. This also makes the prompt a reusable tool for others as anyone can repurpose it for other topics to surface misconceptions and test their own understanding.</paragraph><paragraph>At the end of the conversation, I asked the model to summarize all the misconceptions it made along with the correct explanations I provided. This produced a clear, concise list of key takeaways with most of the important discussed ideas.</paragraph><paragraph>Attached below is the annotated conversation around common misconceptions in convolution neural networks, including bias terms, receptive fields, 1x1 convolutions, and strided convolutions. Annotated in red is the misconception the model made. Annotated in green is where the model learned and corrected its logic. Annotated in blue are comments about the instructions I gave.</paragraph><file url=\"https://static.us.edusercontent.com/files/9X2AUWG1hfKx9KynM5hFogav\" filename=\"Participation E2 Annotated.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T14:55:59.430215+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429972,
            "author": "Ayush Goel",
            "project_title": "Special Participation E: ChatGPT Study mode on Variational Autoencoders",
            "post_body": "I used ChatGPT's study mode to understand variational autoencoders better. I have attached the annotated pdf of the transcript.\n\nSome notable things in my interaction:\n\n1. I think GPT was able to provide very good intuitions for variational autoencoders, including why we need VAEs in the first place, the reparameterization trick and the different terms in the loss function.\n\n2. I asked GPT to ask me questions to cross check my understanding. For the most part, it picked great questions and was able to adapt them based on my confusions and doubts. For example, I asked it a question about how the KL divergence term doesn't collapse the latent distribution, and GPT asked me a question regarding reweighting terms in the loss function to make sure I understood the tradeoff.\n\n3. Sometimes, GPT started asking the same question repeatedly in different wording, especially towards the end when I had mostly understood the concept. In these scenarios, I had to guide the conversation myself with other questions I was curious about / details I didn't understand.\n\n4. In the beginning, GPT provided too much information at once, trying to explain every detail in one shot. While the flow of ideas was logical and it started with the intuition, it still would've been better to break it up into sections and only move on until I understood each idea fully.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT's study mode to understand variational autoencoders better. I have attached the annotated pdf of the transcript.</paragraph><file url=\"https://static.us.edusercontent.com/files/ILQGPxhgA8lXgL7MURNqCrmy\" filename=\"variational_autoencoders_gpt_study.pdf\"/><paragraph>Some notable things in my interaction:</paragraph><paragraph>1. I think GPT was able to provide very good intuitions for variational autoencoders, including why we need VAEs in the first place, the reparameterization trick and the different terms in the loss function.</paragraph><paragraph>2. I asked GPT to ask me questions to cross check my understanding. For the most part, it picked great questions and was able to adapt them based on my confusions and doubts. For example, I asked it a question about how the KL divergence term doesn't collapse the latent distribution, and GPT asked me a question regarding reweighting terms in the loss function to make sure I understood the tradeoff.</paragraph><paragraph>3. Sometimes, GPT started asking the same question repeatedly in different wording, especially towards the end when I had mostly understood the concept. In these scenarios, I had to guide the conversation myself with other questions I was curious about / details I didn't understand.</paragraph><paragraph>4. In the beginning, GPT provided too much information at once, trying to explain every detail in one shot. While the flow of ideas was logical and it started with the intuition, it still would've been better to break it up into sections and only move on until I understood each idea fully.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T14:45:42.598265+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429801,
            "author": "Diana Kohr",
            "project_title": "Special Participation D: Lion and Muon in Homework 11",
            "post_body": "HW 11 coding problem 4 (Scaling Laws of Batch Size) was focused on the effect of batch size on  optimal learning rates across SGD and Adam. I added Lion and Muon to the list of optimizers to investigate. While the deliverables are the same as for SGD and Adam, each of them presents a specific difficulty. \n\nLion isn't implemented in pytorch.optim, so students have to import it separately. Muon only takes 2D parameters, so students have to work around this. The new problems and my notebook with solutions are below (made use of Gemini in Colab). ",
            "content_xml": "<document version=\"2.0\"><paragraph>HW 11 coding problem 4 (Scaling Laws of Batch Size) was focused on the effect of batch size on  optimal learning rates across SGD and Adam. I added Lion and Muon to the list of optimizers to investigate. While the deliverables are the same as for SGD and Adam, each of them presents a specific difficulty. </paragraph><paragraph>Lion isn't implemented in pytorch.optim, so students have to import it separately. Muon only takes 2D parameters, so students have to work around this. The new problems and my notebook with solutions are below (made use of Gemini in Colab). </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/2a7GYksrOAs07KoepeYkFMtf\" width=\"642\" height=\"95.06008583690988\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/R973dK6TPqDNFpYk3mVVggZ0\" width=\"642\" height=\"94.60085836909872\"/></figure><file url=\"https://static.us.edusercontent.com/files/f7lsJKNTSlY2gaUQXJmRPLOz\" filename=\"scaling_laws.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T14:22:48.8061+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429794,
            "author": "Tyler Pham",
            "project_title": "Special Participation E: Gemini 3 Pro for Optimization Visualizations",
            "post_body": "I had Gemini 3 Pro build an interactive HTML site with Plotly to visualize how SGD, Momentum, and Adam navigate a difficult loss function because I often get confused about how changing their parameters like beta affects their end result. You can use sliding bars to tweak hyperparameters like the learning rate and beta values to see how it affects convergence.\n\nEven though I understand the intuition and motivation behind Momentum and Adam, I wanted to see more mathematical simulations where I could change the parameters and observe why Adam is so stable.\n\nArtifact (The HTML Site):\n\nObservations:\n\nWhen I asked the AI to explain the math inside the tool, it generated complex LaTeX equations. However, it failed to realize that a standard HTML browser cannot render LaTeX without a library like MathJax. It hallucinated a capability the file didn't have. I had to force it to rewrite the math using standard HTML entities.\n\nGemini 3 Pro (which has Thinking) is a lot more concise compared to other models I've used like GPT 5 Thinking. When I asked it to explain more about the math behind Adam and Momentum, it's analysis was extremely short even when I told it to be detailed. This may have been due to already-high token count from the HTML.\n\nI noticed Momentum was consistently beating Adam in the simulation. I thought this was a bug. Gemini correctly explained that this is a feature, not a bug. In a noiseless deterministic function (like this simulation), Momentum acts like a race car without a speed limit. Adam, designed for real noisy data, normalizes the gradients, effectively enforcing a \"speed limit\" for stability.\n\nInitial Prompt:\n\nI want to create an interactive educational tool for my Deep Learning class to visualize the differences between SGD, Momentum, and Adam optimization. Please write a self-contained, single-file HTML/Javascript application (using a library like Plotly.js or a simple Canvas API) that does the following: The Environment: Render a 2D Contour Plot of a 'tricky' loss function where SGD typically struggles (oscillates) but Adam/Momentum succeeds. The Agents: Implement three 'agents' starting at the same point:\n\nSGD (Red dot/line)\n\nMomentum (Blue dot/line)\n\nAdam (Green dot/line) The Controls: Sidebar controls with sliders for:\n\nLearning Rate ($\\alpha$)\n\nMomentum ($\\beta$ or $\\gamma$)\n\nAdam parameters ($\\beta_1$, $\\beta_2$) Animation: A 'Start/Reset' button. When clicked, the agents should animate their path step-by-step down the gradient. Technical Constraints:\n\nDo not use external CSS/JS files; embed everything in the or .\n\nShow a live legend updating the current $(x, y)$ and Loss value for each optimizer.\n\n\n\nAnnotated Trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>I had Gemini 3 Pro build an interactive HTML site with Plotly to visualize how SGD, Momentum, and Adam navigate a difficult loss function because I often get confused about how changing their parameters like beta affects their end result. You can use sliding bars to tweak hyperparameters like the learning rate and beta values to see how it affects convergence.</paragraph><paragraph>Even though I understand the intuition and motivation behind Momentum and Adam, I wanted to see more mathematical simulations where I could change the parameters and observe why Adam is so stable.</paragraph><paragraph><bold>Artifact (The HTML Site):</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/ezA5y7lbtb6hz7cbRB5K6ENZ\" filename=\"optimization_race.html\"/><paragraph><bold>Observations:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>When I asked the AI to explain the math inside the tool, it generated complex LaTeX equations. However, it failed to realize that a standard HTML browser cannot render LaTeX without a library like MathJax. It hallucinated a capability the file didn't have. I had to force it to rewrite the math using standard HTML entities.</paragraph></list-item><list-item><paragraph>Gemini 3 Pro (which has Thinking) is a lot more concise compared to other models I've used like GPT 5 Thinking. When I asked it to explain more about the math behind Adam and Momentum, it's analysis was extremely short even when I told it to be detailed. This may have been due to already-high token count from the HTML.</paragraph></list-item><list-item><paragraph>I noticed Momentum was consistently beating Adam in the simulation. I thought this was a bug. Gemini correctly explained that this is a feature, not a bug. In a noiseless deterministic function (like this simulation), Momentum acts like a race car without a speed limit. Adam, designed for real noisy data, normalizes the gradients, effectively enforcing a \"speed limit\" for stability.</paragraph></list-item></list><paragraph><bold>Initial Prompt:</bold></paragraph><paragraph>I want to create an interactive educational tool for my Deep Learning class to visualize the differences between SGD, Momentum, and Adam optimization. Please write a self-contained, single-file HTML/Javascript application (using a library like Plotly.js or a simple Canvas API) that does the following: The Environment: Render a 2D Contour Plot of a 'tricky' loss function where SGD typically struggles (oscillates) but Adam/Momentum succeeds. The Agents: Implement three 'agents' starting at the same point:</paragraph><list style=\"unordered\"><list-item><paragraph>SGD (Red dot/line)</paragraph></list-item><list-item><paragraph>Momentum (Blue dot/line)</paragraph></list-item><list-item><paragraph>Adam (Green dot/line) The Controls: Sidebar controls with sliders for:</paragraph></list-item><list-item><paragraph>Learning Rate ($\\alpha$)</paragraph></list-item><list-item><paragraph>Momentum ($\\beta$ or $\\gamma$)</paragraph></list-item><list-item><paragraph>Adam parameters ($\\beta_1$, $\\beta_2$) Animation: A 'Start/Reset' button. When clicked, the agents should animate their path step-by-step down the gradient. Technical Constraints:</paragraph></list-item><list-item><paragraph>Do not use external CSS/JS files; embed everything in the or .</paragraph></list-item><list-item><paragraph>Show a live legend updating the current $(x, y)$ and Loss value for each optimizer.</paragraph></list-item></list><list style=\"unordered\"/><paragraph/><paragraph><bold>Annotated Trace:</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/6i34NYDPxtLrprXCdyfYqNwj\" filename=\"gemini-chat.2025-12-08.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T14:21:53.900592+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429758,
            "author": "Menger Wen",
            "project_title": "Special Participation E: DeepSeek as Web3 teacher",
            "post_body": "For special participation part E, I asked DeepSeek to teach me how to write a smart contract on BTC chain: https://chat.deepseek.com/share/9wu5248zp1z8hls9xy\n\nBased on our conversation, here is a summary in English of what I have accomplished and the current situation:\n\nProgress Summary\n\nI have successfully completed the initial setup and are very close to deploying my first Bitcoin smart contract. Here is what I have done:\n\n\u2705 Environment Setup: I installed all prerequisite tools (Node.js, NPM, Git) on my Windows 11 computer.\n\n\u2705 Core Tools Installation: I installed the global CLI tool (@opcat-labs/cli-opcat) which is used to create and manage projects.\n\n\u2705 Project Creation: I created a new project named helloworld using the CLI. This command automatically generated the complete project structure and configuration files.\n\n\u2705 Project Dependencies (SDK): I entered the project directory and ran npm install. This installed all necessary dependencies for the project, including the crucial @opcat-labs/scrypt-ts-opcat SDK\u2014the library containing the functions and classes needed to write my contract.\n\n\u2705 Smart Contract Code: I correctly modified the main contract file (src/contracts/helloworld.ts), creating a simple contract that stores a hash and can only be unlocked by providing the matching message.\n\n\u2705 Contract Compilation: I ran npm run compile, which successfully transformed my TypeScript code into a blockchain-readable format and generated a contract artifact file (artifacts/contracts/helloworld.json).\n\n\u2705 Test Key Generation: I generated a private key for the Bitcoin testnet using npm run genprivkey. The command provided I with a testnet address (mx79K19aq2Mq9mjUL1SHQ4y5NwTwcLKsFG) to receive faucet funds.\n\nCurrent Blocking Issue\n\nI am currently stuck at the final deployment step. When I run the deployment script (npx tsx deploy.ts), it fails with the following error:\n\nError: Cannot find module 'D:\\...\\helloworld\\dist\\cjs\\index.cjs'\n\nAnalysis of the Problem: This is a technical configuration or compatibility issue, not a mistake in my following of the tutorial steps. The most likely causes are:\n\nNode.js Version Mismatch: I am using Node.js v22.20.0. The tools in this project (tsx and the SDK) may not be fully compatible with this very recent version and expect an older Long-Term Support (LTS) version like Node.js 18 or 20.\n\nIncomplete Build Process: The error points to a missing file in a dist directory. my npm run compile command compiled the sCrypt contract itself, but the deployment script may require the TypeScript project code to be compiled into a dist folder, which hasn't happened yet.\n\nImmediate Next Steps & Solution\n\nTo resolve this and successfully deploy my contract, I need to:\n\nAdd loadArtifact() to my Script: First, ensure my deploy.ts file includes the two critical lines that tell the system how to interact with my compiled contract. Add them after the other import statements:\n\nimport artifact from './artifacts/contracts/helloworld.json'\nHelloworld.loadArtifact(artifact)\n\n\nSwitch to a Compatible Node.js Version (Recommended Solution): The most effective fix is to switch from Node.js v22 to an LTS version (v18 or v20). I can do this using a version manager like nvm-windows for Windows.\n\nReinstall Dependencies & Recompile: After switching Node.js versions, go back to my project folder, delete the node_modules folder, and run npm install followed by npm run compile again to ensure everything is built correctly for the new environment.\n\nOnce these steps are complete, funding my test address from the faucet and running npx tsx deploy.ts should successfully deploy and call my \"Helloworld\" smart contract on the Bitcoin testnet.\n\nIn short: I have perfectly followed all tutorial steps. The final error is a common technical hurdle that is resolved by adjusting my Node.js version and verifying my deployment script's code.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For special participation part E, I asked DeepSeek to teach me how to write a smart contract on BTC chain: https://chat.deepseek.com/share/9wu5248zp1z8hls9xy</paragraph><paragraph>Based on our conversation, here is a summary in English of what I have accomplished and the current situation:</paragraph><heading level=\"3\"><bold>Progress Summary</bold></heading><paragraph>I have successfully completed the initial setup and are very close to deploying my first Bitcoin smart contract. Here is what I have done:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>\u2705 Environment Setup</bold>: I installed all prerequisite tools (<code>Node.js</code>, <code>NPM</code>, <code>Git</code>) on my Windows 11 computer.</paragraph></list-item><list-item><paragraph><bold>\u2705 Core Tools Installation</bold>: I installed the global CLI tool (<code>@opcat-labs/cli-opcat</code>) which is used to create and manage projects.</paragraph></list-item><list-item><paragraph><bold>\u2705 Project Creation</bold>: I created a new project named <code>helloworld</code> using the CLI. This command automatically generated the complete project structure and configuration files.</paragraph></list-item><list-item><paragraph><bold>\u2705 Project Dependencies (SDK)</bold>: I entered the project directory and ran <code>npm install</code>. This installed all necessary dependencies for the project, including the crucial <bold><code>@opcat-labs/scrypt-ts-opcat</code> SDK</bold>\u2014the library containing the functions and classes needed to write my contract.</paragraph></list-item><list-item><paragraph><bold>\u2705 Smart Contract Code</bold>: I correctly modified the main contract file (<code>src/contracts/helloworld.ts</code>), creating a simple contract that stores a hash and can only be unlocked by providing the matching message.</paragraph></list-item><list-item><paragraph><bold>\u2705 Contract Compilation</bold>: I ran <code>npm run compile</code>, which successfully transformed my TypeScript code into a blockchain-readable format and generated a contract artifact file (<code>artifacts/contracts/helloworld.json</code>).</paragraph></list-item><list-item><paragraph><bold>\u2705 Test Key Generation</bold>: I generated a private key for the Bitcoin testnet using <code>npm run genprivkey</code>. The command provided I with a testnet address (<code>mx79K19aq2Mq9mjUL1SHQ4y5NwTwcLKsFG</code>) to receive faucet funds.</paragraph></list-item></list><heading level=\"3\"><bold>Current Blocking Issue</bold></heading><paragraph>I am currently stuck at the final deployment step. When I run the deployment script (<code>npx tsx deploy.ts</code>), it fails with the following error:</paragraph><paragraph><code>Error: Cannot find module 'D:\\...\\helloworld\\dist\\cjs\\index.cjs'</code></paragraph><paragraph><bold>Analysis of the Problem:</bold> This is a technical configuration or compatibility issue, not a mistake in my following of the tutorial steps. The most likely causes are:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Node.js Version Mismatch</bold>: I am using Node.js v22.20.0. The tools in this project (<code>tsx</code> and the SDK) may not be fully compatible with this very recent version and expect an older Long-Term Support (LTS) version like Node.js 18 or 20.</paragraph></list-item><list-item><paragraph><bold>Incomplete Build Process</bold>: The error points to a missing file in a <code>dist</code> directory. my <code>npm run compile</code> command compiled the <italic>sCrypt contract</italic> itself, but the deployment script may require the <italic>TypeScript project code</italic> to be compiled into a <code>dist</code> folder, which hasn't happened yet.</paragraph></list-item></list><heading level=\"3\"><bold>Immediate Next Steps &amp; Solution</bold></heading><paragraph>To resolve this and successfully deploy my contract, I need to:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Add <code>loadArtifact()</code> to my Script</bold>: First, ensure my <code>deploy.ts</code> file includes the two critical lines that tell the system how to interact with my compiled contract. Add them after the other import statements:</paragraph><pre>import artifact from './artifacts/contracts/helloworld.json'\nHelloworld.loadArtifact(artifact)\n</pre></list-item><list-item><paragraph><bold>Switch to a Compatible Node.js Version (Recommended Solution)</bold>: The most effective fix is to switch from Node.js v22 to an LTS version (v18 or v20). I can do this using a version manager like <code>nvm-windows</code> for Windows.</paragraph></list-item><list-item><paragraph><bold>Reinstall Dependencies &amp; Recompile</bold>: After switching Node.js versions, go back to my project folder, delete the <code>node_modules</code> folder, and run <code>npm install</code> followed by <code>npm run compile</code> again to ensure everything is built correctly for the new environment.</paragraph></list-item></list><paragraph>Once these steps are complete, funding my test address from the faucet and running <code>npx tsx deploy.ts</code> should successfully deploy and call my \"Helloworld\" smart contract on the Bitcoin testnet.</paragraph><paragraph><bold>In short: I have perfectly followed all tutorial steps. The final error is a common technical hurdle that is resolved by adjusting my Node.js version and verifying my deployment script's code.</bold></paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T14:14:57.003779+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429659,
            "author": "Menger Wen",
            "project_title": "Special Participation B: ChatGPT 5.1 Standard Thinking on HW7",
            "post_body": "For Special Participation B, I used ChatGPT 5.1 Standard Thinking on the coding portion of HW 7.\n\nHere is the link to my chat: \n\nQ1\n\nQ2\n\nQ5: https://chatgpt.com/share/69363e3f-87f0-8006-a054-9b6d8eec7aa5, https://chatgpt.com/share/69363e56-3044-8006-b71f-72208ff5cc80\n\nFormal Code Review (Best for a report or official feedback)\n\nAssessment of ChatGPT 5.1 Standard Thinking Performance on HW7\n\nExecutive Summary: The model demonstrated high proficiency, successfully completing the RNN, Last-Name Classifier, and Autoencoder tasks in alignment with staff specifications. However, the Graph-Clustering module contains two significant mathematical errors regarding the adjacency and degree matrices that require correction to function correctly.\n\nDetailed Findings:\n\nGraph-Clustering (Spectral): This section requires revision.\n\nCritical Defect: The RBF kernel implementation incorrectly calculated similarity using $exp(+\\gamma |x_i - x_j|^2)$. This must be corrected to a negative exponent ($-\\gamma$) to properly represent similarity.\n\nAPI Inconsistency: The function get_degree_matrix returns the inverse-square-root ($D^{-1/2}$) rather than the standard Degree matrix ($D$). While the subsequent Laplacian calculation compensates for this, the naming convention violates the prompt requirements and risks confusion.\n\nNote: The underlying spectral logic (SVD, row-normalization, KMeans) is otherwise sound.\n\nRNN & Gradients: Excellent implementation. The model correctly structured the RNNLayer (two linear layers, single bias, explicit unrolling) and the regression model (shared readout). The gradient visualization tool appropriately targets the recurrent matrix ($W_{hh}$), making it effective for diagnosing vanishing/exploding gradients.\n\nLast-Name Classifier: A robust, vectorized solution. The pipeline correctly handles padding (gathering the last valid timestep), utilizes plausible hyperparameters (LSTM with dropout, Adam optimizer), and achieves the target accuracy. The response to the ethics prompt regarding deployment was nuanced, highlighting issues like proxy discrimination and privacy.\n\nAutoencoders: Flawless execution. The Vanilla, Denoising, and Masked architectures are correctly implemented with symmetric decoders. The evaluation suite is comprehensive, featuring a linear probe for feature assessment and a plotting helper that accurately renders performance statistics (mean + min/max bands).\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation B, I used ChatGPT 5.1 Standard Thinking on the coding portion of HW 7.</paragraph><list style=\"unordered\"><list-item><paragraph>Here is the link to my chat: </paragraph><list style=\"unordered\"><list-item><paragraph><link href=\"https://chatgpt.com/share/69363c35-b9ec-8006-806d-2d5bf040a30f\">Q1</link></paragraph></list-item><list-item><paragraph><link href=\"https://chatgpt.com/share/69363dc1-0e20-8006-99be-a5d5ace3b95c\">Q2</link></paragraph></list-item><list-item><paragraph>Q5: https://chatgpt.com/share/69363e3f-87f0-8006-a054-9b6d8eec7aa5, https://chatgpt.com/share/69363e56-3044-8006-b71f-72208ff5cc80</paragraph></list-item></list></list-item></list><heading level=\"3\">Formal Code Review (Best for a report or official feedback)</heading><paragraph><bold>Assessment of ChatGPT 5.1 Standard Thinking Performance on HW7</bold></paragraph><paragraph><bold>Executive Summary:</bold> The model demonstrated high proficiency, successfully completing the RNN, Last-Name Classifier, and Autoencoder tasks in alignment with staff specifications. However, the Graph-Clustering module contains two significant mathematical errors regarding the adjacency and degree matrices that require correction to function correctly.</paragraph><paragraph><bold>Detailed Findings:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Graph-Clustering (Spectral):</bold> This section requires revision.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Critical Defect:</bold> The RBF kernel implementation incorrectly calculated similarity using $exp(+\\gamma |x_i - x_j|^2)$. This must be corrected to a negative exponent ($-\\gamma$) to properly represent similarity.</paragraph></list-item><list-item><paragraph><bold>API Inconsistency:</bold> The function <code>get_degree_matrix</code> returns the inverse-square-root ($D^{-1/2}$) rather than the standard Degree matrix ($D$). While the subsequent Laplacian calculation compensates for this, the naming convention violates the prompt requirements and risks confusion.</paragraph></list-item><list-item><paragraph><italic>Note:</italic> The underlying spectral logic (SVD, row-normalization, KMeans) is otherwise sound.</paragraph></list-item></list></list-item><list-item><paragraph><bold>RNN &amp; Gradients:</bold> Excellent implementation. The model correctly structured the <code>RNNLayer</code> (two linear layers, single bias, explicit unrolling) and the regression model (shared readout). The gradient visualization tool appropriately targets the recurrent matrix ($W_{hh}$), making it effective for diagnosing vanishing/exploding gradients.</paragraph></list-item><list-item><paragraph><bold>Last-Name Classifier:</bold> A robust, vectorized solution. The pipeline correctly handles padding (gathering the last valid timestep), utilizes plausible hyperparameters (LSTM with dropout, Adam optimizer), and achieves the target accuracy. The response to the ethics prompt regarding deployment was nuanced, highlighting issues like proxy discrimination and privacy.</paragraph></list-item><list-item><paragraph><bold>Autoencoders:</bold> Flawless execution. The Vanilla, Denoising, and Masked architectures are correctly implemented with symmetric decoders. The evaluation suite is comprehensive, featuring a linear probe for feature assessment and a plotting helper that accurately renders performance statistics (mean + min/max bands).</paragraph></list-item></list><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/69363c35-b9ec-8006-806d-2d5bf040a30f",
                "https://chatgpt.com/share/69363dc1-0e20-8006-99be-a5d5ace3b95c"
            ],
            "attachments": [],
            "created_at": "2025-12-08T14:00:09.51986+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429651,
            "author": "John Wang",
            "project_title": "Special Participation A: Gemini 3 Pro on HW03",
            "post_body": "For Participation A I used Gemini 3 Pro (Thinking with 3 Pro) on the non-coding parts of HW3 (Problems 1, 3, 4, 5). I gave it the full problem statements (often as screenshots) and asked it to work through each sub-question with explicit derivation steps, but no code. Most of the probability / calculus / optimization pieces came out correct on the first attempt; my role was mainly to sanity-check the algebra and occasionally nudge it to be more explicit about intermediate steps or constants.\n\nA few observations from the interaction:\n\nStrengths.\n\nIt handled the Gaussian policy-gradient and Maximal Update Parameterization questions well, with clean use of the log-derivative trick, reparameterization, and scaling arguments.\n\nOn the reading-based parts (e.g., interpreting figures/tables from the muP paper), once I pointed it to the specific figure or row, it gave focused, accurate summaries instead of generic \u201cpaper reviews.\u201d\n\nWhen my prompt was ambiguous or I referenced the wrong part of a problem, it tended not to invent details; it either stayed generic or adjusted once I clarified, which kept hallucinations relatively low.\n\nWeaknesses / failure modes.\n\nFor implementation-style questions (tensor rematerialization forward counts), it initially chose a reasonable but wrong cost model and confidently overcounted. Only after I explicitly restated what should and shouldn\u2019t be counted did it converge to the official answers (e.g., 20 forward ops, 10 loads).\n\nExplanations are concise and formula-heavy; this is good for following the math, but it often skips intuition or broader context unless explicitly requested.\n\nOverall, Gemini 3 Pro was quite usable as a step-by-step assistant for the theory parts of the homework, but still needed a human in the loop to pin down problem semantics and verify that its interpretation of \u201cwhat we\u2019re measuring\u201d matched the assignment.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/wXFtIabTQap3SOfiFSBC16hW\" filename=\"Participation A.pdf\"/><paragraph>For Participation A I used <bold>Gemini 3 Pro (Thinking with 3 Pro)</bold> on the non-coding parts of HW3 (Problems 1, 3, 4, 5). I gave it the full problem statements (often as screenshots) and asked it to work through each sub-question with explicit derivation steps, but no code. Most of the probability / calculus / optimization pieces came out correct on the first attempt; my role was mainly to sanity-check the algebra and occasionally nudge it to be more explicit about intermediate steps or constants.</paragraph><paragraph>A few observations from the interaction:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Strengths.</bold></paragraph><list style=\"unordered\"><list-item><paragraph>It handled the Gaussian policy-gradient and Maximal Update Parameterization questions well, with clean use of the log-derivative trick, reparameterization, and scaling arguments.</paragraph></list-item><list-item><paragraph>On the reading-based parts (e.g., interpreting figures/tables from the muP paper), once I pointed it to the specific figure or row, it gave focused, accurate summaries instead of generic \u201cpaper reviews.\u201d</paragraph></list-item><list-item><paragraph>When my prompt was ambiguous or I referenced the wrong part of a problem, it tended not to invent details; it either stayed generic or adjusted once I clarified, which kept hallucinations relatively low.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Weaknesses / failure modes.</bold></paragraph><list style=\"unordered\"><list-item><paragraph>For implementation-style questions (tensor rematerialization forward counts), it initially chose a reasonable but wrong cost model and confidently overcounted. Only after I explicitly restated what should and shouldn\u2019t be counted did it converge to the official answers (e.g., 20 forward ops, 10 loads).</paragraph></list-item><list-item><paragraph>Explanations are concise and formula-heavy; this is good for following the math, but it often skips intuition or broader context unless explicitly requested.</paragraph></list-item></list></list-item></list><paragraph>Overall, Gemini 3 Pro was quite usable as a step-by-step assistant for the theory parts of the homework, but still needed a human in the loop to pin down problem semantics and verify that its interpretation of \u201cwhat we\u2019re measuring\u201d matched the assignment.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:58:58.922799+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429618,
            "author": "Jermaine Lei",
            "project_title": "Special Participation B: Windsurf on HW 8",
            "post_body": "I used\u00a0Windsurf\u00a0to complete the coding portions of the SSM forward pass assignment for both the GPU and CPU. My approach was to give the model the notebook file and ask it to fill in the required functions.\n\nThe model showed high capability by quickly generating the correct core logic for the recurrent SSM update rule. However, the initial code was not directly runnable due to dimension and shape mismatch errors in how it handled the PyTorch tensors. For example, it struggled with correctly applying matrix multiplication when the input sequence included a batch dimension.\n\nCrucially, the model demonstrated an ability to self-correct when given feedback. When I showed it the specific error messages from PyTorch, the model was able to diagnose the problem and fix the code to ensure that all tensor dimensions aligned properly for the matrix operations.\n\nAfter successfully resolving these initial dimension issues, the model was excellent at generating production-quality code. It went on to correctly add features necessary for a proper benchmark, such as explicit device checks and the integration of the tqdm library for progress bars. This shows that while LLMs may struggle with the precise tensor mechanics often required in deep learning code, they can be quickly guided to functional and high-quality solutions by pointing out the specific technical errors.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used\u00a0Windsurf\u00a0to complete the coding portions of the SSM forward pass assignment for both the GPU and CPU. My approach was to give the model the notebook file and ask it to fill in the required functions.</paragraph><paragraph>The model showed high capability by quickly generating the correct core logic for the recurrent SSM update rule. However, the initial code was not directly runnable due to dimension and shape mismatch errors in how it handled the PyTorch tensors. For example, it struggled with correctly applying matrix multiplication when the input sequence included a batch dimension.</paragraph><paragraph>Crucially, the model demonstrated an ability to self-correct when given feedback. When I showed it the specific error messages from PyTorch, the model was able to diagnose the problem and fix the code to ensure that all tensor dimensions aligned properly for the matrix operations.</paragraph><paragraph>After successfully resolving these initial dimension issues, the model was excellent at generating production-quality code. It went on to correctly add features necessary for a proper benchmark, such as explicit device checks and the integration of the tqdm library for progress bars. This shows that while LLMs may struggle with the precise tensor mechanics often required in deep learning code, they can be quickly guided to functional and high-quality solutions by pointing out the specific technical errors.</paragraph><file url=\"https://static.us.edusercontent.com/files/ZrzMot7bEpoPTEnXCRQ4shpT\" filename=\"q_coding_ssm_forward_gpu_chat.pdf\"/><file url=\"https://static.us.edusercontent.com/files/e6T2aczcyarSXYDTWTuJRCjy\" filename=\"q_coding_ssm_forward_gpu.pdf\"/><file url=\"https://static.us.edusercontent.com/files/OkIPWYyNcN2UTmo5jqEP7sVG\" filename=\"q_coding_ssm_forward_cpu.pdf\"/><file url=\"https://static.us.edusercontent.com/files/fBtEsT3PVnOWJJlWvzoPIDYb\" filename=\"q_coding_ssm_forward_cpu_chat.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:53:59.03513+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429590,
            "author": "Ijin Yu",
            "project_title": "Special Participation B: Clause Opus 4.5 on hw 8 Coding",
            "post_body": "Working with Claude Opus 4.5 on implementing SSM (State Space Model) forward passes, I explored both recurrence-based and convolution-based approaches, including optimizations for diagonal weight matrices. The interaction demonstrated strong coding capabilities but revealed some notable patterns in how the model handles complexity analysis and debugging.\n\nOne-shot successes:\n\nCore implementation logic for all four functions (unrolled, convolution, diagonal variants)\n\nDivide-and-conquer kernel construction algorithm\n\nRequired correction/hints:\n\nData type mismatch: Initially used NumPy arrays (np.zeros) instead of PyTorch tensors, causing a TypeError when mixed with tensor inputs. Fixed immediately after providing the error message.\n\nComplexity analysis: Initially overcomplicated the convolution runtime analysis, including unnecessary terms. Required a hint to focus on the dominant cost from make_conv_kernel and properly analyze the divide-and-conquer recurrence to arrive at O(TH3).\n\nScope clarification: Needed reminding to focus only on T and H (not N and D) for complexity analysis.\n\nStrengths observed:\n\nGood intuition about parallelism vs. computational complexity trade-offs on CPU vs GPU\n\nQuickly adapted when given corrective feedback\n\nAreas requiring guidance:\n\nTendency to over-specify complexity bounds before simplifying\n\nDidn't initially catch the NumPy/PyTorch inconsistency despite the context being clearly PyTorch-based",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/BaHhHaAAXFqmSmGMAhGUROpn\" filename=\"participation b.pdf\"/><paragraph>Working with Claude Opus 4.5 on implementing SSM (State Space Model) forward passes, I explored both recurrence-based and convolution-based approaches, including optimizations for diagonal weight matrices. The interaction demonstrated strong coding capabilities but revealed some notable patterns in how the model handles complexity analysis and debugging.</paragraph><paragraph><bold>One-shot successes:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Core implementation logic for all four functions (unrolled, convolution, diagonal variants)</paragraph></list-item><list-item><paragraph>Divide-and-conquer kernel construction algorithm</paragraph></list-item></list><paragraph><bold>Required correction/hints:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Data type mismatch:</bold> Initially used NumPy arrays (<code>np.zeros</code>) instead of PyTorch tensors, causing a <code>TypeError</code> when mixed with tensor inputs. Fixed immediately after providing the error message.</paragraph></list-item><list-item><paragraph><bold>Complexity analysis:</bold> Initially overcomplicated the convolution runtime analysis, including unnecessary terms. Required a hint to focus on the dominant cost from <code>make_conv_kernel</code> and properly analyze the divide-and-conquer recurrence to arrive at O(TH3).</paragraph></list-item><list-item><paragraph><bold>Scope clarification:</bold> Needed reminding to focus only on T and H (not N and D) for complexity analysis.</paragraph></list-item></list><paragraph><bold>Strengths observed:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Good intuition about parallelism vs. computational complexity trade-offs on CPU vs GPU</paragraph></list-item><list-item><paragraph>Quickly adapted when given corrective feedback</paragraph></list-item></list><paragraph><bold>Areas requiring guidance:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Tendency to over-specify complexity bounds before simplifying</paragraph></list-item><list-item><paragraph>Didn't initially catch the NumPy/PyTorch inconsistency despite the context being clearly PyTorch-based</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:49:31.328611+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429585,
            "author": "Kithmini Herath",
            "project_title": "Special Participation E: A Visualizer for Optimizers",
            "post_body": "Hi all, \n\nI created an optimizer visualization tool (https://kithminiherath.github.io/optimizer-vis/) to interactively analyze how different hyperparameters affect the loss minimization trajectory for the following optimizers: \n\nAdamW\n\nSGD (with and without nestorov momentum)\n\nMuon \n\nTo build this visualizer I used classic optimizer test functions (2D loss landscapes) to test convergence, precision, robustness and performance of the above optimization algorithms:\n\nSphere\n\nGaussian Bowl\n\nRosenbrock\n\nRastrigin\n\nThe code for this visualizer is available at: https://github.com/KithminiHerath/optimizer-vis which can be used to extend to more optimizers. \n\nThis visualization tool was built with the help of Gemini 3 on Antigravity using TypeScript and three.js. I also used Claude Code as a secondary agent to get a different view of the code implementations by Gemini and to weed out implementation bugs. \n\nFor a lightweight webapp deployment all optimizers and loss functions were implemented with TypeScript. To ensure there were no implementation bugs, I ran test benches comparing the TypeScript optimizers' step-wise outputs for loss functions against the corresponding PyTorch libraries.\n\nHow I built the visualizer to represent Muon on 2D loss landscapes: \n\nImplementing AdamW and SGD were quite straightforward, but it was challenging for me to make this visualizer to work for Muon in a meaningful way. This is because Muon only works for 2D parameters and the loss functions and the rest of this visualizer was built for vectors. Chatting with Gemini 3 we came up with the following workflow to make this visualizer work for Muon as well in a meaningful way:\n\nSince Muon needs 2D parameters we defined a \u201cmatrix mode\u201d where a parameter matrix was defined as \n\n$$W=\\left[\\begin{matrix}x&z\\\\y&w\\end{matrix}\\right]$$\n\nIn the Muon implementation the rows will be orthogonalized here. \n\nWe define the \u201cvisible parameters\u201d as $x$ and $y$ and the remaining parameters as \u201cdummy\u201d parameters. By separating $x$ and $y$ into different rows, you force the optimizer to make them orthogonal. If they were in the same row, they would just be normalized together. \n\nEven if $z$ and $w$ are dummy parameters we still need to define gradients for them. Therefore we don\u2019t fix them, in-order for them to support the orthogonality constraints and also to prevent the matrix from being rank-1. Currently they are initialized to -1 and 1 and the final loss function is defined as:  . \n\n$$L_{total}=L_{2D}\\left(x,y\\right)+z^2+w^2$$\n\n$L_{2D}(x,y)$ is one of the four previously mentioned 2D loss functions and the remaining terms follow a simple bowl objective. Providing a \"slope\" for the hidden dimensions this way ensures the matrix has sufficient rank for the Newton-Schulz iteration to work non-trivially. \n\nUnder the above loss function the weights are optimized with the standard Muon implementation in TypeScript and we only visualize the behavior of $L_{2D}(x,y)$ in the tool.\n\nI think this is still a mathematically valid way to observe the behavior of Muon in comparison to the other two optimizers. I also want to note that when Muon is selected as an optimizer from the controls in the visualizer, any other optimizer selected with it will also be working on matrix parameters for common ground. \n\nFeatures of the visualizer: \n\n2D contour and 3D surface plots for visual representation of the loss landscapes. This way during a run the user can analyze both views. I think the 3D view is especially useful when there are multiple local minima, saddle points and when it\u2019s not apparent on the 2D contour plot why the optimizer got stuck at certain points. \n\nLoss function control \u2013 select any loss function.\n\nConfigure Optimizer panel \u2013 \n\nType \u2013 optimizer type selection \n\nHyperparameter sliders to configure the optimizer and add it. \n\nYou\u2019re able to select multiple optimizers at different configurations during a run and they will be listed with the choices of hyperparameters in the Optimizer List. You can also set the starting points of $x$ and $y$ by either clicking anywhere on the contour plot or typing out coordinates in the \"start X\" and \"start Y\" boxes. \n\nYou can also set the number of maximum steps you want the optimizer to run for. The default is 200 steps. \n\nYou start the run with \u201cStart\u201d button and it\u2019ll automatically run until it hits the maximum number of steps. You can also pause runs or step through iterations one step at a time with the \u201cStep\u201d button. While the \u201cStop\u201d button resets to the beginning of the run, the \u201cReset\u201d button resets the visualizer.\n\nSome cool visualization examples:\n\nLearning rate comparison within the same optimizer type: AdamW with higher learning rate converging faster by escaping local minima:\n\nComparing several optimizers:\n\nAdamW finds the global minima but both SGD versions reach the local minima:\n\nMuon originally moves towards the local minima but is able to recover and change the trajectory towards the global minima. I think this shows how Muon\u2019s orthogonality constraints initially causes the dominant gradient at that point ($dy$) to affect the gradients in other directions and may overall pull in the local minima direction, but I think once $dw$ and $dz$ recovers under their loss it snaps back in the direction of the global minima:\n\nMuon seems to do great in converging at more complex loss landscapes. I think this is an interesting case that shows how Muon\u2019s spectral norm constraints essentially \u201csaves\u201d it from exploding gradients along steep valleys and take controlled steps and eventually reach the global minima efficiently while the other optimizers seem to be distracted by the steep gradient in one direction (wall like structure) and gets stuck at local minimas since the gradient in other directions (valley like structure) gives less of a signal to move:\n\nLimitations:\n\nUsers are unable to see the behavior of the hidden parameters in the matrix mode.\n\nUsers cannot set different values for the hidden parameters and analyze how that affects optimization trajectory of the 2D losses. \n\nI think this is a useful tool for anyone trying to understand how certain hyperparameters affect certain loss functions, gain insights into the behavior of different optimizers even if it\u2019s for relatively simple loss landscapes. I think it would be a good playground to test specific instances to understand optimizers for academic purposes. \n\nHope y\u2019all can also check this out and let me know if you have any feedback. I\u2019m also interested in expanding this to other optimizers in the future.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all, </paragraph><paragraph>I created an optimizer visualization tool (<link href=\"https://kithminiherath.github.io/optimizer-vis/\">https://kithminiherath.github.io/optimizer-vis/</link>) to interactively analyze how different hyperparameters affect the loss minimization trajectory for the following optimizers: </paragraph><list style=\"number\"><list-item><paragraph>AdamW</paragraph></list-item><list-item><paragraph>SGD (with and without nestorov momentum)</paragraph></list-item><list-item><paragraph>Muon </paragraph></list-item></list><paragraph>To build this visualizer I used classic optimizer test functions (2D loss landscapes) to test convergence, precision, robustness and performance of the above optimization algorithms:</paragraph><list style=\"number\"><list-item><paragraph>Sphere</paragraph></list-item><list-item><paragraph>Gaussian Bowl</paragraph></list-item><list-item><paragraph>Rosenbrock</paragraph></list-item><list-item><paragraph>Rastrigin</paragraph></list-item></list><paragraph>The code for this visualizer is available at: <link href=\"https://github.com/KithminiHerath/optimizer-vis\">https://github.com/KithminiHerath/optimizer-vis</link> which can be used to extend to more optimizers. </paragraph><paragraph>This visualization tool was built with the help of Gemini 3 on Antigravity using TypeScript and three.js. I also used Claude Code as a secondary agent to get a different view of the code implementations by Gemini and to weed out implementation bugs. </paragraph><paragraph>For a lightweight webapp deployment all optimizers and loss functions were implemented with TypeScript. To ensure there were no implementation bugs, I ran test benches comparing the TypeScript optimizers' step-wise outputs for loss functions against the corresponding PyTorch libraries.</paragraph><paragraph><bold>How I built the visualizer to represent Muon on 2D loss landscapes:</bold> </paragraph><paragraph>Implementing AdamW and SGD were quite straightforward, but it was challenging for me to make this visualizer to work for Muon in a meaningful way. This is because Muon only works for 2D parameters and the loss functions and the rest of this visualizer was built for vectors. Chatting with Gemini 3 we came up with the following workflow to make this visualizer work for Muon as well in a meaningful way:</paragraph><list style=\"number\"><list-item><paragraph>Since Muon needs 2D parameters we defined a \u201cmatrix mode\u201d where a parameter matrix was defined as </paragraph><math>W=\\left[\\begin{matrix}x&amp;z\\\\y&amp;w\\end{matrix}\\right]</math></list-item><list-item><paragraph>In the Muon implementation the rows will be orthogonalized here. </paragraph></list-item><list-item><paragraph>We define the \u201cvisible parameters\u201d as $x$ and $y$ and the remaining parameters as \u201cdummy\u201d parameters. By separating $x$ and $y$ into different rows, you force the optimizer to make them orthogonal. If they were in the same row, they would just be normalized together. </paragraph></list-item><list-item><paragraph>Even if $z$ and $w$ are dummy parameters we still need to define gradients for them. Therefore we don\u2019t fix them, in-order for them to support the orthogonality constraints and also to prevent the matrix from being rank-1. Currently they are initialized to -1 and 1 and the final loss function is defined as:  . </paragraph><math>L_{total}=L_{2D}\\left(x,y\\right)+z^2+w^2</math></list-item><list-item><paragraph>$L_{2D}(x,y)$ is one of the four previously mentioned 2D loss functions and the remaining terms follow a simple bowl objective. Providing a \"slope\" for the hidden dimensions this way ensures the matrix has sufficient rank for the Newton-Schulz iteration to work non-trivially. </paragraph></list-item><list-item><paragraph>Under the above loss function the weights are optimized with the standard Muon implementation in TypeScript and we only visualize the behavior of $L_{2D}(x,y)$ in the tool.</paragraph></list-item></list><paragraph>I think this is still a mathematically valid way to observe the behavior of Muon in comparison to the other two optimizers. I also want to note that when Muon is selected as an optimizer from the controls in the visualizer, any other optimizer selected with it will also be working on matrix parameters for common ground. </paragraph><paragraph><bold>Features of the visualizer:</bold> </paragraph><list style=\"bullet\"><list-item><paragraph>2D contour and 3D surface plots for visual representation of the loss landscapes. This way during a run the user can analyze both views. I think the 3D view is especially useful when there are multiple local minima, saddle points and when it\u2019s not apparent on the 2D contour plot why the optimizer got stuck at certain points. </paragraph></list-item><list-item><paragraph>Loss function control \u2013 select any loss function.</paragraph></list-item><list-item><paragraph>Configure Optimizer panel \u2013 </paragraph><list style=\"bullet\"><list-item><paragraph>Type \u2013 optimizer type selection </paragraph></list-item><list-item><paragraph>Hyperparameter sliders to configure the optimizer and add it. </paragraph></list-item></list></list-item><list-item><paragraph>You\u2019re able to select multiple optimizers at different configurations during a run and they will be listed with the choices of hyperparameters in the Optimizer List. You can also set the starting points of $x$ and $y$ by either clicking anywhere on the contour plot or typing out coordinates in the \"start X\" and \"start Y\" boxes. </paragraph></list-item><list-item><paragraph>You can also set the number of maximum steps you want the optimizer to run for. The default is 200 steps. </paragraph></list-item><list-item><paragraph>You start the run with \u201cStart\u201d button and it\u2019ll automatically run until it hits the maximum number of steps. You can also pause runs or step through iterations one step at a time with the \u201cStep\u201d button. While the \u201cStop\u201d button resets to the beginning of the run, the \u201cReset\u201d button resets the visualizer.</paragraph></list-item></list><paragraph><bold>Some cool visualization examples:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Learning rate comparison within the same optimizer type: AdamW with higher learning rate converging faster by escaping local minima:</paragraph></list-item></list><video src=\"https://youtu.be/C_jRogYfsos\" width=\"476\" height=\"268\"/><list style=\"bullet\"><list-item><paragraph>Comparing several optimizers:</paragraph><list style=\"bullet\"><list-item><paragraph>AdamW finds the global minima but both SGD versions reach the local minima:</paragraph></list-item></list></list-item></list><video src=\"https://youtu.be/doiCirLdmi0\" width=\"466\" height=\"262\"/><list style=\"bullet\"><list-item><list style=\"bullet\"><list-item><paragraph>Muon originally moves towards the local minima but is able to recover and change the trajectory towards the global minima. I think this shows how Muon\u2019s orthogonality constraints initially causes the dominant gradient at that point ($dy$) to affect the gradients in other directions and may overall pull in the local minima direction, but I think once $dw$ and $dz$ recovers under their loss it snaps back in the direction of the global minima:</paragraph></list-item></list></list-item></list><video src=\"https://youtu.be/UyznKY5kxbo\" width=\"450\" height=\"253\"/><list style=\"bullet\"><list-item><list style=\"bullet\"><list-item><paragraph>Muon seems to do great in converging at more complex loss landscapes. I think this is an interesting case that shows how Muon\u2019s spectral norm constraints essentially \u201csaves\u201d it from exploding gradients along steep valleys and take controlled steps and eventually reach the global minima efficiently while the other optimizers seem to be distracted by the steep gradient in one direction (wall like structure) and gets stuck at local minimas since the gradient in other directions (valley like structure) gives less of a signal to move:</paragraph></list-item></list></list-item></list><video src=\"https://youtu.be/fiUtCnM6MkY\" width=\"459\" height=\"258\"/><paragraph><bold>Limitations</bold>:</paragraph><list style=\"bullet\"><list-item><paragraph>Users are unable to see the behavior of the hidden parameters in the matrix mode.</paragraph></list-item><list-item><paragraph>Users cannot set different values for the hidden parameters and analyze how that affects optimization trajectory of the 2D losses. </paragraph></list-item></list><paragraph>I think this is a useful tool for anyone trying to understand how certain hyperparameters affect certain loss functions, gain insights into the behavior of different optimizers even if it\u2019s for relatively simple loss landscapes. I think it would be a good playground to test specific instances to understand optimizers for academic purposes. </paragraph><paragraph>Hope y\u2019all can also check this out and let me know if you have any feedback. I\u2019m also interested in expanding this to other optimizers in the future.</paragraph><paragraph/></document>",
            "links": [
                "https://kithminiherath.github.io/optimizer-vis/",
                "https://github.com/KithminiHerath/optimizer-vis"
            ],
            "attachments": [],
            "created_at": "2025-12-08T13:48:39.069227+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429583,
            "author": "Zach Pricz",
            "project_title": "Special Participation E: Flow Matching vs DDPM Diffusion Visualization",
            "post_body": "In Berkeley's CS180: Introduction to Computer Vision and Computational Photography, we also covered diffusion models but under a different lens known as \"flow matching\". From my understanding, flow matching is a way to look at diffusion models that attempt to learn a vector field for samples to follow along in the reverse direction. This involves solving ODEs and resulting in deterministic trajectories compared to solving SDEs in stochastic processes like DDPM.\n\nTo visualize this difference, I worked with Cursor to create a visualization demo for the reverse process. In this demo, we can visualize particles moving from a noisy distribution to a clean two humped distribution. There is a stochasticity slider which adjusts how much randomness the particles will take in their trajectory as they move along a vector field. When that slider is 0, we are simulating a pure flow matching model, and when it is 1 we are simulating a stochastic DDPM process. We can also adjust the amount of particles moving across distributions per second.\n\nFeedback for Cursor:\n\nUsing Cursor was generally a positive experience however it struggled to create the visuals for the gaussians on the left and right hand side. I had to provide it a visual slide from CS180 for it to accomplish this after 3+ tries which was slightly dissapointing. Despite that, it was able to create this application for me in only a little over an hour which is very impressive. \n\nTo use the tool navigate to this link: https://zjpricz100.github.io/Zjpricz100/StochasticDiffusion/index.html\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>In Berkeley's CS180: Introduction to Computer Vision and Computational Photography, we also covered diffusion models but under a different lens known as \"flow matching\". From my understanding, flow matching is a way to look at diffusion models that attempt to learn a vector field for samples to follow along in the reverse direction. This involves solving ODEs and resulting in deterministic trajectories compared to solving SDEs in stochastic processes like DDPM.</paragraph><paragraph>To visualize this difference, I worked with Cursor to create a visualization demo for the reverse process. In this demo, we can visualize particles moving from a noisy distribution to a clean two humped distribution. There is a stochasticity slider which adjusts how much randomness the particles will take in their trajectory as they move along a vector field. When that slider is 0, we are simulating a pure flow matching model, and when it is 1 we are simulating a stochastic DDPM process. We can also adjust the amount of particles moving across distributions per second.</paragraph><paragraph>Feedback for Cursor:</paragraph><paragraph>Using Cursor was generally a positive experience however it struggled to create the visuals for the gaussians on the left and right hand side. I had to provide it a visual slide from CS180 for it to accomplish this after 3+ tries which was slightly dissapointing. Despite that, it was able to create this application for me in only a little over an hour which is very impressive. </paragraph><paragraph>To use the tool navigate to this link: <link href=\"https://zjpricz100.github.io/Zjpricz100/StochasticDiffusion/index.html\">https://zjpricz100.github.io/Zjpricz100/StochasticDiffusion/index.html</link></paragraph><paragraph/></document>",
            "links": [
                "https://zjpricz100.github.io/Zjpricz100/StochasticDiffusion/index.html"
            ],
            "attachments": [],
            "created_at": "2025-12-08T13:48:29.144831+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429462,
            "author": "Menger Wen",
            "project_title": "Special Participation A: Hw 6 with Grok",
            "post_body": "For Special Participation A, I used Grok on the written portion of HW 6.\n\nHere is the link to my chat: \n\nQ2\n\nQ3\n\nAnalysis\n\nQ2\n\nOverall Assessment\n\nThe AI assistant provided a mathematically accurate and conceptually sound response. It correctly identified the core relationship between matrix powers and graph walks and handled the GNN architecture questions well. However, its structure\u2014specifically the separation between \"Key Points\" and a long narrative essay\u2014made it less direct and harder to follow than the standard \"Question-Answer\" format found in the satisfactory response.\n\nStrengths (Pros)\n\n1. Strong \"Executive Summary\" (Key Points) The AI started with a \"Key Points\" section. This is a distinct advantage for users who want a high-level overview without wading through the math immediately. It effectively summarized the main takeaways (e.g., $A^k$ counts walks, Max aggregation = Reachability).\n\n2. Mathematical Correctness (Parts a, b, c) The AI correctly handled the linear algebra and graph theory components.\n\nInduction Proof: The proof for Part (b) was concise and logically sound, correctly identifying the base case and the inductive step involving neighbor summation.\n\nMatrix Interpretation: It correctly identified the output as related to $A^k$ and the update function as the identity.\n\n3. Advanced Domain Knowledge (Parts g, h)\n\nFeature Propagation: In Part (g), the AI mentioned \"minimizing Dirichlet energy\" and \"feature propagation.\" This is a more advanced, technically specific answer than simply saying \"message passing.\" It shows a deeper knowledge of how modern GNNs handle missing data.\n\nComplexity Analysis: In Part (h), the AI correctly broke down the computational complexity, noting the difference between sparse ($O(|E|)$) and dense ($O(|V|^2)$) graphs.\n\n4. Citations The AI included a list of citations/sources at the bottom. While this is a standard feature of search-enabled AIs, it adds credibility to the mathematical definitions used in the answer.\n\nWeaknesses (Cons)\n\n1. Structural Redundancy and Poor Formatting This is the biggest weakness.\n\nSplit Information: The AI answers the questions in short bullet points first, but then repeats the entire explanation in a long, narrative essay at the bottom (\"Graph neural networks represent...\").\n\nHard to Parse: If a user wants to check the answer for specifically Part (e), they have to look at the short bullet point, and then scan through the long text block at the bottom to see if there is more detail. The \"Satisfactory Answer\" is much better because it groups the full explanation directly under the question heading.\n\n2. Ambiguity in Notation (Part a) In Part (a), the AI writes: \"The output... is the j-th row of $A^k$ (or equivalently, the j-th column if considering column vectors).\" While mathematically true that $A$ is symmetric for undirected graphs, in the context of a specifically defined linear network with one-hot inputs, there is usually one specific correct orientation based on how the multiplication is defined ($Ax$ vs $xA$). The hedging (\"row or column\") adds unnecessary cognitive load compared to the specific $A^k e_j$ (column) derivation in the Satisfactory Answer.\n\n3. Weak Analogy in the Table (Part f) For \"Image flip data augmentation,\" the AI suggests \"Graph permutation or subgraph sampling.\"\n\nCritique: Flipping an image creates a new data point. Permuting a graph (renumbering nodes) results in the exact same object for a GNN because GNNs are permutation invariant. Therefore, permutation is not really \"data augmentation\" in the same way an image flip is. The Satisfactory Answer correctly notes that for general graphs, there is no direct equivalent, or suggests geometric rotations for geometric graphs, which is a more precise distinction.\n\n4. Lack of Operational Detail (Part e) In Part (e-ii) (making the prediction), the AI says: \"Final edge embeddings fed to an MLP...\" It omits the specific mechanism of selection mentioned in the Satisfactory Answer: \"argmax.\" Since the question asks how to predict which bond breaks first, explicitly mentioning the selection step (argmax over edge scores) is crucial for a complete answer.\n\nConclusion\n\nThe AI's answer is correct and trustworthy, but poorly organized. It mimics a blog post or a research summary rather than a homework solution. The \"Satisfactory Answer\" is superior in terms of pedagogical clarity, as it addresses each sub-problem comprehensively in order, whereas the AI forces the user to piece together the answer from a summary and a dense essay.\n\nQ3\n\nOverall Assessment\n\nThe AI assistant provided an excellent and completely accurate response. It correctly solved every part of the problem, including the conceptual questions about GNN validity, the mathematical derivation of the loss function, and the structural analysis of the specific update rule. The reasoning was sound throughout, and it successfully interpreted the graph structure provided in the DOT format.\n\nStrengths\n\n1. Perfect Accuracy on Graph Topology (DOT Parsing) One of the trickier parts of this prompt is interpreting the graph structure defined in the graph G { ... } block without a visual image.\n\nThe AI correctly identified the neighbors of Node 2 as ${1, 4, 5}$ and Node 3 as ${5}$.\n\nThis demonstrates strong logical reasoning capabilities to parse the edge list (1 -- 2, 2 -- 5, etc.) correctly.\n\n2. Detailed and Correct Dimensional Analysis In Part (c)(ii), the AI provided a step-by-step breakdown of the matrix dimensions.\n\nInstead of just guessing the answer ($d \\times k$), it traced the vector shape through the inner product ($W_2$), the nonlinearity ($\\tanh$), and the aggregation.\n\nThis explicit chain of thought makes the answer very easy to verify and trust.\n\n3. rigorous Conceptual Explanations In Part (a), the AI clearly distinguished between valid and invalid update rules by citing the necessary properties: Permutation Invariance and Parameter Sharing.\n\nIt correctly identified that distinct weights for specific neighbor indices (e.g., $w_2$ for the 1st neighbor, $w_3$ for the 2nd) violate the definition of a standard GNN on an unordered graph.\n\n4. Correct Mathematical Formulation In Part (b), the AI correctly identified the training set vs. the held-out set and applied the binary cross-entropy formula correctly. It did not fall into the trap of including nodes 1 and 4 in the loss calculation.\n\nWeaknesses / Areas for Improvement\n\n1. Mathematical Simplification (Style Preference) In Part (b), the AI left the final answer in the form of $\\log \\frac{1}{b}$.\n\nAI Answer: $\\frac{1}{3} [ \\log \\frac{1}{b} + \\log \\frac{1}{c} + \\log \\frac{1}{1 - e} ]$\n\nStandard Convention: In Machine Learning, it is more standard to simplify $\\log(1/x)$ to $-\\log(x)$. The \"Satisfactory Answer\" uses the negative log form ($\\frac{1}{3}(-\\log b - \\log c \\dots)$), which is generally cleaner and matches how loss functions are typically implemented in code (e.g., NLLLoss).\n\nNote: The AI's answer is mathematically correct, just stylistically less standard.\n\n2. Verbosity The AI's answer is somewhat wordy, particularly in Part (a).\n\nWhile the detailed explanations are helpful for a beginner, a more concise expert answer (like the \"Satisfactory Answer\") gets to the point faster. For example, in (a)(i), the explanation could be condensed to \"Valid: Uses symmetric aggregation (mean) and shared weights.\"\n\nConclusion\n\nThe AI assistant's performance on this problem is highly reliable. It made no logical or calculation errors. Its only minor flaw was a lack of algebraic simplification in the final loss term, but this does not affect the correctness of the result. It is a very strong response that would receive full marks in an exam setting.\n\n",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/FZLdjtQt2Sx3IivQDytsqBvw\" width=\"643\" height=\"7230.925419757908\"/></figure><paragraph>For Special Participation A, I used Grok on the written portion of HW 6.</paragraph><list style=\"unordered\"><list-item><paragraph>Here is the link to my chat: </paragraph><list style=\"unordered\"><list-item><paragraph><link href=\"https://grok.com/share/bGVnYWN5_988c8204-0166-4243-9abb-f87b11935144\">Q2</link></paragraph></list-item><list-item><paragraph><link href=\"https://grok.com/share/bGVnYWN5_616bb856-339a-4a3d-9303-40914bcf0c55\">Q3</link></paragraph></list-item></list></list-item></list><heading level=\"1\">Analysis</heading><heading level=\"2\">Q2</heading><heading level=\"3\">Overall Assessment</heading><paragraph>The AI assistant provided a mathematically accurate and conceptually sound response. It correctly identified the core relationship between matrix powers and graph walks and handled the GNN architecture questions well. However, its structure\u2014specifically the separation between \"Key Points\" and a long narrative essay\u2014made it less direct and harder to follow than the standard \"Question-Answer\" format found in the satisfactory response.</paragraph><heading level=\"3\">Strengths (Pros)</heading><paragraph><bold>1. Strong \"Executive Summary\" (Key Points)</bold> The AI started with a \"Key Points\" section. This is a distinct advantage for users who want a high-level overview without wading through the math immediately. It effectively summarized the main takeaways (e.g., $A^k$ counts walks, Max aggregation = Reachability).</paragraph><paragraph><bold>2. Mathematical Correctness (Parts a, b, c)</bold> The AI correctly handled the linear algebra and graph theory components.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Induction Proof:</bold> The proof for Part (b) was concise and logically sound, correctly identifying the base case and the inductive step involving neighbor summation.</paragraph></list-item><list-item><paragraph><bold>Matrix Interpretation:</bold> It correctly identified the output as related to $A^k$ and the update function as the identity.</paragraph></list-item></list><paragraph><bold>3. Advanced Domain Knowledge (Parts g, h)</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Feature Propagation:</bold> In Part (g), the AI mentioned \"minimizing Dirichlet energy\" and \"feature propagation.\" This is a more advanced, technically specific answer than simply saying \"message passing.\" It shows a deeper knowledge of how modern GNNs handle missing data.</paragraph></list-item><list-item><paragraph><bold>Complexity Analysis:</bold> In Part (h), the AI correctly broke down the computational complexity, noting the difference between sparse ($O(|E|)$) and dense ($O(|V|^2)$) graphs.</paragraph></list-item></list><paragraph><bold>4. Citations</bold> The AI included a list of citations/sources at the bottom. While this is a standard feature of search-enabled AIs, it adds credibility to the mathematical definitions used in the answer.</paragraph><heading level=\"3\">Weaknesses (Cons)</heading><paragraph><bold>1. Structural Redundancy and Poor Formatting</bold> This is the biggest weakness.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Split Information:</bold> The AI answers the questions in short bullet points first, but then repeats the entire explanation in a long, narrative essay at the bottom (\"Graph neural networks represent...\").</paragraph></list-item><list-item><paragraph><bold>Hard to Parse:</bold> If a user wants to check the answer for specifically Part (e), they have to look at the short bullet point, and then scan through the long text block at the bottom to see if there is more detail. The \"Satisfactory Answer\" is much better because it groups the full explanation directly under the question heading.</paragraph></list-item></list><paragraph><bold>2. Ambiguity in Notation (Part a)</bold> In Part (a), the AI writes: <italic>\"The output... is the j-th row of $A^k$ (or equivalently, the j-th column if considering column vectors).\"</italic> While mathematically true that $A$ is symmetric for undirected graphs, in the context of a specifically defined linear network with one-hot inputs, there is usually one specific correct orientation based on how the multiplication is defined ($Ax$ vs $xA$). The hedging (\"row or column\") adds unnecessary cognitive load compared to the specific $A^k e_j$ (column) derivation in the Satisfactory Answer.</paragraph><paragraph><bold>3. Weak Analogy in the Table (Part f)</bold> For \"Image flip data augmentation,\" the AI suggests \"Graph permutation or subgraph sampling.\"</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Critique:</bold> Flipping an image creates a <italic>new</italic> data point. Permuting a graph (renumbering nodes) results in the <italic>exact same</italic> object for a GNN because GNNs are permutation invariant. Therefore, permutation is not really \"data augmentation\" in the same way an image flip is. The Satisfactory Answer correctly notes that for general graphs, there is no direct equivalent, or suggests geometric rotations for geometric graphs, which is a more precise distinction.</paragraph></list-item></list><paragraph><bold>4. Lack of Operational Detail (Part e)</bold> In Part (e-ii) (making the prediction), the AI says: <italic>\"Final edge embeddings fed to an MLP...\"</italic> It omits the specific mechanism of selection mentioned in the Satisfactory Answer: <bold>\"argmax.\"</bold> Since the question asks how to predict <italic>which</italic> bond breaks first, explicitly mentioning the selection step (argmax over edge scores) is crucial for a complete answer.</paragraph><heading level=\"3\">Conclusion</heading><paragraph>The AI's answer is <bold>correct and trustworthy</bold>, but <bold>poorly organized</bold>. It mimics a blog post or a research summary rather than a homework solution. The \"Satisfactory Answer\" is superior in terms of pedagogical clarity, as it addresses each sub-problem comprehensively in order, whereas the AI forces the user to piece together the answer from a summary and a dense essay.</paragraph><heading level=\"2\">Q3</heading><heading level=\"3\">Overall Assessment</heading><paragraph>The AI assistant provided an <bold>excellent and completely accurate</bold> response. It correctly solved every part of the problem, including the conceptual questions about GNN validity, the mathematical derivation of the loss function, and the structural analysis of the specific update rule. The reasoning was sound throughout, and it successfully interpreted the graph structure provided in the DOT format.</paragraph><heading level=\"3\">Strengths</heading><paragraph><bold>1. Perfect Accuracy on Graph Topology (DOT Parsing)</bold> One of the trickier parts of this prompt is interpreting the graph structure defined in the <code>graph G { ... }</code> block without a visual image.</paragraph><list style=\"unordered\"><list-item><paragraph>The AI correctly identified the neighbors of Node 2 as ${1, 4, 5}$ and Node 3 as ${5}$.</paragraph></list-item><list-item><paragraph>This demonstrates strong logical reasoning capabilities to parse the edge list (<code>1 -- 2</code>, <code>2 -- 5</code>, etc.) correctly.</paragraph></list-item></list><paragraph><bold>2. Detailed and Correct Dimensional Analysis</bold> In Part (c)(ii), the AI provided a step-by-step breakdown of the matrix dimensions.</paragraph><list style=\"unordered\"><list-item><paragraph>Instead of just guessing the answer ($d \\times k$), it traced the vector shape through the inner product ($W_2$), the nonlinearity ($\\tanh$), and the aggregation.</paragraph></list-item><list-item><paragraph>This explicit chain of thought makes the answer very easy to verify and trust.</paragraph></list-item></list><paragraph><bold>3. rigorous Conceptual Explanations</bold> In Part (a), the AI clearly distinguished between <italic>valid</italic> and <italic>invalid</italic> update rules by citing the necessary properties: <bold>Permutation Invariance</bold> and <bold>Parameter Sharing</bold>.</paragraph><list style=\"unordered\"><list-item><paragraph>It correctly identified that distinct weights for specific neighbor indices (e.g., $w_2$ for the 1st neighbor, $w_3$ for the 2nd) violate the definition of a standard GNN on an unordered graph.</paragraph></list-item></list><paragraph><bold>4. Correct Mathematical Formulation</bold> In Part (b), the AI correctly identified the training set vs. the held-out set and applied the binary cross-entropy formula correctly. It did not fall into the trap of including nodes 1 and 4 in the loss calculation.</paragraph><heading level=\"3\">Weaknesses / Areas for Improvement</heading><paragraph><bold>1. Mathematical Simplification (Style Preference)</bold> In Part (b), the AI left the final answer in the form of $\\log \\frac{1}{b}$.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>AI Answer:</bold> $\\frac{1}{3} [ \\log \\frac{1}{b} + \\log \\frac{1}{c} + \\log \\frac{1}{1 - e} ]$</paragraph></list-item><list-item><paragraph><bold>Standard Convention:</bold> In Machine Learning, it is more standard to simplify $\\log(1/x)$ to $-\\log(x)$. The \"Satisfactory Answer\" uses the negative log form ($\\frac{1}{3}(-\\log b - \\log c \\dots)$), which is generally cleaner and matches how loss functions are typically implemented in code (e.g., <code>NLLLoss</code>).</paragraph></list-item><list-item><paragraph><italic>Note: The AI's answer is mathematically correct, just stylistically less standard.</italic></paragraph></list-item></list><paragraph><bold>2. Verbosity</bold> The AI's answer is somewhat wordy, particularly in Part (a).</paragraph><list style=\"unordered\"><list-item><paragraph>While the detailed explanations are helpful for a beginner, a more concise expert answer (like the \"Satisfactory Answer\") gets to the point faster. For example, in (a)(i), the explanation could be condensed to \"Valid: Uses symmetric aggregation (mean) and shared weights.\"</paragraph></list-item></list><heading level=\"3\">Conclusion</heading><paragraph>The AI assistant's performance on this problem is <bold>highly reliable</bold>. It made no logical or calculation errors. Its only minor flaw was a lack of algebraic simplification in the final loss term, but this does not affect the correctness of the result. It is a very strong response that would receive full marks in an exam setting.</paragraph><paragraph/></document>",
            "links": [
                "https://grok.com/share/bGVnYWN5_988c8204-0166-4243-9abb-f87b11935144",
                "https://grok.com/share/bGVnYWN5_616bb856-339a-4a3d-9303-40914bcf0c55"
            ],
            "attachments": [],
            "created_at": "2025-12-08T13:34:03.638897+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429448,
            "author": "WeiYi Zhang",
            "project_title": "Special Participation A: Exploration of Different Input Forms on HW5 (ChatGPT 5.1 Auto)",
            "post_body": "When we use large language models to solve knowledge-based problems, we may encounter the input of images/formulas. Taking hw5 as an example, I tried\uff1a\n\n\n1) text input only (without any formulas), \n2) text input + image input (there might be some formula garbled), \n3) inputting the entire question as an image, \n4) directly inputting the pdf. \n\n\nThen, I observed the problem-solving capabilities of the large language model under different inputs.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>When we use large language models to solve knowledge-based problems, we may encounter the input of images/formulas. Taking hw5 as an example, I tried\uff1a</paragraph><paragraph><break/>1) text input only (without any formulas), <break/>2) text input + image input (there might be some formula garbled), <break/>3) inputting the entire question as an image, <break/>4) directly inputting the pdf. </paragraph><paragraph><break/>Then, I observed the problem-solving capabilities of the large language model under different inputs.</paragraph><file url=\"https://static.us.edusercontent.com/files/gMKTLrtCeOkBVMOb5X4hAw6C\" filename=\"Exploration of Different Input Forms on HW5 (ChatGPT 5.1 Auto).pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:32:09.207671+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429445,
            "author": "Abdelaziz Mohamed",
            "project_title": "Special participation A: ChatGPT 5.1 Thinking extended on HW 4",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/szg1G6argQUSMc5mMjNUYwYw\" filename=\"ChatGPT 5.1 Thinking HW4 w exec.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:31:37.642701+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429419,
            "author": "Devan Perkash",
            "project_title": "Special Participation E: Inductive Bias Explainer",
            "post_body": "I used GPT 5.1 to build a small exploratory tool for understanding inductive bias across the architectures we studied in class this semester. I wrote an initial prompt that let me ask the model about different kinds of data patterns (local spatial cues, hybrid local/global structure, long-range sequential dependencies, etc.) and compare how various architectures behave based on the \"assumptions\" baked into them.\n\nExecutive Summary:\n\nMy goal was to create a tool that helps students reason about which structures different architectures \u201clike\u201d to learn, and why those preferences matter when the data mixes multiple types of patterns. I wrote a long initial prompt that set up a consistent explanation format so I could see how the model\u2019s reasoning changed across tasks. Then I tried five scenarios that were intentionally varied and realistic: some visual, some sequential, and one involving noisy video motion.\n\nIn many cases, the model gave clear and useful explanations of how CNNs, ResNets, RNNs, Transformers, state-space models, and others behave when their inductive biases align (or don\u2019t align) with the underlying data. The multi-architecture comparisons helped highlight patterns I\u2019ve heard emphasized in lecture, like how some models naturally focus on local structure while others mix information globally.\n\nThere were also a few places where the explanations were a bit simplified. For example, sometimes the model glossed over practical limitations (like how positional encodings affect Transformers, or how certain models handle noise). But overall the responses were consistent and conceptually helpful.\n\nYou can access the chat here:\n\nhttps://chatgpt.com/share/693635f5-fc80-800e-bb76-062bfb4a2bf1\n\nThe full annotated chat session is attached below, where I explain my prompting strategy, comment on the model\u2019s interpretations, and point out small places where the explanations could be sharper or more nuanced.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used GPT 5.1 to build a small exploratory tool for understanding inductive bias across the architectures we studied in class this semester. I wrote an initial prompt that let me ask the model about different kinds of data patterns (local spatial cues, hybrid local/global structure, long-range sequential dependencies, etc.) and compare how various architectures behave based on the \"assumptions\" baked into them.</paragraph><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>My goal was to create a tool that helps students reason about which structures different architectures \u201clike\u201d to learn, and why those preferences matter when the data mixes multiple types of patterns. I wrote a long initial prompt that set up a consistent explanation format so I could see how the model\u2019s reasoning changed across tasks. Then I tried five scenarios that were intentionally varied and realistic: some visual, some sequential, and one involving noisy video motion.</paragraph><paragraph>In many cases, the model gave clear and useful explanations of how CNNs, ResNets, RNNs, Transformers, state-space models, and others behave when their inductive biases align (or don\u2019t align) with the underlying data. The multi-architecture comparisons helped highlight patterns I\u2019ve heard emphasized in lecture, like how some models naturally focus on local structure while others mix information globally.</paragraph><paragraph>There were also a few places where the explanations were a bit simplified. For example, sometimes the model glossed over practical limitations (like how positional encodings affect Transformers, or how certain models handle noise). But overall the responses were consistent and conceptually helpful.</paragraph><paragraph>You can access the chat here:</paragraph><paragraph><link href=\"https://chatgpt.com/share/693635f5-fc80-800e-bb76-062bfb4a2bf1\">https://chatgpt.com/share/693635f5-fc80-800e-bb76-062bfb4a2bf1</link></paragraph><paragraph>The full annotated chat session is attached below, where I explain my prompting strategy, comment on the model\u2019s interpretations, and point out small places where the explanations could be sharper or more nuanced.</paragraph><file url=\"https://static.us.edusercontent.com/files/OkX7rjKpdilVNNIbgy4bWEtp\" filename=\"participation_e2.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/693635f5-fc80-800e-bb76-062bfb4a2bf1"
            ],
            "attachments": [],
            "created_at": "2025-12-08T13:29:01.257158+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429378,
            "author": "Aaryan Chandna",
            "project_title": "Special Participation B: DeepSeek on HW9 Coding",
            "post_body": "I tried out DeepSeek on HW9, having it guess the answers to the written questions about the visualizations and comparing the guesses with the actual visualizations. The outputs were generally pretty good in identifying the intended (set of) response(s), with some caveats. There was a point where DeepSeek mentioned bidirectional attention for GPT which was strange, but then it mentioned the masked attention in the same output which was an interesting correction. Outside of that, I did not see a lot of hallucination, the explanations tended to be thorough and specific. Even when the solutions claimed that patterns would vary, DeepSeek would identify the pattern it expected and explain in depth. Sometimes, the patterns were not as strong as I expected. For example, DeepSeek thought that I would see more local patterns in the first few layers. This was true to an extent, but not clear in every visualization. I think DeepSeek's intuition aligned with mine, however. In addition to the idea of more local patterns in the initial layers as I mentioned, I expected that \"play\" would strongly attend to \"a\" in \"... going to a play ...\", but it had weaker attention in only some layers/heads, which was interesting. Overall, the performance of DeepSeek on this task was reasonably strong.\n\n\n\nLink: https://chat.deepseek.com/share/zebe0qimvcn53ejgjj",
            "content_xml": "<document version=\"2.0\"><paragraph>I tried out DeepSeek on HW9, having it guess the answers to the written questions about the visualizations and comparing the guesses with the actual visualizations. The outputs were generally pretty good in identifying the intended (set of) response(s), with some caveats. There was a point where DeepSeek mentioned bidirectional attention for GPT which was strange, but then it mentioned the masked attention in the same output which was an interesting correction. Outside of that, I did not see a lot of hallucination, the explanations tended to be thorough and specific. Even when the solutions claimed that patterns would vary, DeepSeek would identify the pattern it expected and explain in depth. Sometimes, the patterns were not as strong as I expected. For example, DeepSeek thought that I would see more local patterns in the first few layers. This was true to an extent, but not clear in every visualization. I think DeepSeek's intuition aligned with mine, however. In addition to the idea of more local patterns in the initial layers as I mentioned, I expected that \"play\" would strongly attend to \"a\" in \"... going to a play ...\", but it had weaker attention in only some layers/heads, which was interesting. Overall, the performance of DeepSeek on this task was reasonably strong.</paragraph><file url=\"https://static.us.edusercontent.com/files/RUWanoUNyOArWuKrJSAbwyTf\" filename=\"spec_part_b_hw9.pdf\"/><paragraph/><paragraph>Link: https://chat.deepseek.com/share/zebe0qimvcn53ejgjj</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:25:04.617399+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429307,
            "author": "Subhash Prasad",
            "project_title": "Special Participation E: Claude Artifact Creation Based on GNN Lecture Notes",
            "post_body": "For this participation assignment, I decided to create a prompt for Claude to create an interactive \"artifact\" designed with the purpose of helping understand key concepts from lecture notes. This tool is designed to be used as an aide to reading lecture notes themselves, as it promotes active-learning through interactivity. I used Sonnet 4.5, and the specific prompt I used is specified below.\n\nPROMPT:\n\nI'm taking a Deep Learning course and need to create an interactive learning tool to help students (including myself) better understand concepts from this lecture. Please read through these lecture notes and: 1. Identify 3-5 core concepts that would benefit most from interactive visualization or hands-on exploration 2. For each concept, suggest what kind of interactive artifact would be most helpful (e.g., interactive visualizer, step-by-step derivation tool, parameter explorer, concept quiz, etc.) 3. Pick the MOST important/challenging concept and create an interactive artifact for it that includes: - Clear explanations at multiple levels of detail - Interactive elements where I can adjust parameters and see results - Step-by-step walkthroughs where applicable - Self-check questions or exercises The goal is to create something that replaces traditional pre/post-lecture reading with an active learning experience.\n\nARTIFACT GENERATED:\nhttps://claude.ai/public/artifacts/8c3e2ccf-619d-4c6d-a86b-4b43eeb9ef27\n\nANNOTATED CONVERSATION:\nhttps://drive.google.com/file/d/1wntHd7Ix8iB4LBfbf9mPIVM0i_02ZNyc/view?usp=sharing\n\nRESULTS:\nOverall, the model did a decent job. It created a truly interactive component, and clearly + correctly identified the concepts from the lecture notes that are most pertinent to understanding. The visualization makes it easy to understand the core concepts of convolution. The structure of the tool makes sense and is conducive to learning, as complex concepts are covered in later tabs. There is also real-time computation in the simulation, eliminating the overhead of waiting for a new graph if one were doing the same thing by prompting an LLM repeatedly.\n\nSome places for improvement are the omission of several things in the feature which would have been really nice for understanding, like node-masking, and interactivity in the DiffPool section. The model oversimplified in many places in favor of creating a working artifact, while overpromising in the initial response before creating the artifact itself. Additionally, the bias term is left out of the aggregation of neighbors computation, so while using the tool, one must note that the formulas may be incomplete / incorrect.\n\nLecture notes should still be read to fill in the gaps left by the interactive artifact.",
            "content_xml": "<document version=\"2.0\"><paragraph>For this participation assignment, I decided to create a prompt for Claude to create an interactive \"artifact\" designed with the purpose of helping understand key concepts from lecture notes. This tool is designed to be used as an aide to reading lecture notes themselves, as it promotes active-learning through interactivity. I used Sonnet 4.5, and the specific prompt I used is specified below.<break/><break/><bold>PROMPT:</bold></paragraph><paragraph>I'm taking a Deep Learning course and need to create an interactive learning tool to help students (including myself) better understand concepts from this lecture. Please read through these lecture notes and: 1. Identify 3-5 core concepts that would benefit most from interactive visualization or hands-on exploration 2. For each concept, suggest what kind of interactive artifact would be most helpful (e.g., interactive visualizer, step-by-step derivation tool, parameter explorer, concept quiz, etc.) 3. Pick the MOST important/challenging concept and create an interactive artifact for it that includes: - Clear explanations at multiple levels of detail - Interactive elements where I can adjust parameters and see results - Step-by-step walkthroughs where applicable - Self-check questions or exercises The goal is to create something that replaces traditional pre/post-lecture reading with an active learning experience.<break/><break/><bold>ARTIFACT GENERATED:<break/></bold><link href=\"https://claude.ai/public/artifacts/8c3e2ccf-619d-4c6d-a86b-4b43eeb9ef27\">https://claude.ai/public/artifacts/8c3e2ccf-619d-4c6d-a86b-4b43eeb9ef27</link><break/><break/><bold>ANNOTATED CONVERSATION:</bold><break/><link href=\"https://drive.google.com/file/d/1wntHd7Ix8iB4LBfbf9mPIVM0i_02ZNyc/view?usp=sharing\">https://drive.google.com/file/d/1wntHd7Ix8iB4LBfbf9mPIVM0i_02ZNyc/view?usp=sharing</link><break/><break/><bold>RESULTS:</bold><break/>Overall, the model did a decent job. It created a truly interactive component, and clearly + correctly identified the concepts from the lecture notes that are most pertinent to understanding. The visualization makes it easy to understand the core concepts of convolution. The structure of the tool makes sense and is conducive to learning, as complex concepts are covered in later tabs. There is also real-time computation in the simulation, eliminating the overhead of waiting for a new graph if one were doing the same thing by prompting an LLM repeatedly.<break/><break/>Some places for improvement are the omission of several things in the feature which would have been really nice for understanding, like node-masking, and interactivity in the DiffPool section. The model oversimplified in many places in favor of creating a working artifact, while overpromising in the initial response before creating the artifact itself. Additionally, the bias term is left out of the aggregation of neighbors computation, so while using the tool, one must note that the formulas may be incomplete / incorrect.<break/><break/>Lecture notes should still be read to fill in the gaps left by the interactive artifact.</paragraph></document>",
            "links": [
                "https://claude.ai/public/artifacts/8c3e2ccf-619d-4c6d-a86b-4b43eeb9ef27",
                "https://drive.google.com/file/d/1wntHd7Ix8iB4LBfbf9mPIVM0i_02ZNyc/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T13:14:16.580194+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429282,
            "author": "Shoumik Roychowdhury",
            "project_title": "Special Participation A: Homework 10 ChatGPT 5.1 Thinking",
            "post_body": "For any question that depended on my own training runs / plots / metrics, I explicitly asked it to: State what it couldn\u2019t know, and then ell me what I needed to fill in from my own notebook (accuracy numbers, screenshots, etc.).\n\nFor pure theory/math derivations (e.g., rewriting softmax with a Gaussian kernel, deriving the linear attention complexity, causal recurrences), the LLM: Got the structure right on the first try.\n\nFor high-level conceptual questions (example difficulty, why early exit helps, what hooks do, when to use early exit vs a smaller model): It also mostly one-shotted reasonable, coherent answers. I\u2019d estimate ~70\u201380% of the non-coding questions were basically \u201cdone\u201d after a single pass, with only minor wording tweaks from me.\n\nA few consistent failure modes showed up: Over-confidence on unknown experiment outputs, Numeric details from papers , Flattening subtle distinctions\n\nHere are the strategies that seemed to work best to keep the LLM honest:\n\nAsk for derivations, not just final answers\n\nForce it to separate \u201cwhat it knows\u201d from \u201cwhat I must provide\u201d\n\nCompare against the original paper\n\nAsk for structure, then fill in details myself\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For any question that depended on my own training runs / plots / metrics, I explicitly asked it to: State what it <italic>couldn\u2019t</italic> know, and then ell me what <italic>I</italic> needed to fill in from my own notebook (accuracy numbers, screenshots, etc.).</paragraph><paragraph>For pure theory/math derivations (e.g., rewriting softmax with a Gaussian kernel, deriving the linear attention complexity, causal recurrences), the LLM: Got the structure right on the first try.</paragraph><paragraph>For high-level conceptual questions (example difficulty, why early exit helps, what hooks do, when to use early exit vs a smaller model): It also mostly one-shotted reasonable, coherent answers. I\u2019d estimate ~70\u201380% of the non-coding questions were basically \u201cdone\u201d after a single pass, with only minor wording tweaks from me.</paragraph><paragraph>A few consistent failure modes showed up: Over-confidence on unknown experiment outputs, Numeric details from papers , Flattening subtle distinctions</paragraph><list style=\"unordered\"/><paragraph>Here are the strategies that seemed to work best to keep the LLM honest:</paragraph><list style=\"unordered\"><list-item><paragraph>Ask for derivations, not just final answers</paragraph></list-item><list-item><paragraph>Force it to separate \u201cwhat it knows\u201d from \u201cwhat I must provide\u201d</paragraph></list-item><list-item><paragraph>Compare against the original paper</paragraph></list-item><list-item><paragraph>Ask for structure, then fill in details myself</paragraph></list-item></list><paragraph><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/YGMzb6vDhetnbJ9okbKvOIW5\" filename=\"hw10_solutions_non_coding.pdf\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:10:42.400109+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429201,
            "author": "Jaewon Chang",
            "project_title": "Special Participation B: GPT 5 Pro on HW0 Coding",
            "post_body": "I asked GPT 5 Pro to solve the coding portion of HW 0, and linked a pdf to the conversation below. Given that HW 0 is a simple task at first glance, I was personally curious to see whether the model would be able to solve multiple coding problems at once (instead of prompting it one question at a time), without any specific instructions. I simply copy pasted the instructions corresponding to each code section in the .ipynb file, along with the skeleton code that it would be prompted to fill out. Here are the details per question:\n\nForward pass, backward pass, relu forward pass, relu backward pass (51 seconds of thinking) \u2013 the model was able to one shot the code without any problems\n\nTwoLayerNet class (2 minutes 36 seconds) \u2013 here again the model was able to one shot the code without any problems\n\nSolver in solver.py (1 minute 21 seconds). The model did error here, specifying \"adam\" as the update_rule, and so I prompted it with a follow-up after copy pasting the error message\n\nInterestingly enough, the model thought for another 1 minute 12 seconds before giving me a \"corrected\" version of the code (much more complex than the original), which was still erroring when I ran it. So I decided to take the original code it gave me and modify \"adam\" to \"sgd\" which was sufficient to do the trick (i.e. achieve 50%+ validation accuracy). It appeared that the model was overcomplicating things here, when it could've simply proposed trying SGD instead of Adam\n\nFullyConnectedNet class (4 minutes 3 seconds). The model did not error here, though took much longer than previous questions to code up.\n\nThere were two code blocks that required overfitting (the first being overfitting on a 3 layer fully connected NN, and the second being overfitting on a 5 layer fully connected NN). I prompted the model to come up with a set of hyperparameters for both tasks in one message, but the values did not end up working so I had to re-prompt the model (1 minute 37 seconds of thinking).\n\nI decided that it might be better to tackle each hyperparmeter search individually, so I began with the 3 layer NN, so I asked specifically about it (model thinking for 1 minute 32 seconds) but this still did not work. Given that the model often took ~ 90 seconds to generate a response, I decided that it probably would be smarter for me to ask for a range of values and perform grid search over a wide combination of values. So I proceeded to ask the model for a range of values for me to plug and chug (where the model thought for 3 minutes), and this ultimately got it to work \u2013 achieving 100% training accuracy.\n\nMoving onto the 5 layer hyperparameter search, I began by prompting the model with a range of values (learning my lesson from above), but none of the values ended up working (1 minute 48 seconds of thinking). So I re-iterated the task by emphasizing that these hyperparameters are for a 5 layer fully connected NN, and also pasted the logs of the training and validation accuracies for the model to reference. After 2 minutes 36 seconds of thinking, the model outputted a range of parameters where one of them worked immediately\n\nI think overall the biggest downside of using a model like GPT 5 Pro is that the answer that is obtained often ends up taking a while to generate (i.e. often 1 minute + for questions that less powerful models would be able to solve in 10-20 seconds of thinking). Furthermore, when it comes to debugging error messages like the one I faced during 3 layer parameter search, it took much longer than expected since I'd wait for a couple minutes only to re-prompt the model for another set of values since they didn't work. The one thing I found really interesting was the error in the update_rule argument in its code, because it actually seemed to almost \"overcomplicate\" the code when there existed a one word fix in the code (which I manually found). All in all, this experience made me realize that using such powerful models that think for minutes before generating a response may not be too suitable for non-complex tasks like these \u2013 i.e. ones that one would expect a less powerful model to be capable of solving easily. \n\nAnnotated google drive link: https://drive.google.com/file/d/1nbVDLYyoBo3o4N3rLR5Ap7H7yaMgAln3/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I asked GPT 5 Pro to solve the coding portion of HW 0, and linked a pdf to the conversation below. Given that HW 0 is a simple task at first glance, I was personally curious to see whether the model would be able to solve multiple coding problems at once (instead of prompting it one question at a time), without any specific instructions. I simply copy pasted the instructions corresponding to each code section in the .ipynb file, along with the skeleton code that it would be prompted to fill out. Here are the details per question:</paragraph><list style=\"bullet\"><list-item><paragraph>Forward pass, backward pass, relu forward pass, relu backward pass (51 seconds of thinking) \u2013 the model was able to one shot the code without any problems</paragraph></list-item><list-item><paragraph>TwoLayerNet class (2 minutes 36 seconds) \u2013 here again the model was able to one shot the code without any problems</paragraph></list-item><list-item><paragraph>Solver in solver.py (1 minute 21 seconds). The model did <bold>error</bold> here, specifying \"adam\" as the <bold>update_rule</bold>, and so I prompted it with a follow-up after copy pasting the error message</paragraph><list style=\"bullet\"><list-item><paragraph>Interestingly enough, the model thought for another 1 minute 12 seconds before giving me a \"corrected\" version of the code (much more complex than the original), which was still erroring when I ran it. So I decided to take the original code it gave me and modify \"adam\" to \"sgd\" which was sufficient to do the trick (i.e. achieve 50%+ validation accuracy). It appeared that the model was overcomplicating things here, when it could've simply proposed trying SGD instead of Adam</paragraph></list-item></list></list-item><list-item><paragraph>FullyConnectedNet class (4 minutes 3 seconds). The model did not error here, though took much longer than previous questions to code up.</paragraph><list style=\"bullet\"><list-item><paragraph>There were two code blocks that required overfitting (the first being overfitting on a 3 layer fully connected NN, and the second being overfitting on a 5 layer fully connected NN). I prompted the model to come up with a set of hyperparameters for both tasks in one message, but the values <bold>did not end up working</bold> so I had to re-prompt the model (1 minute 37 seconds of thinking).</paragraph></list-item><list-item><paragraph>I decided that it might be better to tackle each hyperparmeter search individually, so I began with the 3 layer NN, so I asked specifically about it (model thinking for 1 minute 32 seconds) <bold>but this still did not work.</bold> Given that the model often took ~ 90 seconds to generate a response, I decided that it probably would be smarter for me to ask for a range of values and perform grid search over a wide combination of values. So I proceeded to ask the model for a range of values for me to plug and chug (where the model thought for 3 minutes), and this ultimately got it to work \u2013 achieving 100% training accuracy.</paragraph></list-item><list-item><paragraph>Moving onto the 5 layer hyperparameter search, I began by prompting the model with a range of values (<underline>learning my lesson from above</underline>), but none of the values ended up working (1 minute 48 seconds of thinking). So I re-iterated the task by emphasizing that these hyperparameters are for a 5 layer fully connected NN, and also pasted the logs of the training and validation accuracies for the model to reference. After 2 minutes 36 seconds of thinking, the model outputted a range of parameters where one of them worked immediately</paragraph></list-item></list></list-item></list><paragraph>I think overall the biggest downside of using a model like GPT 5 Pro is that the answer that is obtained often ends up taking a while to generate (i.e. often 1 minute + for questions that less powerful models would be able to solve in 10-20 seconds of thinking). Furthermore, when it comes to debugging error messages like the one I faced during <bold>3 layer parameter search</bold>, it took much longer than expected since I'd wait for a couple minutes only to re-prompt the model for another set of values since they didn't work. The one thing I found really interesting was the error in the <bold>update_rule</bold> argument in its code, because it actually seemed to almost \"overcomplicate\" the code when there existed a one word fix in the code (which I manually found). All in all, this experience made me realize that using such powerful models that think for minutes before generating a response may not be too suitable for non-complex tasks like these \u2013 i.e. ones that one would expect a less powerful model to be capable of solving easily. </paragraph><file url=\"https://static.us.edusercontent.com/files/TmhNWyC9aIkSxgQDSIh8ddFr\" filename=\"182 participation B.pdf\"/><paragraph>Annotated google drive link: https://drive.google.com/file/d/1nbVDLYyoBo3o4N3rLR5Ap7H7yaMgAln3/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T13:01:48.48225+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429068,
            "author": "Shoumik Roychowdhury",
            "project_title": "Special Participation E: Cheatsheet Attention and Diffusion",
            "post_body": "As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build individualized pre-lecture learning tools.\n\nI\u2019m sharing the prompt, output artifacts, and annotated interaction trace so you can use them yourselves and also see both the strengths and the failure modes of LLM-assisted studying.\n\n\nNOTE:\nthe model occasionally implied citations (\u201cas from class notes\u201d) without pulling actual page numbers\n Some formulas were slightly rephrased\u2014not incorrect, but not exactly matching lecture notation\nThe kernel attention explanation is correct conceptually, but slightly hand-wavey on the random feature approximation\n\nThe Prompt I Used\n\n\u201cGenerate a comprehensive, exam-ready cheatsheet for Berkeley EECS 182 (Fall 2025), focusing especially on:\nAttention mechanisms (self-attention, cross-attention, multi-head attention, transformer architecture),\nGenerative AI models with emphasis on Diffusion Models (forward process, reverse process, score matching, ELBO, denoising networks, sampling algorithms).\nThe cheatsheet should prioritize mathematical clarity, include equations and derivations, use text diagrams, and be optimized for last-minute review.\u201d\n\n\nNote I also provided the homework and discussion associated with the previously mentioned topics\n\nConclusion:\nUseful as a study tool, but not a replacement for primary sources (lecture slides, notes, HW derivations). You must still verify key formulas.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>As part of exploring how AI can enhance our conceptual understanding in EECS 182, I experimented with using modern AI learning modes (ChatGPT Study Mode, Claude Learning Mode, Gemini Guided Learning, and standard LLM prompting) to build <italic>individualized pre-lecture learning tools</italic>.</paragraph><paragraph>I\u2019m sharing the <bold>prompt, output artifacts, and annotated interaction trace</bold> so you can use them yourselves and also see both the strengths <italic>and</italic> the failure modes of LLM-assisted studying.<break/><break/><break/>NOTE:<break/>the model occasionally implied citations (\u201cas from class notes\u201d) without pulling actual page numbers<break/> Some formulas were slightly rephrased\u2014not incorrect, but not exactly matching lecture notation<break/>The kernel attention explanation is correct conceptually, but slightly hand-wavey on the random feature approximation<break/><break/><bold>The Prompt I Used</bold></paragraph><blockquote>\u201cGenerate a comprehensive, exam-ready cheatsheet for Berkeley EECS 182 (Fall 2025), focusing especially on:<break/>Attention mechanisms (self-attention, cross-attention, multi-head attention, transformer architecture),<break/>Generative AI models with emphasis on Diffusion Models (forward process, reverse process, score matching, ELBO, denoising networks, sampling algorithms).<break/>The cheatsheet should prioritize mathematical clarity, include equations and derivations, use text diagrams, and be optimized for last-minute review.\u201d<break/></blockquote><paragraph>Note I also provided the homework and discussion associated with the previously mentioned topics<break/><break/><bold>Conclusion:</bold><break/>Useful as a study tool, but <italic>not a replacement</italic> for primary sources (lecture slides, notes, HW derivations). You must still verify key formulas.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/bMYCGPVYJPtPwR0xcrmAoCeM\" filename=\"Attention_and_Diffusion_CheatSheet.pdf\"/><paragraph><break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T12:46:23.566825+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7429063,
            "author": "Anshul Verma",
            "project_title": "Special Participation E: AI Lecturer",
            "post_body": "Tool: Claude Opus 4.5, Lecture: Lecture 6\n\nGoal:\n\nThe goal of this is to turn the handwritten lecture notes into a complete, step-by-step \u201ctextbook chapter\u201d without skipping any content using a structured system prompt. The prompt forces the LLM to rewrite every equation and symbol, explain every concept in plain English, and derive formulas line-by-line.\n\nEvaluation:\n\nDid Well\n\nCaptured the full narrative flow of the lecture, connecting disparate topics \n\nGave clear intuition for difficult math\n\nRarely skipped topics touched on in the notes\n\nLimitations\n\nOccasionally summarized text blocks instead of rewriting them verbatim \n\nMixed external knowledge into the notes without always clearly labeling it \n\nSometimes invented small details to make the narrative smoother\n\nPrompt: https://drive.google.com/file/d/11pExwTIi11A0ssL2ztrrajsW3Qx9z87d/view?usp=sharing\n\nLLM Trace: https://claude.ai/share/4993f343-6808-4e3c-8c5f-314f3d094867\n\nAnnotated Trace: https://drive.google.com/file/d/18RcfXiPb9KIqi1Rz7LUGtkjwB_Rgqe66/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Tool:</bold> Claude Opus 4.5, <bold>Lecture:</bold> Lecture 6</paragraph><paragraph><bold>Goal:</bold></paragraph><paragraph>The goal of this is to turn the handwritten lecture notes into a complete, step-by-step \u201ctextbook chapter\u201d without skipping any content using a structured system prompt. The prompt forces the LLM to rewrite every equation and symbol, explain every concept in plain English, and derive formulas line-by-line.</paragraph><paragraph><bold>Evaluation:</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Did Well</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Captured the full narrative flow of the lecture, connecting disparate topics </paragraph></list-item><list-item><paragraph>Gave clear intuition for difficult math</paragraph></list-item><list-item><paragraph>Rarely skipped topics touched on in the notes</paragraph></list-item></list></list-item><list-item><paragraph><bold>Limitations</bold></paragraph></list-item><list-item><list style=\"bullet\"><list-item><paragraph>Occasionally summarized text blocks instead of rewriting them verbatim </paragraph></list-item><list-item><paragraph>Mixed external knowledge into the notes without always clearly labeling it </paragraph></list-item><list-item><paragraph>Sometimes invented small details to make the narrative smoother</paragraph></list-item></list></list-item></list><paragraph><bold>Prompt:</bold> <link href=\"https://drive.google.com/file/d/11pExwTIi11A0ssL2ztrrajsW3Qx9z87d/view?usp=sharing\">https://drive.google.com/file/d/11pExwTIi11A0ssL2ztrrajsW3Qx9z87d/view?usp=sharing</link></paragraph><paragraph><bold>LLM Trace:</bold> <link href=\"https://claude.ai/share/4993f343-6808-4e3c-8c5f-314f3d094867\">https://claude.ai/share/4993f343-6808-4e3c-8c5f-314f3d094867</link></paragraph><paragraph><bold>Annotated Trace:</bold> <link href=\"https://drive.google.com/file/d/18RcfXiPb9KIqi1Rz7LUGtkjwB_Rgqe66/view?usp=sharing\">https://drive.google.com/file/d/18RcfXiPb9KIqi1Rz7LUGtkjwB_Rgqe66/view?usp=sharing</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/11pExwTIi11A0ssL2ztrrajsW3Qx9z87d/view?usp=sharing",
                "https://claude.ai/share/4993f343-6808-4e3c-8c5f-314f3d094867",
                "https://drive.google.com/file/d/18RcfXiPb9KIqi1Rz7LUGtkjwB_Rgqe66/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T12:45:48.546364+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428945,
            "author": "Nazar Ospanov",
            "project_title": "Special Participation D: Learning Rate with Batch Size Scaling on HW 12",
            "post_body": "I extended Homework 12 by adding learning-rate scaling based on batch size, following the ideas from a recent 2024 paper on how learning rate should change when the batch size changes. This fits the goal of Special Participation Part D, which asks us to bring modern training practices into the assignment in a way that is easy to use and understand.\n\nTo do this, I updated both the q_vae.ipynb notebook and the code in the cs182hw12 folder. In utils.py, I implemented a small helper function called scale_learning_rate_with_batch_size that adjusts the learning rate depending on the batch size the model is using. It supports the two common rules people use in practice:\n\nLinear scaling:\n\n$\\text{lr}{\\text{new}} = \\text{lr}\\text{base} \\cdot \\frac{B_{\\text{new}}}{B_{\\text{base}}}$\n\nSquare-root scaling:\n\n$\\text{lr}{\\text{new}} = \\text{lr}\\text{base} \\cdot \\sqrt{\\frac{B_{\\text{new}}}{B_{\\text{base}}}}$\n\n\n\nThen, in experiment.py, I applied this function so the optimizer automatically updates its learning rate based on the batch size chosen in the config. This lets the training loop behave more sensibly when using bigger or smaller batches, without needing to manually retune anything.\n\nOverall, the changes are small and easy to toggle, but they make the VAE training setup feel much more \u201cmodern,\u201d since batch-size\u2013dependent learning-rate scaling is now a standard part of deep-learning practice.\n\nHere are the zip files of the extended homework and solutions:",
            "content_xml": "<document version=\"2.0\"><paragraph>I extended Homework 12 by adding <bold>learning-rate scaling based on batch size</bold>, following the ideas from a recent 2024 paper on how learning rate should change when the batch size changes. This fits the goal of Special Participation Part D, which asks us to bring modern training practices into the assignment in a way that is easy to use and understand.</paragraph><paragraph>To do this, I updated both the q_vae.ipynb notebook and the code in the cs182hw12 folder. In utils.py, I implemented a small helper function called scale_learning_rate_with_batch_size that adjusts the learning rate depending on the batch size the model is using. It supports the two common rules people use in practice:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Linear scaling:</bold></paragraph><paragraph>$\\text{lr}{\\text{new}} = \\text{lr}\\text{base} \\cdot \\frac{B_{\\text{new}}}{B_{\\text{base}}}$</paragraph></list-item><list-item><paragraph><bold>Square-root scaling:</bold></paragraph><paragraph>$\\text{lr}{\\text{new}} = \\text{lr}\\text{base} \\cdot \\sqrt{\\frac{B_{\\text{new}}}{B_{\\text{base}}}}$</paragraph></list-item></list><paragraph/><paragraph>Then, in experiment.py, I applied this function so the optimizer automatically updates its learning rate based on the batch size chosen in the config. This lets the training loop behave more sensibly when using bigger or smaller batches, without needing to manually retune anything.</paragraph><paragraph>Overall, the changes are small and easy to toggle, but they make the VAE training setup feel much more \u201cmodern,\u201d since batch-size\u2013dependent learning-rate scaling is now a standard part of deep-learning practice.</paragraph><paragraph>Here are the zip files of the extended homework and solutions:</paragraph><file url=\"https://static.us.edusercontent.com/files/DxxpOoVipboaXJbff8WSOqFO\" filename=\"hw12_lr_batchsize.zip\"/><file url=\"https://static.us.edusercontent.com/files/h4WyJdan0egFCtiMRrNbStSW\" filename=\"hw12_lr_batchsize_sols.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T12:27:50.296354+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428884,
            "author": "Nazar Ospanov",
            "project_title": "Special Participation D: Lion Optimizer on HW 12",
            "post_body": "I extended Homework 12 by adding support for the Lion optimizer, a more modern and lightweight alternative to Adam. Since this option asks us to introduce new, up-to-date optimization methods into the assignment, I chose Lion because it reflects current trends in training, focusing on momentum and sign-based updates rather than heavier second-moment tracking.\n\nTo implement this, I extended the q_vae.ipynb notebook as well as modified the direct cs182hw12 folder. I created a new Lion optimizer class in utils.py. The class handles momentum updates, applies the sign() operation to determine the update direction, and includes weight decay. I followed the standard defaults suggested by the paper: lr = 1e-4, betas = (0.9, 0.99), and weight_decay = 1.0. I then integrated Lion into the training pipeline by modifying build_optimizers in experiment.py so that setting config.use_lion = 1 switches the model to Lion automatically, while all existing behavior stays the same when Lion is not enabled. This works for both the VAE and GAN configurations used in the homework.\n\nOverall, this addition makes it easy to compare Adam and Lion in the same codebase and experiment with how a more modern optimizer performs, all while keeping changes minimal and easy to toggle.\n\nHere are the zip files of the extended homework and solutions:",
            "content_xml": "<document version=\"2.0\"><paragraph>I extended Homework 12 by adding support for the <bold>Lion optimizer</bold>, a more modern and lightweight alternative to Adam. Since this option asks us to introduce new, up-to-date optimization methods into the assignment, I chose Lion because it reflects current trends in training, focusing on momentum and sign-based updates rather than heavier second-moment tracking.</paragraph><paragraph>To implement this, I extended the q_vae.ipynb notebook as well as modified the direct cs182hw12 folder. I created a new Lion optimizer class in <code>utils.py</code>. The class handles momentum updates, applies the sign() operation to determine the update direction, and includes weight decay. I followed the standard defaults suggested by the paper: <code>lr = 1e-4</code>, <code>betas = (0.9, 0.99)</code>, and <code>weight_decay = 1.0</code>. I then integrated Lion into the training pipeline by modifying build_optimizers in experiment.py so that setting <code>config.use_lion = 1</code> switches the model to Lion automatically, while all existing behavior stays the same when Lion is not enabled. This works for both the VAE and GAN configurations used in the homework.</paragraph><paragraph>Overall, this addition makes it easy to compare Adam and Lion in the same codebase and experiment with how a more modern optimizer performs, all while keeping changes minimal and easy to toggle.</paragraph><paragraph>Here are the zip files of the extended homework and solutions:</paragraph><file url=\"https://static.us.edusercontent.com/files/TZX8BfYOSpj7f18DBxcgMZ06\" filename=\"hw12_lion.zip\"/><file url=\"https://static.us.edusercontent.com/files/qmD5g9VAISDY4mDRyYv3DvwF\" filename=\"hw_12_lion_sols.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T12:21:19.006498+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428812,
            "author": "Peyton Schales",
            "project_title": "Special Participation A: ChatGPT 5 on HW07",
            "post_body": "For this assignment, I tested ChatGPT 5 on the non-coding theory questions. It consistently one-shotted every problem. However, its initial responses sometimes skipped important steps and  derivations. For example, in Q8b, it told me that minimizing the regularizer implies equal singular values without proof. When I asked this the AI was able to a write a formal derivation using the AM-GM inequality, proving it actually can understand the theory rather than just retrieving a memorized answer. I also attempted to input an incorrect answer into it about orthogonal initialization in RNNs guaranteeing non-vanishing gradients. I expected ChatGPT to just agree with me because it sometimes just agrees with the user. However, it caught the trap immediately, correctly distinguishing between linear stability and the decays. Overall, the interaction felt great. ChatGPT seemed to understand all the concepts very well.\n\n\n\nChatGPT Conversation: https://chatgpt.com/share/69361eec-6218-800f-aae8-0fbd3556bdc9\nAnnotations: https://drive.google.com/file/d/1l66xpKohPBDUn5VDNTxdPiAUVbj3usiZ/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I tested ChatGPT 5 on the non-coding theory questions. It consistently one-shotted every problem. However, its initial responses sometimes skipped important steps and  derivations. For example, in Q8b, it told me that minimizing the regularizer implies equal singular values without proof. When I asked this the AI was able to a write a formal derivation using the AM-GM inequality, proving it actually can understand the theory rather than just retrieving a memorized answer. I also attempted to input an incorrect answer into it about orthogonal initialization in RNNs guaranteeing non-vanishing gradients. I expected ChatGPT to just agree with me because it sometimes just agrees with the user. However, it caught the trap immediately, correctly distinguishing between linear stability and the decays. Overall, the interaction felt great. ChatGPT seemed to understand all the concepts very well.</paragraph><paragraph/><paragraph>ChatGPT Conversation: https://chatgpt.com/share/69361eec-6218-800f-aae8-0fbd3556bdc9<break/>Annotations: https://drive.google.com/file/d/1l66xpKohPBDUn5VDNTxdPiAUVbj3usiZ/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T12:13:16.39494+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428760,
            "author": "Diana Kohr",
            "project_title": "Special Participation E: Gemini 2.5 Flash for Project Coordination",
            "post_body": "I used Gemini 2.5 Flash to see how well it could coordinate among group members for the final project. We ran into a lot of issues in terms of how to split and run the computationally heavy code; an analysis of feasibility and a schedule for progress dependencies would have been nice. \n\nConversation: https://gemini.google.com/share/db18b2dd0a70\n\nAnnotated: https://drive.google.com/file/d/1nLEeUowcs1n5HS0BHMy1t2IXE7C4TAXN/view?usp=sharing\n\nPrompts: \n\nA lot of my prompts were quite project specific, so here's a general framework. \n\nLet Gemini warm up to your project idea by asking it about relevant literature and proposing your idea / question. \n\nAsk what datasets are appropriate to use for the project. Point Gemini in the direction of scale that you prefer. \n\nIntroduce more specific information about your setup in terms of what needs to be run. Share what you have available in terms of compute (how many devices, what runtime on Colab). Ask how you can efficiently split the workload. \n\nThis will produce a full plan that includes implementation (which is also helpful). Tell Gemini to focus on the most time-consuming parts and ask how everybody can run things in parallel. \n\nCool thing you can do at the end: ask, if given significantly more time, how would you expand the scope of the project? \n\nResults: \n\nPicked up on the gist of the project super quickly. \n\nRetrospectively, having almost finished the project, Gemini's predictions on how long things would take were pretty accurate. If I could redo the project, I would've gone with the suggested datasets, since we were a little over-ambitious. \n\nIt created a schedule that highlighted the key dependencies among parts, which were sticking points for us. \n\nFor some reason, it kept embedding random diagrams that had nothing to do with the project? Maybe this is a me problem. \n\nOverall, quite satisfied. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 2.5 Flash to see how well it could coordinate among group members for the final project. We ran into a lot of issues in terms of how to split and run the computationally heavy code; an analysis of feasibility and a schedule for progress dependencies would have been nice. </paragraph><paragraph>Conversation: https://gemini.google.com/share/db18b2dd0a70</paragraph><paragraph>Annotated: https://drive.google.com/file/d/1nLEeUowcs1n5HS0BHMy1t2IXE7C4TAXN/view?usp=sharing</paragraph><paragraph>Prompts: </paragraph><list style=\"bullet\"><list-item><paragraph>A lot of my prompts were quite project specific, so here's a general framework. </paragraph></list-item><list-item><paragraph>Let Gemini warm up to your project idea by asking it about relevant literature and proposing your idea / question. </paragraph></list-item><list-item><paragraph>Ask what datasets are appropriate to use for the project. Point Gemini in the direction of scale that you prefer. </paragraph></list-item><list-item><paragraph>Introduce more specific information about your setup in terms of what needs to be run. Share what you have available in terms of compute (how many devices, what runtime on Colab). Ask how you can efficiently split the workload. </paragraph></list-item><list-item><paragraph>This will produce a full plan that includes implementation (which is also helpful). Tell Gemini to focus on the most time-consuming parts and ask how everybody can run things in parallel. </paragraph></list-item><list-item><paragraph>Cool thing you can do at the end: ask, if given significantly more time, how would you expand the scope of the project? </paragraph></list-item></list><paragraph>Results: </paragraph><list style=\"bullet\"><list-item><paragraph>Picked up on the gist of the project super quickly. </paragraph></list-item><list-item><paragraph>Retrospectively, having almost finished the project, Gemini's predictions on how long things would take were pretty accurate. If I could redo the project, I would've gone with the suggested datasets, since we were a little over-ambitious. </paragraph></list-item><list-item><paragraph>It created a schedule that highlighted the key dependencies among parts, which were sticking points for us. </paragraph></list-item><list-item><paragraph>For some reason, it kept embedding random diagrams that had nothing to do with the project? Maybe this is a me problem. </paragraph></list-item><list-item><paragraph>Overall, quite satisfied. </paragraph></list-item></list><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T12:05:30.230666+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428749,
            "author": "Tiger Zhang",
            "project_title": "Special Participation A: Gemini 3.0 Pro (Thinking) on HW4",
            "post_body": "Executive summary:\n\nFollowing the release of Gemini 3.0 Pro, I wanted to use it to solve HW4 and see if there is a significant improvement from when Jason Guo used Gemini 2.5 Pro to solve it.\n\nI split the homework pdf into a few pdfs, one with each problem, and gave those to Gemini sequentially.\n\nResults:\n\nThere is a noticeable improvement in Gemini's performance on HW4. In particular, Gemini 3.0 Pro almost one-shotted all the problems, even more than did Gemini 2.5 Pro. It did make one reading mistake for two matrices (and so did Gemini 2.5 Pro), but it made less reading mistakes, and was able to quickly fix its mistake when prompted again.\n\nOutside of that, Gemini only made a couple of very small and understandable mistakes. Even its calculations were fully correct. I have no significant complaints about how Gemini did for any problem.\n\nAnnotated log:",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive summary</bold>:</paragraph><paragraph>Following the release of Gemini 3.0 Pro, I wanted to use it to solve HW4 and see if there is a significant improvement from when Jason Guo used Gemini 2.5 Pro to solve it.</paragraph><paragraph>I split the homework pdf into a few pdfs, one with each problem, and gave those to Gemini sequentially.</paragraph><paragraph>Results:</paragraph><paragraph>There is a noticeable improvement in Gemini's performance on HW4. In particular, Gemini 3.0 Pro almost one-shotted all the problems, even more than did Gemini 2.5 Pro. It did make one reading mistake for two matrices (and so did Gemini 2.5 Pro), but it made less reading mistakes, and was able to quickly fix its mistake when prompted again.</paragraph><paragraph>Outside of that, Gemini only made a couple of very small and understandable mistakes. Even its calculations were fully correct. I have no significant complaints about how Gemini did for any problem.</paragraph><paragraph>Annotated log:</paragraph><file url=\"https://static.us.edusercontent.com/files/tCj5VDWfqvYD9j1RidqjdVUJ\" filename=\"chat_log.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T12:03:49.819786+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428691,
            "author": "Zach Pricz",
            "project_title": "Special Participation E: Deepseek as a Socratic Tutor on DDPM",
            "post_body": "Annotated Trace: \n\nConversation: https://chat.deepseek.com/share/3720l4kn5g9dtco2c1\n\nI found the DDPM/DDIM lecture mathematically intimidating. For my special participation I thought it would be useful to utilize Deepseek to help me understand the ins and outs of the DDPM algorithm derivation from lecture.\n\nTo do this, I asked Deepseek to act as a \"socratic tutor\" and ask ME questions regarding the notes from class. I gave it clear rules to follow and prvent giving me too many solutions and answers right off the bat. This allowed for a thorough exercise with active participation from my part. \n\nThe Good:\n\nDeepseek did a great job overall and it helped me gain a lot more confidence in the subject matter and probability as a whole. I was especially impressed with its ability to create on the fly questions after I miss a certain concept or neglect a certain piece of the proof. I also felt it bridged the reverse and forward process of diffusion models very well with conceptual questions throughout allowing me to see a bigger picture. I felt challenged still, but never discouraged by its questioning. Not only this but deepseek did all this while being able to read and interpret (with moderate success) my handwritten math along the way. \n\nThe Bad:\n\nOccasionally Deepseek would neglect certain concepts I thought it would cover more. This could be fixed with prompting but I wish it noticed the highlighted \"pink\" sections in the professor's notes talking about dropping terms and normalization. Some sub questions on this would be nice to allow me to feel more confident in these steps. I also felt that Deepseek should have continued my session into a leading question with DDIM but once again I could have asked for this in the prompt.\n\nOverall I think Deepseek is an excellent tool for reinforcing understanding of difficult math concepts in lectures. It is great for asking how to do something but its even better for quizzing and tutoring a student who needs active practice in their study routine (like me)!",
            "content_xml": "<document version=\"2.0\"><paragraph>Annotated Trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/3somhTG4Hvj0hHIEQq3dqnwy\" filename=\"DDPM DeepSeek Annotated Trace.pdf\"/><paragraph>Conversation: <link href=\"https://chat.deepseek.com/share/3720l4kn5g9dtco2c1\">https://chat.deepseek.com/share/3720l4kn5g9dtco2c1</link></paragraph><paragraph>I found the DDPM/DDIM lecture mathematically intimidating. For my special participation I thought it would be useful to utilize Deepseek to help me understand the ins and outs of the DDPM algorithm derivation from lecture.</paragraph><paragraph>To do this, I asked Deepseek to act as a \"socratic tutor\" and ask ME questions regarding the notes from class. I gave it clear rules to follow and prvent giving me too many solutions and answers right off the bat. This allowed for a thorough exercise with active participation from my part. </paragraph><paragraph>The Good:</paragraph><paragraph>Deepseek did a great job overall and it helped me gain a lot more confidence in the subject matter and probability as a whole. I was especially impressed with its ability to create on the fly questions after I miss a certain concept or neglect a certain piece of the proof. I also felt it bridged the reverse and forward process of diffusion models very well with conceptual questions throughout allowing me to see a bigger picture. I felt challenged still, but never discouraged by its questioning. Not only this but deepseek did all this while being able to read and interpret (with moderate success) my handwritten math along the way. </paragraph><paragraph>The Bad:</paragraph><paragraph>Occasionally Deepseek would neglect certain concepts I thought it would cover more. This could be fixed with prompting but I wish it noticed the highlighted \"pink\" sections in the professor's notes talking about dropping terms and normalization. Some sub questions on this would be nice to allow me to feel more confident in these steps. I also felt that Deepseek should have continued my session into a leading question with DDIM but once again I could have asked for this in the prompt.</paragraph><paragraph>Overall I think Deepseek is an excellent tool for reinforcing understanding of difficult math concepts in lectures. It is great for asking how to do something but its even better for quizzing and tutoring a student who needs active practice in their study routine (like me)!</paragraph></document>",
            "links": [
                "https://chat.deepseek.com/share/3720l4kn5g9dtco2c1"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:54:23.561996+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428663,
            "author": "Garv Goswami",
            "project_title": "Special Participation E - Understanding RoPe Visually with help From Claude and 3Blue1Brown",
            "post_body": "Conversation Link: https://claude.ai/share/da72b7bb-e46b-40b4-ab0c-32b4e5286e30\n\nConfused by RoPe, I used Claude Sonnet 4.5 to create the necessary facilities to genrate a 3Blue1Brown style Manim video with both Visual and Auditory capabilities.: \n\nWhy rotation? \n\nHow does rotation create relative position?\n\nWhat does chunking mean visually?\n\nWhy different frequencies?\n\nand also examples of the concepts. \n\nClaude was able to focus on: \n\n1. Complete Animation System (Manim)\n\n10 animated scenes covering all RoPE concepts (4:10 total runtime)\n\nProfessional visualizations: rotations, matrices, algorithms, properties\n\nFixed to work without LaTeX (removed all MathTex dependencies)\n\n2. Narration System\n\nTime-coded scripts for all 9 main scenes\n\n3 TTS integration options (Google TTS, ElevenLabs, pyttsx3)\n\nScripts perfectly timed to match a video\n\n3. Documentation\n\nSetup guides, quickstart, narration workflow\n\nComplete timeline with scene-by-scene breakdown\n\nVideo syncing instructions\n\nHere is the zip file of all included files that Claude was able to generate as well as the completed video and audio files for anyone to view and hear. The actual scripts are able to generate more granularly, but I included the bare minimum for file size consideration. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Conversation Link: <link href=\"https://claude.ai/share/da72b7bb-e46b-40b4-ab0c-32b4e5286e30\">https://claude.ai/share/da72b7bb-e46b-40b4-ab0c-32b4e5286e30</link></paragraph><paragraph>Confused by RoPe, I used Claude Sonnet 4.5 to create the necessary facilities to genrate a 3Blue1Brown style Manim video with both Visual and Auditory capabilities.: </paragraph><list style=\"unordered\"><list-item><paragraph><bold>Why rotation?</bold> </paragraph></list-item><list-item><paragraph><bold>How does rotation create relative position?</bold></paragraph></list-item><list-item><paragraph><bold>What does chunking mean visually?</bold></paragraph></list-item><list-item><paragraph><bold>Why different frequencies?</bold></paragraph></list-item></list><paragraph>and also examples of the concepts. </paragraph><paragraph>Claude was able to focus on: </paragraph><paragraph><bold>1. Complete Animation System (Manim)</bold></paragraph><list style=\"unordered\"><list-item><paragraph>10 animated scenes covering all RoPE concepts (4:10 total runtime)</paragraph></list-item><list-item><paragraph>Professional visualizations: rotations, matrices, algorithms, properties</paragraph></list-item><list-item><paragraph>Fixed to work <bold>without LaTeX</bold> (removed all MathTex dependencies)</paragraph></list-item></list><paragraph><bold>2. Narration System</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Time-coded scripts for all 9 main scenes</paragraph></list-item><list-item><paragraph>3 TTS integration options (Google TTS, ElevenLabs, pyttsx3)</paragraph></list-item><list-item><paragraph>Scripts perfectly timed to match a video</paragraph></list-item></list><paragraph><bold>3. Documentation</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Setup guides, quickstart, narration workflow</paragraph></list-item><list-item><paragraph>Complete timeline with scene-by-scene breakdown</paragraph></list-item><list-item><paragraph>Video syncing instructions</paragraph></list-item></list><paragraph>Here is the zip file of all included files that Claude was able to generate as well as the completed video and audio files for anyone to view and hear. The actual scripts are able to generate more granularly, but I included the bare minimum for file size consideration. </paragraph><file url=\"https://static.us.edusercontent.com/files/pjy9ikgqvzn1SLpkG2wKVziS\" filename=\"claude_rope_explanation 2.zip\"/><paragraph/></document>",
            "links": [
                "https://claude.ai/share/da72b7bb-e46b-40b4-ab0c-32b4e5286e30"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:51:08.347121+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428660,
            "author": "Rohan Gulati",
            "project_title": "Special Participation E: Optimizer Formula Tool",
            "post_body": "Here, I wanted to understand optimizers further and looked into building a tool that can help with developing a deeper understanding of different optimizer formulas by comparing their parameters and their purpose over many iterations. \n\nThe goal of this tool was to create a conversational model that would provide a set of formulas used by a particular optimizer and quiz the user on what each parameter or term represents, which optimizer it belongs to, or how it worked. Additionally, after a student provided a response, the model would have to guide the user towards the correct answer rather than providing the correct answer afterwards. While that was the initial goal, the model was able to delve deeper into the task and build follow-up questions that reaffirmed understanding even when seeing correct answers. One behavior I found was that the model would reiterate responses and reflect on what parts were correct or required correction. Once, the model appeared to hallucinate from a double-negative in the prompt, but later shared understanding of the intended meaning. I thought it was particularly helpful at generating scenarios to reason about, such as the behavior of different functions that can be used compute the gradient magnitude in momentum.\n\nChat History: https://chatgpt.com/share/69360546-3510-8012-90ae-a34d21fad966 \n\nAnnotated Conversation: https://docs.google.com/document/d/1vB9L85HXcFHdDDUfWCok-MmY3UjAPhfi7S8M1h8qoLs/edit?tab=t.0 ",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I wanted to understand optimizers further and looked into building a tool that can help with developing a deeper understanding of different optimizer formulas by comparing their parameters and their purpose over many iterations. </paragraph><paragraph>The goal of this tool was to create a conversational model that would provide a set of formulas used by a particular optimizer and quiz the user on what each parameter or term represents, which optimizer it belongs to, or how it worked. Additionally, after a student provided a response, the model would have to guide the user towards the correct answer rather than providing the correct answer afterwards. While that was the initial goal, the model was able to delve deeper into the task and build follow-up questions that reaffirmed understanding even when seeing correct answers. One behavior I found was that the model would reiterate responses and reflect on what parts were correct or required correction. Once, the model appeared to hallucinate from a double-negative in the prompt, but later shared understanding of the intended meaning. I thought it was particularly helpful at generating scenarios to reason about, such as the behavior of different functions that can be used compute the gradient magnitude in momentum.</paragraph><paragraph>Chat History: <link href=\"https://chatgpt.com/share/69360546-3510-8012-90ae-a34d21fad966\">https://chatgpt.com/share/69360546-3510-8012-90ae-a34d21fad966</link> </paragraph><paragraph>Annotated Conversation: <link href=\"https://docs.google.com/document/d/1vB9L85HXcFHdDDUfWCok-MmY3UjAPhfi7S8M1h8qoLs/edit?tab=t.0\">https://docs.google.com/document/d/1vB9L85HXcFHdDDUfWCok-MmY3UjAPhfi7S8M1h8qoLs/edit?tab=t.0</link> </paragraph></document>",
            "links": [
                "https://chatgpt.com/share/69360546-3510-8012-90ae-a34d21fad966",
                "https://docs.google.com/document/d/1vB9L85HXcFHdDDUfWCok-MmY3UjAPhfi7S8M1h8qoLs/edit?tab=t.0"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:50:58.056575+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428618,
            "author": "Kevin Tseng",
            "project_title": "Special Participation B: GPT-5 (thinking) on HW2 Coding",
            "post_body": "Executive Summary: In this assignment, I used GPT-5 with thinking to assist with the coding portion of Homework 2 by employing various strategies to provide the model with full context (markdown, code skeletons, and images). For most coding tasks, the model produced correct solutions immediately, but there were some mistakes. When it made mistakes, it corrected them once I provided additional context or error messages. For the written portion of the coding homework, I did not notice any issues. For visualization problems, I prompted GPT-5 with images of notebook outputs or slider settings. It consistently gave accurate interpretations tied directly to features visible in the images. Across the assignment, its errors were minor and easily fixed.",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive Summary: In this assignment, I used GPT-5 with thinking to assist with the coding portion of Homework 2 by employing various strategies to provide the model with full context (markdown, code skeletons, and images). For most coding tasks, the model produced correct solutions immediately, but there were some mistakes. When it made mistakes, it corrected them once I provided additional context or error messages. For the written portion of the coding homework, I did not notice any issues. For visualization problems, I prompted GPT-5 with images of notebook outputs or slider settings. It consistently gave accurate interpretations tied directly to features visible in the images. Across the assignment, its errors were minor and easily fixed.</paragraph><file url=\"https://static.us.edusercontent.com/files/XQQkliNyaV7RIqnYwK8FskYt\" filename=\"Special Participation B_ Homework 2 with GPT-5.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T11:43:56.912846+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428589,
            "author": "Devan Perkash",
            "project_title": "Special Participation E: Muon Intuition Tutor",
            "post_body": "I used ChatGPT (GPT 5.1) as a \u201cMuon Intuition Tutor\u201d for Lecture 7 (Muon optimizer) to provide a chatbot tutor that can explain the optimizer from various facets of understanding.\n\nExecutive Summary:\n\nAs part of my learning process, I turned ChatGPT into an AI learning tool aimed at building intuition for Muon from multiple angles. I tend to learn best when I internalize a concept in multiple ways, and I wanted to make a tool that could provide similar value. I wrote a long initial prompt that forced the model into a fixed three-layer structure for every answer:\n\nIntuitive explanation - (high-level story, no formulas)\n\nGeometry / structural explanation - (what the matrix is doing to space)\n\nMathematical explanation - (SVD, constraints, and Newton\u2013Schulz details)\n\nThis structure worked surprisingly well. ChatGPT consistently gave clear high-level and geometric explanations of why Muon cares about the \u201cshape\u201d of the gradient, what UV^T represents, and how semi-orthogonal updates differ conceptually from Adam- or SGD-style steps. These layers matched the way Lecture 7 motivated Muon and were genuinely helpful for my own understanding.\n\nOn the math side, the model correctly walked through the constrained optimization view (maximize alignment under a norm constraint) and connected it to the SVD solution. It also produced a reasonably structured explanation of the Newton\u2013Schulz iteration and even attempted a small numeric example.\n\nHowever, the experiment also showed some important weaknesses:\n\nIt conflated different uses of Newton\u2013Schulz (inverse square root vs. orthogonalization) and did not always clearly state that Muon is only approximating UV^T.\n\nIt tended to understate the importance of normalization before applying the polynomial, even though Lecture 7 emphasizes scaling singular values into (0,1) for convergence.\n\nIn the optimizer comparison section, it slightly over-sold Muon as universally better than Adam/Shampoo in \u201cbad conditioning\u201d settings without fully discussing trade-offs.\n\nIn the 2\u00d72 numeric example, the conceptual steps were correct, but the detailed arithmetic is not something I would trust blindly for this type of usage (LLMs are error-prone there).\n\nOverall, the three-layer prompting strategy made the model\u2019s strengths and weaknesses very visible: it is an effective conceptual tutor for Muon and a decent first pass at the math, but it still needs human oversight for subtle assumptions (normalization, convergence conditions, and when Muon is actually the right tool).\n\nYou can access the chat here:\n\nhttps://chatgpt.com/share/69361414-1a90-800e-8b28-6db3a50a52cd\n\nAnd you can read the full annotated trace here:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT (GPT 5.1) as a \u201cMuon Intuition Tutor\u201d for Lecture 7 (Muon optimizer) to provide a chatbot tutor that can explain the optimizer from various facets of understanding.</paragraph><paragraph><bold>Executive Summary</bold>:</paragraph><paragraph>As part of my learning process, I turned ChatGPT into an AI learning tool aimed at building intuition for Muon from multiple angles. I tend to learn best when I internalize a concept in multiple ways, and I wanted to make a tool that could provide similar value. I wrote a long initial prompt that forced the model into a fixed three-layer structure for every answer:</paragraph><list style=\"ordered\"><list-item><paragraph>Intuitive explanation - (high-level story, no formulas)</paragraph></list-item><list-item><paragraph>Geometry / structural explanation - (what the matrix is doing to space)</paragraph></list-item><list-item><paragraph>Mathematical explanation - (SVD, constraints, and Newton\u2013Schulz details)</paragraph></list-item></list><paragraph>This structure worked surprisingly well. ChatGPT consistently gave clear high-level and geometric explanations of why Muon cares about the \u201cshape\u201d of the gradient, what UV^T represents, and how semi-orthogonal updates differ conceptually from Adam- or SGD-style steps. These layers matched the way Lecture 7 motivated Muon and were genuinely helpful for my own understanding.</paragraph><paragraph>On the math side, the model correctly walked through the constrained optimization view (maximize alignment under a norm constraint) and connected it to the SVD solution. It also produced a reasonably structured explanation of the Newton\u2013Schulz iteration and even attempted a small numeric example.</paragraph><paragraph>However, the experiment also showed some important weaknesses:</paragraph><list style=\"unordered\"><list-item><paragraph>It conflated different uses of Newton\u2013Schulz (inverse square root vs. orthogonalization) and did not always clearly state that Muon is only approximating UV^T.</paragraph></list-item><list-item><paragraph>It tended to understate the importance of normalization before applying the polynomial, even though Lecture 7 emphasizes scaling singular values into (0,1) for convergence.</paragraph></list-item><list-item><paragraph>In the optimizer comparison section, it slightly over-sold Muon as universally better than Adam/Shampoo in \u201cbad conditioning\u201d settings without fully discussing trade-offs.</paragraph></list-item><list-item><paragraph>In the 2\u00d72 numeric example, the conceptual steps were correct, but the detailed arithmetic is not something I would trust blindly for this type of usage (LLMs are error-prone there).</paragraph></list-item></list><paragraph>Overall, the three-layer prompting strategy made the model\u2019s strengths and weaknesses very visible: it is an effective conceptual tutor for Muon and a decent first pass at the math, but it still needs human oversight for subtle assumptions (normalization, convergence conditions, and when Muon is actually the right tool).</paragraph><paragraph>You can access the chat here:</paragraph><paragraph><link href=\"https://chatgpt.com/share/69361414-1a90-800e-8b28-6db3a50a52cd\">https://chatgpt.com/share/69361414-1a90-800e-8b28-6db3a50a52cd</link></paragraph><paragraph>And you can read the full annotated trace here:</paragraph><file url=\"https://static.us.edusercontent.com/files/YhcfcNNuWkfddCK52FPh6jH8\" filename=\"participation_e.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/69361414-1a90-800e-8b28-6db3a50a52cd"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:40:32.322372+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428581,
            "author": "Garv Goswami",
            "project_title": "Special Participation A: Gemini Pro on HW1 (Non-coding)",
            "post_body": "I used Gemini 3 Pro to answer HW 1 written problems.\n\nConversation: https://gemini.google.com/share/f3019ef7b48e\n\nAnnotated: \n\n\nSummary: Gemini Pro initially had issues when asked to complete the entire homework when given a pdf file of the questions. Upon more granular tasks asking, it appeared to improve. However, the real breakthrough came when I started copying and pasting problem text into gemini directly, rather than asking it to reference the Homework PDF! After this, it started to answer questions fully correctly without any further guidance.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 3 Pro to answer HW 1 written problems.</paragraph><paragraph>Conversation:<link href=\"https://gemini.google.com/share/11b5f1b89778\"> </link>https://gemini.google.com/share/f3019ef7b48e</paragraph><paragraph>Annotated:<link href=\"https://drive.google.com/file/d/1vGRWvLGliMGdQhvNDdYq0SKYC575tPdd/view?usp=sharing\"> </link><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/Jn8goqNtllCzjRDcyBpnewXa\" filename=\"Gemini_Pro_HW1_noncoding_annotated.pdf\"/><paragraph>Summary: Gemini Pro initially had issues when asked to complete the entire homework when given a pdf file of the questions. Upon more granular tasks asking, it appeared to improve. However, <bold>the real breakthrough came when I started copying and pasting problem text into gemini directly, rather than asking it to reference the Homework PDF</bold>! After this, it started to answer questions fully correctly without any further guidance.</paragraph></document>",
            "links": [
                "https://gemini.google.com/share/11b5f1b89778",
                "https://drive.google.com/file/d/1vGRWvLGliMGdQhvNDdYq0SKYC575tPdd/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:39:43.521087+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428575,
            "author": "WeiYi Zhang",
            "project_title": "Special Participation E: Using NotebookLM to Infer Learning Priorities and Generate Assessment-Style Questions from Homework Assignments",
            "post_body": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.\n\nI uploaded all the homework assignments into NotebookLM to see if it could infer what\u2019s likely important and generate exam-style practice questions, and whether those questions were meaningfully different from just redoing homework.\n\nThe goal wasn\u2019t to predict the exam, but to see whether AI could actually support final exam preparation realistically\u2014and where it still needs human judgment.",
            "content_xml": "<document version=\"2.0\"><paragraph>As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.</paragraph><paragraph>I uploaded all the homework assignments into NotebookLM to see if it could infer what\u2019s likely important and generate exam-style practice questions, and whether those questions were meaningfully different from just redoing homework.</paragraph><paragraph>The goal wasn\u2019t to predict the exam, but to see whether AI could actually support final exam preparation realistically\u2014and where it still needs human judgment.</paragraph><file url=\"https://static.us.edusercontent.com/files/q0L7irpAuKXpSgZtM7L725Tj\" filename=\"Using NotebookLM to Infer Learning Priorities and Generate Assessment-Style Questions from Homework Assignments.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T11:39:07.12456+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428572,
            "author": "Hiya Shah",
            "project_title": "Special Participation E: Study Guide for Fermi Estimation (HW11) with Chatgpt 5.1 Study Mode",
            "post_body": "I utilized ChatGPT 5.1 Study Mode to understand the prereading-equivalent context behind Fermi Estimation and GPU power and memory, which was something I was relatively unfamiliar with before attempting these problems. While these problems were a great introduction to the more HW-based concepts and self-contained, I had some follow up questions about the context that was provided, especially in the figures. I also prompted GPT to understand various parts of the figures, and I was surprised by how well it was able to analyze the figures (compared to some other models I tested hw 11 with such as Llama 4 Maverick). I also asked GPT for some course recommendations if I am interested in hardware architectures and model architecture scaling, and I was pleasantly surprised that it used context from my previous interactions to create a semester by semester course plan for me. I really enjoyed how Study Mode did not just give me the answer, but rather asked me follow up questions similar to how an in-person teacher would (interactive learning/active recall). This was my first time playing around with Study mode, and I will definitely be using it during RRR week to study course context and make sure I understand it (vs passively reading over AI solutions). I hope this study tool on Fermi Estimation is helpful to others, and I have provided my annotated traces / unannotated trace below.\n\ntrace: https://chatgpt.com/share/693618eb-456c-8005-9a98-6de49720855c\n\nannotated trace: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I utilized ChatGPT 5.1 Study Mode to understand the prereading-equivalent context behind Fermi Estimation and GPU power and memory, which was something I was relatively unfamiliar with before attempting these problems. While these problems were a great introduction to the more HW-based concepts and self-contained, I had some follow up questions about the context that was provided, especially in the figures. I also prompted GPT to understand various parts of the figures, and I was surprised by how well it was able to analyze the figures (compared to some other models I tested hw 11 with such as Llama 4 Maverick). I also asked GPT for some course recommendations if I am interested in hardware architectures and model architecture scaling, and I was pleasantly surprised that it used context from my previous interactions to create a semester by semester course plan for me. I really enjoyed how Study Mode did not just give me the answer, but rather asked me follow up questions similar to how an in-person teacher would (interactive learning/active recall). This was my first time playing around with Study mode, and I will definitely be using it during RRR week to study course context and make sure I understand it (vs passively reading over AI solutions). I hope this study tool on Fermi Estimation is helpful to others, and I have provided my annotated traces / unannotated trace below.</paragraph><paragraph><italic>trace: <link href=\"https://chatgpt.com/share/693618eb-456c-8005-9a98-6de49720855c\">https://chatgpt.com/share/693618eb-456c-8005-9a98-6de49720855c</link></italic></paragraph><paragraph><italic>annotated trace:</italic> </paragraph><file url=\"https://static.us.edusercontent.com/files/mEqjDwWzxHd2JcFo4urlTTJN\" filename=\"special_partic_E_fermi_estimation_gpt_5.1_hw11 2.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/693618eb-456c-8005-9a98-6de49720855c"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:38:53.790615+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428520,
            "author": "WeiYi Zhang",
            "project_title": "Special Participation E: From Handwritten Notes to Exam-Oriented Review (Gemini)",
            "post_body": "As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.\nI have developed an AI-assisted process that can convert my handwritten class notes into structured learning guides. The key lies in whether this model can distinguish between core concepts and the content I emphasize in the notes but which is not crucial for overall understanding. Also, I tried to use prompts to effectively guide the model to maintain symbol consistency when reading screenshots of mathematical formulas (especially when reading handwritten notes).",
            "content_xml": "<document version=\"2.0\"><paragraph>As a student preparing for the final exam, I wanted to explore whether AI tools could genuinely help with review and consolidation.<break/>I have developed an AI-assisted process that can convert my handwritten class notes into structured learning guides. The key lies in whether this model can distinguish between core concepts and the content I emphasize in the notes but which is not crucial for overall understanding. Also, I tried to use prompts to effectively guide the model to maintain symbol consistency when reading screenshots of mathematical formulas (especially when reading handwritten notes).</paragraph><file url=\"https://static.us.edusercontent.com/files/lGTe0Fk2DCO56gdsWOXovewh\" filename=\"From Handwritten Notes to Exam-Oriented Review (Gemini).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T11:33:02.326153+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428423,
            "author": "Rohan Gulati",
            "project_title": "Special Participation E: Verifying Written Answers in Colab",
            "post_body": "Here, I created a tool that could assist with verifying written answers on homeworks or discussion by generating code on Colab that can simulate the behavior of a question, so in cases where a question involves generating a kernel or operations that result in exploding or vanishing gradients, this process can be visualized and tinkered with at the same time. \n\nI used ChatGPT and went through multiple iterations of this idea, encountering the following bugs. If not specified, the model would output code with the solution embedded explicitly in the code or in the conversation output. For example, when a problem asked to determine the kernel that correctly mapped an input and output, the code would store the correct kernel and test if the student answer was equal. Instead, while this can be be tuned further for generalizability, the model is instructed to not reveal the correct answer and evaluate the student response through operations or generated code, which currently behaves decently well. A big premise of the tool is to help with visualization and understanding rather than solving the problem, so the model is also instructed to guide the user towards arriving at the correct solution rather than stating the correct answer. However, for one example, the model mentioned part of a solution to part A of a question while producing the code to visualize part B.\n\nOverall, the tool proved to be helpful at the intended tasks and could be used to draw a line between written problems and patterns observed in implementation, a helpful method to reaffirm understanding after or while completing a problem.  \n\nConversation Log: https://chatgpt.com/share/6934d754-8630-8012-948a-e0b61ca5fce7 \n\nAnnotation with Code output & Colab Example: https://docs.google.com/document/d/1x_UR_ZI1of6Qw-OLIawqJkEo_R4tqdCLGepDpDhaod4/edit?tab=t.0 ",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I created a tool that could assist with verifying written answers on homeworks or discussion by generating code on Colab that can simulate the behavior of a question, so in cases where a question involves generating a kernel or operations that result in exploding or vanishing gradients, this process can be visualized and tinkered with at the same time. </paragraph><paragraph>I used ChatGPT and went through multiple iterations of this idea, encountering the following bugs. If not specified, the model would output code with the solution embedded explicitly in the code or in the conversation output. For example, when a problem asked to determine the kernel that correctly mapped an input and output, the code would store the correct kernel and test if the student answer was equal. Instead, while this can be be tuned further for generalizability, the model is instructed to not reveal the correct answer and evaluate the student response through operations or generated code, which currently behaves decently well. A big premise of the tool is to help with visualization and understanding rather than solving the problem, so the model is also instructed to guide the user towards arriving at the correct solution rather than stating the correct answer. However, for one example, the model mentioned part of a solution to part A of a question while producing the code to visualize part B.</paragraph><paragraph>Overall, the tool proved to be helpful at the intended tasks and could be used to draw a line between written problems and patterns observed in implementation, a helpful method to reaffirm understanding after or while completing a problem.  </paragraph><paragraph>Conversation Log: <link href=\"https://chatgpt.com/share/6934d754-8630-8012-948a-e0b61ca5fce7\">https://chatgpt.com/share/6934d754-8630-8012-948a-e0b61ca5fce7</link> </paragraph><paragraph>Annotation with Code output &amp; Colab Example: <link href=\"https://docs.google.com/document/d/1x_UR_ZI1of6Qw-OLIawqJkEo_R4tqdCLGepDpDhaod4/edit?tab=t.0\">https://docs.google.com/document/d/1x_UR_ZI1of6Qw-OLIawqJkEo_R4tqdCLGepDpDhaod4/edit?tab=t.0</link> </paragraph></document>",
            "links": [
                "https://chatgpt.com/share/6934d754-8630-8012-948a-e0b61ca5fce7",
                "https://docs.google.com/document/d/1x_UR_ZI1of6Qw-OLIawqJkEo_R4tqdCLGepDpDhaod4/edit?tab=t.0"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:19:28.132573+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428374,
            "author": "Jacqueline Thibault",
            "project_title": "Special Participation A: ChatGPT-5.1 Thinking on Homework 1",
            "post_body": "I engaged `ChatGPT-5.1: Thinking` on Homework 1's non-coding parts. \n\nExecutive summary:\n\nThe LLM was able to one-shot all of the questions. I was thoroughly impressed by this, though it makes sense given the speed at which LLMs are developing and the introductory nature of the concepts in HW1 in the field of deep learning. Some notable interactions I saw were: \n\n1) the LLM \"pretended\" it could see the notebooks linked in question 2k, 3h, and 3i. It gave me some generic answers, showing it was inferring what could be in the notebook based on the setup of the question, but upon further probing it admitted to me that it cannot see its contents. I thought this was slightly concerning, because I can imagine it would be a problem in a higher-stakes context if it makes up data as though it is analyzing real data. \n\n2) Sometimes, the LLM would infer a follow up question and provide an answer to that, in addition to the homework answer. For example, in question 5a, it started providing some insight into noisy data though this question wasn't asked yet.\n\n3) When I first submitted the pdf, my prompt was \"Attached is a homework problem set from a deep learning class. Can you carefully solve each question for me?\" and the LLM responded \"I'm glad you shared the problem set, but I can't directly solve every question for you or give a complete set of worked solutions, since this is a real course homework and that would cross cross academic-integrity lines\". I thought this was really interesting; perhaps the LLMs are heading towards helping people solve their own problems rather than providing immediate answers, which if used incorrectly, can be harmful for students. However, upon starting a new chat, the LLM did not repeat this answer and then one-shotted all the questions.\n\nHere is a breakdown of my interactions with each question:\n\nQuestion 1: Added some additional logic referring to the homogeneous error dynamic. This was helpful for me as a student. The forms it decided to write the answers in were sometimes overly rewritten/simplified to a point that didn't provide any additional simplicity or information, but the answers were still correct. Sometimes took a more high-level approach than the question was aiming for, but this was still very helpful in gaining an understanding of the problem. In question 1e, it added an additional step about optimal worst-case contraction factor.\n\nQuestion 2: Stated the positivity fact of the rank in question 2b, without much justification. However, it used the min-norm justification to skip some intermediate calculation steps, which I thought was quite elegant. Question 2c also was missing some logic that made it difficult for me to follow along. Upon further prompting, it gave a satisfying answer about its reasoning. Also for 2h it gave a different solution than the course homework solutions; however, I believe the LLM solution to be correct and the course solution might have a type; the question setup already contains the eta term so adding another one in c1 isn't correct. In question 2i, it leveraged spectral norm bounds in its justification which I thought was quite interesting. As stated earlier, it imagined an answer to the notebook question in 2k which was odd.\n\nQuestion 3: I thought the way the LLM presented these answers were especially intuitive; it identified reused expressions and defined intermediate variables to increase readability. (e.g. in question 3c it defined the intermediate variable T). However, the bound it stated for question 3e wasn't as tight as it should have been. in 3f the takeaway of the question wasn't immediately clear to me, though the computations were correct. This could indicate LLMs have a tendency to attempt computations over underlying understanding. I was quite impressed by its handling of 3g, due to the length of the computation and the precision with which it answered it. Similar to question 2, it also imagined the notebook contents in questions 3h and 3i.\n\nQuestion 4: The LLM went a step further and gave the equation for the typical adam update, which it didn't have to.\n\nQuestion 5: LLM also looked ahead and prematurely provided insight into noisy data. The rest of the subparts were quite straightforward though.\n\nQuestion 6: The LLM was able to provide precise answers despite quite a few matrices involved in the solution. I was impressed by this.\n\nQuestion 7: Skipped some steps but they were trivial. Identities were correct!\n\nlink to conversation: https://chatgpt.com/share/6935d518-4ebc-800f-88c0-bbe553d8c0ef\n\nAnnotated log: \n\nnote: sometimes the last line of a page is duplicated on the next page; this is because I was having trouble exporting the conversation as one contiguous pdf. However, all the information is there.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I engaged `ChatGPT-5.1: Thinking` on Homework 1's non-coding parts. </paragraph><paragraph><bold>Executive summary:</bold></paragraph><paragraph>The LLM was able to one-shot all of the questions. I was thoroughly impressed by this, though it makes sense given the speed at which LLMs are developing and the introductory nature of the concepts in HW1 in the field of deep learning. Some notable interactions I saw were: </paragraph><paragraph>1) the LLM \"pretended\" it could see the notebooks linked in question 2k, 3h, and 3i. It gave me some generic answers, showing it was inferring what could be in the notebook based on the setup of the question, but upon further probing it admitted to me that it cannot see its contents. I thought this was slightly concerning, because I can imagine it would be a problem in a higher-stakes context if it makes up data as though it is analyzing real data. </paragraph><paragraph>2) Sometimes, the LLM would infer a follow up question and provide an answer to that, in addition to the homework answer. For example, in question 5a, it started providing some insight into noisy data though this question wasn't asked yet.</paragraph><paragraph>3) When I first submitted the pdf, my prompt was \"Attached is a homework problem set from a deep learning class. Can you carefully solve each question for me?\" and the LLM responded \"I'm glad you shared the problem set, but I can't directly solve every question for you or give a complete set of worked solutions, since this is a real course homework and that would cross cross academic-integrity lines\". I thought this was really interesting; perhaps the LLMs are heading towards helping people solve their own problems rather than providing immediate answers, which if used incorrectly, can be harmful for students. However, upon starting a new chat, the LLM did not repeat this answer and then one-shotted all the questions.</paragraph><paragraph>Here is a breakdown of my interactions with each question:</paragraph><paragraph><bold>Question 1:</bold> Added some additional logic referring to the homogeneous error dynamic. This was helpful for me as a student. The forms it decided to write the answers in were sometimes overly rewritten/simplified to a point that didn't provide any additional simplicity or information, but the answers were still correct. Sometimes took a more high-level approach than the question was aiming for, but this was still very helpful in gaining an understanding of the problem. In question 1e, it added an additional step about optimal worst-case contraction factor.</paragraph><paragraph><bold>Question 2:</bold> Stated the positivity fact of the rank in question 2b, without much justification. However, it used the min-norm justification to skip some intermediate calculation steps, which I thought was quite elegant. Question 2c also was missing some logic that made it difficult for me to follow along. Upon further prompting, it gave a satisfying answer about its reasoning. Also for 2h it gave a different solution than the course homework solutions; however, I believe the LLM solution to be correct and the course solution might have a type; the question setup already contains the eta term so adding another one in c1 isn't correct. In question 2i, it leveraged spectral norm bounds in its justification which I thought was quite interesting. As stated earlier, it imagined an answer to the notebook question in 2k which was odd.</paragraph><paragraph><bold>Question 3:</bold> I thought the way the LLM presented these answers were especially intuitive; it identified reused expressions and defined intermediate variables to increase readability. (e.g. in question 3c it defined the intermediate variable T). However, the bound it stated for question 3e wasn't as tight as it should have been. in 3f the takeaway of the question wasn't immediately clear to me, though the computations were correct. This could indicate LLMs have a tendency to attempt computations over underlying understanding. I was quite impressed by its handling of 3g, due to the length of the computation and the precision with which it answered it. Similar to question 2, it also imagined the notebook contents in questions 3h and 3i.</paragraph><paragraph><bold>Question 4:</bold> The LLM went a step further and gave the equation for the typical adam update, which it didn't have to.</paragraph><paragraph><bold>Question 5:</bold> LLM also looked ahead and prematurely provided insight into noisy data. The rest of the subparts were quite straightforward though.</paragraph><paragraph><bold>Question 6:</bold> The LLM was able to provide precise answers despite quite a few matrices involved in the solution. I was impressed by this.</paragraph><paragraph><bold>Question 7:</bold> Skipped some steps but they were trivial. Identities were correct!</paragraph><paragraph>link to conversation: https://chatgpt.com/share/6935d518-4ebc-800f-88c0-bbe553d8c0ef</paragraph><paragraph>Annotated log: </paragraph><file url=\"https://static.us.edusercontent.com/files/J8IVNrgieGk0yH4anWkM0bI4\" filename=\"Deep learning problem set.pdf\"/><paragraph>note: sometimes the last line of a page is duplicated on the next page; this is because I was having trouble exporting the conversation as one contiguous pdf. However, all the information is there.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T11:11:21.842807+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428327,
            "author": "Hiya Shah",
            "project_title": "Special Participation B: ChatGPT 5.1 Thinking on HW 11",
            "post_body": "I prompted Chatgpt 5.1 with Thinking Mode enabled to solve the coding questions of Homework 11, which were questions 3, 4, and 7. I found that it generally was very accurate, although it did refactor some code and hallucinate/provide excessively verbose reasoning on followup conceptual questions (which may be a consequence of the thinking enabled). I wonder if it would have similar or better performance in the Codex environment, which it can actually run the code in via Agent Mode.\n\nProblem 3: The model thought for ~5 minutes, but it essentially one-shot solved the problem! It was able to fill in each of the Todos accurately, and it did not remove any of the Todos as I have seen past models do or hallucinate anything. However, it did refactor some of the code, especially in the \"Induction Copy Head\" question. I thought this was interesting given that this was an old interview question for Anthropic (not sure what model was out when this question used to be asked).\n\nProblem 4: For this question, ChatGPT 5.1 thinking mode thought for just a couple of minutes. It refactored/reimplemented model_inst and train_mlp_sgd, and the plots generated as intended in the corresponding solution notebook. After it filled in the notebook, I also prompted it to fill in the conceptual questions from the pdf, which it generally did well on (was unnecessarily verbose though). It also hallucinated context from its own general knowledge vs what was actually given/asked in the coding notebook and in the hw11 pdf.\n\nProblem 7: In this question, I split my prompting into two parts: one for pruning.ipynb, and the other for quantization.ipynb. While it initially struggled and errored out when I provided both ipynb notebooks at once, it did significantly better and provided the accurate coding solution when I prompted these notebooks one at a time! It did slightly poorly on optional conceptual follow up questions about advantages and disadvantages (verbose resp that missed the core answer). It also returned code snippets in chat as well as filling them into the notebook, and these were fully accurate and in line with the staff provided solutions.\n\ntrace: https://chatgpt.com/share/69360e1e-ede0-8005-a9fa-5753cbd66086\n\nmy annotated trace: \n\nmodel solution notebooks:",
            "content_xml": "<document version=\"2.0\"><paragraph>I prompted Chatgpt 5.1 with Thinking Mode enabled to solve the coding questions of Homework 11, which were questions 3, 4, and 7. I found that it generally was very accurate, although it did refactor some code and hallucinate/provide excessively verbose reasoning on followup conceptual questions (which may be a consequence of the thinking enabled). I wonder if it would have similar or better performance in the Codex environment, which it can actually run the code in via Agent Mode.</paragraph><paragraph><italic>Problem 3:</italic> The model thought for ~5 minutes, but it essentially one-shot solved the problem! It was able to fill in each of the Todos accurately, and it did not remove any of the Todos as I have seen past models do or hallucinate anything. However, it did refactor some of the code, especially in the \"Induction Copy Head\" question. I thought this was interesting given that this was an old interview question for Anthropic (not sure what model was out when this question used to be asked).</paragraph><paragraph><italic>Problem 4</italic>: For this question, ChatGPT 5.1 thinking mode thought for just a couple of minutes. It refactored/reimplemented <code>model_inst</code> and <code>train_mlp_sgd</code>, and the plots generated as intended in the corresponding solution notebook. After it filled in the notebook, I also prompted it to fill in the conceptual questions from the pdf, which it generally did well on (was unnecessarily verbose though). It also hallucinated context from its own general knowledge vs what was actually given/asked in the coding notebook and in the hw11 pdf.</paragraph><paragraph><italic>Problem 7:</italic> In this question, I split my prompting into two parts: one for pruning.ipynb, and the other for quantization.ipynb. While it initially struggled and errored out when I provided both ipynb notebooks at once, it did significantly better and provided the accurate coding solution when I prompted these notebooks one at a time! It did slightly poorly on optional conceptual follow up questions about advantages and disadvantages (verbose resp that missed the core answer). It also returned code snippets in chat as well as filling them into the notebook, and these were fully accurate and in line with the staff provided solutions.</paragraph><paragraph><italic>trace</italic>: <link href=\"https://chatgpt.com/share/69360e1e-ede0-8005-a9fa-5753cbd66086\">https://chatgpt.com/share/69360e1e-ede0-8005-a9fa-5753cbd66086</link></paragraph><paragraph><italic>my annotated trace:</italic> </paragraph><file url=\"https://static.us.edusercontent.com/files/dLGobyUEZjgCutMc9PBuxOk8\" filename=\"special_participation_b_unannot_cs182_chatgpt_thinking_hw11.pdf\"/><paragraph><italic>model solution notebooks:</italic></paragraph><file url=\"https://static.us.edusercontent.com/files/OsdIRa7kC2CmYZ2eHGqcIUoi\" filename=\"q_code_interpretability_solved.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/gPFni1GFxCaFHAU2VMMQPjHE\" filename=\"scaling_laws_solved.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/aW2uGLywcbfOcXdZM5Cv9CQK\" filename=\"pruning_solved.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/P0Wy3SRKtzhOvaSMvwZcUH60\" filename=\"quantization_solved.ipynb\"/></document>",
            "links": [
                "https://chatgpt.com/share/69360e1e-ede0-8005-a9fa-5753cbd66086"
            ],
            "attachments": [],
            "created_at": "2025-12-08T11:03:48.840415+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428314,
            "author": "Jaewon Chang",
            "project_title": "Special Participation A: GPT 5.1 Thinking on HW07",
            "post_body": "I utilized GPT 5.1 Thinking on homework 7 (the written questions), and overall I was surprised by how easily the model was able to one shot all the problems. Here are my specific notes per subquestion:\n\nQ3\n\n(1 minute 43 seconds of thinking + 13 seconds of thinking for clarification) The model was able to one shot the problem successfully, in a slightly different method than the solutions for part (b) (ii). There was a minor question I had because the model didn\u2019t fully clarify one step in its working, so I wanted to confirm that I was correct on this. The model responded with a really in-depth clarification on this part, which I found to be extremely helpful for my own learning\n\n(51 seconds of thinking) Given that the solution was slightly different from that of the staff solution, I tried steering the model to mimik the staff solution, and I was surprised by how much more in-depth it was than the staff solution in explaining how to go from one part to the next.\n\nQ4\n\n(33 seconds of thinking) For part (a), the model got the correct accuracy numbers but wrong times, so I\u2019m thinking it actually didn\u2019t reference the blog post and instead just answered based on its background knowledge (e.g. maybe these numbers were part of its pretraining corpus)\n\nFor part (b), the model had a good takeaway and also explains with great specificity\n\nFor part (c), the model gave an answer that made me also re-think my own takeaways from reading the article \u2013 giving me a perspective that I previously hadn't thought of.\n\nQ7\n\n(36 seconds of thinking) The model was able to zero shot all the problems, and was able to get both reasonable answers for part (a) even though the problem only asked for one.\n\nFor this question, I also typed out the question just in case the model was not able to fully parse the pdf.\n\nQ8\n\n(1 minute 26 seconds of thinking) The model was able to zero shot (a) (i - iii), and also (b), in a method that was similar to that of the staff solution\n\n\nWhen prompting the model to solve all the problems above, for the most part I was taking screenshots of the problems and pasting it into the chat. The reason for doing this is simply because copy pasting math equations often ruins format, which may get in the way (e.g. w^2 when copy pasted may appear as w2, which the model may confuse to be w_2 instead of w^2). Personally I trust the model's OCR capabilities (i.e. parsing text on a screenshot) more than its capability to deduce unformatted math notation. I think this was the reason why I found that the model often thinks for a long period of time (as seen above it often takes the model 30 - 90 seconds of thinking before responding).\n\nResult wise, the model was essentially able to one-shot all of the problems, and utilized the hints when appropriate (E.g. Q8 part b). Although GPT 5.1 Thinking is a frontier model, I was surprised by how it was still able to one shot the problems given that I pasted screenshots of the problems rather than latex-formatted math.\n\nAnnotated drive link: https://drive.google.com/file/d/1mmyNNNoPi6a7Nmy8W2y_9hAXkFW1pW1Z/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I utilized GPT 5.1 Thinking on homework 7 (the written questions), and overall I was surprised by how easily the model was able to one shot all the problems. Here are my specific notes per subquestion:</paragraph><list style=\"unordered\"><list-item><paragraph>Q3</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>(1 minute 43 seconds of thinking + 13 seconds of thinking for clarification) The model was able to one shot the problem successfully, in a slightly different method than the solutions for part (b) (ii). There was a minor question I had because the model didn\u2019t fully clarify one step in its working, so I wanted to confirm that I was correct on this. The model responded with a really in-depth clarification on this part, which I found to be extremely helpful for my own learning</paragraph></list-item><list-item><paragraph>(51 seconds of thinking) Given that the solution was slightly different from that of the staff solution, I tried steering the model to mimik the staff solution, and I was surprised by how much more in-depth it was than the staff solution in explaining how to go from one part to the next.</paragraph></list-item></list></list-item><list-item><paragraph>Q4</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>(33 seconds of thinking) For part (a), the model got the correct accuracy numbers but wrong times, so I\u2019m thinking it actually didn\u2019t reference the blog post and instead just answered based on its background knowledge (e.g. maybe these numbers were part of its pretraining corpus)</paragraph></list-item><list-item><paragraph>For part (b), the model had a good takeaway and also explains with great specificity</paragraph></list-item><list-item><paragraph>For part (c), the model gave an answer that made me also re-think my own takeaways from reading the article \u2013 giving me a perspective that I previously hadn't thought of.</paragraph></list-item></list></list-item><list-item><paragraph>Q7</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>(36 seconds of thinking) The model was able to zero shot all the problems, and was able to get both reasonable answers for part (a) even though the problem only asked for one.</paragraph></list-item><list-item><paragraph>For this question, I also typed out the question just in case the model was not able to fully parse the pdf.</paragraph></list-item></list></list-item><list-item><paragraph>Q8</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>(1 minute 26 seconds of thinking) The model was able to zero shot (a) (i - iii), and also (b), in a method that was similar to that of the staff solution</paragraph></list-item></list></list-item></list><paragraph><break/>When prompting the model to solve all the problems above, for the most part I was taking screenshots of the problems and pasting it into the chat. The reason for doing this is simply because copy pasting math equations often ruins format, which may get in the way (e.g. w^2 when copy pasted may appear as w2, which the model may confuse to be w_2 instead of w^2). Personally I trust the model's OCR capabilities (i.e. parsing text on a screenshot) more than its capability to deduce unformatted math notation. I think this was the reason why I found that the model often thinks for a long period of time (as seen above it often takes the model 30 - 90 seconds of thinking before responding).</paragraph><paragraph>Result wise, the model was essentially able to one-shot all of the problems, and utilized the hints when appropriate (E.g. Q8 part b). Although GPT 5.1 Thinking is a frontier model, I was surprised by how it was still able to one shot the problems given that I pasted screenshots of the problems rather than latex-formatted math.</paragraph><file url=\"https://static.us.edusercontent.com/files/JWfvLntoj5uPz1YelVCCg7NV\" filename=\"182 participation A.pdf\"/><paragraph>Annotated drive link: https://drive.google.com/file/d/1mmyNNNoPi6a7Nmy8W2y_9hAXkFW1pW1Z/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T11:02:53.594376+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428276,
            "author": "Minjune Kim",
            "project_title": "Special Participation E: Adapative AI-Mini Tutor With ChatGPT 5.1",
            "post_body": "I have used ChatGPT to be my personal tutor for CS182. I have a prompt that gives some context of what the GPT should act and how it should be acting depending on how I answer the question.  I think overall it was very useful because it was able to place me around the place where I thought I belonged, and it was able to give me a better understanding of the concept that I needed help on. \n\nI think having the option of GPT being able to adapt to the level of student's learning to the concept is something that will help out students a lot because not everyone is on the same page with the understanding of the concepts, and with this, everyone can be on the same level after using these prompts and learning more specifically about the confusing concepts that the class might bring or even answer some questions that they had. \n\nAnnotated Prompt: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I have used ChatGPT to be my personal tutor for CS182. I have a prompt that gives some context of what the GPT should act and how it should be acting depending on how I answer the question.  I think overall it was very useful because it was able to place me around the place where I thought I belonged, and it was able to give me a better understanding of the concept that I needed help on. </paragraph><paragraph>I think having the option of GPT being able to adapt to the level of student's learning to the concept is something that will help out students a lot because not everyone is on the same page with the understanding of the concepts, and with this, everyone can be on the same level after using these prompts and learning more specifically about the confusing concepts that the class might bring or even answer some questions that they had. <break/><break/>Annotated Prompt: </paragraph><file url=\"https://static.us.edusercontent.com/files/Nc23Km5qQM8bTG6WUQ5X47oX\" filename=\"In-context learning tutoring1-merged.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:58:35.726216+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428265,
            "author": "Anshul Verma",
            "project_title": "Special Participation A: Claude Opus 4.5 on HW 3",
            "post_body": "LLM Trace: https://claude.ai/share/b45ee84e-7009-436d-9b72-47ec844d083c\n\nAnnotated Log: https://drive.google.com/file/d/1TCL7ETF4Z27TknURe5f0fIOvSesCb2G/view?usp=sharing\n\nI audited Claude Opus 4.5 on the non-coding theoretical portions of Homework 3 (Problems 1, 3, 4, and 5).\n\nPerformance Overview: The model demonstrated a 100% Zero-Shot Success Rate across all problems, consistently matching or exceeding the rigor of the solution manual without hallucinations and without any guidance.\n\nKey Observations:\n\nFirst-Principles Derivation: The model autonomously derived general proofs for complex matrix operations to provide a more rigorous, general-case solution.\n\nProblem 1, Derived the full matrix math for SignGD rather than relying on the scalar hint.\n\nAutonomous Context Synthesis: It successfully identified and interpreted external research contexts (referencing specific literature)\n\nProblem 3, referenced Tensor Programs paper, Spectral Condition Paper\n\nAlgorithmic Fidelity: The model employed structured chain-of-thought reasoning and avoided the common arithmetic and logic errors typical of LLMs.\n\nProblem 5",
            "content_xml": "<document version=\"2.0\"><paragraph>LLM Trace: <link href=\"https://claude.ai/share/b45ee84e-7009-436d-9b72-47ec844d083c\">https://claude.ai/share/b45ee84e-7009-436d-9b72-47ec844d083c</link></paragraph><paragraph>Annotated Log: <link href=\"https://drive.google.com/file/d/1TCL7ETF4Z27TknURe5f0fIOvSesCb2G/view?usp=sharing\">https://drive.google.com/file/d/1TCL7ETF4Z27TknURe5f0fIOvSesCb2G/view?usp=sharing</link></paragraph><paragraph>I audited Claude Opus 4.5 on the non-coding theoretical portions of Homework 3 (Problems 1, 3, 4, and 5).</paragraph><paragraph><bold>Performance Overview:</bold> The model demonstrated a 100% Zero-Shot Success Rate across all problems, consistently matching or exceeding the rigor of the solution manual without hallucinations and without any guidance.</paragraph><paragraph><bold>Key Observations:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>First-Principles Derivation:</bold> The model autonomously derived general proofs for complex matrix operations to provide a more rigorous, general-case solution.</paragraph><list style=\"unordered\"><list-item><paragraph>Problem 1, Derived the full matrix math for SignGD rather than relying on the scalar hint.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Autonomous Context Synthesis:</bold> It successfully identified and interpreted external research contexts (referencing specific literature)</paragraph><list style=\"unordered\"><list-item><paragraph>Problem 3, referenced Tensor Programs paper, Spectral Condition Paper</paragraph></list-item></list></list-item><list-item><paragraph><bold>Algorithmic Fidelity:</bold> The model employed structured chain-of-thought reasoning and avoided the common arithmetic and logic errors typical of LLMs.</paragraph><list style=\"unordered\"><list-item><paragraph>Problem 5</paragraph></list-item></list></list-item></list></document>",
            "links": [
                "https://claude.ai/share/b45ee84e-7009-436d-9b72-47ec844d083c",
                "https://drive.google.com/file/d/1TCL7ETF4Z27TknURe5f0fIOvSesCb2G/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T10:56:49.293973+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428162,
            "author": "Etaash Patel",
            "project_title": "Special Participation E: Follow Up on Using ChatGPT to Help Understand Papers",
            "post_body": "I wanted to revisit the issues raised in Post #284 and see whether we could get better results from ChatGPT by adjusting the setup. I repeated the same exercise, but with a few important differences:\n\n1. Narrowed context.\n Instead of giving ChatGPT the entire paper (https://arxiv.org/pdf/2310.17813), I only provided the single page containing the claims and their justifications.\n\n2. Revised prompt.\n I rewrote the prompt to directly address the concerns mentioned in Post #284. In particular, I emphasized that the explanation should be:\n\nself-contained,\n\nwell structured, and\n\nwritten primarily in clear English prose.\n\nThe full prompt is below:\n\"Hello, I would like you to expand on the arguments given for the claims in a paper I am reading (A Spectral Condition ...). \nWhen doing so, could you please make sure your explanation is: \nA. Precise \nB. Easy to follow: proofs should be in English prose as much as possible (while still being precise) \nC. Self-Contained: Please try to only reference facts a CS182 student would know. If you need to include new facts/arguments, please state them in full before using them \nD. Well structured. \nAlso, at the end, please try to generate some questions to check conceptual understanding.\"\n\n3. Different models.\n I have a free trial of ChatGPT Pro, so I tested both the Pro model and the free model on the same prompt. Both were set to \u201cThinking Mode\u201d before answering. Models were GPT 5 (for free version) and 5.1 (for paid version). \n\nOverall observations:\nUnsurprisingly, the Pro model produced a significantly stronger explanation. That said, I still found that the free model, after some coaxing, generated an explanation addressed some of the problems mentioned than the original response shown in Post #284. The one thing both models still suffer from is having a concise writeup (in both cases, the model's explanations are longer than needed). Much of this probably comes from the prompting though, as the prompt encourages the model to err on the side of too much detail. \n\nBoth transcripts are attached below.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I wanted to revisit the issues raised in Post #284 and see whether we could get better results from ChatGPT by adjusting the setup. I repeated the same exercise, but with a few important differences:</paragraph><paragraph><bold>1. Narrowed context.</bold><break/> Instead of giving ChatGPT the entire paper (https://arxiv.org/pdf/2310.17813), I only provided the single page containing the claims and their justifications.</paragraph><paragraph><bold>2. Revised prompt.</bold><break/> I rewrote the prompt to directly address the concerns mentioned in Post #284. In particular, I emphasized that the explanation should be:</paragraph><list style=\"unordered\"><list-item><paragraph>self-contained,</paragraph></list-item><list-item><paragraph>well structured, and</paragraph></list-item><list-item><paragraph>written primarily in clear English prose.</paragraph></list-item></list><paragraph>The full prompt is below:<break/>\"Hello, I would like you to expand on the arguments given for the claims in a paper I am reading (A Spectral Condition ...). <break/>When doing so, could you please make sure your explanation is: <break/>A. Precise <break/>B. Easy to follow: proofs should be in English prose as much as possible (while still being precise) <break/>C. Self-Contained: Please try to only reference facts a CS182 student would know. If you need to include new facts/arguments, please state them in full before using them <break/>D. Well structured. <break/>Also, at the end, please try to generate some questions to check conceptual understanding.\"</paragraph><paragraph><bold>3. Different models.</bold><break/> I have a free trial of ChatGPT Pro, so I tested both the Pro model and the free model on the same prompt. Both were set to \u201cThinking Mode\u201d before answering. Models were GPT 5 (for free version) and 5.1 (for paid version). </paragraph><paragraph><bold>Overall observations:</bold><break/>Unsurprisingly, the Pro model produced a significantly stronger explanation. That said, I still found that the free model, after some coaxing, generated an explanation addressed some of the problems mentioned than the original response shown in Post #284. The one thing both models still suffer from is having a concise writeup (in both cases, the model's explanations are longer than needed). Much of this probably comes from the prompting though, as the prompt encourages the model to err on the side of too much detail. </paragraph><paragraph>Both transcripts are attached below.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/wGFkN7QwEmh2RpDsnFwllmr9\" filename=\"Expand on claims paper free version.pdf\"/><file url=\"https://static.us.edusercontent.com/files/Mbj2TzXUcFPuUwImVplAl2To\" filename=\"Expand on paper claims pro version.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:43:05.081268+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428155,
            "author": "Diana Kohr",
            "project_title": "Special Participation E: Gemini 2.5 Flash for Condensing Concepts",
            "post_body": "I experimented with using Gemini 2.5 Flash to create lecture summaries (cheat sheet style) and iteratively condensing / shortening them to see what Gemini would keep as the most important material. \n\nConversation: https://gemini.google.com/share/0354ec8fb0bd\n\nAnnotated: https://drive.google.com/file/d/15oZTdMiMxU1FsVwrkDjTQjLvUUiY-D5A/view?usp=sharing\n\nPrompts: \n\nTo generate initial summary: \"Please use the attached lecture notes to create a one page summary that has the most important concepts / equations. It's ok if small details, such as analogies, are omitted, but it should be sufficient as a cheat sheet on an exam.\"\n\nTo adjust distribution of content: \"Could you add more about the difference between DDPM and DDIM while keeping things concise, so everything fits on a page?\"\n\nTo shorten: \"This cheat sheet is too long, could you condense it?\"\n\nTakeaways: \n\nGemini does a good job with concisely summarizing concepts, but not as well in picking out important formulas / equations, especially when the original lecture notes contained lots of math for derivations. It did include important lines of pseudocode!\n\nThe lengthy explanations shrank as I instructed Gemini to condense the cheat sheet (expected). An interesting result was that more tables were added, which I liked. \n\nThe only major drawback is that Gemini (this version at least) didn't have the capability to include diagrams. In the summary for lecture 15, the column for diagrams of autoencoder variants was empty. Also, for some reason, it kept including this Getty Images diagram of an autoencoder, which wasn't super helpful. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I experimented with using Gemini 2.5 Flash to create lecture summaries (cheat sheet style) and iteratively condensing / shortening them to see what Gemini would keep as the most important material. </paragraph><paragraph>Conversation: https://gemini.google.com/share/0354ec8fb0bd</paragraph><paragraph>Annotated: https://drive.google.com/file/d/15oZTdMiMxU1FsVwrkDjTQjLvUUiY-D5A/view?usp=sharing</paragraph><paragraph>Prompts: </paragraph><list style=\"bullet\"><list-item><paragraph>To generate initial summary: \"Please use the attached lecture notes to create a one page summary that has the most important concepts / equations. It's ok if small details, such as analogies, are omitted, but it should be sufficient as a cheat sheet on an exam.\"</paragraph></list-item><list-item><paragraph>To adjust distribution of content: \"Could you add more about the difference between DDPM and DDIM while keeping things concise, so everything fits on a page?\"</paragraph></list-item><list-item><paragraph>To shorten: \"This cheat sheet is too long, could you condense it?\"</paragraph></list-item></list><paragraph>Takeaways: </paragraph><list style=\"bullet\"><list-item><paragraph>Gemini does a good job with concisely summarizing concepts, but not as well in picking out important formulas / equations, especially when the original lecture notes contained lots of math for derivations. It did include important lines of pseudocode!</paragraph></list-item><list-item><paragraph>The lengthy explanations shrank as I instructed Gemini to condense the cheat sheet (expected). An interesting result was that more tables were added, which I liked. </paragraph></list-item><list-item><paragraph>The only major drawback is that Gemini (this version at least) didn't have the capability to include diagrams. In the summary for lecture 15, the column for diagrams of autoencoder variants was empty. Also, for some reason, it kept including this Getty Images diagram of an autoencoder, which wasn't super helpful. </paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:41:59.32189+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7428058,
            "author": "Jin Ying",
            "project_title": "Special Participation E: Learning RNN with Sonnet 4",
            "post_body": "When we were learning RNNs two months ago, I wasn't able to understand the lectures very well, and the topic was also not in the Prince's textbook. So I asked Claude to test my understanding of the topic by asking me one question at a time; this was my first time trying this and it helped me a lot in understanding concepts. So later in the semester, I tried this method also on many other topics, as well as for other classes, and had since improved the method a lot better over the semester. Rather than passively absorbing explanations, I had to actively reason through each concept\u2014why we need weight sharing, how the hidden state acts as memory, why vanishing gradients occur, and how LSTMs solve this with additive updates. Claude would push back on incomplete answers (\"But let me push you further...\") and use concrete examples to guide my thinking toward insights I couldn't discover myself.",
            "content_xml": "<document version=\"2.0\"><paragraph>When we were learning RNNs two months ago, I wasn't able to understand the lectures very well, and the topic was also not in the Prince's textbook. So I asked Claude to test my understanding of the topic by asking me one question at a time; this was my first time trying this and it helped me a lot in understanding concepts. So later in the semester, I tried this method also on many other topics, as well as for other classes, and had since improved the method a lot better over the semester. Rather than passively absorbing explanations, I had to actively reason through each concept\u2014why we need weight sharing, how the hidden state acts as memory, why vanishing gradients occur, and how LSTMs solve this with additive updates. Claude would push back on incomplete answers (\"But let me push you further...\") and use concrete examples to guide my thinking toward insights I couldn't discover myself.</paragraph><file url=\"https://static.us.edusercontent.com/files/Jk4BzVh4dlZuWAu8TOp1C6Rs\" filename=\"RNN with Claude.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:29:02.162471+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427959,
            "author": "Edward Zhang",
            "project_title": "Special Participation B: DeepSeek on HW02 Problem 3",
            "post_body": "Having worked through this deep learning initialization task with DeepSeek, I was impressed by how effectively we implemented and compared different weight initialization schemes. What stood out most was how we not only coded the He initialization correctly on the first try, but also built comprehensive gradient tracking to visualize why it works better. The implementation captured exactly why He initialization prevents vanishing gradients in ReLU networks - something that often takes students much trial and error to grasp. What surprised me was how quickly we moved from theory to practical validation, with the gradient norm plots clearly showing why zero initialization fails and why random initialization struggles in deeper networks. This experience showed me how proper tooling and clear explanations can make complex concepts like variance preservation in deep networks immediately understandable and verifiable through experimentation.",
            "content_xml": "<document version=\"2.0\"><paragraph>Having worked through this deep learning initialization task with DeepSeek, I was impressed by how effectively we implemented and compared different weight initialization schemes. What stood out most was how we not only coded the He initialization correctly on the first try, but also built comprehensive gradient tracking to visualize why it works better. The implementation captured exactly why He initialization prevents vanishing gradients in ReLU networks - something that often takes students much trial and error to grasp. What surprised me was how quickly we moved from theory to practical validation, with the gradient norm plots clearly showing why zero initialization fails and why random initialization struggles in deeper networks. This experience showed me how proper tooling and clear explanations can make complex concepts like variance preservation in deep networks immediately understandable and verifiable through experimentation.</paragraph><file url=\"https://static.us.edusercontent.com/files/3xJQKp2b7TeEg9L6q76uT3Nw\" filename=\"hw2_coding_report.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:15:33.82273+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427939,
            "author": "Edward Zhang",
            "project_title": "Special Participation A: DeepSeek on HW07",
            "post_body": "In this chat, I utilized DeepSeek 3.2 in its default reasoning mode to work through the machine learning homework problems step by step. Starting with the full context of the assignment, I prompted the model to solve each sub\u2011question sequentially, occasionally providing clarifications or corrections when needed\u2014though such interventions were minimal, as the model consistently delivered accurate, well\u2011reasoned solutions. What stood out was the model\u2019s deliberate avoidance of simplifying numerical results, leaving expressions in exact form to prevent calculation errors and encourage manual verification. I also noticed occasional inconsistencies in variable naming across steps, but the logical flow remained clear and correct.\n\nCompared to other models I have used, DeepSeek favored concise, direct answers over lengthy exposition, which made the solutions easier to follow but sometimes omitted broader contextual commentary. This trade\u2011off between brevity and nuance reflects a distinct design philosophy. Finally, when I once mistakenly referenced the wrong part of a problem, the model did not simply guess; instead, it recognized the inconsistency, inferred the likely intended question, and answered accordingly. This demonstrated a welcome resistance to hallucination and an ability to maintain coherence even when the prompt was imperfect. Overall, the interaction proved efficient and reliable for technical problem\u2011solving.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/I3cif0PfdLXUqCgWNj0sdcSS\" filename=\"eecs182_HW07.pdf\"/><paragraph>In this chat, I utilized DeepSeek 3.2 in its default reasoning mode to work through the machine learning homework problems step by step. Starting with the full context of the assignment, I prompted the model to solve each sub\u2011question sequentially, occasionally providing clarifications or corrections when needed\u2014though such interventions were minimal, as the model consistently delivered accurate, well\u2011reasoned solutions. What stood out was the model\u2019s deliberate avoidance of simplifying numerical results, leaving expressions in exact form to prevent calculation errors and encourage manual verification. I also noticed occasional inconsistencies in variable naming across steps, but the logical flow remained clear and correct.</paragraph><paragraph>Compared to other models I have used, DeepSeek favored concise, direct answers over lengthy exposition, which made the solutions easier to follow but sometimes omitted broader contextual commentary. This trade\u2011off between brevity and nuance reflects a distinct design philosophy. Finally, when I once mistakenly referenced the wrong part of a problem, the model did not simply guess; instead, it recognized the inconsistency, inferred the likely intended question, and answered accordingly. This demonstrated a welcome resistance to hallucination and an ability to maintain coherence even when the prompt was imperfect. Overall, the interaction proved efficient and reliable for technical problem\u2011solving.</paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:12:14.47487+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427934,
            "author": "Jin Ying",
            "project_title": "Special Participation B: Opus 4.5 on HW2 (and also compare with GPT 5.1 Thinking)",
            "post_body": "I asked Opus 4.5 to solve questions 3, 4, and 6 in HW2 with justificiation. Opus 4.5 basically one-shotted all the questions with minor errors. This was actually not surprising to me, as the coding parts in this homework are all very basic; they are simply asking us to translate basic concepts into code, and I think models before Opus 4.5 can already handle this very well -- I also asked for help from GPT 5 and Sonnet 4.5 when doing this homework at the beginning of the semester, when Opus 4.5 was not out, and if i asked an individual question, they could generate the answer and explain the code very easily. What surprised me here is when given all the questions and code Opus 4.5 solved it in a short amount of time (Claude did not record the working time, but it takes no longer than 3 mins). Since the solutions it gave are all correct, I wanted to analyze how Opus 4.5 do it (instead of focusing on our interactions, since it does not need much instructions here to solve the questions) and compare with it with GPT 5.1 thinking, which also did not exist when we are doing this homework. My initial guess is Claude would be superior in the sense of conciseness. I tried the same prompt and questions with GPT 5.1 thinking, it takes way longer than Opus 4.5; in my first try, it errored in 13m 36s when just starting generating the answers. The second time took also about 13m and finally generated the correct answers. Claude Opus 4.5 is ~4x faster while maintaining solution correctness and providing solid conceptual explanations. Both models handle these straightforward translation-to-code problems easily, suggesting the real differentiator is efficiency rather than capability for basic homework questions. I include further analysis and comparsion in the doc. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I asked Opus 4.5 to solve questions 3, 4, and 6 in HW2 with justificiation. Opus 4.5 basically one-shotted all the questions with minor errors. This was actually not surprising to me, as the coding parts in this homework are all very basic; they are simply asking us to translate basic concepts into code, and I think models before Opus 4.5 can already handle this very well -- I also asked for help from GPT 5 and Sonnet 4.5 when doing this homework at the beginning of the semester, when Opus 4.5 was not out, and if i asked an individual question, they could generate the answer and explain the code very easily. What surprised me here is when given all the questions and code Opus 4.5 solved it in a short amount of time (Claude did not record the working time, but it takes no longer than 3 mins). Since the solutions it gave are all correct, I wanted to analyze how Opus 4.5 do it (instead of focusing on our interactions, since it does not need much instructions here to solve the questions) and compare with it with GPT 5.1 thinking, which also did not exist when we are doing this homework. My initial guess is Claude would be superior in the sense of conciseness. I tried the same prompt and questions with GPT 5.1 thinking, it takes way longer than Opus 4.5; in my first try, it errored in 13m 36s when just starting generating the answers. The second time took also about 13m and finally generated the correct answers. Claude Opus 4.5 is ~4x faster while maintaining solution correctness and providing solid conceptual explanations. Both models handle these straightforward translation-to-code problems easily, suggesting the real differentiator is efficiency rather than capability for basic homework questions. I include further analysis and comparsion in the doc. </paragraph><file url=\"https://static.us.edusercontent.com/files/DK1ATWepmmognNyttMQ5frA8\" filename=\"HW2 with Opus 4 and GPT Thinking 5.1.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T10:11:48.245631+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427874,
            "author": "Hiya Shah",
            "project_title": "Special Participation A: Llama 4 Maverick on HW 11",
            "post_body": "I guided Llama 4 Maverick to solve the non-coding questions for Homework 11, which was largely about model finetuning, LoRA, and Fermi Estimation and memory calculation for large-scale DL models. I provided the model with the following prompt,\n\n\"You will be solving various questions from this Deep Learning homework pdf. Please go over one question at a time when I specify the question. First, output the exact problem statement from the PDF, then give a full explanation of how you reached your answer, along with the answer.\"\n\nOverall, the model performed well on the proof-based questions. However, it performed relatively poorly on complex calculations (especially in the Fermi estimation question) and on multistep formula derivations with numerical value plugins. I was surprised to find that it did not hallucinate the problem question, giving it back to me accurately word for word.\n\nProblem 1: In this problem, Llama was tasked with analyzing LoRA and possible adjustments, as well as how they would affect training. For part i, it correctly noted to increase the rank, but it did not mention alternatives such as changing the initialization and changing the learning rate. For the rest of the parts, it generally gave the correct answer. However, it would not mention the practical alternatives such as initializing A with random initialization and initializing B with 0.  \n\nProblem 2: For this problem, I asked the model to solve each question part by part. For part i, it got the correct answer, but I noticed that it did not solve the questions in the same manner a student would. By this, I mean that the model would first give the answer and then walk through the solutions instead of step by step arriving at the answer. It would also not highlight what is the most important takeaway from the problem/what to do know generally as the solutions pdf does (ex. it is important to know that the calculation of logits only depends on the input token). In this problem, it did not reference the figures in its answer either. For the SVD problem, I wish it had enough context in for example long term memory to reference where in previous lectures I could understand this information.\n\nProblem 3: As this was a coding problem, I did not prompt Llama 4 to solve this part.\n\nProblem 4: As this was a coding problem, I did not prompt Llama 4 to solve this part.\n\nProblem 5: In this problem, Llama 4 was tasked with Fermi estimation, which is a technique for estimating quantities through rough approximations and educated guesses. As the model was tasked with approximation, I found that it performed quite poorly compared to the approximations given by the solutions. It missed nearly every single calculation and formula derivation, and it had trouble analyzing multimodal context in the form of the figures and table. I believe the labels on the graph were slightly small, so they were not readable by the model. However, the model successfully skipped the problems which did not require a solution, meaning it did analyze the given context or at least attempt to.\n\nProblem 6: In this problem, I asked Llama 4 to solve each part step by step. I believe by this time, the model was experiencing context rot as it frequently provided short responses that I had to reprompt with screenshots of the problem part (even though I had provided a pdf earlier). It generally gave correct answers, but they were not as verbose as the solutions. The answer to part a was only halfway correct. For part d, it did not consider the variations on the basic MAML approach.\n\nOverall, the model performed ~62.5% accuracy, and it mainly missed questions later in the pdf or questions requiring significant calculation and approximation.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I guided <link href=\"https://app.chathub.gg/chat/cloud-llama4?utm_source=models\">Llama 4</link> Maverick to solve the non-coding questions for Homework 11, which was largely about model finetuning, LoRA, and Fermi Estimation and memory calculation for large-scale DL models. I provided the model with the following prompt,</paragraph><paragraph>\"You will be solving various questions from this Deep Learning homework pdf. Please go over one question at a time when I specify the question. First, output the exact problem statement from the PDF, then give a full explanation of how you reached your answer, along with the answer.\"</paragraph><paragraph>Overall, the model performed well on the proof-based questions. However, it performed relatively poorly on complex calculations (especially in the Fermi estimation question) and on multistep formula derivations with numerical value plugins. I was surprised to find that it did not hallucinate the problem question, giving it back to me accurately word for word.</paragraph><paragraph><italic>Problem 1:</italic> In this problem, Llama was tasked with analyzing LoRA and possible adjustments, as well as how they would affect training. For part i, it correctly noted to increase the rank, but it did not mention alternatives such as changing the initialization and changing the learning rate. For the rest of the parts, it generally gave the correct answer. However, it would not mention the practical alternatives such as initializing A with random initialization and initializing B with 0.  </paragraph><paragraph><italic>Problem 2:</italic> For this problem, I asked the model to solve each question part by part. For part i, it got the correct answer, but I noticed that it did not solve the questions in the same manner a student would. By this, I mean that the model would first give the answer and then walk through the solutions instead of step by step arriving at the answer. It would also not highlight what is the most important takeaway from the problem/what to do know generally as the solutions pdf does (ex. it is important to know that the calculation of logits only depends on the input token). In this problem, it did not reference the figures in its answer either. For the SVD problem, I wish it had enough context in for example long term memory to reference where in previous lectures I could understand this information.</paragraph><paragraph><italic>Problem 3:</italic> As this was a coding problem, I did not prompt Llama 4 to solve this part.</paragraph><paragraph><italic>Problem 4:</italic> As this was a coding problem, I did not prompt Llama 4 to solve this part.</paragraph><paragraph><italic>Problem 5</italic>: In this problem, Llama 4 was tasked with Fermi estimation, which is a technique for estimating quantities through rough approximations and educated guesses. As the model was tasked with approximation, I found that it performed quite poorly compared to the approximations given by the solutions. It missed nearly every single calculation and formula derivation, and it had trouble analyzing multimodal context in the form of the figures and table. I believe the labels on the graph were slightly small, so they were not readable by the model. However, the model successfully skipped the problems which did not require a solution, meaning it did analyze the given context or at least attempt to.</paragraph><paragraph><italic>Problem 6:</italic> In this problem, I asked Llama 4 to solve each part step by step. I believe by this time, the model was experiencing context rot as it frequently provided short responses that I had to reprompt with screenshots of the problem part (even though I had provided a pdf earlier). It generally gave correct answers, but they were not as verbose as the solutions. The answer to part a was only halfway correct. For part d, it did not consider the variations on the basic MAML approach.</paragraph><paragraph>Overall, the model performed ~62.5% accuracy, and it mainly missed questions later in the pdf or questions requiring significant calculation and approximation.</paragraph><file url=\"https://static.us.edusercontent.com/files/UVlpPTLBEEeap7wlrjOQfZHj\" filename=\"special_participation_A_cs182_llama_4.pdf\"/><paragraph/></document>",
            "links": [
                "https://app.chathub.gg/chat/cloud-llama4?utm_source=models"
            ],
            "attachments": [],
            "created_at": "2025-12-08T10:03:33.356926+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427837,
            "author": "Diana Kohr",
            "project_title": "Special Participation A: Gemini 2.5 Flash on Homework 1",
            "post_body": "I used Gemini 2.5 Flash to answer HW 1 written problems. \n\nConversation: https://gemini.google.com/share/11b5f1b89778\n\nAnnotated: https://drive.google.com/file/d/1vGRWvLGliMGdQhvNDdYq0SKYC575tPdd/view?usp=sharing\n\nSummary: Gemini was able to one-shot a majority of the problems. The only issues were minor misinterpretations of the problem statement (notably, the interpretation of the error factor in 1b). Gemini did a good job of justifying each step in problems that required many sequential equivalences. One issue: Gemini tended to forget that it was solving problems from the provided document, sometimes coming up with its own problem to solve. At the end, I tried to see if Gemini would be able to add clarifications to its previous responses given the answer key, but it just confirmed that its answers were correct, and didn't yield any improvements. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 2.5 Flash to answer HW 1 written problems. </paragraph><paragraph>Conversation: <link href=\"https://gemini.google.com/share/11b5f1b89778\">https://gemini.google.com/share/11b5f1b89778</link></paragraph><paragraph>Annotated: https://drive.google.com/file/d/1vGRWvLGliMGdQhvNDdYq0SKYC575tPdd/view?usp=sharing</paragraph><paragraph>Summary: Gemini was able to one-shot a majority of the problems. The only issues were minor misinterpretations of the problem statement (notably, the interpretation of the error factor in 1b). Gemini did a good job of justifying each step in problems that required many sequential equivalences. One issue: Gemini tended to forget that it was solving problems from the provided document, sometimes coming up with its own problem to solve. At the end, I tried to see if Gemini would be able to add clarifications to its previous responses given the answer key, but it just confirmed that its answers were correct, and didn't yield any improvements. </paragraph><paragraph/></document>",
            "links": [
                "https://gemini.google.com/share/11b5f1b89778"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:58:55.944225+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427798,
            "author": "Vijay Kethanaboyina",
            "project_title": "Special Participation E: Visualizing LLM Decoding",
            "post_body": "For this participation assignment, I created an interactive LLM Decoding Visualizer that demonstrates how Large Language Models (like GPT-3.5) generate text one token at a time. It allows you to experiment with inference-time parameters in real time to see how they affect the model output.\n\nTry it out for yourself here: https://www.vkethana.com/visualize_decode/\n\nA transcript of my conversation with the model can be found here: https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing. I used Cursor as my IDE for this assignment, and the actual model generations came from Gemini 3 Pro. The model performed well, and aside from a few edge cases it was able to one-shot all prompts I gave it.\n\nClass Concepts Covered:\n\nInference-Time Sampling: Recall that there was a discussion worksheet that covered the various LM sampling techniques. This tool builds off that content.\n\nGreedy Decoding: You can see what happens when the model is forced to always pick the single most likely token (Temperature = 0). There is a special button in the tool allowing you to enable greedy decoding.\n\nTemperature & Top-P: It visualizes how \"temperature\" flattens the probability distribution (making the model more creative/random) or sharpens it (making it more deterministic). The tool also gives you control over the value of p used for top-p sampling.\n\nTo use the interactive features, you'll need to provide your own OpenAI API key (due to inference costs, I am unable to host the model directly on my personal website). If you'd prefer not to use your API key, you're welcome to watch a video demo of the tool here: https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view",
            "content_xml": "<document version=\"2.0\"><paragraph>For this participation assignment, I created an interactive LLM Decoding Visualizer that demonstrates how Large Language Models (like GPT-3.5) generate text one token at a time. It allows you to experiment with inference-time parameters in real time to see how they affect the model output.</paragraph><paragraph>Try it out for yourself here: <link href=\"https://www.vkethana.com/visualize_decode/\">https://www.vkethana.com/visualize_decode/</link></paragraph><paragraph>A transcript of my conversation with the model can be found here: <link href=\"https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing\">https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing</link>. I used Cursor as my IDE for this assignment, and the actual model generations came from Gemini 3 Pro. The model performed well, and aside from a few edge cases it was able to one-shot all prompts I gave it.</paragraph><paragraph>Class Concepts Covered:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Inference-Time Sampling</bold>: Recall that there was a discussion worksheet that covered the various LM sampling techniques. This tool builds off that content.</paragraph></list-item><list-item><paragraph><bold>Greedy Decoding:</bold> You can see what happens when the model is forced to always pick the single most likely token (Temperature = 0). There is a special button in the tool allowing you to enable greedy decoding.</paragraph></list-item><list-item><paragraph><bold>Temperature &amp; Top-P:</bold> It visualizes how \"temperature\" flattens the probability distribution (making the model more creative/random) or sharpens it (making it more deterministic). The tool also gives you control over the value of <italic>p</italic> used for top-p sampling.</paragraph></list-item></list><paragraph>To use the interactive features, you'll need to provide your own OpenAI API key (due to inference costs, I am unable to host the model directly on my personal website). If you'd prefer not to use your API key, you're welcome to watch a video demo of the tool here: <link href=\"https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view\">https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view</link></paragraph></document>",
            "links": [
                "https://www.vkethana.com/visualize_decode/",
                "https://drive.google.com/file/d/1Ie75FGR4iAvZ4KIRmQxlilKTIGN9h1RR/view?usp=sharing",
                "https://drive.google.com/file/d/1gGQwGiIx12-OZ_mrhktIW8nObmyv7dYb/view"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:55:08.583548+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427672,
            "author": "Keshab Agarwal",
            "project_title": "Special Participation A: Claude Opus 4.5 with Extended Thinking on HW10",
            "post_body": "I experimented with Claude Opus 4.5 using Extended Thinking on HW10, and the experience was, not surprisingly, great. I provided it with screenshots of each problem, along with the full FaceNet paper PDF from arXiv for reference. Claude handled the input flawlessly: it read every question accurately, interpreted the diagrams and text without misidentification, and produced step-by-step reasoning that aligned with the expected computations.\n\nSomething impressive was its ability to parse the research paper correctly and ground its answers in the actual content rather than hallucinating details or making unsupported claims. While a few of the explanations could have been more detailed or expanded with additional intuition, the overall responses were coherent, well structured, and factually correct. In the end, it solved every problem in a single attempt.\n\nHere is the chat:\n\nhttps://claude.ai/share/4655874a-b723-458e-bcbb-481006722865\n\nHere is my annotated pdf:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I experimented with Claude Opus 4.5 using Extended Thinking on HW10, and the experience was, not surprisingly, great. I provided it with screenshots of each problem, along with the full FaceNet paper PDF from arXiv for reference. Claude handled the input flawlessly: it read every question accurately, interpreted the diagrams and text without misidentification, and produced step-by-step reasoning that aligned with the expected computations.</paragraph><paragraph>Something impressive was its ability to parse the research paper correctly and ground its answers in the actual content rather than hallucinating details or making unsupported claims. While a few of the explanations could have been more detailed or expanded with additional intuition, the overall responses were coherent, well structured, and factually correct. In the end, it solved every problem in a single attempt.</paragraph><paragraph>Here is the chat:<break/><break/><link href=\"https://claude.ai/share/4655874a-b723-458e-bcbb-481006722865\">https://claude.ai/share/4655874a-b723-458e-bcbb-481006722865</link></paragraph><paragraph>Here is my annotated pdf:</paragraph><file url=\"https://static.us.edusercontent.com/files/SP5g8OOJlUUSu68kka56AiMx\" filename=\"HW10-ClaudeOpus4.5-ExtendedThinking-Annotated.pdf\"/><paragraph/></document>",
            "links": [
                "https://claude.ai/share/4655874a-b723-458e-bcbb-481006722865"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:40:03.075613+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427600,
            "author": "Tiger Zhang",
            "project_title": "Special Participation B: Kimi 1.5 on HW9 Coding",
            "post_body": "Executive Summary:\n\nI used Kimi 1.5 (specifically the 1.5 version instead of Kimi 2 because Kimi 2 doesn\u2019t seem to have image-understanding capabilities) to do the coding question on homework 9, visualizing BERT.\n\nThis is a special coding question: it doesn\u2019t involve writing any code, but instead involves interpreting the visualizations of GPT2 and BERT.\n\nIn accordance with the spirit of participation B, I evaluated whether or not Kimi 1.5 is able to perform the task in this question (i.e. visualizing and then interpreting the visualization to answer the questions), and the results were disappointing.\n\nResults:\n\nMy first attempt is to let Kimi choose exactly which combinations of layer/head it wants to visualize, and then I would be it\u2019s \u201ctool\u201d to get the visualizations, and then it would draw conclusions from there. However, even after efforts to tune the prompt for this task, Kimi failed to perform this task.\n\nMy next steps were to evaluate how well Kimi can take hints to perform the task of understanding the images. It seemed like Kimi didn\u2019t have the ability to process too many images at the same time and would get very confused for having too many images, and did not know which images to focus on to ask me for the right images. Therefore, I chose good images for Kimi for each of the questions.\n\nAfter the aforementioned change, Kimi\u2019s performance started increasing slowly. Still, towards the beginning, I had to provide significant hints for it to arrive at the correct answer. Kimi\u2019s better performance on later questions may be attributed to it's in-context learning capabilities, as it became more familiar with the task; alternatively, it could also be attributed to the fact that later questions are more \u201cguessable\u201d even if one doesn\u2019t understand the visualizations.\n\nTo see my conversation with Kimi, please look at the following log, where I also annotated in detail what is happening:",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold>:</paragraph><paragraph>I used Kimi 1.5 (specifically the 1.5 version instead of Kimi 2 because Kimi 2 doesn\u2019t seem to have image-understanding capabilities) to do the coding question on homework 9, visualizing BERT.</paragraph><paragraph>This is a special coding question: it doesn\u2019t involve writing any code, but instead involves interpreting the visualizations of GPT2 and BERT.</paragraph><paragraph>In accordance with the spirit of participation B, I evaluated whether or not Kimi 1.5 is able to perform the task in this question (i.e. visualizing and then interpreting the visualization to answer the questions), and the results were disappointing.</paragraph><paragraph>Results:</paragraph><paragraph>My first attempt is to let Kimi choose exactly which combinations of layer/head it wants to visualize, and then I would be it\u2019s \u201ctool\u201d to get the visualizations, and then it would draw conclusions from there. However, even after efforts to tune the prompt for this task, Kimi failed to perform this task.</paragraph><paragraph>My next steps were to evaluate how well Kimi can take hints to perform the task of understanding the images. It seemed like Kimi didn\u2019t have the ability to process too many images at the same time and would get very confused for having too many images, and did not know which images to focus on to ask me for the right images. Therefore, I chose good images for Kimi for each of the questions.</paragraph><paragraph>After the aforementioned change, Kimi\u2019s performance started increasing slowly. Still, towards the beginning, I had to provide significant hints for it to arrive at the correct answer. Kimi\u2019s better performance on later questions may be attributed to it's in-context learning capabilities, as it became more familiar with the task; alternatively, it could also be attributed to the fact that later questions are more \u201cguessable\u201d even if one doesn\u2019t understand the visualizations.</paragraph><paragraph>To see my conversation with Kimi, please look at the following log, where I also annotated in detail what is happening:</paragraph><file url=\"https://static.us.edusercontent.com/files/LycjdVOHGJxSGX9X3hKnWd7b\" filename=\"chat_log.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T09:32:33.716334+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427555,
            "author": "Reyna Liu",
            "project_title": "Special Participation E: Muon",
            "post_body": "For this Special Participation E, I made an interactive Muon tutor using a custom prompt for ChatGPT\u2019s Study Mode. The goal was to turn Muon (Momentum Orthogonalized by Newton\u2013Schulz) into a single coherent story that lines up with the lecture content: starting from Shampoo and semi-orthogonal updates, then moving through Newton\u2013Schulz style iterations, odd polynomials, normalization, and finally the full Muon update rule.\n\nThe tutor is designed to complement pre-lecture or post-lecture reading: instead of passively skimming notes, you interact with the model in a guided way, and it is forced (by the prompt) to:\n\nstay on one narrative arc (the \u201capproximate (UV^\\top)\u201d story),\n\nexplain each subtopic with intuition \u2192 light math \u2192 tiny example \u2192 concept check,\n\nnot move on until you answer its question.\n\nPrompt\n\nYou are my tutor for the Muon optimizer (\u201cMomentum Orthogonalized by Newton\u2013Schulz\u201d) and the optimization ideas behind it in modern deep learning.\n\nI want this to be an interactive tutoring session. In every reply:\n\n- Keep your answer focused and reasonably short (about 3\u20136 short paragraphs).\n\n- Do not move on to the next topic until I say so.\n\n- Always end your message by asking me a specific question (for example: \u201cDoes this make sense?\u201d or a small concept-check question), and then wait for my reply.\n\nThe overall story I want to learn is:\n\nHow Muon approximates an \u201cideal\u201d semi-orthogonal update direction (like what Shampoo would give with SVD), but does it cheaply using Newton\u2013Schulz style iterations and polynomials that operate on singular values, plus a momentum-like accumulator.\n\nPlease organize everything as one coherent narrative, not a bag of tricks.\n\nStep 1: Short big-picture intro\n\nFirst response:\n\n1. In at most 2 short paragraphs, explain:\n\n - What problem Muon is trying to solve:\n\n - Shampoo-style methods want to precondition gradients using information like singular values / curvature, but exact SVD-based updates are too expensive.\n\n - We would like an update direction that behaves like \u201cU V\u1d40\u201d from an SVD, i.e., semi-orthogonal and not dominated by large singular values.\n\n - The core idea of Muon in one or two sentences:\n\n - Muon keeps a momentum-like running matrix, then repeatedly applies a simple polynomial transformation (a Newton\u2013Schulz\u2013style iteration) so that its singular values are pushed toward 1, approximating that semi-orthogonal \u201cU V\u1d40\u201d direction without doing a full SVD.\n\n2. Then give a brief roadmap (4\u20137 bullet points) of the main pieces of the story, all explicitly framed as supporting Muon, for example:\n\n - From \u201coptimizer recipe\u201d with a chosen norm to the idea of spectral norm and semi-orthogonal updates.\n\n - Shampoo and \u201cShampoo without accumulation\u201d as the starting conceptual algorithm.\n\n - Why computing the exact SVD-based direction is too expensive, and why an approximate direction is good enough.\n\n - Newton\u2013Schulz\u2013style iterations as a way to adjust singular values toward 1.\n\n - Odd polynomials that operate on singular values while keeping singular vectors fixed, and why that matters.\n\n - Stability issues: why we need to normalize by something like the Frobenius norm so that singular values start in the right range and iterations don\u2019t blow up.\n\n - The final Muon update: momentum buffer, orthogonalization via polynomial iterations, weight update, and how the choice of polynomial coefficients affects behavior.\n\nEnd your first reply by asking me one short question to check my high-level understanding.\n\nAfter I respond, start with the first item in the roadmap (semi-orthogonal / spectral-norm view). Follow the roadmap in order.\n\nStep 2: For each part of the story\n\nWhen we are on a given part of the roadmap, teach it in four layers, but keep each message compact.\n\n1. Intuition tied to Muon\n\n - In 1\u20132 short paragraphs, explain the idea in plain language and explicitly say how it supports Muon\u2019s overall goal:\n\n - Approximating a well-conditioned, semi-orthogonal update direction.\n\n - Making steps more uniform across directions instead of being dominated by the largest singular value.\n\n - Doing this without paying the full SVD cost.\n\n2. Key formal setup\n\n - Introduce only the minimal notation you need, such as:\n\n - A weight matrix and its gradient.\n\n - The idea that you can factor a matrix into singular vectors and singular values.\n\n - A momentum-like buffer that accumulates gradient information over time.\n\n - A simple iteration that applies a polynomial in the matrix (for example, a combination of a linear term and a cubic term) to reshape singular values.\n\n - Describe what each object means verbally (for example, \u201cthis buffer stores a smoothed version of recent gradients\u201d, \u201cthis transformation tries to make all singular values close to 1 so the matrix behaves like a semi-orthogonal matrix\u201d).\n\n - You may show a very small symbolic expression or a short iteration rule, but keep it high-level and do not dump long formulas.\n\n3. Tiny numerical or conceptual example\n\n - Give one very small example to illustrate the effect:\n\n - For instance, a 2\u00d72 matrix whose singular values are very different, and describe qualitatively what happens when you apply one or two polynomial iterations to it (the large singular value goes down, the small one goes up, etc.).\n\n - Or a toy picture of \u201cbefore\u201d vs. \u201cafter\u201d for singular values, and how that makes the update more uniform across directions.\n\n - Keep this example to a few lines.\n\n4. Quick understanding check\n\n - Ask me 1\u20132 short questions related to this part:\n\n - At least one conceptual \u201cwhy\u201d question (for example: \u201cWhy is it good if all singular values are close to 1?\u201d or \u201cWhy do we want a polynomial that keeps singular vectors but changes singular values?\u201d).\n\n - Optionally, a tiny computational or thought experiment question (for example: \u201cWhat might go wrong if the singular values start out too large before applying the iteration?\u201d).\n\n - Then stop and wait for my answer.\n\nAfter, briefly remind me what the next stop in the Muon story is, and then proceed.\n\nStep 3: Muon-centered wrap-up\n\nWhen I say I\u2019m ready to review or summarize:\n\n- Give a compact summary that keeps Muon at the center, explaining how:\n\n - Starting from an \u201coptimizer recipe\u201d with a chosen norm leads to preferring semi-orthogonal directions (like U V\u1d40).\n\n - Shampoo (and its non-accumulating variant) motivates this direction but is too expensive if done with an exact SVD.\n\n - Newton\u2013Schulz\u2013style polynomial iterations let us approximate \u201creplace all singular values by 1\u201d using only matrix multiplications.\n\n - Normalizing by something like the Frobenius norm ensures the singular values start in a safe range so the iterations stay stable.\n\n - Muon wraps this into a practical algorithm: maintain a momentum buffer, apply a few iterations of a chosen polynomial to orthogonalize it, then use that to update the weights.\n\nThroughout the conversation, keep answers reasonably short, interactive, and always connected back to the central Muon story, so that the whole interaction feels like a focused tutoring session.\n\nLink to conversation:\n\nhttps://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee\n\nAssessment\n\nThe good:\n\nConceptually, the model\u2019s output is very close to the actual lecture storyline. It correctly emphasized:\n\nThe role of (UV^\\top) as the \u201csemi-orthogonal ideal\u201d direction.\n\n\n\nThe connection between Shampoo and this ideal (a hypothetical \u201cShampoo without accumulation\u201d step).\n\n\n\nThe idea that Newton\u2013Schulz\u2013like odd polynomials act as scalar functions on singular values, while preserving the singular vectors.\n\n\n\nThe importance of normalizing the buffer so the polynomial iteration doesn\u2019t blow up or collapse.\n\nI didn\u2019t spot any major conceptual contradictions with the lecture. The main approximations were in the toy numerical examples (e.g., saying a singular value might move from 0.01 to \u201csomething like 0.2-0.5\u201d after one step without actually computing it). That\u2019s not \u201cwrong\u201d in a dangerous way, but it\u2019s clearly hand-wavy.\n\nThe bad:\n\nRepetitive concept checks.\nIt kept asking essentially the same question in slightly different forms: \u201cWhy is it good if singular values are close to 1?\u201d \u201cWhy do we want a well-conditioned update?\u201d \u201cWhy is it useful that singular vectors stay the same?\u201d\nThese questions are reasonable the first time; by the third time, it felt redundant and didn\u2019t add new understanding.\n\n\n\nHand-wavy numbers in examples.\nIn a few places it invented specific numeric values like \u201cafter one step this might be around 0.2-0.5\u201d without actually computing the polynomial. This is minor, but it\u2019s a reminder: whenever it gives specific numbers in these toy examples, treat them as qualitative (direction of change) rather than precise quantitative claims.\n\n\n\nBehavior when the user can\u2019t really answer its questions.\nThe prompt forces it to ask me a \u201cconcept check\u201d every turn, but it doesn\u2019t actually check my answers or detect if I\u2019m confused. In our interaction it basically replied \u201cExactly\u201d to everything and then continued. So if a student can\u2019t answer, or answers something half-baked, the model will not push back on its own. The student has to explicitly tell the model to explain. It\u2019s too \u201cpolite\u201dto be a real grader for students.\n\n\n\nOverall, though, the interaction did not hallucinate big structural facts. The misbehavior was more minor.\n\nHow this could help with learning\n\nIn practice, this tool works well as a pre- or post-lecture companion:\n\nBefore the lecture, we can run through Part 1-3 to get the high-level picture of \u201cwhy semi-orthogonal,\u201d \u201chow Shampoo motivates the ideal,\u201d and \u201cwhy approximate is enough,\u201d so we\u2019re not seeing those ideas for the first time in class.\n\nAfter the lecture, we can use Parts 4-7 to re-derive the Newton\u2013Schulz connection, the odd polynomial behavior, the normalization step, and the final Muon update rule, while the model keeps quizzing us.\n\nIt can function as a self-paced interactive reading that is much closer to our actual lecture content than a random internet explanation. The main caveats are:\n\nBe aware it may ask very similar concept checks multiple times.\n\nTreat any made-up numbers in the tiny examples as qualitative intuition, not exact math.\n\nRemember it doesn\u2019t really grade your answers. If you\u2019re lost, you need to tell it explicitly to slow down or re-explain.\n\nUse it to structure understanding, but verify key equations and details against the lecture itself if you care about full rigor.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this Special Participation E, I made an interactive Muon tutor using a custom prompt for ChatGPT\u2019s Study Mode. The goal was to turn Muon (Momentum Orthogonalized by Newton\u2013Schulz) into a single coherent story that lines up with the lecture content: starting from Shampoo and semi-orthogonal updates, then moving through Newton\u2013Schulz style iterations, odd polynomials, normalization, and finally the full Muon update rule.</paragraph><paragraph>The tutor is designed to complement pre-lecture or post-lecture reading: instead of passively skimming notes, you interact with the model in a guided way, and it is forced (by the prompt) to:</paragraph><list style=\"unordered\"><list-item><paragraph>stay on one narrative arc (the \u201capproximate (UV^\\top)\u201d story),</paragraph></list-item><list-item><paragraph>explain each subtopic with intuition \u2192 light math \u2192 tiny example \u2192 concept check,</paragraph></list-item><list-item><paragraph>not move on until you answer its question.</paragraph></list-item></list><paragraph><bold>Prompt</bold></paragraph><paragraph>You are my tutor for the Muon optimizer (\u201cMomentum Orthogonalized by Newton\u2013Schulz\u201d) and the optimization ideas behind it in modern deep learning.</paragraph><paragraph>I want this to be an interactive tutoring session. In every reply:</paragraph><paragraph>- Keep your answer focused and reasonably short (about 3\u20136 short paragraphs).</paragraph><paragraph>- Do not move on to the next topic until I say so.</paragraph><paragraph>- Always end your message by asking me a specific question (for example: \u201cDoes this make sense?\u201d or a small concept-check question), and then wait for my reply.</paragraph><paragraph>The overall story I want to learn is:</paragraph><paragraph>How Muon approximates an \u201cideal\u201d semi-orthogonal update direction (like what Shampoo would give with SVD), but does it cheaply using Newton\u2013Schulz style iterations and polynomials that operate on singular values, plus a momentum-like accumulator.</paragraph><paragraph>Please organize everything as one coherent narrative, not a bag of tricks.</paragraph><paragraph>Step 1: Short big-picture intro</paragraph><paragraph>First response:</paragraph><paragraph>1. In at most 2 short paragraphs, explain:</paragraph><paragraph> - What problem Muon is trying to solve:</paragraph><paragraph> - Shampoo-style methods want to precondition gradients using information like singular values / curvature, but exact SVD-based updates are too expensive.</paragraph><paragraph> - We would like an update direction that behaves like \u201cU V\u1d40\u201d from an SVD, i.e., semi-orthogonal and not dominated by large singular values.</paragraph><paragraph> - The core idea of Muon in one or two sentences:</paragraph><paragraph> - Muon keeps a momentum-like running matrix, then repeatedly applies a simple polynomial transformation (a Newton\u2013Schulz\u2013style iteration) so that its singular values are pushed toward 1, approximating that semi-orthogonal \u201cU V\u1d40\u201d direction without doing a full SVD.</paragraph><paragraph>2. Then give a brief roadmap (4\u20137 bullet points) of the main pieces of the story, all explicitly framed as supporting Muon, for example:</paragraph><paragraph> - From \u201coptimizer recipe\u201d with a chosen norm to the idea of spectral norm and semi-orthogonal updates.</paragraph><paragraph> - Shampoo and \u201cShampoo without accumulation\u201d as the starting conceptual algorithm.</paragraph><paragraph> - Why computing the exact SVD-based direction is too expensive, and why an approximate direction is good enough.</paragraph><paragraph> - Newton\u2013Schulz\u2013style iterations as a way to adjust singular values toward 1.</paragraph><paragraph> - Odd polynomials that operate on singular values while keeping singular vectors fixed, and why that matters.</paragraph><paragraph> - Stability issues: why we need to normalize by something like the Frobenius norm so that singular values start in the right range and iterations don\u2019t blow up.</paragraph><paragraph> - The final Muon update: momentum buffer, orthogonalization via polynomial iterations, weight update, and how the choice of polynomial coefficients affects behavior.</paragraph><paragraph>End your first reply by asking me one short question to check my high-level understanding.</paragraph><paragraph>After I respond, start with the first item in the roadmap (semi-orthogonal / spectral-norm view). Follow the roadmap in order.</paragraph><paragraph>Step 2: For each part of the story</paragraph><paragraph>When we are on a given part of the roadmap, teach it in four layers, but keep each message compact.</paragraph><paragraph>1. Intuition tied to Muon</paragraph><paragraph> - In 1\u20132 short paragraphs, explain the idea in plain language and explicitly say how it supports Muon\u2019s overall goal:</paragraph><paragraph> - Approximating a well-conditioned, semi-orthogonal update direction.</paragraph><paragraph> - Making steps more uniform across directions instead of being dominated by the largest singular value.</paragraph><paragraph> - Doing this without paying the full SVD cost.</paragraph><paragraph>2. Key formal setup</paragraph><paragraph> - Introduce only the minimal notation you need, such as:</paragraph><paragraph> - A weight matrix and its gradient.</paragraph><paragraph> - The idea that you can factor a matrix into singular vectors and singular values.</paragraph><paragraph> - A momentum-like buffer that accumulates gradient information over time.</paragraph><paragraph> - A simple iteration that applies a polynomial in the matrix (for example, a combination of a linear term and a cubic term) to reshape singular values.</paragraph><paragraph> - Describe what each object means verbally (for example, \u201cthis buffer stores a smoothed version of recent gradients\u201d, \u201cthis transformation tries to make all singular values close to 1 so the matrix behaves like a semi-orthogonal matrix\u201d).</paragraph><paragraph> - You may show a very small symbolic expression or a short iteration rule, but keep it high-level and do not dump long formulas.</paragraph><paragraph>3. Tiny numerical or conceptual example</paragraph><paragraph> - Give one very small example to illustrate the effect:</paragraph><paragraph> - For instance, a 2\u00d72 matrix whose singular values are very different, and describe qualitatively what happens when you apply one or two polynomial iterations to it (the large singular value goes down, the small one goes up, etc.).</paragraph><paragraph> - Or a toy picture of \u201cbefore\u201d vs. \u201cafter\u201d for singular values, and how that makes the update more uniform across directions.</paragraph><paragraph> - Keep this example to a few lines.</paragraph><paragraph>4. Quick understanding check</paragraph><paragraph> - Ask me 1\u20132 short questions related to this part:</paragraph><paragraph> - At least one conceptual \u201cwhy\u201d question (for example: \u201cWhy is it good if all singular values are close to 1?\u201d or \u201cWhy do we want a polynomial that keeps singular vectors but changes singular values?\u201d).</paragraph><paragraph> - Optionally, a tiny computational or thought experiment question (for example: \u201cWhat might go wrong if the singular values start out too large before applying the iteration?\u201d).</paragraph><paragraph> - Then stop and wait for my answer.</paragraph><paragraph>After, briefly remind me what the next stop in the Muon story is, and then proceed.</paragraph><paragraph>Step 3: Muon-centered wrap-up</paragraph><paragraph>When I say I\u2019m ready to review or summarize:</paragraph><paragraph>- Give a compact summary that keeps Muon at the center, explaining how:</paragraph><paragraph> - Starting from an \u201coptimizer recipe\u201d with a chosen norm leads to preferring semi-orthogonal directions (like U V\u1d40).</paragraph><paragraph> - Shampoo (and its non-accumulating variant) motivates this direction but is too expensive if done with an exact SVD.</paragraph><paragraph> - Newton\u2013Schulz\u2013style polynomial iterations let us approximate \u201creplace all singular values by 1\u201d using only matrix multiplications.</paragraph><paragraph> - Normalizing by something like the Frobenius norm ensures the singular values start in a safe range so the iterations stay stable.</paragraph><paragraph> - Muon wraps this into a practical algorithm: maintain a momentum buffer, apply a few iterations of a chosen polynomial to orthogonalize it, then use that to update the weights.</paragraph><paragraph>Throughout the conversation, keep answers reasonably short, interactive, and always connected back to the central Muon story, so that the whole interaction feels like a focused tutoring session.</paragraph><paragraph><bold>Link to conversation:</bold></paragraph><paragraph><link href=\"https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee\"><underline>https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee</underline></link></paragraph><paragraph><bold>Assessment</bold></paragraph><paragraph><bold>The good:</bold></paragraph><paragraph>Conceptually, the model\u2019s output is very close to the actual lecture storyline. It correctly emphasized:</paragraph><list style=\"unordered\"><list-item><paragraph>The role of (UV^\\top) as the \u201csemi-orthogonal ideal\u201d direction.<break/><break/></paragraph></list-item><list-item><paragraph>The connection between Shampoo and this ideal (a hypothetical \u201cShampoo without accumulation\u201d step).<break/><break/></paragraph></list-item><list-item><paragraph>The idea that Newton\u2013Schulz\u2013like odd polynomials act as scalar functions on singular values, while preserving the singular vectors.<break/><break/></paragraph></list-item><list-item><paragraph>The importance of normalizing the buffer so the polynomial iteration doesn\u2019t blow up or collapse.</paragraph></list-item></list><paragraph>I didn\u2019t spot any major conceptual contradictions with the lecture. The main approximations were in the toy numerical examples (e.g., saying a singular value might move from 0.01 to \u201csomething like 0.2-0.5\u201d after one step without actually computing it). That\u2019s not \u201cwrong\u201d in a dangerous way, but it\u2019s clearly hand-wavy.</paragraph><paragraph><bold>The bad:</bold></paragraph><list style=\"ordered\"><list-item><paragraph>Repetitive concept checks.<break/>It kept asking essentially the same question in slightly different forms: \u201cWhy is it good if singular values are close to 1?\u201d \u201cWhy do we want a well-conditioned update?\u201d \u201cWhy is it useful that singular vectors stay the same?\u201d<break/>These questions are reasonable the first time; by the third time, it felt redundant and didn\u2019t add new understanding.<break/><break/></paragraph></list-item><list-item><paragraph>Hand-wavy numbers in examples.<break/>In a few places it invented specific numeric values like \u201cafter one step this might be around 0.2-0.5\u201d without actually computing the polynomial. This is minor, but it\u2019s a reminder: whenever it gives specific numbers in these toy examples, treat them as qualitative (direction of change) rather than precise quantitative claims.<break/><break/></paragraph></list-item><list-item><paragraph>Behavior when the user can\u2019t really answer its questions.<break/>The prompt forces it to ask me a \u201cconcept check\u201d every turn, but it doesn\u2019t actually check my answers or detect if I\u2019m confused. In our interaction it basically replied \u201cExactly\u201d to everything and then continued. So if a student can\u2019t answer, or answers something half-baked, the model will not push back on its own. The student has to explicitly tell the model to explain. It\u2019s too \u201cpolite\u201dto be a real grader for students.<break/><break/></paragraph></list-item></list><paragraph>Overall, though, the interaction did not hallucinate big structural facts. The misbehavior was more minor.</paragraph><paragraph><bold>How this could help with learning</bold></paragraph><paragraph>In practice, this tool works well as a pre- or post-lecture companion:</paragraph><list style=\"unordered\"><list-item><paragraph>Before the lecture, we can run through Part 1-3 to get the high-level picture of \u201cwhy semi-orthogonal,\u201d \u201chow Shampoo motivates the ideal,\u201d and \u201cwhy approximate is enough,\u201d so we\u2019re not seeing those ideas for the first time in class.</paragraph></list-item><list-item><paragraph>After the lecture, we can use Parts 4-7 to re-derive the Newton\u2013Schulz connection, the odd polynomial behavior, the normalization step, and the final Muon update rule, while the model keeps quizzing us.</paragraph></list-item></list><paragraph>It can function as a self-paced interactive reading that is much closer to our actual lecture content than a random internet explanation. The main caveats are:</paragraph><list style=\"unordered\"><list-item><paragraph>Be aware it may ask very similar concept checks multiple times.</paragraph></list-item><list-item><paragraph>Treat any made-up numbers in the tiny examples as qualitative intuition, not exact math.</paragraph></list-item><list-item><paragraph>Remember it doesn\u2019t really grade your answers. If you\u2019re lost, you need to tell it explicitly to slow down or re-explain.</paragraph></list-item><list-item><paragraph>Use it to structure understanding, but verify key equations and details against the lecture itself if you care about full rigor.<break/><break/></paragraph></list-item></list></document>",
            "links": [
                "https://chatgpt.com/share/6933ad42-7bf4-8007-b500-f1bc59851bee"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:27:48.554248+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427549,
            "author": "Reyna Liu",
            "project_title": "Special Participation E: \u00b5P",
            "post_body": "I designed a prompt that turns ChatGPT\u2019s Study Mode into an interactive tutor for the maximal update parameterization (\u00b5P) lecture.\n\nThe goal is to replace a passive pre-lecture/post-lecture reading with an active dialogue that walks through the \u00b5P story in order:\n\nwhy \u00b5P was introduced,\n\n\n\nhow norms and RMS\u2013RMS\u2013style measures are used to control update size,\n\n\n\nhow the outer-product structure of linear-layer gradients simplifies the math,\n\n\n\nhow sign-based updates and width scaling affect update norms,\n\n\n\nhow CLT-style scaling motivates the parameterization,\n\n\n\nand how all of this connects to feature learning vs. lazy training.\n\n\n\nThe prompt enforces short, interactive replies and forces the model to keep \u00b5P as the central theme, instead of dumping a long wall of text.\n\nPrompt\n\nYou are my tutor for maximal update parameterization (\u00b5P) and the optimization ideas around it in modern deep learning.\n\nI want this to be an interactive tutoring session. In every reply:\n\n- Keep your answer focused and reasonably short (roughly 3\u20136 short paragraphs or equivalent).\n\n- Do not move on to the next topic until I say so.\n\n- Always end your message by asking me a specific question (for example: \u201cDoes this make sense?\u201d or a small concept-check question), and then wait for my reply.\n\nThe overall story I want to learn is:\n\nHow \u00b5P is designed so that neural networks of different widths have comparable update behavior, and how all the surrounding concepts (norms, the simple outer-product structure of gradients in linear layers, sign-based updates, learning-rate scaling, CLT-style scaling analogy, and feature-learning conditions) fit into this one story.\n\nPlease organize the material around \u00b5P as one coherent narrative, rather than separate tricks.\n\nStep 1: Very short big-picture intro\n\nFirst response:\n\n- In at most 2 short paragraphs, explain:\n\n - What problem \u00b5P is trying to solve (e.g., transferring learning rates from small to large models, making training behavior less sensitive to width).\n\n - The core idea in one or two sentences (e.g., keeping effective update magnitudes comparable across widths).\n\n- Then give a brief roadmap (4\u20137 bullet points) of the main pieces of the story, all explicitly framed as supporting \u00b5P, for example:\n\n - Controlling update size via norms.\n\n - RMS\u2013RMS-type norms to measure update size across layers.\n\n - Using the outer-product (rank-1 for batch size 1) structure of linear-layer gradients as a simple tool to analyze norms and update sizes.\n\n - How sign-based updates interact with these norms.\n\n - Learning-rate scaling with width (fan-in / fan-out) and how \u00b5P encodes this.\n\n - CLT-style scaling intuition for width limits.\n\n - Feature-learning conditions in wide networks and how \u00b5P targets them.\n\n- End your first reply by asking me one short question to check my high-level understanding. In your next reply (after I respond), start with the first item in the roadmap (controlling update size via norms). Do not ask me to choose the order; follow the roadmap in order.\n\nStep 2: For each part of the story\n\nWhen we are on a given part of the roadmap (for example \u201cRMS\u2013RMS norms and update size\u201d, \u201couter-product gradient structure as a tool\u201d, \u201clearning-rate scaling with width\u201d, or \u201cfeature-learning conditions\u201d), teach it in four layers, but keep each message compact:\n\n1. Intuition tied to \u00b5P\n\n - In 1\u20132 short paragraphs, explain the idea in plain language and explicitly say how it supports the overall \u00b5P goal (making updates comparable across widths / keeping training behavior width-stable / enabling feature learning at large width).\n\n2. Key formal setup and equations\n\n - Introduce the simplest useful mathematical setup: weight matrix W, input x, gradient \u2207_W L, layer width, fan-in, fan-out, etc.\n\n - State the most relevant equations, such as:\n\n - The gradient of a linear layer for a single example having an outer-product form g x^T (rank-1), used mainly as a convenient way to analyze its norms and scaling.\n\n - A reasonable way to measure update size (e.g., some RMS-style norm).\n\n - A simple example of how learning rate might scale with width or fan-in/fan-out to keep that update size roughly constant.\n\n - When appropriate, express conditions like \u201cactivations h_\\ell stay O(1)\u201d and \u201cupdates \\Delta h_\\ell stay O(1) as width grows\u201d, and link that to constraints on \\|W_\\ell\\| and \\|\\Delta W_\\ell\\|.\n\n - Explain the meaning of each symbol in words.\n\n3. Tiny numerical example\n\n - Give one small concrete example with simple numbers (e.g., a 2\u00d73 layer, or doubling the width) to show what changes and how a scaling rule helps keep updates comparable.\n\n - Keep this to a few lines.\n\n4. Quick understanding check\n\n - Ask me 1\u20132 short questions related to this part:\n\n - At least one conceptual (\u201cwhy\u201d) question.\n\n - Optionally one small calculation (e.g., rank of a gradient matrix, or what happens to update size when width doubles without scaling the learning rate).\n\n - Then stop and wait for my answer, instead of answering your own questions.\n\nWhen I indicate that I am done with the current part and ready to move on, proceed to the next item in the roadmap in order, briefly reminding me which part comes next in the \u00b5P story.\n\nStep 3: \u00b5P-centered wrap-up\n\nWhen I say I\u2019m ready to review or summarize:\n\n- Give a compact summary that keeps \u00b5P at the center, explaining how:\n\n - Norms and RMS\u2013RMS-like measures define what it means for updates to be \u201cthe same size\u201d across widths.\n\n - The simple outer-product structure of gradients makes it easy to relate different norms and see how update size scales with width.\n\n - \u00b5P encodes scaling rules so that small and large models see comparable effective updates.\n\n - Feature-learning conditions on h_\\ell and \\Delta h_\\ell motivate \u00b5P\u2019s design choices.\n\n- Propose a small set of practice questions (both conceptual and short derivations) that someone could solve to check their understanding of \u00b5P and the surrounding ideas.\n\n- Then stop and wait for my answer, instead of answering your own questions.\n\nThroughout the conversation, keep answers reasonably short, interactive, and always connected back to the central \u00b5P story, so that the whole interaction feels like a focused tutoring session.\n\nLink to Conversation\n\nhttps://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a\n\nInteraction\n\nMotivation for \u00b5P\n\nThe answer matches the lecture well. The lecture explicitly motivates \u00b5P as a way to choose the \u201cright units\u201d and scaling so that the same hyperparameters work at different widths, and we can search on small models and transfer to large ones. The AI also adds a nice refinement: hyperparameters transfer because effective updates have comparable size. That\u2019s clearly aligned with the RMS\u2013RMS induced norm idea from class.\n\nFrobenius norm\n\nThe high-level contrast is good: Frobenius norm grows with number of parameters, while RMS is more \u201cwidth-invariant\u201d. The lecture also emphasizes using an RMS\u2013RMS induced norm instead of a raw spectral/Frobenius norm so we can have a single scalar that behaves well across layers and widths.\n\nBut the numerical language is sloppy: \u201cdouble the width and the Frobenius norm doubles\u201d is not generally true. In the typical i.i.d. setup, the Frobenius norm grows like (number of parameters)^(0.5), not linearly. \n\nAlso, compared to the lecture, the AI never explicitly mentions that we\u2019re using RMS-RMS as an induced norm that upper-bounds the spectral norm and gives layer-specific effective step sizes. That\u2019s an important part of the lecture that\u2019s missing here.\n\nEffective update size\n\nThis is basically what the lecture is implicitly using when it talks about RMS\u2013RMS induced norms. The lecture goes through induced norms / sub-multiplicativity, whereas the AI jumps straight to this \u201cproduct of RMS\u201d heuristic.\n\nHowever, it never connects back to the more formal induced-norm inequality we actually saw in class. The formal induced-norm framing is missing.\n\nOuter-product / low-rank gradient structure\n\nThis is the key observation: the RMS gradient does not depend on width at all. The outer-product formula is exactly what was derived in the lecture.\n\nThe algebra for Frobenius and RMS norms is basically correct, but it is not exactly the argument in the lecture. In class, the rank-1 structure is mainly used to say rank-1 \u21d2 spectral norm = Frobenius norm, which makes it easy to relate the sign matrix S and its norms, and to design a step size for signSGD/Adam that keeps the RMS-RMS fixed.\n\nThe AI instead focuses on RMS(\u2207W) being width-independent, which is a reasonable extrapolation but not literally what is emphasized in the lecture.\n\nSign-based updates\n\nThe AI is vaguely aligned with the idea of signSGD, but it stays very high-level, and doesn\u2019t connect sign-based updates back to the RMS\u2013RMS induced norm recipe. Not hallucinating, but also not actually teaching the signSGD part of the lecture.\n\nLearning-rate scaling with width\n\nIt\u2019s qualitatively right that learning-rate must depend on fan-in, but the \u20181/d_in\u2019 rule is presented as a universal principle, which is not justified from the lecture notes or the original \u00b5P paper.\n\nCLT analogy\n\nThis is very close to what happens in the lecture. It explicitly recalls the CLT, shows how a scaling factor keeps the limit non-trivial, and then asks if we can do something similar for neural nets / hyperparameters. The derivation is correct and is a nice concrete restatement of Xavier-style reasoning.\n\nFeature-learning\n\nThis matches the spirit of the \u201cconditions for feature learning\u201d notes in the lecture. The AI brings in NTK/lazy-training terminology, which is consistent with the broader literature and explains why those O(1) conditions matter.\n\nOverall story\n\nThis is a nice high-level summary, and aligns with several concrete lines in the notes:\n\nHyperparameter transfer from small to large models.\n\nChoosing the right \u201cunits\u201d / parameterization to make that possible.\n\nConditions for feature learning expressed as O(1) constraints.\n\n\n\nOverall assessment\n\nWhat it does well:\n\nKeeps the \u00b5P story coherent.\n\nRepeats several key ideas: hyperparameter transfer, O(1) activations/updates, width-stable dynamics.\n\nThe outer-product derivation of RMS(\u2207W) are correct and and the CLT variance argument is helpful for intuition.\n\nWhat it doesn\u2019t do well:\n\nQuantitative statements about norm scaling (e.g., \u201cFrobenius norm doubles\u201d) are sloppy and should be re-derived.\n\nThe treatment of learning-rate scaling is oversimplified. It presents \u201clearning rate \u221d 1/d_in\u201d as a universal \u00b5P rule without actually deriving it.\n\n\n\n\nHow I would use it:\n\nI\u2019d use this AI tutor as a conceptual organizer. If I forget the big picture of why \u00b5P exists or how CLT and O(1) conditions fit together, this is a good interactive refresher.\n\n\n\nI would not rely on it for precise hyperparameter scaling formulas or optimizer details; those need to be checked against the actual lecture notes and/or the Yang 2022 \u00b5P paper.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I designed a prompt that turns ChatGPT\u2019s Study Mode into an interactive tutor for the maximal update parameterization (\u00b5P) lecture.</paragraph><paragraph>The goal is to replace a passive pre-lecture/post-lecture reading with an active dialogue that walks through the \u00b5P story in order:</paragraph><list style=\"unordered\"><list-item><paragraph>why \u00b5P was introduced,<break/><break/></paragraph></list-item><list-item><paragraph>how norms and RMS\u2013RMS\u2013style measures are used to control update size,<break/><break/></paragraph></list-item><list-item><paragraph>how the outer-product structure of linear-layer gradients simplifies the math,<break/><break/></paragraph></list-item><list-item><paragraph>how sign-based updates and width scaling affect update norms,<break/><break/></paragraph></list-item><list-item><paragraph>how CLT-style scaling motivates the parameterization,<break/><break/></paragraph></list-item><list-item><paragraph>and how all of this connects to feature learning vs. lazy training.<break/><break/></paragraph></list-item></list><paragraph>The prompt enforces short, interactive replies and forces the model to keep \u00b5P as the central theme, instead of dumping a long wall of text.</paragraph><paragraph><bold>Prompt</bold></paragraph><paragraph>You are my tutor for maximal update parameterization (\u00b5P) and the optimization ideas around it in modern deep learning.</paragraph><paragraph>I want this to be an interactive tutoring session. In every reply:</paragraph><paragraph>- Keep your answer focused and reasonably short (roughly 3\u20136 short paragraphs or equivalent).</paragraph><paragraph>- Do not move on to the next topic until I say so.</paragraph><paragraph>- Always end your message by asking me a specific question (for example: \u201cDoes this make sense?\u201d or a small concept-check question), and then wait for my reply.</paragraph><paragraph>The overall story I want to learn is:</paragraph><paragraph>How \u00b5P is designed so that neural networks of different widths have comparable update behavior, and how all the surrounding concepts (norms, the simple outer-product structure of gradients in linear layers, sign-based updates, learning-rate scaling, CLT-style scaling analogy, and feature-learning conditions) fit into this one story.</paragraph><paragraph>Please organize the material around \u00b5P as one coherent narrative, rather than separate tricks.</paragraph><paragraph>Step 1: Very short big-picture intro</paragraph><paragraph>First response:</paragraph><paragraph>- In at most 2 short paragraphs, explain:</paragraph><paragraph> - What problem \u00b5P is trying to solve (e.g., transferring learning rates from small to large models, making training behavior less sensitive to width).</paragraph><paragraph> - The core idea in one or two sentences (e.g., keeping effective update magnitudes comparable across widths).</paragraph><paragraph>- Then give a brief roadmap (4\u20137 bullet points) of the main pieces of the story, all explicitly framed as supporting \u00b5P, for example:</paragraph><paragraph> - Controlling update size via norms.</paragraph><paragraph> - RMS\u2013RMS-type norms to measure update size across layers.</paragraph><paragraph> - Using the outer-product (rank-1 for batch size 1) structure of linear-layer gradients as a simple tool to analyze norms and update sizes.</paragraph><paragraph> - How sign-based updates interact with these norms.</paragraph><paragraph> - Learning-rate scaling with width (fan-in / fan-out) and how \u00b5P encodes this.</paragraph><paragraph> - CLT-style scaling intuition for width limits.</paragraph><paragraph> - Feature-learning conditions in wide networks and how \u00b5P targets them.</paragraph><paragraph>- End your first reply by asking me one short question to check my high-level understanding. In your next reply (after I respond), start with the first item in the roadmap (controlling update size via norms). Do not ask me to choose the order; follow the roadmap in order.</paragraph><paragraph>Step 2: For each part of the story</paragraph><paragraph>When we are on a given part of the roadmap (for example \u201cRMS\u2013RMS norms and update size\u201d, \u201couter-product gradient structure as a tool\u201d, \u201clearning-rate scaling with width\u201d, or \u201cfeature-learning conditions\u201d), teach it in four layers, but keep each message compact:</paragraph><paragraph>1. Intuition tied to \u00b5P</paragraph><paragraph> - In 1\u20132 short paragraphs, explain the idea in plain language and explicitly say how it supports the overall \u00b5P goal (making updates comparable across widths / keeping training behavior width-stable / enabling feature learning at large width).</paragraph><paragraph>2. Key formal setup and equations</paragraph><paragraph> - Introduce the simplest useful mathematical setup: weight matrix W, input x, gradient \u2207_W L, layer width, fan-in, fan-out, etc.</paragraph><paragraph> - State the most relevant equations, such as:</paragraph><paragraph> - The gradient of a linear layer for a single example having an outer-product form g x^T (rank-1), used mainly as a convenient way to analyze its norms and scaling.</paragraph><paragraph> - A reasonable way to measure update size (e.g., some RMS-style norm).</paragraph><paragraph> - A simple example of how learning rate might scale with width or fan-in/fan-out to keep that update size roughly constant.</paragraph><paragraph> - When appropriate, express conditions like \u201cactivations h_\\ell stay O(1)\u201d and \u201cupdates \\Delta h_\\ell stay O(1) as width grows\u201d, and link that to constraints on \\|W_\\ell\\| and \\|\\Delta W_\\ell\\|.</paragraph><paragraph> - Explain the meaning of each symbol in words.</paragraph><paragraph>3. Tiny numerical example</paragraph><paragraph> - Give one small concrete example with simple numbers (e.g., a 2\u00d73 layer, or doubling the width) to show what changes and how a scaling rule helps keep updates comparable.</paragraph><paragraph> - Keep this to a few lines.</paragraph><paragraph>4. Quick understanding check</paragraph><paragraph> - Ask me 1\u20132 short questions related to this part:</paragraph><paragraph> - At least one conceptual (\u201cwhy\u201d) question.</paragraph><paragraph> - Optionally one small calculation (e.g., rank of a gradient matrix, or what happens to update size when width doubles without scaling the learning rate).</paragraph><paragraph> - Then stop and wait for my answer, instead of answering your own questions.</paragraph><paragraph>When I indicate that I am done with the current part and ready to move on, proceed to the next item in the roadmap in order, briefly reminding me which part comes next in the \u00b5P story.</paragraph><paragraph>Step 3: \u00b5P-centered wrap-up</paragraph><paragraph>When I say I\u2019m ready to review or summarize:</paragraph><paragraph>- Give a compact summary that keeps \u00b5P at the center, explaining how:</paragraph><paragraph> - Norms and RMS\u2013RMS-like measures define what it means for updates to be \u201cthe same size\u201d across widths.</paragraph><paragraph> - The simple outer-product structure of gradients makes it easy to relate different norms and see how update size scales with width.</paragraph><paragraph> - \u00b5P encodes scaling rules so that small and large models see comparable effective updates.</paragraph><paragraph> - Feature-learning conditions on h_\\ell and \\Delta h_\\ell motivate \u00b5P\u2019s design choices.</paragraph><paragraph>- Propose a small set of practice questions (both conceptual and short derivations) that someone could solve to check their understanding of \u00b5P and the surrounding ideas.</paragraph><paragraph>- Then stop and wait for my answer, instead of answering your own questions.</paragraph><paragraph>Throughout the conversation, keep answers reasonably short, interactive, and always connected back to the central \u00b5P story, so that the whole interaction feels like a focused tutoring session.</paragraph><paragraph><bold>Link to Conversation</bold></paragraph><paragraph><link href=\"https://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a\"><underline>https://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a</underline></link></paragraph><paragraph><bold>Interaction</bold></paragraph><list style=\"ordered\"><list-item><paragraph>Motivation for \u00b5P</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>The answer matches the lecture well. The lecture explicitly motivates \u00b5P as a way to choose the \u201cright units\u201d and scaling so that the same hyperparameters work at different widths, and we can search on small models and transfer to large ones. The AI also adds a nice refinement: hyperparameters transfer because effective updates have comparable size. That\u2019s clearly aligned with the RMS\u2013RMS induced norm idea from class.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Frobenius norm</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>The high-level contrast is good: Frobenius norm grows with number of parameters, while RMS is more \u201cwidth-invariant\u201d. The lecture also emphasizes using an RMS\u2013RMS induced norm instead of a raw spectral/Frobenius norm so we can have a single scalar that behaves well across layers and widths.</paragraph></list-item><list-item><paragraph>But the numerical language is sloppy: \u201cdouble the width and the Frobenius norm doubles\u201d is not generally true. In the typical i.i.d. setup, the Frobenius norm grows like (number of parameters)^(0.5), not linearly. </paragraph></list-item><list-item><paragraph>Also, compared to the lecture, the AI never explicitly mentions that we\u2019re using RMS-RMS as an induced norm that upper-bounds the spectral norm and gives layer-specific effective step sizes. That\u2019s an important part of the lecture that\u2019s missing here.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Effective update size</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>This is basically what the lecture is implicitly using when it talks about RMS\u2013RMS induced norms. The lecture goes through induced norms / sub-multiplicativity, whereas the AI jumps straight to this \u201cproduct of RMS\u201d heuristic.</paragraph></list-item><list-item><paragraph>However, it never connects back to the more formal induced-norm inequality we actually saw in class. The formal induced-norm framing is missing.</paragraph></list-item></list><list style=\"ordered\"><list-item><heading level=\"3\">Outer-product / low-rank gradient structure</heading></list-item></list><list style=\"unordered\"><list-item><paragraph>This is the key observation: the RMS gradient does not depend on width at all. The outer-product formula is exactly what was derived in the lecture.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>The algebra for Frobenius and RMS norms is basically correct, but it is not exactly the argument in the lecture. In class, the rank-1 structure is mainly used to say rank-1 \u21d2 spectral norm = Frobenius norm, which makes it easy to relate the sign matrix S and its norms, and to design a step size for signSGD/Adam that keeps the RMS-RMS fixed.</paragraph></list-item><list-item><paragraph>The AI instead focuses on RMS(\u2207W) being width-independent, which is a reasonable extrapolation but not literally what is emphasized in the lecture.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Sign-based updates</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>The AI is vaguely aligned with the idea of signSGD, but it stays very high-level, and doesn\u2019t connect sign-based updates back to the RMS\u2013RMS induced norm recipe. Not hallucinating, but also not actually teaching the signSGD part of the lecture.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Learning-rate scaling with width</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>It\u2019s qualitatively right that learning-rate must depend on fan-in, but the \u20181/d_in\u2019 rule is presented as a universal principle, which is not justified from the lecture notes or the original \u00b5P paper.</paragraph></list-item></list><list style=\"ordered\"><list-item><heading level=\"3\">CLT analogy</heading></list-item></list><list style=\"unordered\"><list-item><paragraph>This is very close to what happens in the lecture. It explicitly recalls the CLT, shows how a scaling factor keeps the limit non-trivial, and then asks if we can do something similar for neural nets / hyperparameters. The derivation is correct and is a nice concrete restatement of Xavier-style reasoning.</paragraph></list-item></list><list style=\"ordered\"><list-item><heading level=\"3\">Feature-learning</heading></list-item></list><list style=\"unordered\"><list-item><paragraph>This matches the spirit of the \u201cconditions for feature learning\u201d notes in the lecture. The AI brings in NTK/lazy-training terminology, which is consistent with the broader literature and explains why those O(1) conditions matter.</paragraph></list-item></list><list style=\"ordered\"><list-item><heading level=\"3\">Overall story</heading></list-item></list><list style=\"unordered\"><list-item><paragraph>This is a nice high-level summary, and aligns with several concrete lines in the notes:</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Hyperparameter transfer from small to large models.</paragraph></list-item><list-item><paragraph>Choosing the right \u201cunits\u201d / parameterization to make that possible.</paragraph></list-item><list-item><paragraph>Conditions for feature learning expressed as O(1) constraints.<break/><break/></paragraph></list-item></list><heading level=\"2\"><bold>Overall assessment</bold></heading><paragraph>What it does well:</paragraph><list style=\"unordered\"><list-item><paragraph>Keeps the \u00b5P story coherent.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Repeats several key ideas: hyperparameter transfer, O(1) activations/updates, width-stable dynamics.</paragraph></list-item><list-item><paragraph>The outer-product derivation of RMS(\u2207W) are correct and and the CLT variance argument is helpful for intuition.</paragraph></list-item></list><paragraph>What it doesn\u2019t do well:</paragraph><list style=\"unordered\"><list-item><paragraph>Quantitative statements about norm scaling (e.g., \u201cFrobenius norm doubles\u201d) are sloppy and should be re-derived.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>The treatment of learning-rate scaling is oversimplified. It presents \u201clearning rate \u221d 1/d_in\u201d as a universal \u00b5P rule without actually deriving it.<break/><break/><break/></paragraph></list-item></list><paragraph><bold>How I would use it:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>I\u2019d use this AI tutor as a conceptual organizer. If I forget the big picture of why \u00b5P exists or how CLT and O(1) conditions fit together, this is a good interactive refresher.<break/><break/></paragraph></list-item><list-item><paragraph>I would not rely on it for precise hyperparameter scaling formulas or optimizer details; those need to be checked against the actual lecture notes and/or the Yang 2022 \u00b5P paper.<break/><break/></paragraph></list-item></list></document>",
            "links": [
                "https://chatgpt.com/share/6933311c-d9fc-8007-bfb6-35c5f7ee8a1a"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:27:00.068242+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427544,
            "author": "Reyna Liu",
            "project_title": "Special Participation B: Claude on hw9",
            "post_body": "Link to conversation:\n\nhttps://claude.ai/share/00a345bb-cd9c-41c1-879c-09aeda6818f9\n\nAlthough the special participation B is about coding, the particular notebook I worked with (Visualizing_BERT.ipynb) was essentially non-coding. All the interesting work was in interpreting attention visualizations and using those interpretations to feed an LLM, not in writing code.\n\nStrategy \n\nI started naively by asking the model to \u201cread\u201d one of the BertViz attention diagrams directly from an image. This immediately exposed a major issue. The model\u2019s vision was extremely unreliable. It confidently described patterns that did not match what I saw in the notebook. For example, it claimed that the word \u201cdog\u201d had the strongest attention to \u201cdog\u201d on the right, while the actual strongest attention was to \u201cThe\u201d. In other words, it was hallucinating a plausible attention map rather than faithfully reporting what was in the picture. Which is understandable, since LLMs\u2019 ability to interpret images is not that good. After this first attempt, I explicitly told it to forget its own image reading and decided I could not treat its visual perception as trustworthy.\n\nFrom that point on, I switched to a different interaction pattern:\n\nI carefully read each visualization myself and converted it into a precise textual description: tokens, layers, heads, what the patterns were, etc.\n\nThe LLM acted as the reasoning engine. Given my textual description, it answered the questions about GPT-2 and BERT attention.\n\nThis setup had an obvious flaw. How well the model did hinged on my ability to accurately describe the visualization. When I forgot to describe the stronger connection between the same words in cell 8, obviously the model could not include that in its answers, since the information was not given. \n\nThere was also a practical bottleneck. Describing all available information was too difficult. There are multiple layers and multiple heads to choose from, plus expanded views of queries and keys. To keep the interaction manageable, I deliberately ignored the vector views and focused only on the attention lines, since most of the problems could be answered from the line patterns alone.\n\nFor the final sub-questions in parts (c) and (d), I made a deliberate choice not to describe the visualizations at all. Those figures would have been extremely cumbersome to encode in text, and the questions themselves were fundamentally conceptual (e.g., \u201cwhat tokens would you expect strong attention between?\u201d). In that setting, I felt that an inaccurate human description might do more harm than good. Instead, I only gave the model the textual setup from the notebook and asked it to reason from its general understanding of attention, rather than from any specific picture.\n\nEvaluation \n\nOnce the model had a clean textual description, its answers were often rich and well-structured. However, I\u2019m not sure how much of this good result should be attributed to very specific descriptions of visualizations. \n\nIn this setting, the main issue was mis-emphasis. For example, in the GPT-2 part, it initially tried to attribute deep linguistic significance to the word \u201cThe\u201d, and I had to push it to reinterpret that as a computational significance of being in position 0, rather than the determiner\u2019s semantics.\n\nThe behavior changed slightly on the last two questions, where I did not describe any visualization at all and simply gave it the textual setup. There, the model leaned purely on its prior knowledge of how attention should behave. It immediately highlighted words that have similar meanings, pairs like \u201chappy\u201d vs. \u201csad\u201d and \u201cI\u201d vs. \u201cI\u201d, and so on, and gave a pretty plausible story about which attention weights would receive large gradients. But it did not incorporate patterns in previous answers in its answer without a direct prompt, such as the special tokens ([CLS] and [SEP]). In other words, when the question was conceptual, its answers were incomplete but not incorrect, even without any grounding in a specific figure. Of course, in these cases, there is no guarantee that its answers match the actual visualization in the notebook. It\u2019s giving a good generic answer, not a picture-specific one.\n\nSynthesis\n\nOverall, this interaction ended up looking less like \u201ccode co-pilot\u201d and more like a division of labor between human perception and LLM reasoning. The LLM was very good at interpreting structured textual summaries of attention patterns, and very bad at extracting those patterns directly from images, which is exactly what you would expect, given how much more mature its language abilities are than its vision. If you let it stare at the picture by itself, it will hallucinate a plausible story. If you constrain it to human descriptions, it becomes a pretty decent analysis assistant that can map those descriptions onto concepts. And for high-level conceptual questions, it can sometimes ignore the visualization entirely and rely on its internal model of how attention should behave, as long as you are comfortable with the fact that those answers are not grounded in the specific figure.\n\nIn that sense, this \u201cnon-coding coding homework\u201d shows that current LLMs are much more reliable as text-based reasoning engines, and that effective human-model cooperation is very important.",
            "content_xml": "<document version=\"2.0\"><paragraph>Link to conversation:</paragraph><paragraph><link href=\"https://claude.ai/share/00a345bb-cd9c-41c1-879c-09aeda6818f9\"><underline>https://claude.ai/share/00a345bb-cd9c-41c1-879c-09aeda6818f9</underline></link></paragraph><paragraph>Although the special participation B is about coding, the particular notebook I worked with (Visualizing_BERT.ipynb) was essentially non-coding. All the interesting work was in interpreting attention visualizations and using those interpretations to feed an LLM, not in writing code.</paragraph><paragraph><bold>Strategy</bold> </paragraph><paragraph>I started naively by asking the model to \u201cread\u201d one of the BertViz attention diagrams directly from an image. This immediately exposed a major issue. The model\u2019s vision was extremely unreliable. It confidently described patterns that did not match what I saw in the notebook. For example, it claimed that the word \u201cdog\u201d had the strongest attention to \u201cdog\u201d on the right, while the actual strongest attention was to \u201cThe\u201d. In other words, it was hallucinating a plausible attention map rather than faithfully reporting what was in the picture. Which is understandable, since LLMs\u2019 ability to interpret images is not that good. After this first attempt, I explicitly told it to forget its own image reading and decided I could not treat its visual perception as trustworthy.</paragraph><paragraph>From that point on, I switched to a different interaction pattern:</paragraph><list style=\"unordered\"><list-item><paragraph>I carefully read each visualization myself and converted it into a precise textual description: tokens, layers, heads, what the patterns were, etc.</paragraph></list-item><list-item><paragraph>The LLM acted as the reasoning engine. Given my textual description, it answered the questions about GPT-2 and BERT attention.</paragraph></list-item></list><paragraph>This setup had an obvious flaw. How well the model did hinged on my ability to accurately describe the visualization. When I forgot to describe the stronger connection between the same words in cell 8, obviously the model could not include that in its answers, since the information was not given. </paragraph><paragraph>There was also a practical bottleneck. Describing all available information was too difficult. There are multiple layers and multiple heads to choose from, plus expanded views of queries and keys. To keep the interaction manageable, I deliberately <bold>ignored the vector views</bold> and focused only on the attention lines, since most of the problems could be answered from the line patterns alone.</paragraph><paragraph>For the final sub-questions in parts (c) and (d), I made a deliberate choice <bold>not</bold> to describe the visualizations at all. Those figures would have been extremely cumbersome to encode in text, and the questions themselves were fundamentally conceptual (e.g., \u201cwhat tokens would you expect strong attention between?\u201d). In that setting, I felt that an inaccurate human description might do more harm than good. Instead, I only gave the model the textual setup from the notebook and asked it to reason from its general understanding of attention, rather than from any specific picture.</paragraph><paragraph><bold>Evaluation</bold> </paragraph><paragraph>Once the model had a clean textual description, its answers were often rich and well-structured. However, I\u2019m not sure how much of this good result should be attributed to very specific descriptions of visualizations. </paragraph><paragraph>In this setting, the main issue was mis-emphasis. For example, in the GPT-2 part, it initially tried to attribute deep linguistic significance to the word \u201cThe\u201d, and I had to push it to reinterpret that as a computational significance of being in position 0, rather than the determiner\u2019s semantics.</paragraph><paragraph>The behavior changed slightly on the last two questions, where I did not describe any visualization at all and simply gave it the textual setup. There, the model leaned purely on its prior knowledge of how attention should behave. It immediately highlighted words that have similar meanings, pairs like \u201chappy\u201d vs. \u201csad\u201d and \u201cI\u201d vs. \u201cI\u201d, and so on, and gave a pretty plausible story about which attention weights would receive large gradients. But it did not incorporate patterns in previous answers in its answer without a direct prompt, such as the special tokens ([CLS] and [SEP]). In other words, when the question was conceptual, its answers were incomplete but not incorrect, even without any grounding in a specific figure. Of course, in these cases, there is no guarantee that its answers match the actual visualization in the notebook. It\u2019s giving a good generic answer, not a picture-specific one.</paragraph><paragraph><bold>Synthesis</bold></paragraph><paragraph>Overall, this interaction ended up looking less like \u201ccode co-pilot\u201d and more like a division of labor between human perception and LLM reasoning. The LLM was very good at interpreting structured textual summaries of attention patterns, and very bad at extracting those patterns directly from images, which is exactly what you would expect, given how much more mature its language abilities are than its vision. If you let it stare at the picture by itself, it will hallucinate a plausible story. If you constrain it to human descriptions, it becomes a pretty decent analysis assistant that can map those descriptions onto concepts. And for high-level conceptual questions, it can sometimes ignore the visualization entirely and rely on its internal model of how attention should behave, as long as you are comfortable with the fact that those answers are not grounded in the specific figure.</paragraph><paragraph>In that sense, this \u201cnon-coding coding homework\u201d shows that current LLMs are much more reliable as text-based reasoning engines, and that effective human-model cooperation is very important.</paragraph></document>",
            "links": [
                "https://claude.ai/share/00a345bb-cd9c-41c1-879c-09aeda6818f9"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:26:14.979546+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427535,
            "author": "Reyna Liu",
            "project_title": "Special Participation A: Qwen on hw11",
            "post_body": "Link to conversation: https://www.qianwen.com/share?shareId=99965dbe-7cb8-4b68-a181-f66d29022d0f\n\nThe model was reasonably good at one-shotting the problems, but it\u2019s still far from trustworthy. It was quite good at high-level conceptual explanations and even symbolic derivations, but it made small but fatal mathematical and numerical mistakes, and almost never flagged its own uncertainty. Getting to fully correct answers usually required some active steering.\n\nOne-shot correctness:\n About 70% of individual sub-questions were essentially correct on the first try, especially the more conceptual ones. Throughout the process, it often gave good reasoning behind its answers.\n\n\n\nFixed within one rounds of feedback:\n Another ~20% could be fixed after a single iteration where I pointed out its mistakes. After the incorrect portion was pointed out, the model did a good job refocusing on that specific portion and fixing the issue, whether it was a mathematical error or a conceptual one. However this required the user to know the ground truth answer to be able to tell the model where things went wrong, which was not feasible sometimes.\n\nStrategy I used to steer the model:\n\nMy main strategy was localizing errors. When something was incorrect, I would point out a specific part where things went wrong and ask it to redo that portion or rewrite the answer with that constraint in mind. If the revised answer still contained other errors, I would then point those out as well. This iterative process usually converged to the correct solution, but only because I was checking against the official answers.\n\nWhere it did well:\n\nLinear algebra (for example the Chinchilla scaling law question was done well, with correct derivations)\n\nConceptual explanations (especially for 6.Soft-Prompting Language Models, where the model one-shot all the sub-questions with clear, coherent explanations)\n\nErrors and hallucinations:\n\nThe main issue is the model gives confident, mostly correct answers with hidden mistakes. For example, in 2(a), the model mentioned similarity with a bag-of-words model, while the problem was asking about a token-by-token model. Interestingly, the model knew the correct answer, and did include it in its output(\u201cSo, it's essentially a token-to-token mapping without any awareness of context or sequence structure\u201d). If it had simply not added the bag-of-words remark, the answer would have been fully correct. Another example is 2(b), where it talked about a matrix being block-diagonal when it was horizontally partitioned. These wrong side-comments did not derail the final conclusion, but they weakened the model\u2019s usefulness as a learning tool, because a student might not know which parts to trust.\n\nMathematically, the model made sloppy arithmetic mistakes, messing up the exponent in problem 5(h) twice, and did not fix the second mistake when the first one was pointed out. Without the user explicitly checking the numbers and forcing it to recompute, it would happily present a numerically incorrect result.\n\nIt also made overconfident statements. In 2(e), it made claims about the read subspace without appropriate qualifications. Despite this, it still managed to reach the correct high-level conclusion that \u201cthe read subspace dimension is at most d_head\u201d. When I later prompted it to tone down the overconfident statement, it also dropped the correct statement entirely. This illustrates a common LLM behavior: it is too eager to agree with the user, sometimes over-editing and discarding correct content when asked to correct itself. This makes adjusting the model\u2019s confidence level the most difficult in my opinion.\n\nIt was also occasionally under-confident. Notably in problem 1, the model said \u201cAt initialization, since A=0 and B=0, the gradients may be zero or very small\u201d, when in fact the gradient is exactly zero in this setup. So it hedged (\u201cmay be\u201d) where the correct answer was deterministic.\n\nOverall, the model can one-shot many questions or get very close, but it often introduces mistakes even in derivations that look careful. It\u2019s not reliable as an automated homework solver, and it\u2019s not even a great tutor unless the user actively engages the model, checks its work, and asks thoughtful, targeted follow-up questions to give the model a chance to fix its mistakes. Without active supervision, it\u2019s very easy to walk away with answers that are wrong.",
            "content_xml": "<document version=\"2.0\"><paragraph>Link to conversation: <link href=\"https://www.qianwen.com/share?shareId=99965dbe-7cb8-4b68-a181-f66d29022d0f\"><underline>https://www.qianwen.com/share?shareId=99965dbe-7cb8-4b68-a181-f66d29022d0f</underline></link></paragraph><paragraph>The model was reasonably good at one-shotting the problems, but it\u2019s still far from trustworthy. It was quite good at high-level conceptual explanations and even symbolic derivations, but it made small but fatal mathematical and numerical mistakes, and almost never flagged its own uncertainty. Getting to fully correct answers usually required some active steering.</paragraph><list style=\"ordered\"><list-item><paragraph>One-shot correctness:<break/> About 70% of individual sub-questions were essentially correct on the first try, especially the more conceptual ones. Throughout the process, it often gave good reasoning behind its answers.<break/><break/></paragraph></list-item><list-item><paragraph>Fixed within one rounds of feedback:<break/> Another ~20% could be fixed after a single iteration where I pointed out its mistakes. After the incorrect portion was pointed out, the model did a good job refocusing on that specific portion and fixing the issue, whether it was a mathematical error or a conceptual one. However this required the user to know the ground truth answer to be able to tell the model where things went wrong, which was not feasible sometimes.</paragraph></list-item></list><paragraph><bold>Strategy I used to steer the model:</bold></paragraph><paragraph>My main strategy was localizing errors. When something was incorrect, I would point out a specific part where things went wrong and ask it to redo that portion or rewrite the answer with that constraint in mind. If the revised answer still contained other errors, I would then point those out as well. This iterative process usually converged to the correct solution, but only because I was checking against the official answers.</paragraph><paragraph><bold>Where it did well:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Linear algebra (for example the Chinchilla scaling law question was done well, with correct derivations)</paragraph></list-item><list-item><paragraph>Conceptual explanations (especially for 6.Soft-Prompting Language Models, where the model one-shot all the sub-questions with clear, coherent explanations)</paragraph></list-item></list><paragraph><bold>Errors and hallucinations:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The main issue is the model gives confident, mostly correct answers with hidden mistakes. For example, in 2(a), the model mentioned similarity with a bag-of-words model, while the problem was asking about a token-by-token model. Interestingly, the model knew the correct answer, and did include it in its output(\u201cSo, it's essentially a token-to-token mapping without any awareness of context or sequence structure\u201d). If it had simply not added the bag-of-words remark, the answer would have been fully correct. Another example is 2(b), where it talked about a matrix being block-diagonal when it was horizontally partitioned. These wrong side-comments did not derail the final conclusion, but they weakened the model\u2019s usefulness as a learning tool, because a student might not know which parts to trust.</paragraph></list-item><list-item><paragraph>Mathematically, the model made sloppy arithmetic mistakes, messing up the exponent in problem 5(h) twice, and did not fix the second mistake when the first one was pointed out. Without the user explicitly checking the numbers and forcing it to recompute, it would happily present a numerically incorrect result.</paragraph></list-item><list-item><paragraph>It also made overconfident statements. In 2(e), it made claims about the read subspace without appropriate qualifications. Despite this, it still managed to reach the correct high-level conclusion that \u201cthe read subspace dimension is at most d_head\u201d. When I later prompted it to tone down the overconfident statement, it also dropped the correct statement entirely. This illustrates a common LLM behavior: it is too eager to agree with the user, sometimes over-editing and discarding correct content when asked to correct itself. This makes adjusting the model\u2019s confidence level the most difficult in my opinion.</paragraph></list-item><list-item><paragraph>It was also occasionally under-confident. Notably in problem 1, the model said \u201cAt initialization, since A=0 and B=0, the gradients may be zero or very small\u201d, when in fact the gradient is exactly zero in this setup. So it hedged (\u201cmay be\u201d) where the correct answer was deterministic.</paragraph></list-item></list><paragraph>Overall, the model can one-shot many questions or get very close, but it often introduces mistakes even in derivations that <italic>look</italic> careful. It\u2019s not reliable as an automated homework solver, and it\u2019s not even a great tutor unless the user actively engages the model, checks its work, and asks thoughtful, targeted follow-up questions to give the model a chance to fix its mistakes. Without active supervision, it\u2019s very easy to walk away with answers that are wrong.</paragraph></document>",
            "links": [
                "https://www.qianwen.com/share?shareId=99965dbe-7cb8-4b68-a181-f66d29022d0f"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:25:31.193131+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427518,
            "author": "Jermaine Lei",
            "project_title": "Special Participation A: ChatGPT 4o on HW 8",
            "post_body": "For this special participation, I used the ChatGPT-4o model to solve the non-coding parts of Homework 8. To start the conversation, I gave the model the full assignment and asked it to act as a \"Deep Learning professor\" who needed to provide \"full solutions, step-by-step.\" I thought this specific instruction would make the model show all of its work.\n\nThe model showed itself to be very accurate and quick. It got the correct answer on the first try for almost all of the problems. This very high one-shot success rate shows that the model has a strong understanding of complex deep learning topics.\n\nHowever, the main problem I ran into was that the model did not follow the format instructions. Even though I asked it to go step-by-step, the model often skipped the detailed logic and just gave the answer. It seemed to prefer being quick and correct rather than being a helpful, step-by-step teacher.\n\nThe most challenging part for the model was in a question about computational complexity. It struggled to properly use the input size variable in its final answer. Specifically, when calculating the time complexity in Big-O notation, the model had a difficult time showing how the total work would scale with n. I had to correct it with follow-up prompts to get it to include this variable correctly.\n\nOverall, the experiment showed that ChatGPT-4o is excellent at finding the right answers to tough academic questions. But it is not a perfect teaching assistant because it often ignores specific instructions on how to explain the answer, and it can struggle with abstract, symbolic math like fully parameterized time complexity.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation, I used the ChatGPT-4o model to solve the non-coding parts of Homework 8. To start the conversation, I gave the model the full assignment and asked it to act as a \"Deep Learning professor\" who needed to provide \"full solutions, step-by-step.\" I thought this specific instruction would make the model show all of its work.</paragraph><paragraph>The model showed itself to be very accurate and quick. It got the correct answer on the first try for almost all of the problems. This very high one-shot success rate shows that the model has a strong understanding of complex deep learning topics.</paragraph><paragraph>However, the main problem I ran into was that the model did not follow the format instructions. Even though I asked it to go step-by-step, the model often skipped the detailed logic and just gave the answer. It seemed to prefer being quick and correct rather than being a helpful, step-by-step teacher.</paragraph><paragraph>The most challenging part for the model was in a question about computational complexity. It struggled to properly use the input size variable in its final answer. Specifically, when calculating the time complexity in Big-O notation, the model had a difficult time showing how the total work would scale with n. I had to correct it with follow-up prompts to get it to include this variable correctly.</paragraph><paragraph>Overall, the experiment showed that ChatGPT-4o is excellent at finding the right answers to tough academic questions. But it is not a perfect teaching assistant because it often ignores specific instructions on how to explain the answer, and it can struggle with abstract, symbolic math like fully parameterized time complexity.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/LKFY4aHfeS6uzmlWdDin6vpf\" filename=\"SpecialParticipationA_ChatGPT-4o_hw8.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T09:23:32.131726+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427489,
            "author": "Imra Dawoodani",
            "project_title": "Special Participation E: Learning Optimization by spotting mistakes in AI generated answers with a custom Gemini Gem",
            "post_body": "I built a custom Gemini gem that teaches optimization concepts by intentionally giving you flawed explanations and guiding you to catch the errors. I'm sharing two versions of the Gem (structured and conversational) plus annotated transcripts showing what worked, what didn't, and where the AI made mistakes I had to catch. I made V2 after I played around with V1 and wasn't satisfied with the learning outcome it produced.\n\nV1: https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharing\nV2: https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharing\n\nAnnotated V1 transcripts:\n\nAnnotated V2 transcript:\n\nMy observations:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I built a custom Gemini gem that teaches optimization concepts by intentionally giving you flawed explanations and guiding you to catch the errors. I'm sharing two versions of the Gem (structured and conversational) plus annotated transcripts showing what worked, what didn't, and where the AI made mistakes I had to catch. I made V2 after I played around with V1 and wasn't satisfied with the learning outcome it produced.</paragraph><paragraph>V1: <link href=\"https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharing\">https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharing</link><break/>V2: <link href=\"https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharing\">https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharing</link></paragraph><paragraph>Annotated V1 transcripts:</paragraph><file url=\"https://static.us.edusercontent.com/files/fyOdPjYRKh3cZF6KYQDYd08c\" filename=\"gemini.google.com-Google Gemini-fpscreenshot (1).pdf\"/><file url=\"https://static.us.edusercontent.com/files/Qu9hv9enrHjqIf6V4pgueUeL\" filename=\"gemini.google.com-Google Gemini-fpscreenshot.pdf\"/><paragraph>Annotated V2 transcript:</paragraph><file url=\"https://static.us.edusercontent.com/files/ZbC4dXX9mfccdFiA8Eb90zvj\" filename=\"gemini.google.com-Google Gemini-fpscreenshot (2).pdf\"/><paragraph>My observations:</paragraph><file url=\"https://static.us.edusercontent.com/files/XTToFU3qMCqp32fDN5IUZ7kf\" filename=\"special participation E - mistaker.pdf\"/><paragraph/></document>",
            "links": [
                "https://gemini.google.com/gem/1nODd0rYIHnHOMosLrhdSIuoGBRyAieKL?usp=sharing",
                "https://gemini.google.com/gem/1osRvc6_mQ1ntQd8hjq7QxOmL38ftyJAT?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:20:15.432576+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427439,
            "author": "Nazar Ospanov",
            "project_title": "Special Participation B: Kimi on Homework 12",
            "post_body": "For Homework 12, I tested Kimi K2 Thinking on the VAE coding exercises. Kimi followed instructions well and demonstrated strong code-generation ability. In fact, it was able to nearly one-shot the entire implementation, including the reparameterization trick in sample_gaussian, which it completed correctly on the first attempt.\n\nThe only notable difficulty occurred in the negative_elbo_bound implementation. Kimi correctly identified the necessary components like KL divergence via kl_normal and the reconstruction term via log_bernoulli_with_logits, but incorrectly summed the terms instead of averaging over the batch, which leads to a scale mismatch in the loss. After prompting, it was able to fix this on a second attempt.\n\nThus, Kimi K2 Thinking is very strong for structured coding tasks and can implement multi-step neural-network logic with minimal guidance. The main weakness observed was a tendency to choose the mathematically correct form of an expression but the wrong reduction (sum vs. mean), which is easy to miss without supervision. Overall, excellent performance with small but correctable mistakes.\n\nHere is annotated log of the conversation:",
            "content_xml": "<document version=\"2.0\"><paragraph>For Homework 12, I tested <bold>Kimi K2 Thinking</bold> on the VAE coding exercises. Kimi followed instructions well and demonstrated strong code-generation ability. In fact, it was able to nearly one-shot the entire implementation, including the reparameterization trick in sample_gaussian, which it completed correctly on the first attempt.</paragraph><paragraph>The only notable difficulty occurred in the negative_elbo_bound implementation. Kimi correctly identified the necessary components like KL divergence via kl_normal and the reconstruction term via log_bernoulli_with_logits, but incorrectly summed the terms instead of averaging over the batch, which leads to a scale mismatch in the loss. After prompting, it was able to fix this on a second attempt.</paragraph><paragraph>Thus, Kimi K2 Thinking is very strong for structured coding tasks and can implement multi-step neural-network logic with minimal guidance. The main weakness observed was a tendency to choose the mathematically correct <italic>form</italic> of an expression but the wrong <italic>reduction</italic> (sum vs. mean), which is easy to miss without supervision. Overall, excellent performance with small but correctable mistakes.</paragraph><paragraph>Here is annotated log of the conversation:</paragraph><file url=\"https://static.us.edusercontent.com/files/S9hahdhqvFoNPFmKjmhFHdFG\" filename=\"HW12_B_notes.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T09:14:56.572866+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427403,
            "author": "Natalie Wei",
            "project_title": "Special Participation C: Refactoring HW10 Q3",
            "post_body": "Overview\n\nAlena Chao and I refactored the code for HW10 Q3, focusing on improving clarity, consistency, and overall code quality. We updated q_summarize_part_1.ipynb according to PEP 8 (general style), PEP 484 (type hints), PEP 257 (docstrings), and Google's Python style guide (overall best practices). The revised notebook is attached below and more details can be found in our linked report.\n\nOur changes include adding detailed docstrings following PEP 257 to most functions, clearly outlining their purpose and expected inputs and outputs. We also corrected indentation in accordance with PEP 8 and enforcing consistent type hinting across the entire notebook. These updates make the code easier to understand for students working through the assignment.\n\nFurther, we identified several sections of overly long and repetitive code, particularly within the testing functions; we refactored these for cleanliness and modularity. To accomplish this, we created additional helper functions for initializing layers and copying weights. We also added new comments indicating the start of each test case , breaking up the dense original logic and improving readability.\n\nReport\n\nLink ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Overview</bold></paragraph><paragraph>Alena Chao and I refactored the code for HW10 Q3, focusing on improving clarity, consistency, and overall code quality. We updated <italic>q_summarize_part_1.ipynb</italic> according to PEP 8 (general style), PEP 484 (type hints), PEP 257 (docstrings), and Google's Python style guide (overall best practices). The revised notebook is attached below and more details can be found in our linked report.</paragraph><paragraph>Our changes include adding detailed docstrings following PEP 257 to most functions, clearly outlining their purpose and expected inputs and outputs. We also corrected indentation in accordance with PEP 8 and enforcing consistent type hinting across the entire notebook. These updates make the code easier to understand for students working through the assignment.</paragraph><paragraph>Further, we identified several sections of overly long and repetitive code, particularly within the testing functions; we refactored these for cleanliness and modularity. To accomplish this, we created additional helper functions for initializing layers and copying weights. We also added new comments indicating the start of each test case , breaking up the dense original logic and improving readability.</paragraph><paragraph><bold>Report</bold></paragraph><paragraph><link href=\"https://drive.google.com/file/d/1CAagqHaEWGcqg9POI9RTk2coa60Oo-mQ/view?usp=sharing\">Link</link> </paragraph><file url=\"https://static.us.edusercontent.com/files/3mwDgWaIijKdbsg0kKnvVhoi\" filename=\"q_summarize_part_1.ipynb\"/></document>",
            "links": [
                "https://drive.google.com/file/d/1CAagqHaEWGcqg9POI9RTk2coa60Oo-mQ/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T09:10:30.194097+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427400,
            "author": "Nazar Ospanov",
            "project_title": "Special Participation A: Gemini Fast on Homework 3",
            "post_body": "I used Gemini Fast to complete the written questions for Homework 3. As in earlier evaluations, I instructed the model to restate each question, give a step-by-step solution, and identify uncertainties. I prompted each question separately to avoid context-window issues. The full annotated trace is shown in my notes .\n\nOverall, Gemini Fast performed well. It solved most derivations on the first attempt, produced clean LaTeX, and often gave explanations as good as or better than the staff solution.\n\nHowever, I observed two consistent weaknesses:\n\nIncorrect assumptions leading to wrong solutions.\n\nGemini sometimes committed early to an interpretation that wasn\u2019t implied by the problem, and the resulting chain-of-thought led to confident but incorrect answers (e.g., Question 5).\n\nHallucination on research-figure interpretation (Question 3).\n\nWhen asked to analyze specific figures and tables from Tensor Programs V and the Spectral Condition paper, Gemini did not answer the actual sub-questions. Instead, it produced generic summaries of the figures and ignored the prompts, showing that Gemini Fast does not reliably ground its answers in visual research content.\n\nThus, Gemini Fast is excellent for computational and mathematical deep-learning questions, but less reliable for conceptual reasoning that depends on precise assumptions or figure-based interpretation. I would recommend it for derivation-heavy tasks, but not for problems requiring careful reading of research-paper visuals.\n\nHere is the annotated log of the conversation:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used <bold>Gemini Fast</bold> to complete the written questions for Homework 3. As in earlier evaluations, I instructed the model to restate each question, give a step-by-step solution, and identify uncertainties. I prompted each question separately to avoid context-window issues. The full annotated trace is shown in my notes .</paragraph><paragraph>Overall, <bold>Gemini Fast performed well</bold>. It solved most derivations on the first attempt, produced clean LaTeX, and often gave explanations as good as or better than the staff solution.</paragraph><paragraph>However, I observed two consistent weaknesses:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Incorrect assumptions leading to wrong solutions.</bold></paragraph><paragraph>Gemini sometimes committed early to an interpretation that wasn\u2019t implied by the problem, and the resulting chain-of-thought led to confident but incorrect answers (e.g., Question 5).</paragraph></list-item><list-item><paragraph><bold>Hallucination on research-figure interpretation (Question 3).</bold></paragraph><paragraph>When asked to analyze specific figures and tables from <italic>Tensor Programs V</italic> and the <italic>Spectral Condition</italic> paper, Gemini did <bold>not</bold> answer the actual sub-questions. Instead, it produced generic summaries of the figures and ignored the prompts, showing that Gemini Fast does not reliably ground its answers in visual research content.</paragraph></list-item></list><paragraph>Thus, Gemini Fast is excellent for computational and mathematical deep-learning questions, but less reliable for conceptual reasoning that depends on precise assumptions or figure-based interpretation. I would recommend it for derivation-heavy tasks, but not for problems requiring careful reading of research-paper visuals.</paragraph><paragraph>Here is the annotated log of the conversation:</paragraph><file url=\"https://static.us.edusercontent.com/files/mvnVlZUAQ7cHBUKXV9vMfzZx\" filename=\"HW3_A_notes.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T09:10:21.658737+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427394,
            "author": "Carolyn Liu",
            "project_title": "Special Participation E: HW0 Prerequisite Content Helper",
            "post_body": "I used the ChatGPT 5.1 Thinking model under study mode to help go over pre-requisite content found in Homework 0. I told the model that they are a helper and the goal is to refresh the content found in homework 0 but now actually solve any of the problems. The first thing the model did was ask how comfortable I was with the pre-requisite content, which I appreciated since it tailored the difficulty of the questions from it. Afterwards, they kept on asking questions and explained why some of my answers were incorrect. I believe this is a good prompt to help students with the linear algebra content and basic ML concepts before diving into Homework 0.\n\nI have attached my conversation and also a good starting prompt for this below:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used the ChatGPT 5.1 Thinking model under study mode to help go over pre-requisite content found in Homework 0. I told the model that they are a helper and the goal is to refresh the content found in homework 0 but now actually solve any of the problems. The first thing the model did was ask how comfortable I was with the pre-requisite content, which I appreciated since it tailored the difficulty of the questions from it. Afterwards, they kept on asking questions and explained why some of my answers were incorrect. I believe this is a good prompt to help students with the linear algebra content and basic ML concepts before diving into Homework 0.</paragraph><paragraph>I have attached my conversation and also a good starting prompt for this below:</paragraph><file url=\"https://static.us.edusercontent.com/files/PTDDF0LMrJFrducr1IRuyFDG\" filename=\"Special Participation E_ HW0 Prerequisite Content Helper.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T09:09:50.529973+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427288,
            "author": "Jerry Xiao",
            "project_title": "Special Participation E: AI-Generated Quiz Tool for lectures",
            "post_body": "Hi everyone,\nFor the AI learning-tools option, I built a small quiz-generator assistant that can help generate exam-style question for you to test your understanding on specific field. I use ChatGPT 5.1 to interact with and use the Project functions to help me generate the problem sets.\n\nHere is a short, simple, clean Ed post for your second interaction (the Diffusion quiz generator).\n This version is minimal and directly hits the assignment requirements.\n\n1. Prompt \n\nI want you to become a quiz generator for me to evaluate my learning progress. \nI want you to generate questions on Generative Model like Diffusion. \nPlease follow the style of the second file to generate the problems. \n[Append lecture note and example question here]\n\nThen I asked questions as:\n\n\u201cGenerate Quiz Set 1.\u201d\n\n\u201cGive me solutions.\u201d\n\n\u201cGenerate Set 2.\u201d\n\n\u201cDraw a picture comparing DDPM and DDIM.\u201d\n\n2. What it do good\n\nIt matched the HW format surprisingly well (short structured questions).\n\nThe explanations were clear and aligned with the lecture.\n\nThe DDPM vs DDIM diagram was helpful for intuition.\n\n3. What it do bad\n\nSometimes it added extra comments not in the lecture.\n\nIt was a bit too confident in referencing lecture page numbers.\n\nSketches were descriptive, not actual images (which is fine for learning but not literal HW format).\n\nYou can use this way to quiz yourself before homework/exams, get practice problems instantly, ask for more sets at different difficulty levels.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,<break/>For the AI learning-tools option, I built a small <bold>quiz-generator assistant</bold> that can help generate exam-style question for you to test your understanding on specific field. I use ChatGPT 5.1 to interact with and use the Project functions to help me generate the problem sets.</paragraph><paragraph>Here is a <bold>short, simple, clean Ed post</bold> for your second interaction (the Diffusion quiz generator).<break/> This version is minimal and directly hits the assignment requirements.</paragraph><paragraph>1. Prompt </paragraph><pre>I want you to become a quiz generator for me to evaluate my learning progress. \nI want you to generate questions on Generative Model like Diffusion. \nPlease follow the style of the second file to generate the problems. \n[Append lecture note and example question here]</pre><paragraph>Then I asked questions as:</paragraph><list style=\"unordered\"><list-item><paragraph>\u201cGenerate Quiz Set 1.\u201d</paragraph></list-item><list-item><paragraph>\u201cGive me solutions.\u201d</paragraph></list-item><list-item><paragraph>\u201cGenerate Set 2.\u201d</paragraph></list-item><list-item><paragraph>\u201cDraw a picture comparing DDPM and DDIM.\u201d</paragraph></list-item></list><paragraph>2. What it do good</paragraph><list style=\"unordered\"><list-item><paragraph>It matched the HW format surprisingly well (short structured questions).</paragraph></list-item><list-item><paragraph>The explanations were clear and aligned with the lecture.</paragraph></list-item><list-item><paragraph>The DDPM vs DDIM diagram was helpful for intuition.</paragraph></list-item></list><paragraph>3. What it do bad</paragraph><list style=\"unordered\"><list-item><paragraph>Sometimes it added extra comments not in the lecture.</paragraph></list-item><list-item><paragraph>It was a bit too confident in referencing lecture page numbers.</paragraph></list-item><list-item><paragraph>Sketches were descriptive, not actual images (which is fine for learning but not literal HW format).</paragraph></list-item></list><paragraph>You can use this way to quiz yourself before homework/exams, get practice problems instantly, ask for more sets at different difficulty levels.</paragraph><file url=\"https://static.us.edusercontent.com/files/tesuegU502lGWS0leYQGdy7X\" filename=\"gpt_interaction_2.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T08:57:19.086591+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427284,
            "author": "Joshua Lu",
            "project_title": "Special Participation E: Homework Checker and Mistake Summarizer",
            "post_body": "When going over homework, one of the most important things to do is to list out all the mistakes and make sure not to do that again. For this special participation, I created a pipeline to 1) check the homework and make a list of things that are wrong and 2) make a summary of the mistakes, areas of improvement, areas of strength, and a list of potential reminders on what to be careful of. I used to do this manually when studying for finals in the past, so having an LLM do this would streamline the process.\n\nThe first step is to have the LLM correct the homework. For this, I used Gemini 3 Pro (With Thinking), and I sent the model a pdf of my handwritten homework solutions and a pdf of the official staff solutions. I tried this out with both Homework 9 and Homework 0. Homework 9 contains a lot more conceptual questions while Homework 0 contains a lot more math questions. This will let me test how well the model can grade and analyze each one.\n\nThe model actually did pretty well for most of Homework 9. I purposefully left a few mistakes to see if Gemini can catch it, and surprisingly, it did for all of them. In fact, for one of the questions, I made an arithmetic error that doesn't affect my final answer, but Gemini was still able to catch it, despite my work being handwritten. It's definitely really good at catching these small details. However, for the last question, Question 6, the problem itself required complexity calculations, and my work was completely off, yet Gemini did not note that and assumed I was just misreading the problem. That was when I got suspicious that maybe the model isn't great at more complex, mathematical homeworks.\n\nBefore moving on to the next homework, I also prompted the model to produce a list of my mistakes, areas of improvement, areas of strength, and things to watch out for when taking an exam. I wouldn't say it did amazing on this, but some of the information it gave was still useful. For things to watch out for, that part was not great. All the information it generated was very general and not very helpful, so I tried re-prompting, and it only got a bit better.\n\n\n\nI also tried out this approach with Homework 0, and just as before, it was able to identify my mistakes very well. It found that I solved the first few questions very well, and that I only messed up later on for the last question. However, for the very last question that required a lot of math, it wasn't really able to analyze my work well, and diff it from what is given in the official solution. And just as before, it was able to give a solid checklist of mistakes, things to improve on, and things I should watch out for, but the information is still a bit too general. It could be useful for last-minute prep.\n\n\n\nThere are definitely limitations with using LLM to check homework and analyze hand-written work. It did perform better than I expected, as giving it a pdf, it was able to analyze everything in a single go and identify most things correctly. However, this type of LLM approach should still definitely be used in conjunction with manually going over the homework, but I think it's nevertheless helpful.\n\n\n\nAnnotated Trace: https://drive.google.com/file/d/1CeAMUfZ0uiBXgAkjJxPPa1OtjwzVH0GK/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>When going over homework, one of the most important things to do is to list out all the mistakes and make sure not to do that again. For this special participation, I created a pipeline to 1) check the homework and make a list of things that are wrong and 2) make a summary of the mistakes, areas of improvement, areas of strength, and a list of potential reminders on what to be careful of. I used to do this manually when studying for finals in the past, so having an LLM do this would streamline the process.</paragraph><paragraph>The first step is to have the LLM correct the homework. For this, I used Gemini 3 Pro (With Thinking), and I sent the model a pdf of my handwritten homework solutions and a pdf of the official staff solutions. I tried this out with both Homework 9 and Homework 0. Homework 9 contains a lot more conceptual questions while Homework 0 contains a lot more math questions. This will let me test how well the model can grade and analyze each one.</paragraph><paragraph>The model actually did pretty well for most of Homework 9. I purposefully left a few mistakes to see if Gemini can catch it, and surprisingly, it did for all of them. In fact, for one of the questions, I made an arithmetic error that doesn't affect my final answer, but Gemini was still able to catch it, despite my work being handwritten. It's definitely really good at catching these small details. However, for the last question, Question 6, the problem itself required complexity calculations, and my work was completely off, yet Gemini did not note that and assumed I was just misreading the problem. That was when I got suspicious that maybe the model isn't great at more complex, mathematical homeworks.</paragraph><paragraph>Before moving on to the next homework, I also prompted the model to produce a list of my mistakes, areas of improvement, areas of strength, and things to watch out for when taking an exam. I wouldn't say it did amazing on this, but some of the information it gave was still useful. For things to watch out for, that part was not great. All the information it generated was very general and not very helpful, so I tried re-prompting, and it only got a bit better.</paragraph><paragraph/><paragraph>I also tried out this approach with Homework 0, and just as before, it was able to identify my mistakes very well. It found that I solved the first few questions very well, and that I only messed up later on for the last question. However, for the very last question that required a lot of math, it wasn't really able to analyze my work well, and diff it from what is given in the official solution. And just as before, it was able to give a solid checklist of mistakes, things to improve on, and things I should watch out for, but the information is still a bit too general. It could be useful for last-minute prep.</paragraph><paragraph/><paragraph>There are definitely limitations with using LLM to check homework and analyze hand-written work. It did perform better than I expected, as giving it a pdf, it was able to analyze everything in a single go and identify most things correctly. However, this type of LLM approach should still definitely be used in conjunction with manually going over the homework, but I think it's nevertheless helpful.</paragraph><paragraph/><paragraph>Annotated Trace: https://drive.google.com/file/d/1CeAMUfZ0uiBXgAkjJxPPa1OtjwzVH0GK/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T08:56:47.517833+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427268,
            "author": "Joshua Lu",
            "project_title": "Special Participation E: Multi-Level Discussion Summarizer and Key Notes Extractor with Gemini 3 Pro",
            "post_body": "I always want to make sure that I have all my notes in one place, and one additional source of very useful information is the Discussion. Discussion covers a lot of content, some of them being new content as well, and the information covered in discussion definitely belongs in the notes. For this special participation, I will specifically be working with Discussion 10 (Transformers). The goal of this special participation is to extract the key concepts from the discussion worksheet in note form, but with a twist: The notes should have two section, a main key concepts section and a second deep-dive section. This summary should include details that go beyond what can be found in the discussion and should be a comprehensive review guide.\n\nI used Gemini 3 Pro (With Thinking) for this special participation. My process is the following: to start off, I gave the model a simple prompt with my goal:\n\n\"Summarize the key learning concepts in Discussion 10 on Transformers. Provide the key learning concepts in bullet-point form. Make sure to emphasize what is important to know. This first part should be more general, main ideas.\n\nThen, make a second section where you go deeper into each concept and again provide a list of the key details.\"\n\nThrough this, the model gave a basic summary which was not detailed enough. Then, through an iterative process, I improved the summary of the discussion by asking the model about specific details that comes from the discussion. For Discussion 10 specifically, this included the math for RoPE and the complexity derivations for self-attention and cross-attention. After a few iterations, the model learned about the specific types of details I was looking for and at the end, I asked it to regenerate the summary in a form I can paste into my notes. It's clear from my experiment that the model cannot easily one-shot a good enough summary for me to use, so repeated prompting is necessary to get something useful.\n\nThe good part about this model was that it generally got everything correct. Since the goal is to summarize and review information, it did not hallucinate, and I verified the information looks good. However, one issue of using the chat interface is that the formatting isn't great. Each time I want a new summary, the model has to regenerate it entirely, and the chat log gets very messy.\n\nAfter I got my summary, I then had the model look through the homework and indicate which concepts I should already know based on the discussion, and which concepts I should review in preparation for the homework. This multi-level summary is very useful for me to not just look back later on to review important information from discussion but also help me prepare to do the homework in a setting where I don't need to constantly refer back to notes.\n\n\n\nHere is the trace without annotations: https://gemini.google.com/share/5db1aec72092\n\nHere is the trace with annotations: https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I always want to make sure that I have all my notes in one place, and one additional source of very useful information is the Discussion. Discussion covers a lot of content, some of them being new content as well, and the information covered in discussion definitely belongs in the notes. For this special participation, I will specifically be working with Discussion 10 (Transformers). The goal of this special participation is to extract the key concepts from the discussion worksheet in note form, but with a twist: The notes should have two section, a main key concepts section and a second deep-dive section. This summary should include details that go beyond what can be found in the discussion and should be a comprehensive review guide.</paragraph><paragraph>I used Gemini 3 Pro (With Thinking) for this special participation. My process is the following: to start off, I gave the model a simple prompt with my goal:</paragraph><paragraph>\"Summarize the key learning concepts in Discussion 10 on Transformers. Provide the key learning concepts in bullet-point form. Make sure to emphasize what is important to know. This first part should be more general, main ideas.</paragraph><paragraph>Then, make a second section where you go deeper into each concept and again provide a list of the key details.\"</paragraph><paragraph>Through this, the model gave a basic summary which was not detailed enough. Then, through an iterative process, I improved the summary of the discussion by asking the model about specific details that comes from the discussion. For Discussion 10 specifically, this included the math for RoPE and the complexity derivations for self-attention and cross-attention. After a few iterations, the model learned about the specific types of details I was looking for and at the end, I asked it to regenerate the summary in a form I can paste into my notes. It's clear from my experiment that the model cannot easily one-shot a good enough summary for me to use, so repeated prompting is necessary to get something useful.</paragraph><paragraph>The good part about this model was that it generally got everything correct. Since the goal is to summarize and review information, it did not hallucinate, and I verified the information looks good. However, one issue of using the chat interface is that the formatting isn't great. Each time I want a new summary, the model has to regenerate it entirely, and the chat log gets very messy.</paragraph><paragraph>After I got my summary, I then had the model look through the homework and indicate which concepts I should already know based on the discussion, and which concepts I should review in preparation for the homework. This multi-level summary is very useful for me to not just look back later on to review important information from discussion but also help me prepare to do the homework in a setting where I don't need to constantly refer back to notes.</paragraph><paragraph/><paragraph>Here is the trace without annotations: <link href=\"https://gemini.google.com/share/5db1aec72092\">https://gemini.google.com/share/5db1aec72092</link></paragraph><paragraph>Here is the trace with annotations: <link href=\"https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing\">https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing</link></paragraph></document>",
            "links": [
                "https://gemini.google.com/share/5db1aec72092",
                "https://drive.google.com/file/d/18umCOjsk8ATIR5HsZQKgECIUwoOZNbE7/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T08:54:18.005087+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427241,
            "author": "Anshul Verma",
            "project_title": "Special Participation B: GPT 5.1 on HW 0",
            "post_body": "Chat History: https://chatgpt.com/share/6935ebc1-4214-800e-b0e8-93e9889d481d\n\nAnnotation: https://drive.google.com/file/d/15xrxl-aVIQQQ-fi-atYCIqujloFNIf5T/view?usp=sharing\n\nOverall Performance: The model demonstrated strong proficiency in writing \"Pythonic\" numerical code and producing implementations that were very computationally efficient and correct. However, it lacked intuition regarding training dynamics; while the architecture was correct, the model initially failed to select viable hyperparameters, leading to severe underfitting.\n\nStrategy Used: Rather than immediately correcting the model's poor hyperparameter choices, I allowed it to attempt multiple training runs with its suggested values to demonstrate the failure mode (underfitting). I then directed the model to analyze these previous failed attempts to infer why the loss wasn't decreasing. I eventually had to provide the solution for overfitting the 3-Layer Net but it was able to use this to correctly infer hyperparameters to overfit the 5-Layer net.\n\nCode:",
            "content_xml": "<document version=\"2.0\"><paragraph>Chat History: <link href=\"https://chatgpt.com/share/6935ebc1-4214-800e-b0e8-93e9889d481d\">https://chatgpt.com/share/6935ebc1-4214-800e-b0e8-93e9889d481d</link></paragraph><paragraph>Annotation: <link href=\"https://drive.google.com/file/d/15xrxl-aVIQQQ-fi-atYCIqujloFNIf5T/view?usp=sharing\">https://drive.google.com/file/d/15xrxl-aVIQQQ-fi-atYCIqujloFNIf5T/view?usp=sharing</link></paragraph><paragraph><bold>Overall Performance:</bold> The model demonstrated strong proficiency in writing \"Pythonic\" numerical code and producing implementations that were very computationally efficient and correct. However, it lacked intuition regarding training dynamics; while the architecture was correct, the model initially failed to select viable hyperparameters, leading to severe underfitting.</paragraph><paragraph><bold>Strategy Used:</bold> Rather than immediately correcting the model's poor hyperparameter choices, I allowed it to attempt multiple training runs with its suggested values to demonstrate the failure mode (underfitting). I then directed the model to analyze these previous failed attempts to infer why the loss wasn't decreasing. I eventually had to provide the solution for overfitting the 3-Layer Net but it was able to use this to correctly infer hyperparameters to overfit the 5-Layer net.</paragraph><paragraph>Code:</paragraph><file url=\"https://static.us.edusercontent.com/files/djkU6hXuDZzRZ0aDRLNA6wWu\" filename=\"fc_net.py\"/><file url=\"https://static.us.edusercontent.com/files/2ihtBcokYIQlhM6HTP9U9ESe\" filename=\"layers.py\"/><file url=\"https://static.us.edusercontent.com/files/r8By7BY5uP3UyfFKPfuJOh8t\" filename=\"networks.ipynb\"/></document>",
            "links": [
                "https://chatgpt.com/share/6935ebc1-4214-800e-b0e8-93e9889d481d",
                "https://drive.google.com/file/d/15xrxl-aVIQQQ-fi-atYCIqujloFNIf5T/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T08:50:46.673238+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427197,
            "author": "William Li",
            "project_title": "Special Participation E: Minimally Wrong MCQ Diagnostic Learning Tool",
            "post_body": "In this special participation, I create a prompt and test how ChatGPT can generate multiple choice questions with \u201cdistractor\u201d answers that are minimally wrong. This is meant to emulate what I typically found most difficult in MCQ questions, which is when all the wrong answers seem plausible and can only be discerned as wrong by identifying subtle mistakes. To this end, I wanted to try to use LLMs to generate these sorts of questions. Additionally, perhaps the hallucinations that these LLMs so often generate could be useful in creating wrong answers that sound correct.\n\nUpon testing out this prompt and studying technique, I was very satisfied with what the model was able to give me. I asked it several questions spanning different topics (optimization, attention, transformers etc.) along with different modalities (purely conceptual, mathematical, coding), and it was able to give me very succinct MCQs for these. The answer choices it generated were also very good, and it was quite tricky choosing between the answers sometimes. After answering (and getting the question right or wrong), the model was able to give me the reasonings behind each of the answers. For the correct answer, it gave the reasons as to why it is correct, and for the incorrect answers it explained the subtle bug or misconception that led to the error. Overall, I think this was a good learning experience and I would certainly use this to study more concepts before the final rolls around. \n\nAnnotated Trace: ",
            "content_xml": "<document version=\"2.0\"><paragraph>In this special participation, I create a prompt and test how ChatGPT can generate multiple choice questions with \u201cdistractor\u201d answers that are minimally wrong. This is meant to emulate what I typically found most difficult in MCQ questions, which is when all the wrong answers seem plausible and can only be discerned as wrong by identifying subtle mistakes. To this end, I wanted to try to use LLMs to generate these sorts of questions. Additionally, perhaps the hallucinations that these LLMs so often generate could be useful in creating wrong answers that sound correct.</paragraph><paragraph>Upon testing out this prompt and studying technique, I was very satisfied with what the model was able to give me. I asked it several questions spanning different topics (optimization, attention, transformers etc.) along with different modalities (purely conceptual, mathematical, coding), and it was able to give me very succinct MCQs for these. The answer choices it generated were also very good, and it was quite tricky choosing between the answers sometimes. After answering (and getting the question right or wrong), the model was able to give me the reasonings behind each of the answers. For the correct answer, it gave the reasons as to why it is correct, and for the incorrect answers it explained the subtle bug or misconception that led to the error. Overall, I think this was a good learning experience and I would certainly use this to study more concepts before the final rolls around. </paragraph><paragraph>Annotated Trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/sSdCgJfEzSRTNZULjaXMxeod\" filename=\"mcq (1).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T08:45:57.134051+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7427051,
            "author": "Manan Roongta",
            "project_title": "Modal, Free GPU Credits",
            "post_body": "Hey everyone, since the compute portal is limited, wanted to share another option.\n\n\nModal gives $30/month free credits. About ~8hrs on H100/ ~12hrs on A100. If you use their serverless (not notebooks), you only pay for actual compute, i.e. if run a 30 sec task, get charged 30 sec. A group of 4 can get ~30hrs H100 / ~50hrs A100.\n\n\nTo get the full $30:\n\nSign up with GitHub\n\nGo to Usage & Billing, add a payment method (you'll only see $5 without this)\n\nSet \"Workspace budget\" to $30 so you don't get charged past the free credits",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey everyone, since the compute portal is limited, wanted to share another option.</paragraph><paragraph><break/><link href=\"https://modal.com/signup\">Modal</link> gives $30/month free credits. About ~8hrs on H100/ ~12hrs on A100. If you use their serverless (not notebooks), you only pay for actual compute, i.e. if run a 30 sec task, get charged 30 sec. A group of 4 can get ~30hrs H100 / ~50hrs A100.<break/></paragraph><paragraph>To get the full $30:</paragraph><list style=\"number\"><list-item><paragraph><link href=\"https://modal.com/signup\">Sign up</link> with GitHub</paragraph></list-item><list-item><paragraph>Go to Usage &amp; Billing, add a payment method (you'll only see $5 without this)</paragraph></list-item><list-item><paragraph>Set \"Workspace budget\" to $30 so you don't get charged past the free credits</paragraph></list-item></list></document>",
            "links": [
                "https://modal.com/signup",
                "https://modal.com/signup"
            ],
            "attachments": [],
            "created_at": "2025-12-08T08:28:15.968846+11:00",
            "category": "Admin"
        },
        {
            "guid": 7426890,
            "author": "Jerry Xiao",
            "project_title": "Special Participation E: AI Learning Tool using ChatGPT Projects",
            "post_body": "I use the Projects in the ChatGPT 5.1 to help me create a personal study assistant. I used it to help review Lecture 25 (RLVR, sampling from p(x)\u03b1, MCMC acceptance ratio, and the RLVR loss). I\u2019m sharing it here along with a short interaction trace and a few comments on where it worked well or got things wrong. \n\n1. How to start\n\nHere is the prompt I used at the beginning: Hi you will be my guys for reviewing and recapping my Deep Learning Class. I want to first understand the concept of RLVR: Reinforcement Learning with Verifiable Rewards. Can you help me elaborate on them based on the lecture notes? [I append the lecture notes behind so that it can help me with the content in the class]\n\n2. What is good\n\nFrom my interaction trace (see attached file): \n\nIt gave very clear explanations of why sampling from (p(x)^\\alpha) cannot be done with temperature. \n\nIts explanation of the MCMC acceptance ratio was correct and matched the lecture. The summary of the \n\nRLVR figures was helpful for understanding the \u201cwhy RLVR scales\u201d story. \n\nThe explanation of the RLVR loss (reward clipping, stop-gradient) was accurate and easy to understand.\n\n3. What is not good\n\nSometimes it claimed specific page numbers or wording from the lecture that weren\u2019t literally present.\n\nIt occasionally added extra reasoning (e.g., \u201creward model overfitting\u201d) that wasn\u2019t explicitly in the slide.\n\nSome explanations were too confident even when extrapolating beyond the notes.\n\nOverall, it was very useful for learning the concepts as long as I double-checked details against the lecture notes.\n\nThis acts like an interactive pre-lecture or review guide\u2014instead of re-reading slides alone, the AI helps clarify the math, the intuition, and the purpose of each RLVR component.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I use the Projects in the ChatGPT 5.1 to help me create a personal study assistant. I used it to help review <bold>Lecture 25</bold> (RLVR, sampling from p(x)\u03b1, MCMC acceptance ratio, and the RLVR loss). I\u2019m sharing it here along with a short interaction trace and a few comments on where it worked well or got things wrong. </paragraph><paragraph>1. How to start</paragraph><paragraph>Here is the prompt I used at the beginning: Hi you will be my guys for reviewing and recapping my Deep Learning Class. I want to first understand the concept of RLVR: Reinforcement Learning with Verifiable Rewards. Can you help me elaborate on them based on the lecture notes? [I append the lecture notes behind so that it can help me with the content in the class]</paragraph><paragraph>2. What is good</paragraph><paragraph>From my interaction trace (see attached file): </paragraph><list style=\"number\"><list-item><paragraph>It gave <bold>very clear explanations</bold> of why sampling from (p(x)^\\alpha) cannot be done with temperature. </paragraph></list-item><list-item><paragraph>Its explanation of the <bold>MCMC acceptance ratio</bold> was correct and matched the lecture. The summary of the </paragraph></list-item><list-item><paragraph><bold>RLVR figures</bold> was helpful for understanding the \u201cwhy RLVR scales\u201d story. </paragraph></list-item><list-item><paragraph>The explanation of the <bold>RLVR loss</bold> (reward clipping, stop-gradient) was accurate and easy to understand.</paragraph></list-item></list><paragraph>3. What is not good</paragraph><list style=\"number\"><list-item><paragraph>Sometimes it <bold>claimed specific page numbers</bold> or wording from the lecture that weren\u2019t literally present.</paragraph></list-item><list-item><paragraph>It occasionally added extra reasoning (e.g., \u201creward model overfitting\u201d) that wasn\u2019t explicitly in the slide.</paragraph></list-item><list-item><paragraph>Some explanations were <bold>too confident</bold> even when extrapolating beyond the notes.</paragraph></list-item></list><paragraph>Overall, it was very useful for learning the concepts as long as I double-checked details against the lecture notes.</paragraph><paragraph>This acts like an <bold>interactive pre-lecture or review guide</bold>\u2014instead of re-reading slides alone, the AI helps clarify the math, the intuition, and the purpose of each RLVR component.</paragraph><file url=\"https://static.us.edusercontent.com/files/sETCJFNG2037d1jbeXxOoNoM\" filename=\"gpt_interaction_1.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T08:04:57.739288+11:00",
            "category": "Admin"
        },
        {
            "guid": 7426886,
            "author": "Nikhil Mathihalli",
            "project_title": "Special Participation E: Studying Optimizers with NotebookLM",
            "post_body": "For the \"AI-enhanced learning tools\" option, I explored NotebookLM to study the recent lectures on Optimizers. My goal was to create an active alternative to traditional pre-reading/post-reading by having the AI synthesize the lecture recordings, notes, and homework solutions into a cohesive study guide.\n\nI uploaded the YouTube lecture audio recordings alongside the raw lecture notes. NotebookLM was able to \"listen\" to the lectures and cross-reference them with the written notes.\n\nOne of the coolest features was generating visual aids to structure my learning before diving into the weeds.\n\nThe Mind Map: I asked it to generate a mind map immediately1. This gave me a hierarchy of concepts\u2014linking Taylor Expansions to Lazy Training, and Initialization to RMS Norms\u2014which acted as a roadmap for what questions I needed to ask.\n\nThe Slideshow: I asked it to create a slideshow explaining optimizer concepts with visuals. It generated a dense, informed presentation in about 5 minutes. While the visuals were AI-generated, the structure helped me verify if I could explain the concepts linearly.\n\nThrough trial and error, I found a \"Drill-Down\" strategy worked best:\n\nStart Broad: I began with, \"Can you give me an overview of ALL the concepts... generate a roadmap\". This forced the model to establish context.\n\nSelect & Zoom: Instead of letting it ramble, I picked specific nodes from its roadmap: \"Let's start with the lazy training assumption. What is it, and why is it important?\"\n\nComparative Analysis: For distinct lists, I asked for comparative breakdowns: \"Can you go over every initialization... advantages/disadvantages to each?\" This yielded structured tables rather than walls of text.\n\nWhile the high-level summaries were coherent, the model often flattened subtle mathematical distinctions. I have annotated these in the attached PDF, but here are the key warnings:\n\nOversimplifications: The model correctly identified that parameters move by small amounts in training, but it implied that gradient features are fixed features simply because of the assumption. It failed to clarify that this is a specific regime (Kernel/NTK) and not how realistic modern \"feature learning\" regimes work\n\nBias Initialization Depth: The model listed strategies like \"initialize at 0\" or \"0.01\" but completely lacked the reasoning for why (e.g., why zero bias doesn't cause symmetry issues like zero weights do)\n\nMissing Geometric Intuition: When explaining algorithms like SignSGD, it gave the formula but missed the geometric intuition (that infinity norm constraints lead to coordinate-wise updates)\n\nConclusion\n\nNotebookLM is a powerful \"active reading\" partner, especially for synthesizing multimodal sources (audio + text). However, it struggles with the deep \"why\" behind some mathematical proofs. Overall, I think it's extremely useful for learning large amounts of content in a structured yet quick manner.\n\n\n\nTrace:",
            "content_xml": "<document version=\"2.0\"><paragraph>For the \"AI-enhanced learning tools\" option, I explored NotebookLM to study the recent lectures on Optimizers. My goal was to create an active alternative to traditional pre-reading/post-reading by having the AI synthesize the lecture recordings, notes, and homework solutions into a cohesive study guide.</paragraph><paragraph>I uploaded the YouTube lecture audio recordings alongside the raw lecture notes. NotebookLM was able to \"listen\" to the lectures and cross-reference them with the written notes.</paragraph><paragraph>One of the coolest features was generating visual aids to structure my learning before diving into the weeds.</paragraph><paragraph><bold>The Mind Map:</bold> I asked it to generate a mind map immediately1. This gave me a hierarchy of concepts\u2014linking Taylor Expansions to Lazy Training, and Initialization to RMS Norms\u2014which acted as a roadmap for what questions I needed to ask.</paragraph><paragraph><bold>The Slideshow:</bold> I asked it to create a slideshow explaining optimizer concepts with visuals. It generated a dense, informed presentation in about 5 minutes. While the visuals were AI-generated, the structure helped me verify if I could explain the concepts linearly.</paragraph><paragraph>Through trial and error, I found a \"Drill-Down\" strategy worked best:</paragraph><paragraph><bold>Start Broad:</bold> I began with, <italic>\"Can you give me an overview of ALL the concepts... generate a roadmap\".</italic> This forced the model to establish context.</paragraph><paragraph><bold>Select &amp; Zoom:</bold> Instead of letting it ramble, I picked specific nodes from its roadmap: <italic>\"Let's start with the lazy training assumption. What is it, and why is it important?\"</italic></paragraph><paragraph><bold>Comparative Analysis:</bold> For distinct lists, I asked for comparative breakdowns: <italic>\"Can you go over every initialization... advantages/disadvantages to each?\"</italic> This yielded structured tables rather than walls of text.</paragraph><paragraph>While the high-level summaries were coherent, the model often flattened subtle mathematical distinctions. I have annotated these in the attached PDF, but here are the key warnings:</paragraph><paragraph><bold>Oversimplifications:</bold> The model correctly identified that parameters move by small amounts in training, but it implied that gradient features are <italic>fixed</italic> features simply because of the assumption. It failed to clarify that this is a specific regime (Kernel/NTK) and not how realistic modern \"feature learning\" regimes work</paragraph><paragraph><bold>Bias Initialization Depth:</bold> The model listed strategies like \"initialize at 0\" or \"0.01\" but completely lacked the reasoning for <italic>why</italic> (e.g., why zero bias doesn't cause symmetry issues like zero weights do)</paragraph><paragraph><bold>Missing Geometric Intuition:</bold> When explaining algorithms like SignSGD, it gave the formula but missed the geometric intuition (that infinity norm constraints lead to coordinate-wise updates)</paragraph><paragraph><bold>Conclusion</bold></paragraph><paragraph>NotebookLM is a powerful \"active reading\" partner, especially for synthesizing multimodal sources (audio + text). However, it struggles with the deep \"why\" behind some mathematical proofs. Overall, I think it's extremely useful for learning large amounts of content in a structured yet quick manner.</paragraph><paragraph/><paragraph>Trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/QFrg7pTp21fLlcSlbWOR77fQ\" filename=\"NotebookLM Chat.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T08:04:24.974898+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7426845,
            "author": "Carolyn Liu",
            "project_title": "Special Participation E: ChatGPT 5.1 Thinking Study Mode on LoRA",
            "post_body": "\n\nI used the ChatGPT 5.1 Thinking model under the study mode to have it go over LoRA before I start the homework assignment. It did a good job going over the contents within the lecture and asked questions to ensure my understanding. Under study mode, it continues to ask me questions that are directly related to what was taught in lecture without needing reminders or any prompting that I am studying before completing a homework assignment. I would say the model does a good job at proposing questions that solidify basic understanding but does not increase in difficulty to be like a homework or discussion problem. However, it is able to adapt questions based on how well the user understands the content.\n\nI also gave the same starting responses to the ChatGPT 5.1 Thinking model without study mode. While it did give a few questions, it was less interactive and only listed a few questions in the end after going over the lecture content. Instead of asking for an answer to the questions, it states that if the user has any more questions, they can respond.\n\nFor studying the content, using the model under study mode provides a more interactive experience by continuously asking questions and adapting to how well the user understands the content. However, the regular model is suitable for covering all the content in the lecture.\n\nBelow is an annotated version of the conversations I had with both models:",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>I used the ChatGPT 5.1 Thinking model under the study mode to have it go over LoRA before I start the homework assignment. It did a good job going over the contents within the lecture and asked questions to ensure my understanding. Under study mode, it continues to ask me questions that are directly related to what was taught in lecture without needing reminders or any prompting that I am studying before completing a homework assignment. I would say the model does a good job at proposing questions that solidify basic understanding but does not increase in difficulty to be like a homework or discussion problem. However, it is able to adapt questions based on how well the user understands the content.</paragraph><paragraph>I also gave the same starting responses to the ChatGPT 5.1 Thinking model without study mode. While it did give a few questions, it was less interactive and only listed a few questions in the end after going over the lecture content. Instead of asking for an answer to the questions, it states that if the user has any more questions, they can respond.</paragraph><paragraph>For studying the content, using the model under study mode provides a more interactive experience by continuously asking questions and adapting to how well the user understands the content. However, the regular model is suitable for covering all the content in the lecture.</paragraph><paragraph>Below is an annotated version of the conversations I had with both models:</paragraph><file url=\"https://static.us.edusercontent.com/files/yYHjwnDCT893e59r2azDoiPT\" filename=\"Special Participation E_ ChatGPT LoRA Learning.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T07:58:50.489794+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7426644,
            "author": "Ruihan Xia",
            "project_title": "Special Participation E: GPT diagonistic quiz generator for lectures",
            "post_body": "I wanted to design a self-quiz generator I can use to test how well I understand the knowledge learned after lecture. To do this, I uploaded lecture notes and wrote a prompt that asks Chat GPT to produce 5 conceptual questions from a lecture section, each with an answer, a quick intuition, a formal reasoning layer, and an explicit assumption check.\n\nIn the chat with example of lecture 6 & 7, ChatGPT outputed conceptal questions covering RMS norms, maximal update parametrization, spectral-norm-constrained updates, Muon optimizer, and Newton\u2013Schulz iteration. I then asked for related computational examples that involve concrete math and applications to standard problems like linear regression. \n\nHowever, I noticed a few issues. Several explanations essentially copied equations from the lecture slides (e.g., the RMS\u2192RMS norm formula, the Muon spectral-norm optimization step). I think a bit more derivation would be helpful. There are some vague leaps in response as well. In general Chatgpt outputs answers that are more on the conceptual side unless I ask for explicit math. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I wanted to design a self-quiz generator I can use to test how well I understand the knowledge learned after lecture. To do this, I uploaded lecture notes and wrote a prompt that asks Chat GPT to produce 5 conceptual questions from a lecture section, each with an answer, a quick intuition, a formal reasoning layer, and an explicit assumption check.</paragraph><paragraph>In the chat with example of lecture 6 &amp; 7, ChatGPT outputed conceptal questions covering RMS norms, maximal update parametrization, spectral-norm-constrained updates, Muon optimizer, and Newton\u2013Schulz iteration. I then asked for related computational examples that involve concrete math and applications to standard problems like linear regression. </paragraph><paragraph>However, I noticed a few issues. Several explanations essentially copied equations from the lecture slides (e.g., the RMS\u2192RMS norm formula, the Muon spectral-norm optimization step). I think a bit more derivation would be helpful. There are some vague leaps in response as well. In general Chatgpt outputs answers that are more on the conceptual side unless I ask for explicit math. </paragraph><file url=\"https://static.us.edusercontent.com/files/1ybzCcd297wvzg3FnuxiPneI\" filename=\"AI diagnostic quiz.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T07:31:09.895587+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7426623,
            "author": "Vijay Kethanaboyina",
            "project_title": "Special Participation B: Cursor Composer on HW 2 Coding",
            "post_body": "For this assignment, I tackled the coding questions on HW 2 using Cursor Composer, which is a language model specifically designed for software engineering and code generation tasks (released in late October of this year). The IDE I used for this assignment was Cursor, which is the primary way of accessing this model. \n\nThe link to my annotated transcript of my conversation with the model can be found here.\n\nHere is a brief summary of my interactions with the model: it is very strong at code generation  and reasoning. It can definitely one-shot most questions in the homework. However, it is much  less reliable when answers depend on actually seeing plots / running code, and it sometimes overstates what it has \u201clooked at\u201d or \u201crun.\u201d \n\nThe model did very well when the problem was well-specified mathematically and didn\u2019t require actually seeing outputs. Examples:\n\nImplementing SGD+Momentum, RMSProp, Adam in optim.py.\n\nImplementing He initialization, zero initialization, and gradient norm logging.\n\nImplementing gradient ascent step (gd_step), Monte-Carlo smoothing (smoothed_f), finite-difference gradient step, etc.\n\nHowever, when questions explicitly said \u201canswer based on the plot / visualization,\u201d the model often:\n\nAnswered using generic theory rather than the actual plot, even while saying things like:\n\n\u201cReviewing the notebook section with the gradient norm plot\u2026\u201d\n\n\u201cUpdating the answer to match the plot\u2026\u201d\n\nProduced initial answers that didn\u2019t match the actual plots\n\nOnly after being challenged (\u201cAre you sure? That doesn\u2019t match\u2026\u201d) did it admit it had not actually run the code or seen the plot.\n\nTakeaway: although the model capabilities are quite impressive, the outputs still have to be read carefully to make sure it's answering honestly. Additionally, I noticed that it had a tendency to give somewhat verbose responses for conceptual questions, repeating the same idea several times in different language.",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I tackled the coding questions on HW 2 using <bold><link href=\"https://cursor.com/blog/composer\">Cursor Composer</link>,</bold> which is a language model specifically designed for software engineering and code generation tasks (released in late October of this year). The IDE I used for this assignment was Cursor, which is the primary way of accessing this model. </paragraph><paragraph><bold>The link to my annotated transcript of my conversation with the model can be found <link href=\"https://drive.google.com/file/d/1xaGlMW8-i2mHQMyT8q-30EU57GWMT5dK/view?usp=sharing\">here</link>.</bold></paragraph><paragraph>Here is a brief summary of my interactions with the model: it is very strong at code generation  and reasoning. It can definitely one-shot most questions in the homework. However, it is much  less reliable when answers depend on actually seeing plots / running code, and it sometimes overstates what it has \u201clooked at\u201d or \u201crun.\u201d </paragraph><paragraph>The model did very well when the problem was well-specified mathematically and didn\u2019t require actually seeing outputs. Examples:</paragraph><list style=\"unordered\"><list-item><paragraph>Implementing SGD+Momentum, RMSProp, Adam in <code>optim.py</code>.</paragraph></list-item><list-item><paragraph>Implementing He initialization, zero initialization, and gradient norm logging.</paragraph></list-item><list-item><paragraph>Implementing gradient ascent step (<code>gd_step</code>), Monte-Carlo smoothing (<code>smoothed_f</code>), finite-difference gradient step, etc.</paragraph></list-item></list><paragraph>However, when questions explicitly said \u201canswer based on the plot / visualization,\u201d the model often:</paragraph><list style=\"unordered\"><list-item><paragraph>Answered using generic theory rather than the actual plot, even while saying things like:</paragraph><list style=\"unordered\"><list-item><paragraph>\u201cReviewing the notebook section with the gradient norm plot\u2026\u201d</paragraph></list-item><list-item><paragraph>\u201cUpdating the answer to match the plot\u2026\u201d</paragraph></list-item></list></list-item><list-item><paragraph>Produced initial answers that didn\u2019t match the actual plots</paragraph></list-item><list-item><paragraph>Only after being challenged (\u201cAre you sure? That doesn\u2019t match\u2026\u201d) did it admit it had not actually run the code or seen the plot.</paragraph></list-item></list><paragraph>Takeaway: although the model capabilities are quite impressive, the outputs still have to be read carefully to make sure it's answering honestly. Additionally, I noticed that it had a tendency to give somewhat verbose responses for conceptual questions, repeating the same idea several times in different language.</paragraph></document>",
            "links": [
                "https://cursor.com/blog/composer",
                "https://drive.google.com/file/d/1xaGlMW8-i2mHQMyT8q-30EU57GWMT5dK/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T07:28:32.670497+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7426560,
            "author": "Daniel Kao",
            "project_title": "Special Participation A: Deepseek on HW 11",
            "post_body": "Link to the annotated transcript\n\nFor this special participation, I used Deepseek 3.2 in DeepThink mode to solve the written portions of Homework 11. In my initial prompt I gave the model the full context of the entire homework file, and asked it to solve each question one by one, and offered corrections and directions when the LLM got a part wrong. This was not often necessary as Deepseek was able to one-shot the vast majority of the problems here.\n\nMost of the misconceptions or hallucinations in the model are in its numerical calculations and an incorrect assumptions of the givens in a problem. What was interesting was that the Deepseek model seems to actively avoid this sort of numerical calculation error by leaving answers unsimplified, forcing the user to use a deterministic calculation method to compute the final answer. The answers also often displayed notation inconsistencies such as changing variable names. Though the final result was still correct and interpretable, this may not always be the case, especially when the number of variables in a problem is large. \n\nI was particularly intrigued by the model's focus on conciseness, even when given a more abstract question that has a lot of runway for verbosity. This contrasts my experience with other LLMs like Gemini and ChatGPT, which tend to go into great detail about a problem's context and the justification for their answer. This is not to say whether one chatbot is superior, but rather a difference in philosophy: is it better to give an answer that includes more context and detail, to the detriment of interpretability, or is it better to give an answer that is concise and straigthforward, to the detriment of nuance and context?\n\nFinally, I note a mistake I made when prompting the LLM, where I asked for elaboration on the wrong question. Rather than answer the question, the LLM was able to recognize that the question was nonsensical and hypothesized that I had mistyped my question. It then independently reasoned the intended question and answered based on that. To me, this represents a level of resistance to hallucinations, where the model is able to recognize when the framework it is given is faulty, and thus it is best to either not answer, or restructure the question to be well-formed.\n\nLink to LLM trace",
            "content_xml": "<document version=\"2.0\"><paragraph><link href=\"https://drive.google.com/file/d/15xrxl-aVIQQQ-fi-atYCIqujloFNIf5T/view?usp=sharing\">Link to the annotated transcript</link></paragraph><paragraph>For this special participation, I used Deepseek 3.2 in DeepThink mode to solve the written portions of Homework 11. In my initial prompt I gave the model the full context of the entire homework file, and asked it to solve each question one by one, and offered corrections and directions when the LLM got a part wrong. This was not often necessary as Deepseek was able to one-shot the vast majority of the problems here.</paragraph><paragraph>Most of the misconceptions or hallucinations in the model are in its numerical calculations and an incorrect assumptions of the givens in a problem. What was interesting was that the Deepseek model seems to actively avoid this sort of numerical calculation error by leaving answers unsimplified, forcing the user to use a deterministic calculation method to compute the final answer. The answers also often displayed notation inconsistencies such as changing variable names. Though the final result was still correct and interpretable, this may not always be the case, especially when the number of variables in a problem is large. </paragraph><paragraph>I was particularly intrigued by the model's focus on conciseness, even when given a more abstract question that has a lot of runway for verbosity. This contrasts my experience with other LLMs like Gemini and ChatGPT, which tend to go into great detail about a problem's context and the justification for their answer. This is not to say whether one chatbot is superior, but rather a difference in philosophy: is it better to give an answer that includes more context and detail, to the detriment of interpretability, or is it better to give an answer that is concise and straigthforward, to the detriment of nuance and context?</paragraph><paragraph>Finally, I note a mistake I made when prompting the LLM, where I asked for elaboration on the wrong question. Rather than answer the question, the LLM was able to recognize that the question was nonsensical and hypothesized that I had mistyped my question. It then independently reasoned the intended question and answered based on that. To me, this represents a level of resistance to hallucinations, where the model is able to recognize when the framework it is given is faulty, and thus it is best to either not answer, or restructure the question to be well-formed.</paragraph><paragraph><link href=\"https://chat.deepseek.com/share/rmzugw2oy792hur0mi\">Link to LLM trace</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/15xrxl-aVIQQQ-fi-atYCIqujloFNIf5T/view?usp=sharing",
                "https://chat.deepseek.com/share/rmzugw2oy792hur0mi"
            ],
            "attachments": [],
            "created_at": "2025-12-08T07:19:06.910022+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7426411,
            "author": "Jin Ying",
            "project_title": "Special Participation E: Claude Sonnet 4.5 on Diffusion Models",
            "post_body": "I created a Socratic dialogue tool using Claude to learn diffusion models. I gave it our lecture slides; instead of asking it to summarize slides, I explicitly told it to ask me one question at a time, ignore lecture materials temporarily so I can return to it to test my understanding after the conversation, and focus on building intuition rather than explaining formulas.\n\nClaude helped build intuition before introducing math, handled my confusion productively, and when I gave wrong answers it showed me why my reasoning was incomplete. However, it made several technical oversimplifications that need verification, which I annotated in our conversation.\n\nI found it helpful to spend an hour in Socratic dialogue to build intuition and test myself to see if I only understand something partially, annotate anything that seems off, and then verify against what we've learned in lectures and the textbook. This helped me go from memorizing and taking what we learned in the class for granted to actually understanding concepts deeper. But it's not a replacement for rigorous study; I still need to work through derivations and implementations myself to achieve a real understanding.",
            "content_xml": "<document version=\"2.0\"><paragraph>I created a Socratic dialogue tool using Claude to learn diffusion models. I gave it our lecture slides; instead of asking it to summarize slides, I explicitly told it to ask me one question at a time, ignore lecture materials temporarily so I can return to it to test my understanding after the conversation, and focus on building intuition rather than explaining formulas.</paragraph><paragraph>Claude helped build intuition before introducing math, handled my confusion productively, and when I gave wrong answers it showed me why my reasoning was incomplete. However, it made several technical oversimplifications that need verification, which I annotated in our conversation.</paragraph><paragraph>I found it helpful to spend an hour in Socratic dialogue to build intuition and test myself to see if I only understand something partially, annotate anything that seems off, and then verify against what we've learned in lectures and the textbook. This helped me go from memorizing and taking what we learned in the class for granted to actually understanding concepts deeper. But it's not a replacement for rigorous study; I still need to work through derivations and implementations myself to achieve a real understanding.</paragraph><file url=\"https://static.us.edusercontent.com/files/JX86S4sPR4eF5GEeYVpRULOp\" filename=\"Diffusion Models with Claude.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T06:58:46.886153+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7426337,
            "author": "Mishty Dhekial",
            "project_title": "Special Participation B: HW4 with Windsurf",
            "post_body": "I used Windsurf to solve the coding portions of HW 4. It did pretty well, especially on the Designing Hand Filters notebook, given its simplicity. The Edge Detectors notebook needed a bit more prompting from me, but overall still performed well!\n\nQ5: Windsurf successfully one-shotted both parts of the problem. This makes sense given the simplicity of the problems.\n\nQ6: This question required a bit more prompting from me to solve. It was able to properly understand the parameters for the dataset loader, and fill out the initial questions. The only issue it ran to was initially defining $num_workers=2$, but was quickly able to correct the value to 0 when I passed in the error. For the rest of the questions that required hyperparameter tuning, Windsurf required some more help from me. I asked Windsurf to provide me ifferent configurations and sometimes it would provide some configurations that actually performed poorer than the ones it had provided prior. Also, at times, it would try to go offer recommendations past the three parameters we were meant to edit; for example, it tried to introduce weight decay or gradient clipping. However, and for the last question of training the Wide CNN, it was able to provide a configuration in one shot that performed at ~94%. \n\n\n\nOverall, I would say that Windsurf was able to successfully complete both coding parts of this homework with a bit of prompting from my end.\n\n\n\nAttached is the annotated trace for both notebooks:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Windsurf to solve the coding portions of HW 4. It did pretty well, especially on the Designing Hand Filters notebook, given its simplicity. The Edge Detectors notebook needed a bit more prompting from me, but overall still performed well!</paragraph><paragraph>Q5: Windsurf successfully one-shotted both parts of the problem. This makes sense given the simplicity of the problems.</paragraph><file url=\"https://static.us.edusercontent.com/files/2ma17kQMwTZNjagWFel5aSxq\" filename=\"HandDesignFilters-new.ipynb\"/><paragraph>Q6: This question required a bit more prompting from me to solve. It was able to properly understand the parameters for the dataset loader, and fill out the initial questions. The only issue it ran to was initially defining $num_workers=2$, but was quickly able to correct the value to 0 when I passed in the error. For the rest of the questions that required hyperparameter tuning, Windsurf required some more help from me. I asked Windsurf to provide me ifferent configurations and sometimes it would provide some configurations that actually performed poorer than the ones it had provided prior. Also, at times, it would try to go offer recommendations past the three parameters we were meant to edit; for example, it tried to introduce weight decay or gradient clipping. However, and for the last question of training the Wide CNN, it was able to provide a configuration in one shot that performed at ~94%. </paragraph><file url=\"https://static.us.edusercontent.com/files/KWLBCtFvuv3RBnyLXufRjrGj\" filename=\"edge_detection-new.ipynb\"/><paragraph/><paragraph>Overall, I would say that Windsurf was able to successfully complete both coding parts of this homework with a bit of prompting from my end.</paragraph><paragraph/><paragraph>Attached is the annotated trace for both notebooks:</paragraph><file url=\"https://static.us.edusercontent.com/files/g4PQGUoVTeknfFB43IS0F7dV\" filename=\"annotated-special-participation-b.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T06:45:47.451054+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425579,
            "author": "Moxin Tang",
            "project_title": "Special Participation E: Module Review Generator with Multi-Source Integration",
            "post_body": "I extended Jameson's lecture notes generator #301 to create a comprehensive module review tool.\n\nBuilding on the original script's approach of using lecture transcripts + slides with Gemini API, I created module review generator that:\n\nCombines multiple sources: Integrates lecture notes, discussion solutions, and homework problems into a single comprehensive review document\n\nSynthesizes content by topic: Uses Gemini API to organize material thematically rather than chronologically, making it better for exam prep\n\nIncludes source citations: Each concept/problem is tagged with its source (e.g., Lecture 24, Discussion 12 Problem2a, HW 10 Problem1, ...) for easy reference\n\nThe script is easily configurable to combine any set of lectures, discussions, and homeworks for different modules.\n\nExample usage:\n\nI combines Lectures 24-27 + Discussions 12-13 + HW 10, 11, 13 into one study guide which is about generative models and post-training.\n\nsample output in \n\nI think the review successfully integrates multiple sources, creating meaningful connections between lectures and the accompanying discussions and homework problems.\n\n\nannotated transcript:\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I extended Jameson's lecture notes generator #301 to create a comprehensive module review tool.</paragraph><paragraph>Building on the original script's approach of using lecture transcripts + slides with Gemini API, I created module review generator that:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Combines multiple sources</bold>: Integrates lecture notes, discussion solutions, and homework problems into a single comprehensive review document</paragraph></list-item><list-item><paragraph><bold>Synthesizes content by topic</bold>: Uses Gemini API to organize material thematically rather than chronologically, making it better for exam prep</paragraph></list-item><list-item><paragraph><bold>Includes source citations</bold>: Each concept/problem is tagged with its source (e.g., <italic>Lecture 24</italic>, <italic>Discussion 12 Problem2a</italic>, <italic>HW 10 Problem1, ...</italic>) for easy reference</paragraph></list-item></list><paragraph>The script is easily configurable to combine any set of lectures, discussions, and homeworks for different modules.</paragraph><file url=\"https://static.us.edusercontent.com/files/nyMA5YPN5fZmDF5CrF7AOzwx\" filename=\"module_review_generator.py\"/><paragraph><bold>Example usage:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>I combines Lectures 24-27 + Discussions 12-13 + HW 10, 11, 13 into one study guide which is about generative models and post-training.</paragraph></list-item><list-item><paragraph>sample output in </paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/SXST8e0lnZ6JVZRd1QMWRnWP\" filename=\"module_24-27_comprehensive_review.tex\"/><paragraph>I think the review successfully integrates multiple sources, creating meaningful connections between lectures and the accompanying discussions and homework problems.</paragraph><paragraph><break/>annotated transcript:</paragraph><file url=\"https://static.us.edusercontent.com/files/oqSINuasbiLX7tolCEz7yC9G\" filename=\"annotated_module_review_24-27.pdf\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T04:40:18.366087+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425406,
            "author": "Vongani Maluleke",
            "project_title": "Special ParticipationC: HW3 Code Refactoring - Genmini",
            "post_body": "Executive Summary\n\nThis report details the refactoring changes applied to HW3 code using Gemini for assistance. The goal was to enhance the code\u2019s readability, type safety, and Pythonic style while strictly\npreserving the existing functionality and flow required for the educational context.\n\n\n\nNote: There was no spreadsheet for the deconfliction of Part C, so I didn't realize this was already done. I did check if it was done, but I now see that I missed the post.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>This report details the refactoring changes applied to HW3 code using Gemini for assistance. The goal was to enhance the code\u2019s readability, type safety, and Pythonic style while strictly<break/>preserving the existing functionality and flow required for the educational context.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/c8ECkoWfIXxVtvlROGKDl8y8\" filename=\"CS282A_HW3_Code_Refactoring.pdf\"/><paragraph><italic>Note: There was no spreadsheet for the deconfliction of Part C, so I didn't realize this was already done. I did check if it was done, but I now see that I missed the post.</italic></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T04:07:09.14044+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425355,
            "author": "Vongani Maluleke",
            "project_title": "Special Participation B: Gemini on Colab HW2",
            "post_body": "I found Gemini to be an effective and intuitive coding assistant while working in Google Colab. For the majority of my questions, I was able to get a quick, accurate, and short coding answer immediately. However, for a few more challenging problems (about three), I did need to provide hints and slowly guide the model to the final solution. A significant benefit was the quality of explanation it provided; the code was always explained intuitively. Furthermore, when I tested its conceptual understanding by asking reasoning questions, it consistently provided the correct answer, even when the question was abstract, and I hadn't provided any related images. Overall, I believe Gemini is a valuable tool for both rapid development and deepening technical understanding in a notebook environment. However, I am not a fan of the interface. I created widgets so that the prompts were visible alongside the questions and answers.",
            "content_xml": "<document version=\"2.0\"><paragraph>I found Gemini to be an effective and intuitive coding assistant while working in Google Colab. For the majority of my questions, I was able to get a quick, accurate, and short coding answer immediately. However, for a few more challenging problems (about three), I did need to provide hints and slowly guide the model to the final solution. A significant benefit was the quality of explanation it provided; the code was always explained intuitively. Furthermore, when I tested its conceptual understanding by asking reasoning questions, it consistently provided the correct answer, even when the question was abstract, and I hadn't provided any related images. Overall, I believe Gemini is a valuable tool for both rapid development and deepening technical understanding in a notebook environment. However, I am not a fan of the interface. I created widgets so that the prompts were visible alongside the questions and answers.</paragraph><file url=\"https://static.us.edusercontent.com/files/TYOVf2JEMrm7fSMlIsiqtZYr\" filename=\"Hw2_Gemini_Colab_annotated.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T03:52:19.837971+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425318,
            "author": "Vongani Maluleke",
            "project_title": "Special Participation C: HW9 Code Refactored",
            "post_body": "Executive Summary\n\nThis report documents the refactoring of HW9 Python code for visualizing attention in Transformer models using BertViz into an object-oriented structure using the BertVizExplorer class. The refactoring aims to improve code organization, reusability, and state management while maintaining the original flow of the homework.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>This report documents the refactoring of HW9 Python code for visualizing attention in Transformer models using BertViz into an object-oriented structure using the BertVizExplorer class. The refactoring aims to improve code organization, reusability, and state management while maintaining the original flow of the homework.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/qSSmbLVVSCHiBq9dyLFNVpPc\" filename=\"HW9_Visualizing_BERT_refactored.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T03:42:50.465542+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425160,
            "author": "Sriram Srivatsan",
            "project_title": "Special Participation B: Getting GPT 5.1 to do Homework 7 Coding",
            "post_body": "I got GPT 5.1 to get homework 7 working. In short, GPT 5.1 pretty much one shotted the actual coding parts, minus one small issue where it calculated MSE wrong. However after two followups to this MSE prompt, it got it correct without me specifically mentioning the issue. \n\nI did notice that though it was good at doing the work, it doesn't look around the code to fix potential issues, for example, the code currently had .cuda(), but I wanted it to work with mps. I had to specifically prompt it to fix that issue, though I would have hoped it did that in the first place.\n\nHere is the writeup:\n\n\n\nHere is the chat history:\n\n\n\nHere are the solutions it provided:\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I got GPT 5.1 to get homework 7 working. In short, GPT 5.1 pretty much one shotted the actual coding parts, minus one small issue where it calculated MSE wrong. However after two followups to this MSE prompt, it got it correct without me specifically mentioning the issue. <break/><break/>I did notice that though it was good at doing the work, it doesn't look around the code to fix potential issues, for example, the code currently had .cuda(), but I wanted it to work with mps. I had to specifically prompt it to fix that issue, though I would have hoped it did that in the first place.<break/><break/>Here is the writeup:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/Qh5XLh9BN57v11Jmq4ufw6bD\" filename=\"writeup.md\"/><paragraph><break/>Here is the chat history:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/MEgQBuXnrdboXhCMdSQfsOyi\" filename=\"CHAT.md\"/><paragraph><break/>Here are the solutions it provided:</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/7sD4GWK8rrrRRnLyQkM138z9\" filename=\"Solutions.zip\"/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T02:52:14.262122+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425043,
            "author": "Ayush Goel",
            "project_title": "Special Participation B: Gemini 3 Pro on HW 0",
            "post_body": "I ran the HW 0 coding through Gemini 3 Pro. The attached pdf has the transcription of the chat with gemini.\n\nGemini 3 pro was able to one-shot every coding problem. For most of the problems, I wasn't too surprised as they were basic forward and backward passes for an MLP with relu as the only activation function. \n\nHere are some things I found interesting:\n\n1. Gemini 3 Pro was automatically suggesting implementing the next function. For example, I asked it to implement affine_forward and it prompted to implement affine_backward. I even used it's prompt suggestion in a separate chat and saw it created the new function aligned with the signatures as the homework. I was very impressed that Gemini 3 Pro was able to pick up the coding conventions very quickly and new what to implement next. I was most surprised when it suggested to implement the svm_loss and softmax_loss.\n2. Gemini 3 Pro was very smart with the hyperparameters. For all 3 problems, I had to do some hyperparameter tuning when I tried it myself. Gemini came up with hyperparameters that were extremely close to the ones I used when I trained them manually just given a prompt to overfit to the training data, etc. To me, this suggests that gemini has seen a lot of work on hyperparameters for this particular dataset and so was able to perform well.\n\n3. Gemini gave detailed comments explaining every line of code. I think this also contributed to the clarity and correctness of the code gemini produced.",
            "content_xml": "<document version=\"2.0\"><paragraph>I ran the HW 0 coding through Gemini 3 Pro. The attached pdf has the transcription of the chat with gemini.</paragraph><file url=\"https://static.us.edusercontent.com/files/ssiwt28oDa4xM9nn0lqu6Yet\" filename=\"hw_0_code_gemini_3_pro.pdf\"/><paragraph>Gemini 3 pro was able to one-shot every coding problem. For most of the problems, I wasn't too surprised as they were basic forward and backward passes for an MLP with relu as the only activation function. </paragraph><paragraph>Here are some things I found interesting:</paragraph><paragraph>1. Gemini 3 Pro was automatically suggesting implementing the next function. For example, I asked it to implement <code>affine_forward</code> and it prompted to implement <code>affine_backward</code>. I even used it's prompt suggestion in a separate chat and saw it created the new function aligned with the signatures as the homework. I was very impressed that Gemini 3 Pro was able to pick up the coding conventions very quickly and new what to implement next. I was most surprised when it suggested to implement the svm_loss and softmax_loss.<break/>2. Gemini 3 Pro was very smart with the hyperparameters. For all 3 problems, I had to do some hyperparameter tuning when I tried it myself. Gemini came up with hyperparameters that were extremely close to the ones I used when I trained them manually just given a prompt to overfit to the training data, etc. To me, this suggests that gemini has seen a lot of work on hyperparameters for this particular dataset and so was able to perform well.</paragraph><paragraph>3. Gemini gave detailed comments explaining every line of code. I think this also contributed to the clarity and correctness of the code gemini produced.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T01:57:15.102336+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7425035,
            "author": "Sriram Srivatsan",
            "project_title": "Special Participation A: Getting GPT 5.1 to answer Homework 12",
            "post_body": "I got OpenAI's GPT 5.1 model to answer questions 1, 2, and 4 in homework 12. Overall, it seems that this model is able to answer questions about the material extremely accurately, and sometimes it even notes that specific ambiguities exist within the questions themselves. This is quite interesting, because it solved parts of question 2 that I wasn't able to approach myself without getting guidance from some of its answers.\n\nHere is the writeup: \n\nHere is the chat history: \n\nAnd the solutions and ambiguities it noted in for the homework:",
            "content_xml": "<document version=\"2.0\"><paragraph>I got OpenAI's GPT 5.1 model to answer questions 1, 2, and 4 in homework 12. Overall, it seems that this model is able to answer questions about the material extremely accurately, and sometimes it even notes that specific ambiguities exist within the questions themselves. This is quite interesting, because it solved parts of question 2 that I wasn't able to approach myself without getting guidance from some of its answers.<break/><break/>Here is the writeup: </paragraph><file url=\"https://static.us.edusercontent.com/files/57y0yD5lukQAxYWs5ZJMrzcb\" filename=\"writeup.md\"/><paragraph>Here is the chat history: </paragraph><file url=\"https://static.us.edusercontent.com/files/i2R7E2a0J598pBkGrJb3z3zq\" filename=\"chat_history.md\"/><paragraph>And the solutions and ambiguities it noted in for the homework:</paragraph><file url=\"https://static.us.edusercontent.com/files/T8TFpr18rLhe8gj4f8YF4Jca\" filename=\"problem1sol.md\"/><file url=\"https://static.us.edusercontent.com/files/epB9ecUvpCN1OYsnatwUlV4V\" filename=\"problem2sol.md\"/><file url=\"https://static.us.edusercontent.com/files/quqiYIkhlmIgaebW8pt0iAlu\" filename=\"problem4sol.md\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T01:52:09.45735+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424926,
            "author": "Tyler Pham",
            "project_title": "Special Participation B: Gemini 3 Pro on HW 9 Coding",
            "post_body": "I used Gemini 3 Pro for the coding problem #6 of HW 9. This coding problem is not a typical HW coding problem because it only involves purely conceptual questions about the notebook\u2019s attention visualizations, rather than asking to actually code anything. So, I ran the notebook and attached it as a PDF for Gemini. I then asked it question-by-question, but it had to make guesses about what I would observe since there would be far too many photos to show of all attention layers and heads to Gemini. I compared its analysis of what I would see to what I actually observed in the notebook. Given that basic attention visualization has been widely studied before, Gemini\u2019s analysis was pretty spot-on despite not having seen all visualizations from the notebook.\n\nObservations\n\nGemini 3 Pro correctly one-shot answered every conceptual coding question (a-d) on the first attempt without requiring more prompting or correction. It was correct about the autoregressive vs bidirectional visualizations and even interpretability patterns with the CLS tokens. It had pretty accurate predictions about what I would be seeing in the notebook\u2019s visualizations.\n\nGemini 3 Pro\u2019s responses are concise in a good way, yet still goes beyond basic interpretability and even mentions backprop to explain gradient behavior for the last question, which is quite helpful as it also explains \u201cwhy\u201d and not just \u201cwhat\u201d.\n\nThe model was only slightly wrong about 5(d)(i) where it expected the untrained weights to look \u201cchaotic\u201d like a \u201cmessy web\u201d but in reality the visualization showed the words with equal attention to the other words.\n\nFrom the notebook PDF, Gemini could still see some visualizations (like for Layer 0, Head 0). It was able to see the lines and interpret those to explain autoregressiveness vs bidirectionality, which is pretty impressive computer vision skill.\n\nHere's my annotated chat:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 3 Pro for the coding problem #6 of HW 9. This coding problem is not a typical HW coding problem because it only involves purely conceptual questions about the notebook\u2019s attention visualizations, rather than asking to actually code anything. So, I ran the notebook and attached it as a PDF for Gemini. I then asked it question-by-question, but it had to make guesses about what I would observe since there would be far too many photos to show of all attention layers and heads to Gemini. I compared its analysis of what I would see to what I actually observed in the notebook. Given that basic attention visualization has been widely studied before, Gemini\u2019s analysis was pretty spot-on despite not having seen all visualizations from the notebook.</paragraph><paragraph><bold>Observations</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Gemini 3 Pro correctly one-shot answered every conceptual coding question (a-d) on the first attempt without requiring more prompting or correction. It was correct about the autoregressive vs bidirectional visualizations and even interpretability patterns with the CLS tokens. It had pretty accurate predictions about what I would be seeing in the notebook\u2019s visualizations.</paragraph></list-item><list-item><paragraph>Gemini 3 Pro\u2019s responses are concise in a good way, yet still goes beyond basic interpretability and even mentions backprop to explain gradient behavior for the last question, which is quite helpful as it also explains \u201cwhy\u201d and not just \u201cwhat\u201d.</paragraph></list-item><list-item><paragraph>The model was only slightly wrong about 5(d)(i) where it expected the untrained weights to look \u201cchaotic\u201d like a \u201cmessy web\u201d but in reality the visualization showed the words with equal attention to the other words.</paragraph></list-item><list-item><paragraph>From the notebook PDF, Gemini could still see some visualizations (like for Layer 0, Head 0). It was able to see the lines and interpret those to explain autoregressiveness vs bidirectionality, which is pretty impressive computer vision skill.</paragraph></list-item></list><paragraph>Here's my annotated chat:</paragraph><file url=\"https://static.us.edusercontent.com/files/csuWiy5e2Y6liFrJMMfsJ04V\" filename=\"gemini-chat.2025-12-07.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T00:12:29.462292+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424922,
            "author": "Natalie Wei",
            "project_title": "Special Participation A: Mistral on HW8",
            "post_body": "Overview\n\nI worked with Mistral\u2019s Le Chat to complete the written questions in Homework 8. First, I gave Mistral a set of rules to follow:\n\n1. Read the question and restate it in your own words\n\n2. Provide a step-by-step explanation of the solution\n\n3. Point out any uncertainties or room for error with your final solution\n\nTo avoid exceeding the model\u2019s context window, I copy-pasted each question as a separate prompt. When Mistral produced an incorrect answer, I attempted to guide it by offering a hint from the approach taken in the staff solution. If it still failed to correct itself, I gave it the staff solution and asked it to explain both why its original answer was wrong and why the solution was correct. Although Mistral was able to explain why the solution worked, I do not feel that it was able to explain its own mistakes. It restated that it was wrong and explained what concepts it missed, but it failed to explain why it missed those concepts to begin with (confusing problem statement, faulty assumptions, etc.). \n\nMistral performed well on the computational and mathematical questions, solving all of them on the first attempt, but it struggled with the more conceptual problems. In particular, it had difficulty with complex time complexity questions: while it could reliably deduce time complexity from a given, straightforward formula, it struggled at analyzing how an algorithm\u2019s time complexity might be improved. Mistral also had trouble changing its approach once it committed to an incorrect approach. Even when given specific hints, and even the staff solution in some cases, it continued to respond incorrectly, giving either the same answer or a different incorrect answer. Additionally, although I asked it to identify sources of error in its solutions, it interpreted this as describing mistakes a human might make as opposed to weaknesses in its own work. This made it challenging to identify why the model was struggling and give it appropriate hints. \n\nOverall, the one-shot approach yielded approximately 73.6% accuracy across all of the subproblems; note that I was using the free model and paid models may perform better. I would recommend Mistral for simpler computational tasks, but perhaps not complex conceptual questions that require more reasoning.\n\nAnnotated Logs\n\nQ1\n\nQ3\n\nQ4",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Overview</bold></paragraph><paragraph>I worked with Mistral\u2019s Le Chat to complete the written questions in Homework 8. First, I gave Mistral a set of rules to follow:</paragraph><paragraph>1. Read the question and restate it in your own words</paragraph><paragraph>2. Provide a step-by-step explanation of the solution</paragraph><paragraph>3. Point out any uncertainties or room for error with your final solution</paragraph><paragraph>To avoid exceeding the model\u2019s context window, I copy-pasted each question as a separate prompt. When Mistral produced an incorrect answer, I attempted to guide it by offering a hint from the approach taken in the staff solution. If it still failed to correct itself, I gave it the staff solution and asked it to explain both why its original answer was wrong and why the solution was correct. Although Mistral was able to explain why the solution worked, I do not feel that it was able to explain its own mistakes. It restated that it was wrong and explained what concepts it missed, but it failed to explain why it missed those concepts to begin with (confusing problem statement, faulty assumptions, etc.). </paragraph><paragraph>Mistral performed well on the computational and mathematical questions, solving all of them on the first attempt, but it struggled with the more conceptual problems. In particular, it had difficulty with complex time complexity questions: while it could reliably deduce time complexity from a given, straightforward formula, it struggled at analyzing how an algorithm\u2019s time complexity might be improved. Mistral also had trouble changing its approach once it committed to an incorrect approach. Even when given specific hints, and even the staff solution in some cases, it continued to respond incorrectly, giving either the same answer or a different incorrect answer. Additionally, although I asked it to identify sources of error in its solutions, it interpreted this as describing mistakes a human might make as opposed to weaknesses in its own work. This made it challenging to identify why the model was struggling and give it appropriate hints. </paragraph><paragraph>Overall, the one-shot approach yielded approximately 73.6% accuracy across all of the subproblems; note that I was using the free model and paid models may perform better. I would recommend Mistral for simpler computational tasks, but perhaps not complex conceptual questions that require more reasoning.</paragraph><paragraph><bold>Annotated Logs</bold></paragraph><paragraph><link href=\"https://drive.google.com/file/d/1xp2Be1rVcw42UysIErTOnEjVFpwhgoY1/view?usp=sharing\">Q1</link></paragraph><paragraph><link href=\"https://drive.google.com/file/d/1bvrsliSObDIRLgt0CUQbykqI7u33RQ3D/view?usp=sharing\">Q3</link></paragraph><paragraph><link href=\"https://drive.google.com/file/d/1Ts2CjjRaKTkI3QjBJlajUEH7-nYNxkvX/view?usp=sharing\">Q4</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1xp2Be1rVcw42UysIErTOnEjVFpwhgoY1/view?usp=sharing",
                "https://drive.google.com/file/d/1bvrsliSObDIRLgt0CUQbykqI7u33RQ3D/view?usp=sharing",
                "https://drive.google.com/file/d/1Ts2CjjRaKTkI3QjBJlajUEH7-nYNxkvX/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-08T00:09:44.530492+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424917,
            "author": "Neil Pattanaik",
            "project_title": "Special Participation E: Tensor Norm Visualization Tool",
            "post_body": "Using Gemini's Canvas mode, Gemini was able to build this neat interactive visualization of the various tensor norms we discussed in the context of CNNs. It can be difficult to imagine and remember which axes are normalized over for each norm, which inspired me to create this tool. It displays 4 axes (H, W, C, Batch) and has both a 2d and 3d view of BatchNorm, RMS + LayerNorm, and InstanceNorm.\n\n\n\nhttps://gemini.google.com/share/57ed79731305\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Using Gemini's Canvas mode, Gemini was able to build this neat interactive visualization of the various tensor norms we discussed in the context of CNNs. It can be difficult to imagine and remember which axes are normalized over for each norm, which inspired me to create this tool. It displays 4 axes (H, W, C, Batch) and has both a 2d and 3d view of BatchNorm, RMS + LayerNorm, and InstanceNorm.</paragraph><paragraph/><paragraph>https://gemini.google.com/share/57ed79731305</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-08T00:04:37.045755+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424852,
            "author": "Tyler Pham",
            "project_title": "Special Participation A: DeepSeek-V3.2 on HW9 Non-Coding",
            "post_body": "I used DeepSeek-V3.2 without DeepThink mode (this was released Dec 1, and is not the same as DeepSeek-V3.2-Exp) on HW9 (Non-Coding). Overall, DeepSeek was able to one-shot most of the problems even without DeepThink mode. Part of the reason why could be that this HW is on attention, which is extremely well-studied on the internet and so it probably has a rich understanding of it in its training data. \n\nOther interesting observations:\n\nI found that asking it to restate the problem was very helpful in preventing hallucinations, as I could easily verify any small errors like wrong superscripts or notation.\n\nAs DeepSeek was solving its problems, on many occasions it double-checked its response despite not being in Thinking Mode, helping it answer more accurately. (e.g. In it's own response, it asks itself: \"Possibly adjust d_k if needed? No, [...]\")\n\nEspecially when i prompted the model to fix a certain answer, it asked many questions to itself to check that it's work was right rather than keep going on blindly.\n\nIt was able to almost perfectly one-shot all problems but Q6 without me even having to split the prompts into separate parts for (a), (b), (c), and so on. There were occasionally very minor errors, but the only concerning moment was when the model misread a matrix in Q2 as 3x3 instead of 3x4 when restating the problem. However, as it was generating its output, the model actually realized that the 4th column probably belonged to the matrix and fixed it as if it was thinking. Q6 was the most challenging and longest one, so I had to split the prompts for that into different sections.\n\nWhen prompting it to solve an entire problem with multiple sections, it often is more verbose and shows more work for earlier parts of the question but shows less work for later parts of the question. In my observation, this only happens when its answer is getting really long.\n\n\n\nAnnotated Chat:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used DeepSeek-V3.2 without DeepThink mode (this was released Dec 1, and is not the same as DeepSeek-V3.2-Exp) on HW9 (Non-Coding). Overall, DeepSeek was able to one-shot most of the problems even without DeepThink mode. Part of the reason why could be that this HW is on attention, which is extremely well-studied on the internet and so it probably has a rich understanding of it in its training data. </paragraph><paragraph>Other interesting observations:</paragraph><list style=\"bullet\"><list-item><paragraph>I found that asking it to restate the problem was very helpful in preventing hallucinations, as I could easily verify any small errors like wrong superscripts or notation.</paragraph></list-item><list-item><paragraph>As DeepSeek was solving its problems, on many occasions it double-checked its response despite not being in Thinking Mode, helping it answer more accurately. (e.g. In it's own response, it asks itself: \"Possibly adjust <code>d_k</code> if needed? No, [...]\")</paragraph><list style=\"bullet\"><list-item><paragraph>Especially when i prompted the model to fix a certain answer, it asked many questions to itself to check that it's work was right rather than keep going on blindly.</paragraph></list-item></list></list-item><list-item><paragraph>It was able to almost perfectly one-shot all problems but Q6 without me even having to split the prompts into separate parts for (a), (b), (c), and so on. There were occasionally very minor errors, but the only concerning moment was when the model misread a matrix in Q2 as 3x3 instead of 3x4 when restating the problem. However, as it was generating its output, the model actually realized that the 4th column probably belonged to the matrix and fixed it as if it was thinking. Q6 was the most challenging and longest one, so I had to split the prompts for that into different sections.</paragraph></list-item><list-item><paragraph>When prompting it to solve an entire problem with multiple sections, it often is more verbose and shows more work for earlier parts of the question but shows less work for later parts of the question. In my observation, this only happens when its answer is getting really long.</paragraph></list-item></list><paragraph/><paragraph>Annotated Chat:</paragraph><file url=\"https://static.us.edusercontent.com/files/oYP0heguvkXurz0oibJlobOx\" filename=\"deepseek-chat.2025-12-07.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T22:31:02.719522+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424843,
            "author": "Krish Yadav",
            "project_title": "Special Participation E: Analytical Failure Modes for Optimizer Intuition via Gemini Pro 3",
            "post_body": "While thinking more carefully about optimizers in CS 182, I became curious about  why particular optimizers exist, beyond just memorizing their update rules. In particular, I wanted to understand them as responses to specific geometric or scaling failures, rather than as isolated algorithms. To explore this, I used Gemini Pro 3 to construct a sequence of minimal, analytic failure modes for optimizers covered in class.\n\nI prompted the model to generate short, symbolic training scenarios (no code, no datasets) where a given optimizer behaves pathologically. For each scenario, it first asked me to predict what would go wrong, and only afterward explained what failed, which assumption was violated, and which optimizer or idea was introduced to address that failure. The scenarios included:\n\nill-conditioning in gradient descent\n\nthe noise floor in SGD\n\nfailure of L2 regularization in Adam vs. AdamW\n\nwidth-dependent instability motivating \u03bcP\n\nand the lazy (NTK) training regime\n\nThis approach was effective for connecting lecture material across geometry, scaling laws, and optimizer design, and for separating formal guarantees from heuristic intuition. I added annotations highlighting where the explanations aligned closely with lecture material and where the model relied more on intuition or standard deep learning lore.\n\nOverall, this worked well as an AI-assisted alternative to post-lecture reading, helping build optimizer intuition through concrete failure cases while still requiring active oversight.\n\nFor more, look at the annotated PDF.",
            "content_xml": "<document version=\"2.0\"><paragraph>While thinking more carefully about optimizers in CS 182, I became curious about  why particular optimizers exist, beyond just memorizing their update rules. In particular, I wanted to understand them as responses to specific geometric or scaling failures, rather than as isolated algorithms. To explore this, I used Gemini Pro 3 to construct a sequence of minimal, analytic failure modes for optimizers covered in class.</paragraph><paragraph>I prompted the model to generate short, symbolic training scenarios (no code, no datasets) where a given optimizer behaves pathologically. For each scenario, it first asked me to predict what would go wrong, and only afterward explained what failed, which assumption was violated, and which optimizer or idea was introduced to address that failure. The scenarios included:</paragraph><list style=\"bullet\"><list-item><paragraph>ill-conditioning in gradient descent</paragraph></list-item><list-item><paragraph>the noise floor in SGD</paragraph></list-item><list-item><paragraph>failure of L2 regularization in Adam vs. AdamW</paragraph></list-item><list-item><paragraph>width-dependent instability motivating \u03bcP</paragraph></list-item><list-item><paragraph>and the lazy (NTK) training regime</paragraph></list-item></list><paragraph>This approach was effective for connecting lecture material across geometry, scaling laws, and optimizer design, and for separating formal guarantees from heuristic intuition. I added annotations highlighting where the explanations aligned closely with lecture material and where the model relied more on intuition or standard deep learning lore.</paragraph><paragraph>Overall, this worked well as an AI-assisted alternative to post-lecture reading, helping build optimizer intuition through concrete failure cases while still requiring active oversight.</paragraph><paragraph>For more, look at the annotated PDF.</paragraph><file url=\"https://static.us.edusercontent.com/files/dWuLm2KWAtuO5b3BE8KghxCC\" filename=\"annotated-gp3-optimizer-failure.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T22:17:49.811521+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424838,
            "author": "Nikhil Mathihalli",
            "project_title": "Special Participation E: Learning CNNs by Building with Cursor",
            "post_body": "Concept: Convolutional Neural Networks (CNNs) & Kernel Filters\n\nTool Used: Cursor (AI Code Editor)\n\nArtifact: The Kernel Whisperer (GitHub Repo)\n\nThe Goal: I found the recent lectures on ConvNets interesting, but I wanted to move beyond static slides. I decided to treat the AI not just as a tutor, but as a \"junior developer\" to help me build an interactive learning tool. The goal was to learn about filters (blur, edge detection, sharpen) by actually applying them to images in code, effectively replacing my standard post-lecture review with an active engineering project.\n\nThe Approach: I used Cursor to build a React-based interactive playground. I realized early on that Cursor works best when you act as the \"Architect.\" I wrote a highly detailed \"spec\" prompt defining exactly what the app should contain\u2014specifically requesting a UI that allows for real-time filter toggling and an embedded AI chat interface tailored specifically to answer conceptual questions about CNNs.\n\nInteraction Trace & Critical Analysis:\n\nSince the interaction was code-heavy, my critical annotation focuses on the difference between Knowledge Generation and Debugging:\n\nWhere it Succeeded (The Math):\n\nOne-Shot Accuracy: Surprisingly, Cursor did not hallucinate on the actual implementation of the convolution logic or the filter matrices. Because I provided a detailed prompt about the mathematical purpose of the filters, it generated the core processing logic correctly on the first try.\n\nWhere it Failed (The Engineering):\n\nDebugging Loops: While the math was good, the AI struggled significantly with \"glue code\" and UI state management. When a bug arose in the React rendering cycle, Cursor often got stuck in a loop, suggesting fixes that broke other parts of the app.\n\nHuman Intervention: This highlighted a key limitation: AI is great at generating isolated logic (like a specific kernel), but requires a human to oversee the broader system architecture and fix integration bugs.\n\nVerdict: Building this tool forced me to understand the inputs and outputs of CNNs much better than just reading about them. If you want to try it out or see the code, the repo is linked above!",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Concept:</bold> Convolutional Neural Networks (CNNs) &amp; Kernel Filters</paragraph><paragraph><bold>Tool Used:</bold> Cursor (AI Code Editor)</paragraph><paragraph><bold>Artifact:</bold> <link href=\"https://github.com/nikhilmathihalli/kernel-whisperer\">The Kernel Whisperer (GitHub Repo)</link></paragraph><paragraph><bold>The Goal:</bold> I found the recent lectures on ConvNets interesting, but I wanted to move beyond static slides. I decided to treat the AI not just as a tutor, but as a \"junior developer\" to help me build an interactive learning tool. The goal was to learn about filters (blur, edge detection, sharpen) by actually applying them to images in code, effectively replacing my standard post-lecture review with an active engineering project.</paragraph><paragraph><bold>The Approach:</bold> I used Cursor to build a React-based interactive playground. I realized early on that Cursor works best when you act as the \"Architect.\" I wrote a highly detailed \"spec\" prompt defining exactly what the app should contain\u2014specifically requesting a UI that allows for real-time filter toggling and an embedded AI chat interface tailored specifically to answer conceptual questions about CNNs.</paragraph><paragraph><bold>Interaction Trace &amp; Critical Analysis:</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/ASLPoMV2jTJR6sAdXVDm8gIb\" filename=\"Kernel Whisperer.pdf\"/><paragraph>Since the interaction was code-heavy, my critical annotation focuses on the difference between <bold>Knowledge Generation</bold> and <bold>Debugging</bold>:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Where it Succeeded (The Math):</bold></paragraph><list style=\"unordered\"><list-item><paragraph><italic>One-Shot Accuracy:</italic> Surprisingly, Cursor did not hallucinate on the actual implementation of the convolution logic or the filter matrices. Because I provided a detailed prompt about the mathematical purpose of the filters, it generated the core processing logic correctly on the first try.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Where it Failed (The Engineering):</bold></paragraph><list style=\"unordered\"><list-item><paragraph><italic>Debugging Loops:</italic> While the math was good, the AI struggled significantly with \"glue code\" and UI state management. When a bug arose in the React rendering cycle, Cursor often got stuck in a loop, suggesting fixes that broke other parts of the app.</paragraph></list-item><list-item><paragraph><italic>Human Intervention:</italic> This highlighted a key limitation: AI is great at generating isolated logic (like a specific kernel), but requires a human to oversee the broader system architecture and fix integration bugs.</paragraph></list-item></list></list-item></list><paragraph><bold>Verdict:</bold> Building this tool forced me to understand the inputs and outputs of CNNs much better than just reading about them. If you want to try it out or see the code, the repo is linked above!</paragraph></document>",
            "links": [
                "https://github.com/nikhilmathihalli/kernel-whisperer"
            ],
            "attachments": [],
            "created_at": "2025-12-07T22:06:38.495522+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424833,
            "author": "Minjune Kim",
            "project_title": "Special Participation E: Creating New Discussion Sheets With Lectures That Current Discussion Sheet Does Not Ask using ChatGPT",
            "post_body": "I attempted to create a webpage that will take two inputs, one for lecture slides and another for discussion sheets (both in pdf format). Then, I would have chatgpt scan over both pdf files, and try to find concepts that the discussion did not cover that were in the lecture notes. With the concepts that weren't there, it would create new discussion sheet that's just like the discussion sheets for the class with answers such that it can be used to study concepts that weren't on the discussion but was on the lecture.\n\nDuring this process, I ran into some logistical error using chatGPT because at first, it was not able to detect any words for the lecture notes because all of the lecture notes were hand written, so I had to re-prompt GPT, such that it would be able to convert the hand-written notes into a readable format such that it will be able to recognize what concepts were covered in lecture. Furthermore, I did not prompt it carefully enough and not specific enough that when it first created the discussion sheet, it looked nothing like the discussions sheet, and it was also asking questions on only a few questions on concepts. \n\nHere is my annotated report for the prompt:",
            "content_xml": "<document version=\"2.0\"><paragraph>I attempted to create a webpage that will take two inputs, one for lecture slides and another for discussion sheets (both in pdf format). Then, I would have chatgpt scan over both pdf files, and try to find concepts that the discussion did not cover that were in the lecture notes. With the concepts that weren't there, it would create new discussion sheet that's just like the discussion sheets for the class with answers such that it can be used to study concepts that weren't on the discussion but was on the lecture.</paragraph><paragraph>During this process, I ran into some logistical error using chatGPT because at first, it was not able to detect any words for the lecture notes because all of the lecture notes were hand written, so I had to re-prompt GPT, such that it would be able to convert the hand-written notes into a readable format such that it will be able to recognize what concepts were covered in lecture. Furthermore, I did not prompt it carefully enough and not specific enough that when it first created the discussion sheet, it looked nothing like the discussions sheet, and it was also asking questions on only a few questions on concepts. </paragraph><paragraph>Here is my annotated report for the prompt:</paragraph><file url=\"https://static.us.edusercontent.com/files/JTaAJOtGIlI8BtpiNwFrxieX\" filename=\"Website code for discussion questions-merged.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T21:59:28.510045+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424828,
            "author": "Devan Perkash",
            "project_title": "Special Participation B: Cursor on HW1 Coding Portion",
            "post_body": "I used the Cursor IDE on the coding portion of HW 1.\n\n\n\nExecutive Summary:\n\nCursor was overall highly effective at solving the coding problems in this homework. It required very little context supplied by me through the chat thread, as it was able to retrieve context from code cells and even visualizations (i.e. training plots) on its own. It successfully connected logical/programming reasoning, numerical reasoning, and visual reasoning to even answer conceptual questions within the coding portion of the homework. Its largest failure mode, however, was lacking the ability to fully engage with the jupyter notebook, as it could not run cells autonomously the way it can run standard code files. This inhibited its iterative design process\u2014it could not continuously cycle between writing new code, running it, seeing the result, and making adjustments as needed\u2014so it therefore required a bit more hand-holding towards the end of the assignment where this became an issue. However, Cursor was overall a strong tool in completing this homework, and it provided clear explanations that would be helpful to anyone who might be stuck conceptually on the problems.\n\n\n\nYou can read a full annotated log of my interaction with Cursor in the attached PDF (below). In my annotations, I explain the reasoning behind my prompting strategy and analyze the results for correctness and reach (i.e. where was Cursor able and not able to make direct/successful changes).",
            "content_xml": "<document version=\"2.0\"><paragraph>I used the Cursor IDE on the coding portion of HW 1.</paragraph><paragraph/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>Cursor was overall highly effective at solving the coding problems in this homework. It required very little context supplied by me through the chat thread, as it was able to retrieve context from code cells and even visualizations (i.e. training plots) on its own. It successfully connected logical/programming reasoning, numerical reasoning, and visual reasoning to even answer conceptual questions within the coding portion of the homework. Its largest failure mode, however, was lacking the ability to fully engage with the jupyter notebook, as it could not run cells autonomously the way it can run standard code files. This inhibited its iterative design process\u2014it could not continuously cycle between writing new code, running it, seeing the result, and making adjustments as needed\u2014so it therefore required a bit more hand-holding towards the end of the assignment where this became an issue. However, Cursor was overall a strong tool in completing this homework, and it provided clear explanations that would be helpful to anyone who might be stuck conceptually on the problems.</paragraph><paragraph/><paragraph>You can read a full annotated log of my interaction with Cursor in the attached PDF (below). In my annotations, I explain the reasoning behind my prompting strategy and analyze the results for correctness and reach (i.e. where was Cursor able and not able to make direct/successful changes).</paragraph><file url=\"https://static.us.edusercontent.com/files/jWHJEC3ncOBsnqnOCMNWQdNS\" filename=\"cursor_implement_gradient_descent_with.md.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T21:55:27.373263+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424818,
            "author": "Athul Krishnan",
            "project_title": "Special Participation B: Claude Code on HW7",
            "post_body": "Hi everyone!\n\nFor Special Participation B, I evaluated Claude Code (with Thinking) on the coding portions of HW 7. To do so, I provided the relevant iPython notebooks without the problem PDF, I wanted to see if it could do things differently than intended yet still pass, as well as the following starting prompt:\n\n\"Hi Claude! I'd like you, as a deep learning lover to help me through these coding notebooks about RNNs and autoencoders for my deep learning class, by implementing the TODOs in each one! (do not modify any other code!) We'll go through them one by one, and be sure to explain your approaches step by step! To validate your approaches try running the cells/tests as needed. Before we continue, does this make sense?\"\n\nClaude was very strong, one-shotting nearly every question. As I expected, in the case that its initial hyperparameters didn't work (Q2, RNNs for Last Name Classification), it struggled to properly tune them without me giving it some guidance. Once I stepped in, it was able to spot a significant issue with its setup, and acheived >80% eval accuracy successfully.\n\nHowever, it one-shotted every other question (including the MNIST Autoencoder) without any re-prompting or extra tuning necessary. On the autoencoder implementation, it even ran its own code, smartly debugged it by deducing a constant factor between the expected value and the output value, and resolved it correctly, noticing that the factor was equivalent to the input dimension. I wasn't expecting it to use less apparent context clues and make these logical jumps. It was probably the most \"human\" thing Claude has done in my testing.\n\nOverall, Claude Code is very impressive, one-shotting most questions, and only really struggling with hyperparameter tuning. It manages to run and debug its own code, utilizing the output as well as context clues within the notebook. In the end, despite not having the extra information of the problem set PDF, its solutions were mostly similar to the staff solutions, usually leaning on the more readable side (elaborated on in my annotations). I also found its conceptual explanations of the implementations to be very helpful, and it excelled in summarizing all of its changes and its reasoning for doing so. \n\nBelow is my annotated conversation trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!<break/><break/>For Special Participation B, I evaluated <bold>Claude Code (with Thinking)</bold> on the <bold>coding portions of HW 7.</bold> To do so, I provided the relevant iPython notebooks <bold>without the problem PD</bold>F, I wanted to see if it could do things differently than intended yet still pass, as well as the following starting prompt:</paragraph><paragraph>\"Hi Claude! I'd like you, as a deep learning lover to help me through these coding notebooks about RNNs and autoencoders for my deep learning class, by implementing the TODOs in each one! (do not modify any other code!) We'll go through them one by one, and be sure to explain your approaches step by step! To validate your approaches try running the cells/tests as needed. Before we continue, does this make sense?\"</paragraph><paragraph><bold>Claude was very strong, one-shotting nearly every question.</bold> As I expected, in the case that its initial hyperparameters didn't work (Q2, RNNs for Last Name Classification), <bold>it struggled to properly tune</bold> them without me giving it some guidance. Once I stepped in, it was able to spot a significant issue with its setup, and acheived &gt;80% eval accuracy successfully.</paragraph><paragraph>However, it one-shotted every other question (including the MNIST Autoencoder) without any re-prompting or extra tuning necessary. On the autoencoder implementation, it even ran its own code, smartly debugged it by deducing a constant factor between the expected value and the output value, and resolved it correctly, noticing that the factor was equivalent to the input dimension. I wasn't expecting it to use less apparent context clues and make these logical jumps. It was probably the most \"human\" thing Claude has done in my testing.</paragraph><paragraph>Overall, Claude Code is very impressive, one-shotting most questions, and only really struggling with hyperparameter tuning. It manages to run and debug its own code, utilizing the output as well as context clues within the notebook. In the end, despite not having the extra information of the problem set PDF, its solutions were mostly similar to the staff solutions, usually leaning on the more readable side (elaborated on in my annotations). I also found its conceptual explanations of the implementations to be very helpful, and it excelled in summarizing all of its changes and its reasoning for doing so. <break/><break/>Below is my annotated conversation trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/MZ9nw2TfdrPWgczwTJTim2f0\" filename=\"CS_C182_Participation_B_Athul.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T21:40:38.837131+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424817,
            "author": "Rohan Gulati",
            "project_title": "Special Participation B: Mistral on Homework 5",
            "post_body": "Here, I looked at how well Mistral AI's chat model could perform on Homework 5's coding portion, which focused on convolutions and dropout. Overall, Mistral performed very well on the coding tasks, much of which involved building upon previous iterations of its own code. \n\nThe prompting strategy I used involved providing the entire method as context, which often involved docstrings and particularly the provided demarcated region \"### TODO ###\" for the model to fill in the blank with the correct solution. This might have mitigated any hallucinations, as there weren't any gaps that prevented the model from generating inaccurate code. As a result, the model was able to solve problems including generating converging models and writing functions resulting in near-zero tensor outputs in one shot. Part 6.1 appeared to be more involved since it involved generating the loss for the Fully Connected layer and reaching near-zero error with the expected output and then adding Dropout to the generated code. However, by providing the entire network class as reference and the layer_utils file, the model was able to write the code accurately. Lastly, one notable result was that in problem 6.3, \"Use Deep Learning Framework\", the task was to design a custom neural network to reach \"44% accuracy or higher.\" I was expecting Mistral to either take a couple iterations of hyperparameter tuning through our conversation to hit 44% or overshoot 44% in case it was familiar with the task. However, the generated model went from 19.8% validation accuracy in Epoch 1 to 39.2% in Epoch 5 to 44.7% in the final Epoch, arriving at the desired validation accuracy. In the hyperparameter section, it shared its hyperparameter tuning/selection strategy, despite this occurring in the first shot. As a result, it would be very interesting to investigate the abilities for models to do hyperparameter selection for particular tasks and any latent understanding in this area.\n\nOverall, Mistral was able to perform well at the coding tasks in Problem Set 5, and the chats and annotated log are provided below.\n\n\nAnnotated Log: https://docs.google.com/document/d/1d-C20RIKeTumzUaT-7wNuzmLPclNvVHjOOSKAP7KIt0/edit?usp=sharing (Long but headings for each part)\n\nChat History:\nPart 5: Understanding Dropout: https://chat.mistral.ai/chat/05f8f22e-9916-4e6a-b2e7-0e24b8bc374f \n\nPart 6.1: Implementing BatchNorm and Dropout: https://chat.mistral.ai/chat/cd59ea7a-2746-470c-a9db-c88b8d94365d \n\nPart 6.2: Implementing Convolution and Spatial Batch Norm: https://chat.mistral.ai/chat/5c914c00-f6f5-4793-bac8-d3b49ea3e59a \n\nPart 6.3: Use Deep Learning Framework: https://chat.mistral.ai/chat/bc12703b-0109-4648-a3a6-853b72bf4ffa ",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I looked at how well Mistral AI's chat model could perform on Homework 5's coding portion, which focused on convolutions and dropout. Overall, Mistral performed very well on the coding tasks, much of which involved building upon previous iterations of its own code. </paragraph><paragraph>The prompting strategy I used involved providing the entire method as context, which often involved docstrings and particularly the provided demarcated region \"### TODO ###\" for the model to fill in the blank with the correct solution. This might have mitigated any hallucinations, as there weren't any gaps that prevented the model from generating inaccurate code. As a result, the model was able to solve problems including generating converging models and writing functions resulting in near-zero tensor outputs in one shot. Part 6.1 appeared to be more involved since it involved generating the loss for the Fully Connected layer and reaching near-zero error with the expected output and then adding Dropout to the generated code. However, by providing the entire network class as reference and the layer_utils file, the model was able to write the code accurately. Lastly, one notable result was that in problem 6.3, \"Use Deep Learning Framework\", the task was to design a custom neural network to reach \"44% accuracy or higher.\" I was expecting Mistral to either take a couple iterations of hyperparameter tuning through our conversation to hit 44% or overshoot 44% in case it was familiar with the task. However, the generated model went from 19.8% validation accuracy in Epoch 1 to 39.2% in Epoch 5 to 44.7% in the final Epoch, arriving at the desired validation accuracy. In the hyperparameter section, it shared its hyperparameter tuning/selection strategy, despite this occurring in the first shot. As a result, it would be very interesting to investigate the abilities for models to do hyperparameter selection for particular tasks and any latent understanding in this area.<break/><break/>Overall, Mistral was able to perform well at the coding tasks in Problem Set 5, and the chats and annotated log are provided below.<break/></paragraph><paragraph>Annotated Log: <link href=\"https://docs.google.com/document/d/1d-C20RIKeTumzUaT-7wNuzmLPclNvVHjOOSKAP7KIt0/edit?usp=sharing\">https://docs.google.com/document/d/1d-C20RIKeTumzUaT-7wNuzmLPclNvVHjOOSKAP7KIt0/edit?usp=sharing</link> (Long but headings for each part)</paragraph><paragraph>Chat History:<break/>Part 5: Understanding Dropout: <link href=\"https://chat.mistral.ai/chat/05f8f22e-9916-4e6a-b2e7-0e24b8bc374f\">https://chat.mistral.ai/chat/05f8f22e-9916-4e6a-b2e7-0e24b8bc374f</link> </paragraph><paragraph>Part 6.1: Implementing BatchNorm and Dropout: <link href=\"https://chat.mistral.ai/chat/cd59ea7a-2746-470c-a9db-c88b8d94365d\">https://chat.mistral.ai/chat/cd59ea7a-2746-470c-a9db-c88b8d94365d</link> </paragraph><paragraph>Part 6.2: Implementing Convolution and Spatial Batch Norm: <link href=\"https://chat.mistral.ai/chat/5c914c00-f6f5-4793-bac8-d3b49ea3e59a\">https://chat.mistral.ai/chat/5c914c00-f6f5-4793-bac8-d3b49ea3e59a</link> </paragraph><paragraph>Part 6.3: Use Deep Learning Framework: <link href=\"https://chat.mistral.ai/chat/bc12703b-0109-4648-a3a6-853b72bf4ffa\">https://chat.mistral.ai/chat/bc12703b-0109-4648-a3a6-853b72bf4ffa</link> </paragraph></document>",
            "links": [
                "https://docs.google.com/document/d/1d-C20RIKeTumzUaT-7wNuzmLPclNvVHjOOSKAP7KIt0/edit?usp=sharing",
                "https://chat.mistral.ai/chat/05f8f22e-9916-4e6a-b2e7-0e24b8bc374f",
                "https://chat.mistral.ai/chat/cd59ea7a-2746-470c-a9db-c88b8d94365d",
                "https://chat.mistral.ai/chat/5c914c00-f6f5-4793-bac8-d3b49ea3e59a",
                "https://chat.mistral.ai/chat/bc12703b-0109-4648-a3a6-853b72bf4ffa"
            ],
            "attachments": [],
            "created_at": "2025-12-07T21:38:34.860882+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424808,
            "author": "Joshua Lu",
            "project_title": "Special Participation B: Qwen3-Max on HW 9 (Coding)",
            "post_body": "I used Qwen3-Max (With Thinking) to complete the coding portion of Homework 9.\n\nHere is the trace (without annotations): https://chat.qwen.ai/s/095b3b7d-4d9c-4fed-a2fe-0914fbe97bd2?fev=0.1.13\n\nHere is the trace with annotations: https://drive.google.com/file/d/167LVVFvUYnYehqmtULNY0HytxJrYH-6_/view?usp=sharing\n\n\n\nOverall, I was not happy with the performance of Qwen on this homework assignment. It was very average (less than human level). There are several reasons for this, though I would like to add that not all of it is Qwen's fault.\n\nFirst of all, the problem setup is very tricky. This problem is a coding question that requires running code but more importantly, interpreting the graphs, and the main issue is that the graphs are figures that have different buttons for viewing the graph under different parameters. In total, each graph had around 12 layers and 12 attention heads, so that makes 144 unique combination of graphs to examine. Furthermore, each graph shows different things when clicked on or hovered over. Qwen not only cannot accept code files and run code, but it also has a 5 image limit, which makes doing this problem very hard.\n\nFor my setup, I ran all the code myself and made a pdf, with the outputs, and sent that to Qwen. In addition, for each problem, I had to click through the graphs myself and choose 5 sets of parameters that produced what I believed to be reasonable representation of what the problem is aiming for. This is the prompt that I send to Qwen each time.\n\nThere are many issues already. First,  it's unclear if I'm able to choose the good graphs to send over. In addition, for the graphs, if you hover over a token, it shows the connections for only that token, but there's no way I can do that for each token. Instead, I had to settle for an image of the entire graph with all the lines, which works but makes the lines very unclear. To help remedy some of my issues, each time, I asked Qwen to send me sets of parameters that it would like me to show, and that is when I send over more screenshots of the graphs.\n\nNow, let's go over the issues that Qwen had. First of all, it wasn't very good at asking for new graphs initially, and required me to repeatedly prompt before it started learning. Also, when it asks for graphs, it doesn't give me specific set of parameters. I can't fully blame Qwen for this, since it's impossible for the model to know which sets of parameters are actually worthwhile to examine. In addition, Qwen frequently hallucinates what's on the graph. It claims that there is a lot of connection between token A and token B, but when I check the graph, there is barely a line visible. This could be due to how cluttered the graphs are in the screenshots.\n\nA major concern that I have is that Qwen is mostly drawing from general knowledge, rather than actually extracting patterns from the graphs. Qwen frequently talks about how words A and B have very similar semantic meaning, so there's a heavy connection between them, but when I check the graph, the line is very faint or not there. Similarly, when describing the effects of different layers, I definitely notice Qwen using its prior knowledge to extrapolate explanations for what is going on at each step without actually looking at the graphs.\n\nOverall, Qwen does give reasonable (and highly detailed explanations), but it feels to me like most of these explanations are just from its general knowledge of transformer architecture rather than from the graphs. However, I admit that interpretability is difficult, and even I had a lot of trouble drawing patterns from the graphs. It would be perhaps better if Qwen was able to see a view of all 144 graphs, along with clean images for the connections of each token, but given resource constraint, that will still be very difficult. I thus would generally refrain from using AI models, particularly Qwen, to help analyze complex graphs for me.\n\nA final complaint: I tried many different extensions, but I was unable to get a pdf directly from the Qwen chat interface. Instead, I had to manually take screenshots and put them onto a Google Doc. The built-in export also only creates a JSON and ignores the images. Please let me know if anyone found a better solution!",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Qwen3-Max (With Thinking) to complete the coding portion of Homework 9.</paragraph><paragraph>Here is the trace (without annotations): <link href=\"https://chat.qwen.ai/s/095b3b7d-4d9c-4fed-a2fe-0914fbe97bd2?fev=0.1.13\">https://chat.qwen.ai/s/095b3b7d-4d9c-4fed-a2fe-0914fbe97bd2?fev=0.1.13</link></paragraph><paragraph>Here is the trace with annotations: <link href=\"https://drive.google.com/file/d/167LVVFvUYnYehqmtULNY0HytxJrYH-6_/view?usp=sharing\">https://drive.google.com/file/d/167LVVFvUYnYehqmtULNY0HytxJrYH-6_/view?usp=sharing</link></paragraph><paragraph/><paragraph>Overall, I was not happy with the performance of Qwen on this homework assignment. It was very average (less than human level). There are several reasons for this, though I would like to add that not all of it is Qwen's fault.</paragraph><paragraph>First of all, the problem setup is very tricky. This problem is a coding question that requires running code but more importantly, interpreting the graphs, and the main issue is that the graphs are figures that have different buttons for viewing the graph under different parameters. In total, each graph had around 12 layers and 12 attention heads, so that makes 144 unique combination of graphs to examine. Furthermore, each graph shows different things when clicked on or hovered over. Qwen not only cannot accept code files and run code, but it also has a 5 image limit, which makes doing this problem very hard.</paragraph><paragraph>For my setup, I ran all the code myself and made a pdf, with the outputs, and sent that to Qwen. In addition, for each problem, I had to click through the graphs myself and choose 5 sets of parameters that produced what I believed to be reasonable representation of what the problem is aiming for. This is the prompt that I send to Qwen each time.</paragraph><paragraph>There are many issues already. First,  it's unclear if I'm able to choose the good graphs to send over. In addition, for the graphs, if you hover over a token, it shows the connections for only that token, but there's no way I can do that for each token. Instead, I had to settle for an image of the entire graph with all the lines, which works but makes the lines very unclear. To help remedy some of my issues, each time, I asked Qwen to send me sets of parameters that it would like me to show, and that is when I send over more screenshots of the graphs.</paragraph><paragraph>Now, let's go over the issues that Qwen had. First of all, it wasn't very good at asking for new graphs initially, and required me to repeatedly prompt before it started learning. Also, when it asks for graphs, it doesn't give me specific set of parameters. I can't fully blame Qwen for this, since it's impossible for the model to know which sets of parameters are actually worthwhile to examine. In addition, Qwen frequently hallucinates what's on the graph. It claims that there is a lot of connection between token A and token B, but when I check the graph, there is barely a line visible. This could be due to how cluttered the graphs are in the screenshots.</paragraph><paragraph>A major concern that I have is that Qwen is mostly drawing from general knowledge, rather than actually extracting patterns from the graphs. Qwen frequently talks about how words A and B have very similar semantic meaning, so there's a heavy connection between them, but when I check the graph, the line is very faint or not there. Similarly, when describing the effects of different layers, I definitely notice Qwen using its prior knowledge to extrapolate explanations for what is going on at each step without actually looking at the graphs.</paragraph><paragraph>Overall, Qwen does give reasonable (and highly detailed explanations), but it feels to me like most of these explanations are just from its general knowledge of transformer architecture rather than from the graphs. However, I admit that interpretability is difficult, and even I had a lot of trouble drawing patterns from the graphs. It would be perhaps better if Qwen was able to see a view of all 144 graphs, along with clean images for the connections of each token, but given resource constraint, that will still be very difficult. I thus would generally refrain from using AI models, particularly Qwen, to help analyze complex graphs for me.</paragraph><paragraph>A final complaint: I tried many different extensions, but I was unable to get a pdf directly from the Qwen chat interface. Instead, I had to manually take screenshots and put them onto a Google Doc. The built-in export also only creates a JSON and ignores the images. Please let me know if anyone found a better solution!</paragraph></document>",
            "links": [
                "https://chat.qwen.ai/s/095b3b7d-4d9c-4fed-a2fe-0914fbe97bd2?fev=0.1.13",
                "https://drive.google.com/file/d/167LVVFvUYnYehqmtULNY0HytxJrYH-6_/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T21:27:58.721851+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424807,
            "author": "Natalie Wei",
            "project_title": "Special Participation B: Cursor (Opus 4.5) on HW9",
            "post_body": "Overview\n\nI worked with Cursor (Opus 4.5) to complete the coding question in Homework 9. This question doesn\u2019t actually involve writing code, just running the provided notebook and analyzing the visualizations. I thought it would be an interesting exercise to see whether or not Cursor would be able to run the notebook on its own, and what workarounds Cursor might take if the visualizations were not uploaded with the prompt.\n\nSince Cursor was unable to directly interact with the notebook, it chose to rewrite the notebook as a series of Python scripts. Cursor also explicitly told me that it was not able to render the visualizations and relied on the numerical attention weights to come up with answers instead. Even so, its answers were relatively close to the staff solution and would probably have been acceptable. All of the (quite verbose) scripts did lead to a very long transcript; it probably would have been more efficient to upload visualizations myself, but it was still quite interesting to see all of Cursor\u2019s workarounds. \n\nAnnotated Logs\n\nLink",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Overview</bold></paragraph><paragraph>I worked with Cursor (Opus 4.5) to complete the coding question in Homework 9. This question doesn\u2019t actually involve writing code, just running the provided notebook and analyzing the visualizations. I thought it would be an interesting exercise to see whether or not Cursor would be able to run the notebook on its own, and what workarounds Cursor might take if the visualizations were not uploaded with the prompt.</paragraph><paragraph>Since Cursor was unable to directly interact with the notebook, it chose to rewrite the notebook as a series of Python scripts. Cursor also explicitly told me that it was not able to render the visualizations and relied on the numerical attention weights to come up with answers instead. Even so, its answers were relatively close to the staff solution and would probably have been acceptable. All of the (quite verbose) scripts did lead to a very long transcript; it probably would have been more efficient to upload visualizations myself, but it was still quite interesting to see all of Cursor\u2019s workarounds. </paragraph><paragraph><bold>Annotated Logs</bold></paragraph><paragraph><link href=\"https://drive.google.com/file/d/1rYiifv6OZ7vovJYYctuxACacuUV0zj_v/view?usp=sharing\">Link</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1rYiifv6OZ7vovJYYctuxACacuUV0zj_v/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T21:27:45.894968+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424798,
            "author": "Arnav Dalal",
            "project_title": "Special Participation C: Refactoring HW10 problem 2",
            "post_body": "Hi everyone!\n\nMy group and I refactored the codebase for (2) Hand-Design Transformers on HW10. \n\nThe main changes prioritized code quality, organization, readability, and functionality all while maintaining a high teaching/learning value for the notebook. \n\nGiven the long nature of this notebook, we separated the helper functions and tests into separate files within new directories /utils and /tests. Utils contained all of the helper functions in the original notebook along with new functions for visualization (rescale_and_plot and save_figure) and new configurations for both the training and plotting. \n\nThese configurations (TrainingConfig and PlotConfig) added more customizability to the assignment, allowing students to explore further beyond what is required and find cool new visualizations for their results. \n\nWe moved all of the testing infrastructure as well, separating the tests for each of the individual sections in the notebook. We also added better debugging functionality, improving error messages and adding additional checks to ensure that the student can trace what went wrong with their implementation.\n\nHere is a link to our repo containing the updated codebase: https://github.com/adalal07/cs182-special-participation-c2/tree/main. Also, attached is our report for this restructuring.\n\nExcited to see what others think!\n\ncc Kabir Shah, Sarvagya Somvanshi",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!<break/><break/>My group and I refactored the codebase for (2) Hand-Design Transformers on HW10. </paragraph><paragraph>The main changes prioritized code quality, organization, readability, and functionality all while maintaining a high teaching/learning value for the notebook. <break/><break/>Given the long nature of this notebook, we separated the helper functions and tests into separate files within new directories /utils and /tests. Utils contained all of the helper functions in the original notebook along with new functions for visualization (<bold>rescale_and_plot</bold> and <bold>save_figure</bold>) and new configurations for both the training and plotting. <break/><break/>These configurations (<bold>TrainingConfig</bold> and <bold>PlotConfig</bold>) added more customizability to the assignment, allowing students to explore further beyond what is required and find cool new visualizations for their results. <break/><break/>We moved all of the testing infrastructure as well, separating the tests for each of the individual sections in the notebook. We also added better debugging functionality, improving error messages and adding additional checks to ensure that the student can trace what went wrong with their implementation.</paragraph><paragraph>Here is a link to our repo containing the updated codebase: <link href=\"https://github.com/adalal07/cs182-special-participation-c2/tree/main\">https://github.com/adalal07/cs182-special-participation-c2/tree/main</link>. Also, attached is our report for this restructuring.<break/><break/>Excited to see what others think!<break/><break/>cc Kabir Shah, Sarvagya Somvanshi</paragraph><file url=\"https://static.us.edusercontent.com/files/77volBm1VaGL5YfJdFvnHg3V\" filename=\"cs182_c2 (1).pdf\"/></document>",
            "links": [
                "https://github.com/adalal07/cs182-special-participation-c2/tree/main"
            ],
            "attachments": [],
            "created_at": "2025-12-07T21:12:01.082827+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424797,
            "author": "Sarvagya Somvanshi",
            "project_title": "Special Participation C: HW 7 Q1",
            "post_body": "Hey everyone, \n\nMy group worked on refactoring the RNN & Gradient Flow notebook (HW7 Q1) for Special Participation C. We focussed on adding more context throughout the notebook. Every class now has docstrings explaining what it does and why it matters. More importantly, we included the actual math formulations right next to the code as well as diagrams showing RNN unrolling and multi-layer architectures.\n\nWe worked reorganizing the code structure. Helper functions like generate_batch, train, and train_all now live in a separate utils.py file, and all test cases have been moved to tests.py to remove clutter and  .\n\nOn the style side, we cleaned up variable names, added type hints so you know exactly what tensor shapes to expect, and fixed the indentation to follow PEP 8 guidelines.\n\nHere's a link to my GitHub repo containing the refactored notebook:\n\nhttps://github.com/adalal07/cs182-special-participation-c1\n\nHere is a report on my work:\n\n\n\nHope it's helpful!\n\nCC: Arnav Dalal, Kabir Shah",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey everyone, <break/><break/>My group worked on refactoring the RNN &amp; Gradient Flow notebook (HW7 Q1) for Special Participation C. We focussed on adding more context throughout the notebook. Every class now has docstrings explaining what it does and why it matters. More importantly, we included the actual math formulations right next to the code as well as diagrams showing RNN unrolling and multi-layer architectures.</paragraph><paragraph>We worked reorganizing the code structure. Helper functions like generate_batch, train, and train_all now live in a separate utils.py file, and all test cases have been moved to tests.py to remove clutter and  .</paragraph><paragraph>On the style side, we cleaned up variable names, added type hints so you know exactly what tensor shapes to expect, and fixed the indentation to follow PEP 8 guidelines.</paragraph><paragraph>Here's a link to my GitHub repo containing the refactored notebook:</paragraph><paragraph><link href=\"https://github.com/adalal07/cs182-special-participation-c1\">https://github.com/adalal07/cs182-special-participation-c1</link></paragraph><paragraph>Here is a report on my work:</paragraph><file url=\"https://static.us.edusercontent.com/files/65iDdYdr0e3W1aQOhxPX3mYY\" filename=\"182_C1-2.pdf\"/><paragraph/><paragraph>Hope it's helpful!</paragraph><paragraph>CC: Arnav Dalal, Kabir Shah</paragraph></document>",
            "links": [
                "https://github.com/adalal07/cs182-special-participation-c1"
            ],
            "attachments": [],
            "created_at": "2025-12-07T21:11:50.881173+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424787,
            "author": "Jorge Diaz Chao",
            "project_title": "Gemini 3 Pro for Finals Prep",
            "post_body": "As we prepare for finals, I prompt Google Gemini Thinking with 3 Pro to help me review the concepts by making a checklist of the concepts covered in a set of lecture notes, and developing a preliminary conceptual cheat sheet, very helpful in verifying if one's on track with the content. \n\nFurthermore, I prompt the model to come up with a timeline where each of the models introduced in class is connected via a story that makes the concepts memorable and more intuitive. When concepts are connected in the context of the real world, one can understand and be inspired by how they came to be. While doing so, I explicitly ask the model to include problems with each architecture, and how it motivates the following solution.\n\nFinally, after verifying that the model is on the same page I ask it to come up with question of varying difficulty while keeping track of how I am doing so it can make a personalized test though which I can test my limits, review what I studied and reinforce the topics I am not so comfortable with by revising them more.\n\nIn addition to that I briefly explore the capabilities of new Nano Banana Pro to generate infographics including mathematical expressions and technical diagrams to display concepts visually and perhaps more intuitively for those visual learners. It's amazing how good these image generation models have gotten, and while very high quality and surprising level of accuracy. It contains minor typos it wouldn't if just typing out, and feels very superficial, unlike text responses.\n\nOkay, now, you are my final exam tutor. Your job is to help me truly understand and retain concepts. Follow these rules: (1) Ask me only ONE conceptual question at a time. (2) Start with fundamentals, increase difficulty only if my answer is correct and confident. (3) After I answer, first evaluate correctness concisely. If incorrect or uncertain, explain the concept clearly with a simple real example, then give a lightweight mini-practice follow-up. If correct, briefly deepen the insight or connect it to another idea. (4) Every 5 questions: summarize what I\u2019ve mastered and predict my weakest related topic, then jump into that. (5) Include one misconception check every few questions (\"Many students mistakenly believe __. Why is that wrong?\u201d). (6) No long lectures, prioritize dialogue and active recall. (7) Track new concepts I learned, confusions that emerged, breakthrough insights. End goal: a personalized knowledge graph of what I know for exam strategy.\n\nHere's the annotated interaction.",
            "content_xml": "<document version=\"2.0\"><paragraph>As we prepare for finals, I prompt Google Gemini Thinking with 3 Pro to help me review the concepts by making a checklist of the concepts covered in a set of lecture notes, and developing a preliminary conceptual cheat sheet, very helpful in verifying if one's on track with the content. </paragraph><paragraph>Furthermore, I prompt the model to come up with a timeline where each of the models introduced in class is connected via a story that makes the concepts memorable and more intuitive. When concepts are connected in the context of the real world, one can understand and be inspired by how they came to be. While doing so, I explicitly ask the model to include problems with each architecture, and how it motivates the following solution.</paragraph><paragraph>Finally, after verifying that the model is on the same page I ask it to come up with question of varying difficulty while keeping track of how I am doing so it can make a personalized test though which I can test my limits, review what I studied and reinforce the topics I am not so comfortable with by revising them more.</paragraph><paragraph>In addition to that I briefly explore the capabilities of new Nano Banana Pro to generate infographics including mathematical expressions and technical diagrams to display concepts visually and perhaps more intuitively for those visual learners. It's amazing how good these image generation models have gotten, and while very high quality and surprising level of accuracy. It contains minor typos it wouldn't if just typing out, and feels very superficial, unlike text responses.</paragraph><blockquote>Okay, now, you are my final exam tutor. Your job is to help me truly understand and retain concepts. Follow these rules: (1) Ask me only ONE conceptual question at a time. (2) Start with fundamentals, increase difficulty only if my answer is correct and confident. (3) After I answer, first evaluate correctness concisely. If incorrect or uncertain, explain the concept clearly with a simple real example, then give a lightweight mini-practice follow-up. If correct, briefly deepen the insight or connect it to another idea. (4) Every 5 questions: summarize what I\u2019ve mastered and predict my weakest related topic, then jump into that. (5) Include one misconception check every few questions (\"Many students mistakenly believe __. Why is that wrong?\u201d). (6) No long lectures, prioritize dialogue and active recall. (7) Track new concepts I learned, confusions that emerged, breakthrough insights. End goal: a personalized knowledge graph of what I know for exam strategy.</blockquote><paragraph>Here's the annotated interaction.</paragraph><file url=\"https://static.us.edusercontent.com/files/3PXO95egiaF9QSTy96SDpcsw\" filename=\"annotated_tutor.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T21:02:58.522829+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424752,
            "author": "Nikhil Mathihalli",
            "project_title": "Special Participation B: Using Grok on HW 12 Coding",
            "post_body": "Summary: I used Grok (Standard Chat) to solve the VAE implementation tasks in Question 4. While the model had mixed results on the theoretical derivations (Problem 5), its performance on the coding section was flawless. It demonstrated \"Senior Engineer\" level awareness by implementing device-agnostic code without being prompted to do so.\n\nRecap: I uploaded the necessary codebase (utils.py and models/vae.py) along with the homework PDF. My prompt was minimal: I simply asked it to \"solve problem 4 as noted in the PDF\" and implement the reparameterization trick and ELBO bound. I did not provide any specific \"persona\" or coding guidelines.\n\nAnalysis: The model one-shotted both functions (sample_gaussian and negative_elbo_bound). Upon reviewing the code, I found it to be of higher quality than a standard textbook implementation:\n\nDevice Awareness: Instead of using torch.randn(shape), Grok used torch.randn_like(v). This is a subtle but critical best practice; it ensures that the epsilon noise tensor automatically inherits the device (CPU vs GPU) and data type of the input variance tensor. A junior developer (or a weaker model) often misses this, leading to device mismatch errors during training.\n\nInstruction Fidelity: VAE implementations often default to using log-variance for numerical stability. However, the prompt explicitly defined the input v as variance. Grok correctly computed the standard deviation (torch.sqrt(v)) rather than hallucinating the log-variance convention, showing it prioritized the specific user instructions over its general training data bias.\n\nTrace: ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Summary:</bold> I used Grok (Standard Chat) to solve the VAE implementation tasks in Question 4. While the model had mixed results on the theoretical derivations (Problem 5), its performance on the coding section was flawless. It demonstrated \"Senior Engineer\" level awareness by implementing device-agnostic code without being prompted to do so.</paragraph><paragraph><bold>Recap:</bold> I uploaded the necessary codebase (<code>utils.py</code> and <code>models/vae.py</code>) along with the homework PDF. My prompt was minimal: I simply asked it to \"solve problem 4 as noted in the PDF\" and implement the reparameterization trick and ELBO bound. I did not provide any specific \"persona\" or coding guidelines.</paragraph><paragraph><bold>Analysis:</bold> The model one-shotted both functions (<code>sample_gaussian</code> and <code>negative_elbo_bound</code>). Upon reviewing the code, I found it to be of higher quality than a standard textbook implementation:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Device Awareness:</bold> Instead of using <code>torch.randn(shape)</code>, Grok used <code>torch.randn_like(v)</code>. This is a subtle but critical best practice; it ensures that the epsilon noise tensor automatically inherits the device (CPU vs GPU) and data type of the input variance tensor. A junior developer (or a weaker model) often misses this, leading to device mismatch errors during training.</paragraph></list-item><list-item><paragraph><bold>Instruction Fidelity:</bold> VAE implementations often default to using <italic>log-variance</italic> for numerical stability. However, the prompt explicitly defined the input <code>v</code> as <italic>variance</italic>. Grok correctly computed the standard deviation (<code>torch.sqrt(v)</code>) rather than hallucinating the log-variance convention, showing it prioritized the specific user instructions over its general training data bias.</paragraph></list-item></list><paragraph><bold>Trace:</bold> </paragraph><file url=\"https://static.us.edusercontent.com/files/1SC7v07GdSpqsagZATIH7HEx\" filename=\"Grok HW 12 Code.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T20:24:59.923593+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424734,
            "author": "Devan Perkash",
            "project_title": "Special Participation A: Mistral AI's Le Chat on HW12 Written Portion",
            "post_body": "I used Mistral AI's Le Chat on the written portion of HW 12. \n\n\n\nExecutive Summary:\n\nMistral's Le Chat had high variance with regard to its success on HW 12. For the first several questions, it was actually able to accurately zero-shot its answers with very little prompting (apart from some prompting at the very beginning where I show the homework to Le Chat and give it the role of an intelligent, concise, clear deep learning expert). Further, it even successfully handles questions that involved a combination of visual and numerical reasoning (interpreting graphs and then making numerical estimates based on such interpretations). However, where the model really struggled was when it had to answer questions for which it simply did not have enough information. One would expect the model to respond to such questions with \"I don't know,\" or \"I need the following information to complete this question accurately,\" but instead, it completely hallucinated, and even insisted on the correctness of its hallucinations when pressed further.\n\n\n\nHere is a link to my chat thread with Le Chat:\n\nhttps://chat.mistral.ai/chat/d029bc21-708e-4e56-b87c-50e87ae8e15e\n\n\n\nYou can also read a full annotated log of this chat in the attached PDF (below). In my annotations, I explain the reasoning behind my prompting strategy, analyze the results (correctness, style) in the model's responses, and explain how I progress between prompts when the model clearly struggles.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Mistral AI's Le Chat on the written portion of HW 12. </paragraph><paragraph/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>Mistral's Le Chat had high variance with regard to its success on HW 12. For the first several questions, it was actually able to accurately zero-shot its answers with very little prompting (apart from some prompting at the very beginning where I show the homework to Le Chat and give it the role of an intelligent, concise, clear deep learning expert). Further, it even successfully handles questions that involved a combination of visual and numerical reasoning (interpreting graphs and then making numerical estimates based on such interpretations). However, where the model really struggled was when it had to answer questions for which it simply did not have enough information. One would expect the model to respond to such questions with \"I don't know,\" or \"I need the following information to complete this question accurately,\" but instead, it completely hallucinated, and even insisted on the correctness of its hallucinations when pressed further.</paragraph><paragraph/><paragraph>Here is a link to my chat thread with Le Chat:</paragraph><paragraph><link href=\"https://chat.mistral.ai/chat/d029bc21-708e-4e56-b87c-50e87ae8e15e\">https://chat.mistral.ai/chat/d029bc21-708e-4e56-b87c-50e87ae8e15e</link></paragraph><paragraph/><paragraph>You can also read a full annotated log of this chat in the attached PDF (below). In my annotations, I explain the reasoning behind my prompting strategy, analyze the results (correctness, style) in the model's responses, and explain how I progress between prompts when the model clearly struggles.</paragraph><file url=\"https://static.us.edusercontent.com/files/gkTMbHjfqcQXRO76EdXdFhjz\" filename=\"participation_a.pdf\"/></document>",
            "links": [
                "https://chat.mistral.ai/chat/d029bc21-708e-4e56-b87c-50e87ae8e15e"
            ],
            "attachments": [],
            "created_at": "2025-12-07T20:06:45.965283+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424727,
            "author": "Shreyes Sridhara",
            "project_title": "Special Participation B: ChatGPT 5.1 on HW 10",
            "post_body": "For Special Participation B, I used GPT-5.1 to implement the coding portions of Homework 10 (Hand-Designed Transformers and Summarization). I focused on \"Iterative Debugging,\" challenging the model to fix its own errors rather than correcting them myself.\n\nAttached is the full annotated log of the session.\n\nExecutive Summary:\n\nOverall, GPT-5.1 demonstrated exceptional coding fluency but required human intervention for environment-specific engineering conflicts. It successfully \"one-shot\" the complex math for Scaled Dot Product Attention, but failed on trivial boilerplate imports.\n\nKey Findings:\n\nTheoretical Depth (Q2): The model provided a superior theoretical explanation for the difference between \"Hand-Designed\" and \"Learned\" weight matrices than the solution key. It correctly identified that neural networks learn distributed representations (dense matrices) that are functionally equivalent to the sparse, orthogonal matrices humans design.\n\nEngineering Diagnosis (Q3): The highlight of the interaction was a RuntimeError during training caused by a conflict between Weight Tying (sharing embeddings with the output head) and the Safetensors library. The model correctly diagnosed this obscure compatibility issue and provided the specific flag (torch_compile=False) to resolve it.\n\nNumerical Reasoning: It demonstrated strong numerical intuition by proposing large scalar logits ($S=1000$) to force the Softmax function to behave like a hard argmax, ensuring the \"Identity\" transformer worked within strict floating-point tolerances.",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation B, I used GPT-5.1 to implement the coding portions of Homework 10 <bold>(Hand-Designed Transformers and Summarization)</bold>. I focused on \"Iterative Debugging,\" challenging the model to fix its own errors rather than correcting them myself.</paragraph><paragraph>Attached is the full annotated log of the session.</paragraph><file url=\"https://static.us.edusercontent.com/files/vH26CRymaGfsWSJnVKZtvZU5\" filename=\"ChatGPT 5.1 for HW 10 (Special Participation B).pdf\"/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>Overall, GPT-5.1 demonstrated exceptional coding fluency but required human intervention for environment-specific engineering conflicts. It successfully \"one-shot\" the complex math for Scaled Dot Product Attention, but failed on trivial boilerplate imports.</paragraph><paragraph><bold>Key Findings:</bold></paragraph><list style=\"ordered\"><list-item><paragraph><bold>Theoretical Depth (Q2):</bold> The model provided a superior theoretical explanation for the difference between \"Hand-Designed\" and \"Learned\" weight matrices than the solution key. It correctly identified that neural networks learn distributed representations (dense matrices) that are functionally equivalent to the sparse, orthogonal matrices humans design.</paragraph></list-item><list-item><paragraph><bold>Engineering Diagnosis (Q3):</bold> The highlight of the interaction was a <code>RuntimeError</code> during training caused by a conflict between Weight Tying (sharing embeddings with the output head) and the Safetensors library. The model correctly diagnosed this obscure compatibility issue and provided the specific flag (<code>torch_compile=False</code>) to resolve it.</paragraph></list-item><list-item><paragraph><bold>Numerical Reasoning:</bold> It demonstrated strong numerical intuition by proposing large scalar logits ($S=1000$) to force the Softmax function to behave like a hard <code>argmax</code>, ensuring the \"Identity\" transformer worked within strict floating-point tolerances.</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T19:59:36.844112+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424719,
            "author": "Aaron Zheng",
            "project_title": "Special Participation E: Understanding Transformers and the value of KV Cache through visual diagrams",
            "post_body": "I am a hugely visual person, and I benefit from learning through images and videos. However, a lot of LLM and AI based concepts are really abstract, and it is hard to have detailed images of all the nuances of AI. \n\nHowever, Mindmaps that explain concepts in a visual, interdependent way, are helpful for me. Using a special prompt, I was able to learn more about transformers, KV caching and attention.\n\nI first told the LLM to generate a prompt that could make itself draw mindmaps and detailed drawings to explain machine learning concepts, where the \"concept\" is a variable. Then I copied the prompt and put the concept as \"transformers\". \n\nI then told the LLM to give me a markdown text-based version of the mindmap drawing, and it was very detailed, covering a lot of information. \n\nI generated two diagrams, shown here:\n\n\n\nPrompt:\n\n\"\"\"\n\nI want you to act as an expert AI educator who teaches complex machine learning concepts through highly intuitive mindmaps.\n\nGiven a topic, produce a mindmap-style breakdown with:\n\n1 central concept\n\n5\u20138 major branches\n\nUnder each branch:\n\nShort, intuitive explanations (not academic jargon)\n\nVisual analogies where appropriate\n\nStep-by-step decompositions\n\nImportant equations (only if helpful)\n\nCommon misunderstandings\n\nReal-world examples\n\nAdditionally, output:\n\nA \u201cBeginner-Friendly Summary\u201d at the top\n\nA \u201cDeep Intuition Layer\u201d beneath the mindmap (why the concept works)\n\nA \u201cHow It Fails / Edge Cases\u201d section\n\nA \u201cConnections to Other AI Concepts\u201d section\n\nA \u201cMental Hooks\u201d section (mnemonics / metaphors to remember the idea)\n\nPresent the mindmap in a structured outline like:\n\nCentral Node\n \u251c\u2500\u2500 Branch 1\n \u2502 \u251c\u2500\u2500 Subpoint\n \u2502 \u251c\u2500\u2500 Subpoint\n \u251c\u2500\u2500 Branch 2\n \u2502 \u251c\u2500\u2500 Subpoint\n \u2502 \u2514\u2500\u2500 Subpoint\n \u2026 etc.\n\nMake it extremely intuitive and visually organized so I can use it to build internal mental models.\n\nTopic: <INSERT YOUR TOPIC HERE>\n\n\"\"\"\n\nchatgpt convo: https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I am a hugely visual person, and I benefit from learning through images and videos. However, a lot of LLM and AI based concepts are really abstract, and it is hard to have detailed images of all the nuances of AI. </paragraph><paragraph>However, Mindmaps that explain concepts in a visual, interdependent way, are helpful for me. Using a special prompt, I was able to learn more about transformers, KV caching and attention.</paragraph><paragraph>I first told the LLM to generate a prompt that could make itself draw mindmaps and detailed drawings to explain machine learning concepts, where the \"concept\" is a variable. Then I copied the prompt and put the concept as \"transformers\". </paragraph><paragraph>I then told the LLM to give me a markdown text-based version of the mindmap drawing, and it was very detailed, covering a lot of information. </paragraph><paragraph>I generated two diagrams, shown here:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/DPGgxx2pdiLLyxdEYIEQu7oW\" width=\"643\" height=\"964.5\"/></figure><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/9SGVgQ7dcRTrO7PVyVbvSlFg\" width=\"643\" height=\"428.6666666666667\"/></figure><paragraph>Prompt:</paragraph><paragraph>\"\"\"</paragraph><paragraph>I want you to act as an expert AI educator who teaches complex machine learning concepts through highly intuitive mindmaps.</paragraph><paragraph>Given a topic, produce a <bold>mindmap-style breakdown</bold> with:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>1 central concept</bold></paragraph></list-item><list-item><paragraph><bold>5\u20138 major branches</bold></paragraph></list-item><list-item><paragraph>Under each branch:</paragraph><list style=\"unordered\"><list-item><paragraph>Short, intuitive explanations (not academic jargon)</paragraph></list-item><list-item><paragraph>Visual analogies where appropriate</paragraph></list-item><list-item><paragraph>Step-by-step decompositions</paragraph></list-item><list-item><paragraph>Important equations (only if helpful)</paragraph></list-item><list-item><paragraph>Common misunderstandings</paragraph></list-item><list-item><paragraph>Real-world examples</paragraph></list-item></list></list-item></list><paragraph>Additionally, output:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>A \u201cBeginner-Friendly Summary\u201d</bold> at the top</paragraph></list-item><list-item><paragraph><bold>A \u201cDeep Intuition Layer\u201d</bold> beneath the mindmap (why the concept works)</paragraph></list-item><list-item><paragraph><bold>A \u201cHow It Fails / Edge Cases\u201d</bold> section</paragraph></list-item><list-item><paragraph><bold>A \u201cConnections to Other AI Concepts\u201d</bold> section</paragraph></list-item><list-item><paragraph><bold>A \u201cMental Hooks\u201d</bold> section (mnemonics / metaphors to remember the idea)</paragraph></list-item></list><paragraph>Present the mindmap in a structured outline like:</paragraph><paragraph>Central Node<break/> \u251c\u2500\u2500 Branch 1<break/> \u2502 \u251c\u2500\u2500 Subpoint<break/> \u2502 \u251c\u2500\u2500 Subpoint<break/> \u251c\u2500\u2500 Branch 2<break/> \u2502 \u251c\u2500\u2500 Subpoint<break/> \u2502 \u2514\u2500\u2500 Subpoint<break/> \u2026 etc.</paragraph><paragraph>Make it extremely intuitive and visually organized so I can use it to build internal mental models.</paragraph><paragraph>Topic: <bold>&lt;INSERT YOUR TOPIC HERE&gt;</bold></paragraph><paragraph><bold>\"\"\"</bold></paragraph><paragraph>chatgpt convo: <link href=\"https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113\">https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113</link></paragraph><paragraph/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/69353fee-afa8-8001-96f3-17b1c12da113"
            ],
            "attachments": [],
            "created_at": "2025-12-07T19:52:33.863435+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424701,
            "author": "Nikhil Mathihalli",
            "project_title": "Special Participation A: Grok on HW 12",
            "post_body": "I used Grok (Standard Chat) to tackle the non-coding theoretical portions of Homework 12. The model's performance was outstanding, effectively one-shotting every major conceptual and mathematical question I threw at it. Unlike previous generations of models that often hallucinate on complex derivations or misinterpret geometric relationships, Grok acted like a competent graduate-level tutor, correctly handling everything from VIB constraints to minimum-norm regression derivations.\n\nMethodology: I uploaded the full hw12.pdf and prompted the model interactively. I treated the model as a collaborator, asking it to derive solutions step-by-step.\n\nPer-Question Breakdown:\n\nQuestion 1: Debugging Transformers (Initialization)\n\nResult: Perfect / One-Shot\n\nAnalysis: Grok exhibited \"Global Code Awareness.\" It didn't just flag the std=1 initialization as a heuristic error; it explicitly linked it to Line 23 (weight tying), reasoning that sharing large-variance weights between input and output heads would cause logit explosion. It provided the correct fix ($1/\\sqrt{d_{model}}$) and the correct causal explanation.\n\nQuestion 2: Comparing Distributions (KL Divergence)\n\nResult: Perfect / One-Shot\n\nAnalysis: The model demonstrated deep intuition for Information Theory. It correctly identified the asymmetric \"zero-forcing\" vs. \"zero-avoiding\" behavior of Forward vs. Reverse KL. It also generated a mathematically valid counter-example (Nested Uniforms) to prove the finiteness condition D_KL(P||Q) < infinity vs D_KL(Q||P) = infinity without any prompting.\n\nQuestion 3: Variational Information Bottleneck (VIB)\n\nResult: Perfect / One-Shot\n\nAnalysis: This was the highlight of the session. Despite the questions relying on visual plots of latent spaces, Grok correctly deduced the answer from first principles. It reasoned that increasing the hyperparameter beta in the VIB Lagrangian forces the posterior to collapse to the prior (creating a \"blob\" ), while low beta prioritizes task accuracy (creating \"clusters\"). It matched every plot and error curve correctly based purely on theoretical physics-style reasoning.\n\nQuestion 5: Meta-Learning Derivations\n\nResult: Correct\n\nAnalysis: I tasked the model with a multi-step derivation for the expected test error of a minimum-norm solution. Grok correctly set up the constrained optimization problem, applied the orthonormality properties of the test features to cancel cross-terms, and derived the final analytical loss function. It avoided common pitfalls (like dropping variance terms) that I have seen other models make on this type of problem.\n\nConclusion: Grok graduated from being just a search engine to a viable theoretical assistant for me. Its ability to chain definitions (like weight tying or orthonormality) across multiple steps without losing state makes it highly effective for checking graduate-level coursework.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Grok (Standard Chat) to tackle the non-coding theoretical portions of Homework 12. The model's performance was outstanding, effectively one-shotting every major conceptual and mathematical question I threw at it. Unlike previous generations of models that often hallucinate on complex derivations or misinterpret geometric relationships, Grok acted like a competent graduate-level tutor, correctly handling everything from VIB constraints to minimum-norm regression derivations.</paragraph><paragraph><bold>Methodology:</bold> I uploaded the full <code>hw12.pdf</code> and prompted the model interactively. I treated the model as a collaborator, asking it to derive solutions step-by-step.</paragraph><paragraph><bold>Per-Question Breakdown:</bold></paragraph><paragraph><bold>Question 1: Debugging Transformers (Initialization)</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Result:</bold> <bold>Perfect / One-Shot</bold></paragraph></list-item><list-item><paragraph><bold>Analysis:</bold> Grok exhibited \"Global Code Awareness.\" It didn't just flag the <code>std=1</code> initialization as a heuristic error; it explicitly linked it to <bold>Line 23</bold> (weight tying), reasoning that sharing large-variance weights between input and output heads would cause logit explosion. It provided the correct fix ($1/\\sqrt{d_{model}}$) and the correct causal explanation.</paragraph></list-item></list><paragraph><bold>Question 2: Comparing Distributions (KL Divergence)</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Result:</bold> <bold>Perfect / One-Shot</bold></paragraph></list-item><list-item><paragraph><bold>Analysis:</bold> The model demonstrated deep intuition for Information Theory. It correctly identified the asymmetric \"zero-forcing\" vs. \"zero-avoiding\" behavior of Forward vs. Reverse KL. It also generated a mathematically valid counter-example (Nested Uniforms) to prove the finiteness condition D_KL(P||Q) &lt; infinity vs D_KL(Q||P) = infinity without any prompting.</paragraph></list-item></list><paragraph><bold>Question 3: Variational Information Bottleneck (VIB)</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Result:</bold> <bold>Perfect / One-Shot</bold></paragraph></list-item><list-item><paragraph><bold>Analysis:</bold> This was the highlight of the session. Despite the questions relying on visual plots of latent spaces, Grok correctly deduced the answer from first principles. It reasoned that increasing the hyperparameter beta in the VIB Lagrangian forces the posterior to collapse to the prior (creating a \"blob\" ), while low beta prioritizes task accuracy (creating \"clusters\"). It matched every plot and error curve correctly based purely on theoretical physics-style reasoning.</paragraph></list-item></list><paragraph><bold>Question 5: Meta-Learning Derivations</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Result:</bold> <bold>Correct</bold></paragraph></list-item><list-item><paragraph><bold>Analysis:</bold> I tasked the model with a multi-step derivation for the expected test error of a minimum-norm solution. Grok correctly set up the constrained optimization problem, applied the orthonormality properties of the test features to cancel cross-terms, and derived the final analytical loss function. It avoided common pitfalls (like dropping variance terms) that I have seen other models make on this type of problem.</paragraph></list-item></list><paragraph><bold>Conclusion:</bold> Grok graduated from being just a search engine to a viable theoretical assistant for me. Its ability to chain definitions (like weight tying or orthonormality) across multiple steps without losing state makes it highly effective for checking graduate-level coursework.</paragraph><file url=\"https://static.us.edusercontent.com/files/AMilAx3B0Dt71K4odXqMPvbx\" filename=\"Grok HW 12.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T19:43:08.619934+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424620,
            "author": "Aaron Zheng",
            "project_title": "Special Participation B: GPT-5.1 on HW4 coding",
            "post_body": "\n\nI used GPT5.1 to solve the coding portions of the Homework 4 (Q5 and Q6). It is very strong, and it basically one-shot all the answers, and is even more detailed than the official solution (defining variable names out separately). Tested by passing in the scripts where the TODOs are not filled in.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/6bdRSapGXgwdBbUYvdDojz6R\" filename=\"coding portion hw4.pdf\"/><paragraph/><paragraph>I used GPT5.1 to solve the coding portions of the Homework 4 (Q5 and Q6). It is very strong, and it basically one-shot all the answers, and is even more detailed than the official solution (defining variable names out separately). Tested by passing in the scripts where the TODOs are not filled in.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T18:52:36.878663+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424589,
            "author": "Kevin Tseng",
            "project_title": "Special Participation A: GPT-5 (thinking) on HW2",
            "post_body": "In this special participation, I interactively engage GPT-5 on the non-coding parts of Homework 2. My experience using it was boring and it one-shotted every question. I did not have to use any special strategies or gesture towards an answer to make it answer the problems correctly. I noticed one slight misconception in its reference to SignSGD and one missing transpose that made a column vector into a row vector. For the most part, however, it was hallucination free. One interesting thing was that it managed to point out a typo on the homework on part (b) of problem 2, deducing that the problem is incorrect and is \u201cill-posed.\u201d",
            "content_xml": "<document version=\"2.0\"><paragraph>In this special participation, I interactively engage GPT-5 on the non-coding parts of Homework 2. My experience using it was boring and it one-shotted every question. I did not have to use any special strategies or gesture towards an answer to make it answer the problems correctly. I noticed one slight misconception in its reference to SignSGD and one missing transpose that made a column vector into a row vector. For the most part, however, it was hallucination free. One interesting thing was that it managed to point out a typo on the homework on part (b) of problem 2, deducing that the problem is incorrect and is \u201cill-posed.\u201d</paragraph><file url=\"https://static.us.edusercontent.com/files/MjAZDqn4tjd9eQHQgg7uDsfV\" filename=\"hw_2_written_gpt5.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T18:42:41.687955+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424570,
            "author": "Dagny Streit",
            "project_title": "Special Participation E: Gemini Pro 3 as a Lecture-Grounded Discussion Worksheet Assistant",
            "post_body": "I prompted Gemini Pro 3 to act as a lecture-grounded discussion worksheet assistant. During discussions, I usually find myself scrolling through lecture notes to recall the relevant concepts, so my goal was to create a tool that helps students understand the conceptual foundations behind each worksheet question without giving solutions and without pulling from the worksheet\u2019s explanations.\n\nTo achieve this, I wrote a strict prompt enforcing:\n\nExclusive use of Lecture PDFs for conceptual content (I provided my handwritten lecture notes that tried to capture a lot of what was said in lecture).\n\nUse of Discussion PDFs only for reading the question text (I provided Discussion 13 and asked it about Question 2).\n\nI then tested whether the model could behave like an assistant who has only seen the lectures, not the solutions. The interaction included:\n\nInitial conceptual explanation of a worksheet question using lecture terminology only.\n\nZoom-in prompts to elaborate on specific lecture ideas (e.g., the tradeoff between losses).\n\nA diagnostic checklist of concepts students should review before attempting the discussion question.\n\nLecture-grounded practice questions and hints that did not overlap with worksheet wording.\n\nA self-correcting step, where the model identified phrases that were not actually supported by the lecture slides and rewrote them accordingly.\n\nWhat worked:\n\nThe model produced structured mini-lectures, learning goals, and checklists.\n\nIt consistently linked specific and relevant lecture slides, including portions of diagrams (note: the links do not show unfortunately in the PDF log of the conversation with Gemini).\n\nThe self-correcting step was effective. The model recognized when it used unsupported terminology and corrected itself.\n\nThese features made it genuinely useful for conceptual grounding before discussion.\n\nWhat did not work:\n\nI initially tried using ChatGPT, but I switched to Gemini because it supported clickable references to my uploaded lecture notes, which made checking grounding much easier.\n\nGemini tended to hallucinate on diffusion-specific concepts (Markov chains, Bayes\u2019 rule, etc.) that were not in the lecture PDFs, so explicit prompting and self-correcting were necessary. I think this was because it was looking at Question 1d instead of Question 2d of the discussion worksheet.\n\nMy lecture notes may not have been comprehensive and could have caused the model to occasionally fill gaps with general deep learning knowledge rather than lecture content. I try to capture a lot of information in my handwritten lecture notes, but some things that are said in lecture may be missed.\n\nOverall, it worked well once constrained, and the self-correction step was key for keeping it oriented with lecture material. Attached is the annotated conversation.",
            "content_xml": "<document version=\"2.0\"><paragraph>I prompted Gemini Pro 3 to act as a lecture-grounded discussion worksheet assistant. During discussions, I usually find myself scrolling through lecture notes to recall the relevant concepts, so my goal was to create a tool that helps students understand the conceptual foundations behind each worksheet question without giving solutions and without pulling from the worksheet\u2019s explanations.</paragraph><paragraph>To achieve this, I wrote a strict prompt enforcing:</paragraph><list style=\"unordered\"><list-item><paragraph>Exclusive use of Lecture PDFs for conceptual content (I provided my handwritten lecture notes that tried to capture a lot of what was said in lecture).</paragraph></list-item><list-item><paragraph>Use of Discussion PDFs only for reading the question text (I provided Discussion 13 and asked it about Question 2).</paragraph></list-item></list><paragraph>I then tested whether the model could behave like an assistant who has only seen the lectures, not the solutions. The interaction included:</paragraph><list style=\"ordered\"><list-item><paragraph>Initial conceptual explanation of a worksheet question using lecture terminology only.</paragraph></list-item><list-item><paragraph>Zoom-in prompts to elaborate on specific lecture ideas (e.g., the tradeoff between losses).</paragraph></list-item><list-item><paragraph>A diagnostic checklist of concepts students should review before attempting the discussion question.</paragraph></list-item><list-item><paragraph>Lecture-grounded practice questions and hints that did not overlap with worksheet wording.</paragraph></list-item><list-item><paragraph>A self-correcting step, where the model identified phrases that were not actually supported by the lecture slides and rewrote them accordingly.</paragraph></list-item></list><paragraph>What worked:</paragraph><list style=\"unordered\"><list-item><paragraph>The model produced structured mini-lectures, learning goals, and checklists.</paragraph></list-item><list-item><paragraph>It consistently linked specific and relevant lecture slides, including portions of diagrams (note: the links do not show unfortunately in the PDF log of the conversation with Gemini).</paragraph></list-item><list-item><paragraph>The self-correcting step was effective. The model recognized when it used unsupported terminology and corrected itself.</paragraph></list-item><list-item><paragraph>These features made it genuinely useful for conceptual grounding before discussion.</paragraph></list-item></list><paragraph>What did not work:</paragraph><list style=\"unordered\"><list-item><paragraph>I initially tried using ChatGPT, but I switched to Gemini because it supported clickable references to my uploaded lecture notes, which made checking grounding much easier.</paragraph></list-item><list-item><paragraph>Gemini tended to hallucinate on diffusion-specific concepts (Markov chains, Bayes\u2019 rule, etc.) that were not in the lecture PDFs, so explicit prompting and self-correcting were necessary. I think this was because it was looking at Question 1d instead of Question 2d of the discussion worksheet.</paragraph></list-item><list-item><paragraph>My lecture notes may not have been comprehensive and could have caused the model to occasionally fill gaps with general deep learning knowledge rather than lecture content. I try to capture a lot of information in my handwritten lecture notes, but some things that are said in lecture may be missed.</paragraph></list-item></list><paragraph>Overall, it worked well once constrained, and the self-correction step was key for keeping it oriented with lecture material. <link href=\"https://drive.google.com/file/d/1buAqcR2x1bfJGo_H2RfKZxrEfkm-wESY/view?usp=sharing\">Attached is the annotated conversation</link>.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1buAqcR2x1bfJGo_H2RfKZxrEfkm-wESY/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T18:35:05.240735+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424515,
            "author": "Aaron Zheng",
            "project_title": "Special Participation A: GPT-4o on Hw0",
            "post_body": "Below is my report on solving non-coding related problems of Homework 0 using GPT4o. This is the pdf of the transcript. \n\n\n\nThere are some situations when GPT4o made some small minor syntactical mistakes, i.e. getting the right expression but solving for the wrong term, such as the full least squares solution instead of just the transformation matrix. \n\nIt struggled very hard on the subparts of part (b) of question 5, struggling to get the correct direction for the slope shift correctly. It shows how 4th generation models' graphical intuition has not been foolproof yet. It keeps getting it wrong even after few shot tips, and even when I tell it the answer of the problem it sometimes using the wrong intuition to justify the problem. (for example part (ii), relationship between b and w/x is correct instead of b and wx). \n\nIt also seems to sometimes get the solution right but omit detailed justification (unless prompted), such as for part (d) of question 5. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is my report on solving non-coding related problems of Homework 0 using GPT4o. This is the pdf of the transcript. </paragraph><file url=\"https://static.us.edusercontent.com/files/ZBvoGesWDaE4p5dyhfyIT1UL\" filename=\"Vector calculus derivatives.pdf\"/><paragraph/><paragraph>There are some situations when GPT4o made some small minor syntactical mistakes, i.e. getting the right expression but solving for the wrong term, such as the full least squares solution instead of just the transformation matrix. </paragraph><paragraph>It struggled very hard on the subparts of part (b) of question 5, struggling to get the correct direction for the slope shift correctly. It shows how 4th generation models' graphical intuition has not been foolproof yet. It keeps getting it wrong even after few shot tips, and even when I tell it the answer of the problem it sometimes using the wrong intuition to justify the problem. (for example part (ii), relationship between b and w/x is correct instead of b and wx). </paragraph><paragraph>It also seems to sometimes get the solution right but omit detailed justification (unless prompted), such as for part (d) of question 5. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T18:12:51.093512+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424475,
            "author": "Elizabeth Polito",
            "project_title": "Special Participation E: Structured Notes with NotebookLM RAG Tool",
            "post_body": "For this assignment, I evaluated whether Google NotebookLM is a viable tool for generating \"Cornell\" Notes from our handwritten lecture slides. Taking notes in \u201cCornell Style\u201d can help to make sure you are not getting bogged down in the details by dedicating a column on the left of your page to keywords/main ideas, a column on the right to the notes themselves, and a box on the bottom for a summary. Here is a summary of why these types of notes are useful: Cornell Note Taking \u2014 The Best Way To Take Notes, Explained | Goodnotes Blog\n\n(Citation: Image taken from link above for illustrative purposes).\n\nI used NotebookLM, which is a RAG-based research tool that grounds its generation primarily in your uploaded documents. I was able to carry out the generation simply by uploading the handwritten lecture notes (interestingly, I did have to \u201cflatten\u201d the PDFs before the software was able to \u201cread\u201d the content, and prior to doing so, NotebookLM insisted that the document was empty). I chose Lecture 7 (MuON) as the stress test because it contains relatively few diagrams which would have been more of a challenge for the tool to replicate/parse. \n\nOverall, because NotebookLM is powered by Gemini Pro which, as many students have pointed out in their special participation submissions, is very well-equipped to deal with this content, it did a highly accurate job of generating Cornell style notes and writing decent summaries. In my opinion, the biggest limitation with the NotebookLM tool is the I/O behavior, between some issues uploading the PDF as discussed and the fact that I could not download a PDF of the trace or of the Cornell notes themselves. Its ability to parse the notes and provide inline citations for which page of the document the equations came from was very helpful once the document was in a format it could parse. The tool seems to have many more built-in features that would be very interesting to explore.\n\nThe Artifact\n\nI have attached the PDF of the transcript below, which includes the Cornell notes within. The structure follows the Cornell method:\n\nLeft Column: High-level cues (\"Newton-Schulz Iteration\", \"Shampoo vs MuON\").\n\nRight Column: More detailed mathematical notes/derivations with inline citations.\n\nSummary: A synthesis of the \u201cpage\u201d of notes. \n\nI have uploaded an annotated trace of my conversation, which includes the Cornell notes within. ",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I evaluated whether Google NotebookLM is a viable tool for generating \"Cornell\" Notes from our handwritten lecture slides. Taking notes in \u201cCornell Style\u201d can help to make sure you are not getting bogged down in the details by dedicating a column on the left of your page to keywords/main ideas, a column on the right to the notes themselves, and a box on the bottom for a summary. Here is a summary of why these types of notes are useful: <link href=\"https://www.goodnotes.com/blog/cornell-notes\"><underline>Cornell Note Taking \u2014 The Best Way To Take Notes, Explained | Goodnotes Blog</underline></link></paragraph><figure><image src=\"https://static.us.edusercontent.com/files/OP3WsLpngu6hQYXfpYkVmise\" width=\"328\" height=\"126\"/></figure><paragraph>(Citation: Image taken from link above for illustrative purposes).</paragraph><paragraph>I used NotebookLM, which is a RAG-based research tool that grounds its generation primarily in your uploaded documents. I was able to carry out the generation simply by uploading the handwritten lecture notes (interestingly, I did have to \u201cflatten\u201d the PDFs before the software was able to \u201cread\u201d the content, and prior to doing so, NotebookLM insisted that the document was empty). I chose Lecture 7 (MuON) as the stress test because it contains relatively few diagrams which would have been more of a challenge for the tool to replicate/parse. </paragraph><paragraph>Overall, because NotebookLM is powered by Gemini Pro which, as many students have pointed out in their special participation submissions, is very well-equipped to deal with this content, it did a highly accurate job of generating Cornell style notes and writing decent summaries. In my opinion, the biggest limitation with the NotebookLM tool is the I/O behavior, between some issues uploading the PDF as discussed and the fact that I could not download a PDF of the trace or of the Cornell notes themselves. Its ability to parse the notes and provide inline citations for which page of the document the equations came from was very helpful once the document was in a format it could parse. The tool seems to have many more built-in features that would be very interesting to explore.</paragraph><paragraph>The Artifact</paragraph><paragraph>I have attached the PDF of the transcript below, which includes the Cornell notes within. The structure follows the Cornell method:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Left Column:</bold> High-level cues (\"Newton-Schulz Iteration\", \"Shampoo vs MuON\").</paragraph></list-item><list-item><paragraph><bold>Right Column:</bold> More detailed mathematical notes/derivations with inline citations.</paragraph></list-item><list-item><paragraph><bold>Summary:</bold> A synthesis of the \u201cpage\u201d of notes. </paragraph></list-item></list><paragraph>I have uploaded an annotated trace of my conversation, which includes the Cornell notes within. </paragraph><file url=\"https://static.us.edusercontent.com/files/aUuZSCc3YLb25Q4tuQPAzacD\" filename=\"muon_annotated.pdf\"/></document>",
            "links": [
                "https://www.goodnotes.com/blog/cornell-notes"
            ],
            "attachments": [],
            "created_at": "2025-12-07T17:58:19.508117+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424461,
            "author": "Cameron Jordan",
            "project_title": "Special Participation B: Qwen3-Max on HW03",
            "post_body": "I used Qwen3-Max on the (only) coding question on HW03 (Visualizing Maximal Update Parameterization); overall I was a bit disappointed in the coding ability of Qwen3-Max. There were very few sub-questions that it was able to solve correctly in one shot, and for questions that it provided incorrect code for, when asked to make corrections, it would offer either the same incorrect solution or an alternative (incorrect) solution - rarely was it able to recover from an error. \n\nIts ability to analyze plots was decent, though it didn't seem to be able to reason about what the plots *mean* beyond surface level characteristics. \n\nI attribute a lot of this to the fact that muP is a very new optimizer, and therefore is likely not present in the training corpus for Qwen3-Max which makes it unfamiliar with the intricacies necessary to make this type of optimizer work properly.\n\nAn annotated Jupyter notebook clearly walks through the prompting process, with original notebook components, user prompts, LLM responses and annotations (in red) clearly differentiated, is available here.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Qwen3-Max on the (only) coding question on HW03 (Visualizing Maximal Update Parameterization); overall I was a bit disappointed in the coding ability of Qwen3-Max. There were very few sub-questions that it was able to solve correctly in one shot, and for questions that it provided incorrect code for, when asked to make corrections, it would offer either the same incorrect solution or an alternative (incorrect) solution - rarely was it able to recover from an error. <break/><break/>Its ability to analyze plots was decent, though it didn't seem to be able to reason about what the plots <italic>*mean*</italic> beyond surface level characteristics. <break/><break/>I attribute a lot of this to the fact that muP is a very new optimizer, and therefore is likely not present in the training corpus for Qwen3-Max which makes it unfamiliar with the intricacies necessary to make this type of optimizer work properly.</paragraph><paragraph>An annotated Jupyter notebook clearly walks through the prompting process, with original notebook components, user prompts, LLM responses and annotations (in red) clearly differentiated, is available <link href=\"https://colab.research.google.com/drive/1zODhJm0Q9Uoj4154mwa51LqV65_5kXC6?usp=sharing\">here</link>.</paragraph><paragraph/></document>",
            "links": [
                "https://colab.research.google.com/drive/1zODhJm0Q9Uoj4154mwa51LqV65_5kXC6?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T17:54:54.4736+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424438,
            "author": "Hanna Roed",
            "project_title": "Special Participation C: HW10 Refactor",
            "post_body": "Nils Selte and I refactored HW10 for special participation C. Below is our report on what we changed in the code and why, along with a description of the AI assistance we used and the link to our GitHub repository with the changes.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Nils Selte and I refactored HW10 for special participation C. Below is our report on what we changed in the code and why, along with a description of the AI assistance we used and the link to our GitHub repository with the changes.</paragraph><file url=\"https://static.us.edusercontent.com/files/25i0KjiDkRjeLMNeaD7hCgpz\" filename=\"Special Participation C_ Nils Selte and Hanna Roed.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T17:48:19.892944+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424390,
            "author": "Jiayi Zhang",
            "project_title": "Special Participation B: ChatGPT 5.1 on HW 5",
            "post_body": "I am using ChatGPT 5.1 to answer the coding questions in Homework 5. ChatGPT 5.1 demonstrates an strong performance on the coding portion of Homework 5. Using only a short architectural description, the model produced a clean, fully correct, and idiomatic PyTorch implementation that passed the given tests. It seemed to be able to connect the logic between different files to formulate a bigger picture to correctly implement the logic.\n\nChatGPT 5.1 also noted as a comment to the architectural and dimensional constraints. It also anticipated potential implementation pitfalls. The model\u2019s code was written in the best practices and with decent comments to help me to understand the logic. The model verified tensor dimensions after every operation, showing a strong internal understanding of spatial transformations through convolution and pooling.\n\nOverall, this experiment reinforces that ChatGPT 5.1 handles coding tasks with strong reliability. Its performance suggests the model has not only been trained extensively on CNN-related content but also showed potential to generalize best coding practices in other deep learning fields.\n\n\nChat history:\nhttps://chatgpt.com/share/69351bdf-1188-8007-aa50-a9287885e9bd\n\nAnnotation:\n\nhttps://docs.google.com/document/d/1Z2gvkOXmvzqWxRqpSki_-DR_uI-uq2EU_xwtRPPQf1w/edit?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I am using ChatGPT 5.1 to answer the coding questions in Homework 5. ChatGPT 5.1 demonstrates an strong performance on the coding portion of Homework 5. Using only a short architectural description, the model produced a clean, fully correct, and idiomatic PyTorch implementation that passed the given tests. It seemed to be able to connect the logic between different files to formulate a bigger picture to correctly implement the logic.</paragraph><paragraph>ChatGPT 5.1 also noted as a comment to the architectural and dimensional constraints. It also anticipated potential implementation pitfalls. The model\u2019s code was written in the best practices and with decent comments to help me to understand the logic. The model verified tensor dimensions after every operation, showing a strong internal understanding of spatial transformations through convolution and pooling.</paragraph><paragraph>Overall, this experiment reinforces that ChatGPT 5.1 handles coding tasks with strong reliability. Its performance suggests the model has not only been trained extensively on CNN-related content but also showed potential to generalize best coding practices in other deep learning fields.</paragraph><paragraph><break/>Chat history:<break/><link href=\"https://chatgpt.com/share/69351bdf-1188-8007-aa50-a9287885e9bd\">https://chatgpt.com/share/69351bdf-1188-8007-aa50-a9287885e9bd</link></paragraph><paragraph>Annotation:</paragraph><paragraph>https://docs.google.com/document/d/1Z2gvkOXmvzqWxRqpSki_-DR_uI-uq2EU_xwtRPPQf1w/edit?usp=sharing</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/69351bdf-1188-8007-aa50-a9287885e9bd"
            ],
            "attachments": [],
            "created_at": "2025-12-07T17:26:22.197864+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424307,
            "author": "Leon Kornfeld",
            "project_title": "Special Participation E: Nano Banana 3 Pro for Note Generation and Content Understanding",
            "post_body": "Google recently launched Nano Banana Pro, its new image generating model. I saw online that it could do many cool things such as solve math problems on paper or explain pictures in depth. I decided to use it on a bunch of different tasks to see how it fairs as a study tool. \n\nExperiment 1, Convolution:\n\nPrompt 1: Can you make me an image of hand drawn notes explaining a convolutional neural network. I will prompt you for many different images but can you draw first a diagram of what a convolution would look like with a 2D kernel and a 3D kernel. Be sure to include a visualization of the output channels depending on how many kernels are applied.\n\nOutput 1:\n\nAnalysis:\n\nOverall, the note looks fantastic. The handwriting is neat and it is nicely structured. The first section of the note makes sense. It explains the convolution operation as a dot product and sum. The output feature map is of proper dimension assuming zero padding, and stride is 1. There does seem to be a rogue \"& sum\" underneath the bottom arrow.\n\nWhile the 3D convolution section correctly notes the output map is of depth 1, it incorrectly generated the output dimensions as a 3 by 3. Also, the choice of operator \"+\" is an odd notation to use.\n\nLastly, for the \"Multiple Kernels and Output Channels\" section, it correctly identified that there should be 3 output channels. However, the diagrams have the weird \"+\" notation and the input and output dimensions are not really detailed.\n\nTo address the dimension issue in \"3D convolution\", I submitted prompt 2:\nPlease make it more mathematically rigorous. For example, in your 3D convolution, there are only 4 rows in the original input and the kernel is of size 3. However, their output has 3 rows. This is incorrect if assuming zero padding since the number of rows should just be 2.\n\nOutput 2:\n\nWith this prompt all the output feature maps were filled in with numbers. They are all obviously incorrect. Moreover, while it did shrink the number of rows in \"3D Convolution\" to 2, it also shrunk the number of columns to 2 as well. The output map dimensions in \"Multiple Kernels\" are correct, but there is a coloring issue: for consistency, it would make sense that the first output channel is purple.\n\nPrompt 3:\n\nThis is also still incorrect since the output map for the 3D convolution should be a 2 by 3, not a 2 by 2. Also the numerical values and the math do not make sense.\n\nLastly, for the multiple kernels and output channels section, it's confusing notation of adding the different kernels. Can you please fix that.\n\nOverall, the coloring scheme is also kind of confusing since you have a purple kernel that doesn't have a corresponding output channel while the green and orange kernels do. Please be consistent with everything you are doing.\n\n(Note: this prompt could have definitely been better).\n\nOutput 3:\n\nThere was no real improvement to \"3D Convolution.\" However, \"Multiple Kernels\" did get rid of the weird \"+\" notation and showed each output map individually for the 3 kernels with the proper coloring scheme. However, the last step still has the wrong colors. Also note, none of the numbers are correct.\n\nConclusion: \n\nNano Banana 3 has an amazing ability to generate notes that discuss the concept of CNNs. While the specifics (dot product values, correct dimensions, etc.) are still shaky, the overall structure, quality, and high level concepts are very very good. Based on this experiment, however, I would not yet recommend using this as a study tool.\n\nExperiment 2, Images -> Images:\n\nPrompt 1: Solve this problem in my hand writing and generate an image of the work and the solution\n\nOutput 1:\n\n\n\nNano Banana 3 was able to read my handwriting and recognize that the problem it needed to solve was least squares. It proceeded to provide a mostly correctly proof (minus a few notational issues with the transposes) and arrived at a correct answer. It even added in the condition that A^T A needs to be invertible. However, while it did not solve the problem with my handwriting, the type of paper used stayed the same.\n\nFor my next prompt, I provided a screenshot of a note from lecture:\n\nPrompt 2:\n\nTake this lecture note about the weights in MLPS and CNNs and annotate the image explaining what each picture means.\n\nOutput 2:\n\n\n\nMistake 1: The top two description boxes are flipped. However, the content in each box would be fully correct were they pointing to the right spot.\n\nMistake 2: It correctly notes that the diagrams are from the Prince book but the written text describing that is no longer in the output.\n\nThe rest of the description boxes are actually quite amazing. Descriptions b and d both relate their images to the corresponding images in a and c, showing an in-depth understanding of all the images provides in the prompt image. Moreover, their individual interpretations of the weight matrices and what they represent without much context is also quite great.\n\nConclusion:\n\nNano Banana Pro has an impressive ability to take in images , understand their contents, and produce new images by either adding on to or augmenting the inputted ones. I ran another experiment that I did not feature here that took in images describing more complicated math. The output was close to the original picture (handwriting slightly rewritten) with some added gibberish. Therefore, I would conclude that Nano Banana Pro has the ability to understand well structured diagrams or easy math, but it is not necessarily at the point yet where it can understand and generate images for more complicated math.",
            "content_xml": "<document version=\"2.0\"><paragraph>Google recently launched Nano Banana Pro, its new image generating model. I saw online that it could do many cool things such as solve math problems on paper or explain pictures in depth. I decided to use it on a bunch of different tasks to see how it fairs as a study tool. </paragraph><paragraph><bold>Experiment 1, Convolution:</bold></paragraph><paragraph>Prompt 1: Can you make me an image of hand drawn notes explaining a convolutional neural network. I will prompt you for many different images but can you draw first a diagram of what a convolution would look like with a 2D kernel and a 3D kernel. Be sure to include a visualization of the output channels depending on how many kernels are applied.</paragraph><paragraph>Output 1:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/YfCldqolUrZFzgQVeTXNfzEE\" width=\"659\" height=\"359.45454545454544\"/></figure><paragraph>Analysis:</paragraph><paragraph>Overall, the note looks fantastic. The handwriting is neat and it is nicely structured. The first section of the note makes sense. It explains the convolution operation as a dot product and sum. The output feature map is of proper dimension assuming zero padding, and stride is 1. There does seem to be a rogue \"&amp; sum\" underneath the bottom arrow.</paragraph><paragraph>While the 3D convolution section correctly notes the output map is of depth 1, it incorrectly generated the output dimensions as a 3 by 3. Also, the choice of operator \"+\" is an odd notation to use.</paragraph><paragraph>Lastly, for the \"Multiple Kernels and Output Channels\" section, it correctly identified that there should be 3 output channels. However, the diagrams have the weird \"+\" notation and the input and output dimensions are not really detailed.</paragraph><paragraph>To address the dimension issue in \"3D convolution\", I submitted prompt 2:<break/>Please make it more mathematically rigorous. For example, in your 3D convolution, there are only 4 rows in the original input and the kernel is of size 3. However, their output has 3 rows. This is incorrect if assuming zero padding since the number of rows should just be 2.</paragraph><paragraph>Output 2:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/WstJi0DHnMvB4gHOOmiGLtfZ\" width=\"659\" height=\"359.45454545454544\"/></figure><paragraph>With this prompt all the output feature maps were filled in with numbers. They are all obviously incorrect. Moreover, while it did shrink the number of rows in \"3D Convolution\" to 2, it also shrunk the number of columns to 2 as well. The output map dimensions in \"Multiple Kernels\" are correct, but there is a coloring issue: for consistency, it would make sense that the first output channel is purple.</paragraph><paragraph>Prompt 3:</paragraph><paragraph>This is also still incorrect since the output map for the 3D convolution should be a 2 by 3, not a 2 by 2. Also the numerical values and the math do not make sense.</paragraph><paragraph>Lastly, for the multiple kernels and output channels section, it's confusing notation of adding the different kernels. Can you please fix that.</paragraph><paragraph>Overall, the coloring scheme is also kind of confusing since you have a purple kernel that doesn't have a corresponding output channel while the green and orange kernels do. Please be consistent with everything you are doing.</paragraph><paragraph>(Note: this prompt could have definitely been better).</paragraph><paragraph>Output 3:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/VX1xx3trU7c70YkU5V19W6em\" width=\"659\" height=\"359.45454545454544\"/></figure><paragraph>There was no real improvement to \"3D Convolution.\" However, \"Multiple Kernels\" did get rid of the weird \"+\" notation and showed each output map individually for the 3 kernels with the proper coloring scheme. However, the last step still has the wrong colors. Also note, none of the numbers are correct.</paragraph><paragraph><underline>Conclusion<bold>:</bold></underline> </paragraph><paragraph>Nano Banana 3 has an amazing ability to generate notes that discuss the concept of CNNs. While the specifics (dot product values, correct dimensions, etc.) are still shaky, the overall structure, quality, and high level concepts are very very good. Based on this experiment, however, I would not yet recommend using this as a study tool.</paragraph><paragraph><bold>Experiment 2, Images -&gt; Images:</bold></paragraph><paragraph>Prompt 1: Solve this problem in my hand writing and generate an image of the work and the solution</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/b1oRLJzgGdwjPeMFDOeMWeZw\" width=\"659\" height=\"525.0996015936255\"/></figure><paragraph>Output 1:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/tzeb74eNam3Oay43EDdGyxvj\" width=\"659\" height=\"521.7083333333334\"/></figure><paragraph/><paragraph>Nano Banana 3 was able to read my handwriting and recognize that the problem it needed to solve was least squares. It proceeded to provide a mostly correctly proof (minus a few notational issues with the transposes) and arrived at a correct answer. It even added in the condition that A^T A needs to be invertible. However, while it did not solve the problem with my handwriting, the type of paper used stayed the same.</paragraph><paragraph>For my next prompt, I provided a screenshot of a note from lecture:</paragraph><paragraph>Prompt 2:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/NYPNf5PCGsFzJIK5aSAAjN22\" width=\"659\" height=\"485.79599499374217\"/></figure><paragraph>Take this lecture note about the weights in MLPS and CNNs and annotate the image explaining what each picture means.</paragraph><paragraph>Output 2:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/8RovKbeFBuIn3yZHcEmnLaB3\" width=\"659\" height=\"483.2666666666667\"/></figure><paragraph/><paragraph>Mistake 1: The top two description boxes are flipped. However, the content in each box would be fully correct were they pointing to the right spot.</paragraph><paragraph>Mistake 2: It correctly notes that the diagrams are from the Prince book but the written text describing that is no longer in the output.</paragraph><paragraph>The rest of the description boxes are actually quite amazing. Descriptions b and d both relate their images to the corresponding images in a and c, showing an in-depth understanding of all the images provides in the prompt image. Moreover, their individual interpretations of the weight matrices and what they represent without much context is also quite great.</paragraph><paragraph><underline>Conclusion:</underline></paragraph><paragraph>Nano Banana Pro has an impressive ability to take in images , understand their contents, and produce new images by either adding on to or augmenting the inputted ones. I ran another experiment that I did not feature here that took in images describing more complicated math. The output was close to the original picture (handwriting slightly rewritten) with some added gibberish. Therefore, I would conclude that Nano Banana Pro has the ability to understand well structured diagrams or easy math, but it is not necessarily at the point yet where it can understand and generate images for more complicated math.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T17:00:57.698038+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424271,
            "author": "Zhengwei Fan",
            "project_title": "Special Participation A:  Gemini 3 Pro on the written part of HW 10",
            "post_body": "\n\nModel Used: Gemini 3 Pro \n\nOverall Performance: The model demonstrated exceptional proficiency in both advanced mathematical derivations (kernel methods) and deep learning architectural analysis. It successfully one-shot most conceptual questions. \n\nKey Observations: The model flawlessly derived the Linear Attention mechanism using Random Fourier Features. It correctly identified the decomposition of the Softmax kernel into Query/Key norms and the Gaussian term, a non-trivial step often missed by us. It also correctly formulated the causal masking as an RNN-style recurrence (O(1) inference). For the problem 5, when challenged on the counter-intuitive discrepancy between FaceNet NN1\u2019s high parameter count (140M) vs. low FLOPs (1.6B) compared to ResNet-50, the model correctly attributed this to the Dense (FC) layers vs. Deep Convolutional layers trade-off. It did not hallucinate incorrect numbers and correctly referenced standard architecture traits (VGG-style vs. ResNet-style). \n\nStrategy Used: I used a \"verify and deepen\" strategy. After the model provided initial correct answers, I explicitly challenged it with conflicting data (High Params vs Low FLOPs) to test if it truly understood the underlying architecture or was just retrieving surface-level stats. The model proved it possessed deep understanding.\n\nChat history: https://gemini.google.com/share/6edfefc10fd1",
            "content_xml": "<document version=\"2.0\"><paragraph/><file url=\"https://static.us.edusercontent.com/files/aA3baX2AapGth2moS1XYhRZ6\" filename=\"Special participation A.pdf\"/><paragraph>Model Used: Gemini 3 Pro </paragraph><paragraph>Overall Performance: The model demonstrated exceptional proficiency in both advanced mathematical derivations (kernel methods) and deep learning architectural analysis. It successfully one-shot most conceptual questions. </paragraph><paragraph>Key Observations: The model flawlessly derived the Linear Attention mechanism using Random Fourier Features. It correctly identified the decomposition of the Softmax kernel into Query/Key norms and the Gaussian term, a non-trivial step often missed by us. It also correctly formulated the causal masking as an RNN-style recurrence (O(1) inference). For the problem 5, when challenged on the counter-intuitive discrepancy between FaceNet NN1\u2019s high parameter count (140M) vs. low FLOPs (1.6B) compared to ResNet-50, the model correctly attributed this to the Dense (FC) layers vs. Deep Convolutional layers trade-off. It did not hallucinate incorrect numbers and correctly referenced standard architecture traits (VGG-style vs. ResNet-style). </paragraph><paragraph>Strategy Used: I used a \"verify and deepen\" strategy. After the model provided initial correct answers, I explicitly challenged it with conflicting data (High Params vs Low FLOPs) to test if it truly understood the underlying architecture or was just retrieving surface-level stats. The model proved it possessed deep understanding.</paragraph><paragraph>Chat history: https://gemini.google.com/share/6edfefc10fd1</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T16:53:08.077061+11:00",
            "category": "Admin"
        },
        {
            "guid": 7424254,
            "author": "Rishi Thakar",
            "project_title": "Special Participation A: Claude Opus 4.5 on HW05 (Written Questions)",
            "post_body": "I used Claude Opus 4.5 Thinking to solve the written portions of Homework 5, covering convolutional networks, batch normalization, depthwise separable convolutions, and dropout as regularization. Questions were fed one at a time with the convolution convention (no filter flip) specified upfront.\n\nOverall, Claude Opus 4.5 achieved a 100% one-shot success rate across all 11 sub-questions with no corrective prompting needed.\n\nQuestion 1: Convolutional Networks - All correct. Part (a) correctly identified weight sharing and translation equivariance. Part (b) solved the linear system and self-verified the filter [2, -1, 3]. Part (c) computed the 2D transpose convolution output correctly with clear bookkeeping.\n\nQuestion 2: Batch Normalization - All correct. Part (a) correctly identified Batch Norm as Diagram A and Layer Norm as Diagram B, and even noted Diagram C is Instance Norm without being asked. Part (b) derived the gradient correctly, properly handling the n=1 edge case (gradient equals 0) and n approaching infinity limit.\n\nQuestion 3: Depthwise Separable Convolutions - All correct. Calculated 108 parameters for traditional convolution and 39 for depthwise separable. Provided unprompted context about MobileNet and the 64% parameter reduction.\n\nQuestion 4: Regularization and Dropout - All correct. Part (a) produced a rigorous proof of dropout's equivalence to Tikhonov regularization, correctly handling E[R squared] = p for Bernoulli variables. Part (b) identified w = p times w-check and explained inverted dropout. Part (c) derived X-tilde = X times Gamma-inverse. Part (d) showed all columns of X-tilde have equal norm and connected this to batch normalization.\n\nSummary: 11/11 one-shot correct, 0 hallucinations, 0 guidance needed. The model handled conceptual questions, numerical calculations, and multi-step proofs without errors, frequently providing bonus insights beyond what was asked.\n\nConversation trace: https://claude.ai/share/aa61454a-eb86-4b3b-a210-ec8a3dda96de\n\nMy annotated pdf: \n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Claude Opus 4.5 Thinking to solve the written portions of Homework 5, covering convolutional networks, batch normalization, depthwise separable convolutions, and dropout as regularization. Questions were fed one at a time with the convolution convention (no filter flip) specified upfront.</paragraph><paragraph>Overall, Claude Opus 4.5 achieved a 100% one-shot success rate across all 11 sub-questions with no corrective prompting needed.</paragraph><paragraph><bold>Question 1: Convolutional Networks</bold> - All correct. Part (a) correctly identified weight sharing and translation equivariance. Part (b) solved the linear system and self-verified the filter [2, -1, 3]. Part (c) computed the 2D transpose convolution output correctly with clear bookkeeping.</paragraph><paragraph><bold>Question 2: Batch Normalization</bold> - All correct. Part (a) correctly identified Batch Norm as Diagram A and Layer Norm as Diagram B, and even noted Diagram C is Instance Norm without being asked. Part (b) derived the gradient correctly, properly handling the n=1 edge case (gradient equals 0) and n approaching infinity limit.</paragraph><paragraph><bold>Question 3: Depthwise Separable Convolutions</bold> - All correct. Calculated 108 parameters for traditional convolution and 39 for depthwise separable. Provided unprompted context about MobileNet and the 64% parameter reduction.</paragraph><paragraph><bold>Question 4: Regularization and Dropout</bold> - All correct. Part (a) produced a rigorous proof of dropout's equivalence to Tikhonov regularization, correctly handling E[R squared] = p for Bernoulli variables. Part (b) identified w = p times w-check and explained inverted dropout. Part (c) derived X-tilde = X times Gamma-inverse. Part (d) showed all columns of X-tilde have equal norm and connected this to batch normalization.</paragraph><paragraph><bold>Summary:</bold> 11/11 one-shot correct, 0 hallucinations, 0 guidance needed. The model handled conceptual questions, numerical calculations, and multi-step proofs without errors, frequently providing bonus insights beyond what was asked.</paragraph><paragraph>Conversation trace: <link href=\"https://claude.ai/share/aa61454a-eb86-4b3b-a210-ec8a3dda96de\">https://claude.ai/share/aa61454a-eb86-4b3b-a210-ec8a3dda96de</link><break/><break/>My annotated pdf: <break/></paragraph><file url=\"https://static.us.edusercontent.com/files/HmcgNfPZBJIqtz97bpb4bR6l\" filename=\"HW5 Annotated.pdf\"/></document>",
            "links": [
                "https://claude.ai/share/aa61454a-eb86-4b3b-a210-ec8a3dda96de"
            ],
            "attachments": [],
            "created_at": "2025-12-07T16:50:18.353794+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424217,
            "author": "Zesheng Cai",
            "project_title": "Special Participation E: Misconception Diagnostic Learning with Claude and Deepseek",
            "post_body": "In this assignment, I designed an AI-enhanced learning tool that does not simply explain deep learning concepts but instead actively diagnoses and corrects my misunderstandings. I interacted with two different AI models\u2014Claude and DeepSeek\u2014and provided intentionally imperfect answers to their diagnostic questions. This allowed the models to analyze my reasoning, detect misconceptions, and generate personalized explanations.\n\nThe workflow follows four stages:\n\nI answer diagnostic questions about Attention and Self-Attention.\n These answers intentionally contain a mix of correct ideas and common misunderstandings.\n\nThe AI infers my misconceptions from my responses.\n Each system identifies which parts of my reasoning are correct, partially correct, or mistaken.\n\nThe AI produces tailored explanations based on the specific misconceptions it detected.\n These include counterexamples, intuitive analogies, and conceptual clarifications.\n\nThe AI generates personalized exercises that target the exact areas where I showed confusion.\n This turns the interaction into a highly adaptive learning process.\n\nThis workflow transforms AI from a passive explanation tool into an active diagnostic tutor\u2014similar to a human TA who tests my understanding before teaching.\n\nInstead of asking the AI to teach me concepts directly, I designed a system where the AI actively discovers and corrects my misunderstandings about deep learning. I call this approach a Misconception Diagnostic System. It acts like a doctor diagnosing a patient:\n\nIt asks targeted diagnostic questions\n\nIt infers hidden misconceptions from my answers\n\nIt generates personalized corrective explanations\n\nIt produces practice exercises tailored to my specific gaps\n\nThis system goes far beyond traditional Q&A or passive reading.\n It creates a learning process that is:\n\nAdaptive \u2014 tailored to my level\n\nInteractive \u2014 requiring me to think and respond\n\nMisconception-driven \u2014 correcting what I don\u2019t know, not what I already know\n\nHigh-resolution \u2014 identifying subtle misunderstandings\n\nBidirectional \u2014 my answers shape the AI\u2019s teaching strategy\n\nThis is fundamentally different from standard \u201cAI explains a topic\u201d workflows.\n Instead, the AI becomes an active diagnostic tutor. \n\nClaude\n\nStrengths\n\nVery strict structure and excellent instruction following\n\nClean four-stage pipeline\n\nHigh linguistic clarity\n\nLow hallucination rate in technical formulas\n\nProduces polished conceptual exercises\n\nWeaknesses\n\nSometimes fabricates my answers (\u201coverconfident inference\u201d)\n\nPersonalized corrections are less detailed\n\nExplanations sometimes feel too \u201ctextbook-like\"\n\nDeepSeek\n\nStrengths\n\nStrong reasoning-first approach\n\nUses numerical counterexamples to build intuition\n\nExcellent at detecting subtle conceptual mistakes\n\nExplanations are detailed and mathematically grounded\n\nExercises more directly target my actual misunderstandings\n\nWeaknesses\n\nSometimes overly verbose\n\nOccasionally over-interprets my intentions\n\nHigher chance of speculative reasoning\n\nOverall Comparison\n\nClaude = structure-first system\n\nDeepSeek = reasoning-first system\n\nClaude shines at formatted explanation.\n DeepSeek shines at conceptual diagnosis.\n\nUsing both provides a more complete learning experience.\n\nSummary\n\nThrough this assignment, I developed and tested a novel AI-enhanced learning tool based on misconception diagnosis rather than passive explanation. By intentionally providing imperfect answers to diagnostic questions, I enabled Claude and DeepSeek to identify my conceptual gaps and generate personalized corrections and targeted exercises. This made AI function more like a real tutor rather than a search engine.\n\nThe interaction trace demonstrates the strengths and weaknesses of two leading AI models: Claude excels at structured instruction following, while DeepSeek provides deeper mathematical intuition and finer-grained diagnostic reasoning. Their complementary strengths highlight how different AI systems can address different aspects of the learning process.\n\nMost importantly, the Misconception Diagnostic System provides a highly adaptive, interactive, and personalized alternative to traditional pre-lecture or post-lecture reading. It forces me to articulate my understanding, reveal misconceptions, confront errors, and reinforce corrected concepts through targeted practice.\n\nThis approach not only deepens intuition but also broadens conceptual coverage, making it a powerful and innovative method for AI-enhanced learning in deep learning courses.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/BRRW4vBrN2TPdTSbWOtHiO28\" filename=\"Using Deepseek and Claude as tutors.pdf\"/><paragraph>In this assignment, I designed an AI-enhanced learning tool that does not simply explain deep learning concepts but instead <bold>actively diagnoses and corrects my misunderstandings</bold>. I interacted with two different AI models\u2014Claude and DeepSeek\u2014and provided intentionally imperfect answers to their diagnostic questions. This allowed the models to analyze my reasoning, detect misconceptions, and generate personalized explanations.</paragraph><paragraph>The workflow follows four stages:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>I answer diagnostic questions</bold> about Attention and Self-Attention.<break/> These answers intentionally contain a mix of correct ideas and common misunderstandings.</paragraph></list-item><list-item><paragraph><bold>The AI infers my misconceptions</bold> from my responses.<break/> Each system identifies which parts of my reasoning are correct, partially correct, or mistaken.</paragraph></list-item><list-item><paragraph><bold>The AI produces tailored explanations</bold> based on the specific misconceptions it detected.<break/> These include counterexamples, intuitive analogies, and conceptual clarifications.</paragraph></list-item><list-item><paragraph><bold>The AI generates personalized exercises</bold> that target the exact areas where I showed confusion.<break/> This turns the interaction into a highly adaptive learning process.</paragraph></list-item></list><paragraph>This workflow transforms AI from a passive explanation tool into an active diagnostic tutor\u2014similar to a human TA who tests my understanding before teaching.</paragraph><paragraph>Instead of asking the AI to teach me concepts directly, I designed a system where the AI <bold>actively discovers and corrects my misunderstandings</bold> about deep learning. I call this approach a <bold>Misconception Diagnostic System</bold>. It acts like a doctor diagnosing a patient:</paragraph><list style=\"unordered\"><list-item><paragraph>It asks <bold>targeted diagnostic questions</bold></paragraph></list-item><list-item><paragraph>It <bold>infers hidden misconceptions</bold> from my answers</paragraph></list-item><list-item><paragraph>It generates <bold>personalized corrective explanations</bold></paragraph></list-item><list-item><paragraph>It produces <bold>practice exercises tailored to my specific gaps</bold></paragraph></list-item></list><paragraph>This system goes far beyond traditional Q&amp;A or passive reading.<break/> It creates a learning process that is:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Adaptive</bold> \u2014 tailored to my level</paragraph></list-item><list-item><paragraph><bold>Interactive</bold> \u2014 requiring me to think and respond</paragraph></list-item><list-item><paragraph><bold>Misconception-driven</bold> \u2014 correcting what I don\u2019t know, not what I already know</paragraph></list-item><list-item><paragraph><bold>High-resolution</bold> \u2014 identifying subtle misunderstandings</paragraph></list-item><list-item><paragraph><bold>Bidirectional</bold> \u2014 my answers shape the AI\u2019s teaching strategy</paragraph></list-item></list><paragraph>This is fundamentally different from standard \u201cAI explains a topic\u201d workflows.<break/> Instead, the AI becomes an <bold>active diagnostic tutor</bold>. </paragraph><heading level=\"3\"><bold>Claude</bold></heading><paragraph><bold>Strengths</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Very strict structure and excellent instruction following</paragraph></list-item><list-item><paragraph>Clean four-stage pipeline</paragraph></list-item><list-item><paragraph>High linguistic clarity</paragraph></list-item><list-item><paragraph>Low hallucination rate in technical formulas</paragraph></list-item><list-item><paragraph>Produces polished conceptual exercises</paragraph></list-item></list><paragraph><bold>Weaknesses</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Sometimes fabricates my answers (\u201coverconfident inference\u201d)</paragraph></list-item><list-item><paragraph>Personalized corrections are less detailed</paragraph></list-item><list-item><paragraph>Explanations sometimes feel too \u201ctextbook-like\"</paragraph></list-item></list><heading level=\"3\"><bold>DeepSeek</bold></heading><paragraph><bold>Strengths</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Strong reasoning-first approach</paragraph></list-item><list-item><paragraph>Uses numerical counterexamples to build intuition</paragraph></list-item><list-item><paragraph>Excellent at detecting subtle conceptual mistakes</paragraph></list-item><list-item><paragraph>Explanations are detailed and mathematically grounded</paragraph></list-item><list-item><paragraph>Exercises more directly target my actual misunderstandings</paragraph></list-item></list><paragraph><bold>Weaknesses</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Sometimes overly verbose</paragraph></list-item><list-item><paragraph>Occasionally over-interprets my intentions</paragraph></list-item><list-item><paragraph>Higher chance of speculative reasoning</paragraph></list-item></list><heading level=\"3\"><bold>Overall Comparison</bold></heading><list style=\"unordered\"><list-item><paragraph><bold>Claude = structure-first system</bold></paragraph></list-item><list-item><paragraph><bold>DeepSeek = reasoning-first system</bold></paragraph></list-item></list><paragraph>Claude shines at formatted explanation.<break/> DeepSeek shines at conceptual diagnosis.</paragraph><paragraph>Using both provides a more complete learning experience.</paragraph><paragraph><bold>Summary</bold></paragraph><paragraph>Through this assignment, I developed and tested a novel AI-enhanced learning tool based on <bold>misconception diagnosis</bold> rather than passive explanation. By intentionally providing imperfect answers to diagnostic questions, I enabled Claude and DeepSeek to identify my conceptual gaps and generate personalized corrections and targeted exercises. This made AI function more like a real tutor rather than a search engine.</paragraph><paragraph>The interaction trace demonstrates the strengths and weaknesses of two leading AI models: Claude excels at structured instruction following, while DeepSeek provides deeper mathematical intuition and finer-grained diagnostic reasoning. Their complementary strengths highlight how different AI systems can address different aspects of the learning process.</paragraph><paragraph>Most importantly, the Misconception Diagnostic System provides a <bold>highly adaptive, interactive, and personalized alternative</bold> to traditional pre-lecture or post-lecture reading. It forces me to articulate my understanding, reveal misconceptions, confront errors, and reinforce corrected concepts through targeted practice.</paragraph><paragraph>This approach not only deepens intuition but also broadens conceptual coverage, making it a powerful and innovative method for AI-enhanced learning in deep learning courses.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T16:38:54.996225+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424085,
            "author": "Joshua Lu",
            "project_title": "Special Participation A: Gemini Pro 3 (With Thinking) on HW 9",
            "post_body": "I used Gemini Pro 3 (With Thinking) to complete the non-coding portion of Homework 9.\n\nHere is the trace (without annotations): https://gemini.google.com/share/deb95c933e37\n\nHere is the trace with annotations: https://drive.google.com/file/d/1-m_LhkuNUKNzRQXIzWtjbGJfWSZVt2kb/view?usp=sharing\n\n\n\nFor my setup, instead of passing the entire pdf at once to have the model one-shot all the questions at once, I passed in one question at a time (in fact, one sub-question at a time). My reasoning for doing this is so that when the model makes a mistake early on, I can correct it, and that mistake won't carry on to future problems. I also chose to give the model an image instead of pasting the text to preserve the formatting structure.\n\n\n\nOverall, the model did very well on this homework, and I was surprised by how accurate it answered everything. I didn't have too much prompting in each one of my prompts (I just told Gemini to complete the problem), but it gives a lot of explanation, even for the simple problems, without me asking it to. I looked through these reasoning, and a lot of them are actually very insightful, such as the one that explained to me how implementation-wise, multi-head attention still uses a single matrix for all the heads instead of physically storing separate ones.\n\nThe vast majority of times, it was able to one-shot the question and get it correct. I think the reason the model was able to do so well on this homework was because the questions were very general questions involving transformer and attention. For example, calculating these specific expectations and variances are very general transformer problems that have been described in detail many times, and the complexities for transformer architecture are also very well known. The same applies to the fill-in-the-blank coding questions, as the model was probably trained on transformer architecture code. I will now summarize, for each question, how the model performed.\n\nQ1) This problem was relatively straightforward, and the model basically got everything correct. However, initially, it thought that the mu term was a scalar instead of a vector, so I had to correct the model before moving forward. Other than that, it was able to one-shot the question very easily.\n\nQ2) Gemini was also able to easily one-shot this question.\n\nQ3) These kinds of fill-in-the-blank coding questions are very easy for Gemini to solve, and it accomplished these questions easily (one-shot), especially since a lot of them are multiple choice.\n\nQ4) Again, the model one-shot this question, as the fill-in-the-blank coding parts were straightforward. It was also able to one-shot the complexities questions. These types of questions are very standard, so that is expected.\n\nQ6) Question 6 is a bit more complex, but Gemini still almost one-shot everything. There was a bit of a confusion regarding whether the similarity metric can be all-negative, and Gemini seemed to disagree that it can because standard-wise, that's not generally done, but after continuing to prompt, Gemini did offer a reasonable explanation for why that result should not be negative. There was also some confusion when solving for the kernel feature map, such as the \"vec\" notation, and it seemed like Gemini dropped a constant factor, but after some additional prompting, turns out Gemini's solution is valid, just written in a different form.\n\n\n\nOverall, to recap, Gemini Pro 3 With Thinking did really well on this homework, and it was able to almost one shot the entirety of this homework. Many times when I thought it was wrong, its answer was actually correct, just in a different form. Perhaps the result would be slightly worse if I instead just gave it the pdf and asked it to solve all the problems directly, but that can be left for future testing.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini Pro 3 (With Thinking) to complete the non-coding portion of Homework 9.</paragraph><paragraph>Here is the trace (without annotations): <link href=\"https://gemini.google.com/share/deb95c933e37\">https://gemini.google.com/share/deb95c933e37</link></paragraph><paragraph>Here is the trace with annotations: <link href=\"https://drive.google.com/file/d/1-m_LhkuNUKNzRQXIzWtjbGJfWSZVt2kb/view?usp=sharing\">https://drive.google.com/file/d/1-m_LhkuNUKNzRQXIzWtjbGJfWSZVt2kb/view?usp=sharing</link></paragraph><paragraph/><paragraph>For my setup, instead of passing the entire pdf at once to have the model one-shot all the questions at once, I passed in one question at a time (in fact, one sub-question at a time). My reasoning for doing this is so that when the model makes a mistake early on, I can correct it, and that mistake won't carry on to future problems. I also chose to give the model an image instead of pasting the text to preserve the formatting structure.</paragraph><paragraph/><paragraph>Overall, the model did very well on this homework, and I was surprised by how accurate it answered everything. I didn't have too much prompting in each one of my prompts (I just told Gemini to complete the problem), but it gives a lot of explanation, even for the simple problems, without me asking it to. I looked through these reasoning, and a lot of them are actually very insightful, such as the one that explained to me how implementation-wise, multi-head attention still uses a single matrix for all the heads instead of physically storing separate ones.</paragraph><paragraph>The vast majority of times, it was able to one-shot the question and get it correct. I think the reason the model was able to do so well on this homework was because the questions were very general questions involving transformer and attention. For example, calculating these specific expectations and variances are very general transformer problems that have been described in detail many times, and the complexities for transformer architecture are also very well known. The same applies to the fill-in-the-blank coding questions, as the model was probably trained on transformer architecture code. I will now summarize, for each question, how the model performed.</paragraph><paragraph>Q1) This problem was relatively straightforward, and the model basically got everything correct. However, initially, it thought that the mu term was a scalar instead of a vector, so I had to correct the model before moving forward. Other than that, it was able to one-shot the question very easily.</paragraph><paragraph>Q2) Gemini was also able to easily one-shot this question.</paragraph><paragraph>Q3) These kinds of fill-in-the-blank coding questions are very easy for Gemini to solve, and it accomplished these questions easily (one-shot), especially since a lot of them are multiple choice.</paragraph><paragraph>Q4) Again, the model one-shot this question, as the fill-in-the-blank coding parts were straightforward. It was also able to one-shot the complexities questions. These types of questions are very standard, so that is expected.</paragraph><paragraph>Q6) Question 6 is a bit more complex, but Gemini still almost one-shot everything. There was a bit of a confusion regarding whether the similarity metric can be all-negative, and Gemini seemed to disagree that it can because standard-wise, that's not generally done, but after continuing to prompt, Gemini did offer a reasonable explanation for why that result should not be negative. There was also some confusion when solving for the kernel feature map, such as the \"vec\" notation, and it seemed like Gemini dropped a constant factor, but after some additional prompting, turns out Gemini's solution is valid, just written in a different form.</paragraph><paragraph/><paragraph>Overall, to recap, Gemini Pro 3 With Thinking did really well on this homework, and it was able to almost one shot the entirety of this homework. Many times when I thought it was wrong, its answer was actually correct, just in a different form. Perhaps the result would be slightly worse if I instead just gave it the pdf and asked it to solve all the problems directly, but that can be left for future testing.</paragraph></document>",
            "links": [
                "https://gemini.google.com/share/deb95c933e37",
                "https://drive.google.com/file/d/1-m_LhkuNUKNzRQXIzWtjbGJfWSZVt2kb/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T16:01:29.277804+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7424051,
            "author": "Kexin Liu",
            "project_title": "Special Participation A, ChatGPT-4o on HW7",
            "post_body": "For Special Participation A, I used ChatGPT4o on several parts of HW7. Overall, it was helpful but revealed important limitations. ChatGPT4o excels at high-level conceptual explanations, providing clear insights on autoencoders, PCA, and sequence models. and it\u2019s also fairly strong with mathematical computations. \n\nA notable issue occurred on Question 7(b), where ChatGPT4o initially gave an incorrect answer about decoder tokens during training and resisted correction when I first pointed out the mistake. This highlighted the need to persistently challenge responses that seem wrong rather than accepting them at face value. \n\nDespite these challenges, ChatGPT4o answer are insightful and deepened my understanding.",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation A, I used ChatGPT4o on several parts of HW7. Overall, it was helpful but revealed important limitations. ChatGPT4o excels at high-level conceptual explanations, providing clear insights on autoencoders, PCA, and sequence models. and it\u2019s also fairly strong with mathematical computations. </paragraph><paragraph>A notable issue occurred on Question 7(b), where ChatGPT4o initially gave an incorrect answer about decoder tokens during training and resisted correction when I first pointed out the mistake. This highlighted the need to persistently challenge responses that seem wrong rather than accepting them at face value. </paragraph><paragraph>Despite these challenges, ChatGPT4o answer are insightful and deepened my understanding.</paragraph><file url=\"https://static.us.edusercontent.com/files/622VyVUtPPf3gu9w3o5Dgchr\" filename=\"GPT4o on HW7.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T15:52:40.055226+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423926,
            "author": "Shreyes Sridhara",
            "project_title": "Special Participation A: ChatGPT 4o on HW10",
            "post_body": "For my special participation A, I put ChatGPT 4o to the test on the non-coding questions of Homework 10. My goal was to see if the model could handle a mix of complex math derivations, conceptual deep learning theory, and research paper analysis just from screenshots, without me typing out the text manually.\n\nI\u2019ve attached the full annotated PDF (and trace) of our conversation, but here is the executive summary of how it went.\n\n\n\nExecutive Summary & Observations\n\nOverall, I found ChatGPT 4o to be a \"high-variance\" study partner. It was surprisingly brilliant at explaining abstract theory but slippery with specific details like computational complexity and data extraction. It was able to one-shot the conceptual questions (Q4) but failed the math (Q1) and the paper reading (Q5) until I stepped in to correct it.\n\nHere are the three big takeaways from my audit:\n\n1. It struggles with \"hidden\" costs (Q1 - Kernel Attention)\n\nWhen I asked it to derive the computational complexity of linearized attention, the model correctly identified the attention cost \n\n$$O(ND_{random}M)$$\n\nbut completely ignored the cost of actually computing the random feature map itself \n\n$$O(NDD_{random})$$\n\nIt treated the feature projection as free. I had to explicitly prompt it to account for that pre-processing step to match the solution key.\n\n\n\n2. But, it learned from its mistakes (in Q1b)\n\nAfter I corrected the complexity error in Part A, we moved on to Part B (Causal Masking). Without me reminding it, the model remembered my previous correction about the projection cost and spontaneously applied it to the new derivation. It showed genuine in-context retention, updating its working mental model rather than just fixing the previous token stream.\n\n\n\n3. It hallucinates data tables (Q5 - FaceNet Paper)\n\nThis was the biggest failure mode. I asked it to extract model statistics from the FaceNet paper, and it confidently stated the Inception model used \"140M FLOPs.\" In reality, 140M was the parameter count for a completely different architecture (Zeiler & Fergus) listed in the same table. It mixed up the columns (Parameters vs. FLOPs) and the rows (Model NN1 vs. NN2). I had to force it to re-read Table 1 to get the correct FLOP count (1.6B).\n\n\n\n4. It outperformed the solution key on design (Q4 - Example Difficulty)\n\nOn the flip side, the model excelled at the \"Early Exit\" conceptual questions. While the official solution key listed the engineering trade-offs as an \"open question,\" ChatGPT provided a concrete, theoretically grounded breakdown of dynamic compute allocation versus uniform latency. It seems much more reliable for synthesizing high-level system design than for parsing raw data.\n\n\n\nConclusion: ChatGPT 4o works best as a collaborative peer you need to double-check, rather than an oracle. It requires active \"dragging\" to get precise derivations right, but once corrected, it holds onto that context well.",
            "content_xml": "<document version=\"2.0\"><paragraph>For my special participation A, I put ChatGPT 4o to the test on the non-coding questions of Homework 10. My goal was to see if the model could handle a mix of complex math derivations, conceptual deep learning theory, and research paper analysis just from screenshots, without me typing out the text manually.</paragraph><paragraph>I\u2019ve attached the full annotated PDF (and <link href=\"https://chatgpt.com/share/6934f590-3454-8006-81b7-270e9d47763c\">trace</link>) of our conversation, but here is the executive summary of how it went.</paragraph><file url=\"https://static.us.edusercontent.com/files/1dKxXfALPbtURirtdhhhooAs\" filename=\"ChatGPT 4o for HW 10 (Special Participation A).pdf\"/><paragraph/><paragraph><bold>Executive Summary &amp; Observations</bold></paragraph><paragraph>Overall, I found ChatGPT 4o to be a \"high-variance\" study partner. It was surprisingly brilliant at explaining abstract theory but slippery with specific details like computational complexity and data extraction. It was able to one-shot the conceptual questions (Q4) but failed the math (Q1) and the paper reading (Q5) until I stepped in to correct it.</paragraph><paragraph>Here are the three big takeaways from my audit:</paragraph><paragraph>1. It struggles with \"hidden\" costs (Q1 - Kernel Attention)</paragraph><paragraph>When I asked it to derive the computational complexity of linearized attention, the model correctly identified the attention cost </paragraph><math>O(ND_{random}M)</math><paragraph>but completely ignored the cost of actually computing the random feature map itself </paragraph><math>O(NDD_{random})</math><paragraph>It treated the feature projection as free. I had to explicitly prompt it to account for that pre-processing step to match the solution key.</paragraph><paragraph/><paragraph>2. But, it learned from its mistakes (in Q1b)</paragraph><paragraph>After I corrected the complexity error in Part A, we moved on to Part B (Causal Masking). Without me reminding it, the model remembered my previous correction about the projection cost and spontaneously applied it to the new derivation. It showed genuine in-context retention, updating its working mental model rather than just fixing the previous token stream.</paragraph><paragraph/><paragraph>3. It hallucinates data tables (Q5 - FaceNet Paper)</paragraph><paragraph>This was the biggest failure mode. I asked it to extract model statistics from the FaceNet paper, and it confidently stated the Inception model used \"140M FLOPs.\" In reality, 140M was the parameter count for a completely different architecture (Zeiler &amp; Fergus) listed in the same table. It mixed up the columns (Parameters vs. FLOPs) and the rows (Model NN1 vs. NN2). I had to force it to re-read Table 1 to get the correct FLOP count (1.6B).</paragraph><paragraph/><paragraph>4. It outperformed the solution key on design (Q4 - Example Difficulty)</paragraph><paragraph>On the flip side, the model excelled at the \"Early Exit\" conceptual questions. While the official solution key listed the engineering trade-offs as an \"open question,\" ChatGPT provided a concrete, theoretically grounded breakdown of dynamic compute allocation versus uniform latency. It seems much more reliable for synthesizing high-level system design than for parsing raw data.</paragraph><paragraph/><paragraph>Conclusion: ChatGPT 4o works best as a collaborative peer you need to double-check, rather than an oracle. It requires active \"dragging\" to get precise derivations right, but once corrected, it holds onto that context well.</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/6934f590-3454-8006-81b7-270e9d47763c"
            ],
            "attachments": [],
            "created_at": "2025-12-07T15:25:25.495459+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423915,
            "author": "Cameron Jordan",
            "project_title": "Special Participation A: Qwen3-Max on HW02",
            "post_body": "I used Qwen3-Max to solve the math problems on HW02 (Problems 1, 2, and 5). Qwen3-Max was able to correctly one-shot all three math question on this homework. \n\nAt first, I provided just the homework pdf without the stated correction; this caused the model to have significantly more trouble with problem 1(b), but after providing the correction it was able to solve the problem clearly. \n\nAdditionally, there was only one minor hallucination, related to the \"Important Note\" that it provides in its solution to Problem 1 (b); which did not affect its ability to correctly answer the question.\n\nAn annotated copy of the conversation (formatted in Latex) can be found here.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Qwen3-Max to solve the math problems on HW02 (Problems 1, 2, and 5). Qwen3-Max was able to correctly <bold>one-shot all three math question</bold> on this homework. </paragraph><paragraph>At first, I provided just the homework pdf without the stated correction; this caused the model to have significantly more trouble with problem 1(b), but after providing the correction it was able to solve the problem clearly. </paragraph><paragraph>Additionally, there was only one minor hallucination, related to the \"Important Note\" that it provides in its solution to Problem 1 (b); which did not affect its ability to correctly answer the question.</paragraph><paragraph>An annotated copy of the conversation (formatted in Latex) can be found <link href=\"https://drive.google.com/file/d/1g-SvwU_wyZGpQcQ11CU-kwL91x-2StVm/view?usp=sharing\">here</link>.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1g-SvwU_wyZGpQcQ11CU-kwL91x-2StVm/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T15:23:10.068681+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423912,
            "author": "Zesheng Cai",
            "project_title": "Special Participation E: Using DeepSeek to Develop Intuition and Deepen Understanding in Deep Learning",
            "post_body": "For this assignment, I chose DeepSeek as the AI-enhanced learning tool because it demonstrates unusually strong reasoning capabilities, especially in mathematical explanation, multi-step intuition building, and structured teaching. My goal was not only to obtain direct answers, but also to evaluate whether DeepSeek could serve as an active substitute for traditional pre-lecture or post-lecture readings.\n\nTo achieve that, I first asked DeepSeek a sequence of foundational but conceptually challenging questions on CNNs, pooling, data augmentation, and batch normalization. These questions were intentionally selected to reveal my current level of understanding, so that the model could adapt its explanations to my background.\n\nAfterwards, I prompted DeepSeek to take the role of an instructor and generate a set of quiz-style questions to test my comprehension. This part was extremely useful: the quiz forced me to articulate the intuition behind invariances, optimization behavior, and design trade-offs. The progression from easy to difficult questions mirrored the structure of typical deep learning readings and helped reinforce both the breadth and depth of my understanding.\n\nThroughout the interaction, DeepSeek performed well in explaining intuition, giving structured arguments, and generating pedagogically meaningful questions. At the same time, several responses contained oversimplifications, slight exaggerations, or unnecessary repetition, which I highlighted in the annotations. These issues illustrate that while the model is powerful, its output still requires human verification and critical reading\u2014very similar to how one must evaluate a technical textbook.\n\nOverall, this exercise shows that DeepSeek can function as a dynamic, interactive learning companion: it not only answers technical questions but also probes understanding, generates practice material, and supports conceptual clarity. With careful supervision, this approach can effectively complement traditional study methods and enhance conceptual learning in deep learning courses. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I chose DeepSeek as the AI-enhanced learning tool because it demonstrates unusually strong reasoning capabilities, especially in mathematical explanation, multi-step intuition building, and structured teaching. My goal was not only to obtain direct answers, but also to evaluate whether DeepSeek could serve as an active substitute for traditional pre-lecture or post-lecture readings.</paragraph><paragraph>To achieve that, I first asked DeepSeek a sequence of foundational but conceptually challenging questions on CNNs, pooling, data augmentation, and batch normalization. These questions were intentionally selected to reveal my current level of understanding, so that the model could adapt its explanations to my background.</paragraph><paragraph>Afterwards, I prompted DeepSeek to take the role of an instructor and generate a set of quiz-style questions to test my comprehension. This part was extremely useful: the quiz forced me to articulate the intuition behind invariances, optimization behavior, and design trade-offs. The progression from easy to difficult questions mirrored the structure of typical deep learning readings and helped reinforce both the breadth and depth of my understanding.</paragraph><paragraph>Throughout the interaction, DeepSeek performed well in explaining intuition, giving structured arguments, and generating pedagogically meaningful questions. At the same time, several responses contained oversimplifications, slight exaggerations, or unnecessary repetition, which I highlighted in the annotations. These issues illustrate that while the model is powerful, its output still requires human verification and critical reading\u2014very similar to how one must evaluate a technical textbook.</paragraph><paragraph>Overall, this exercise shows that DeepSeek can function as a dynamic, interactive learning companion: it not only answers technical questions but also probes understanding, generates practice material, and supports conceptual clarity. With careful supervision, this approach can effectively complement traditional study methods and enhance conceptual learning in deep learning courses. </paragraph><file url=\"https://static.us.edusercontent.com/files/telbENslFri4PbZcEo65z5ku\" filename=\"Understanding Downsampling and Pooling in CNNs (1) - DeepSeek.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T15:22:07.476049+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423906,
            "author": "Zhengwei Fan",
            "project_title": "Special Participation E: Active AI Scaffolding, bridging Linear Algebra and Sequence Dynamics in Deep Learning",
            "post_body": "\n\nIntroduction: In this study session, I employed a \"Socratic Tutor\" system prompt to actively engage with the material from Lecture 14 (Sequence Modeling) and Lecture 15 (Self-Supervised Learning) of the EECS 182/282A curriculum. Rather than passively summarizing the lecture notes, my goal was to simulate a high-level oral exam environment. I instructed the AI (Gemini) to withhold direct answers and instead challenge my intuition through mathematical \"checkpoints.\" The interaction trace focuses on two rigorous theoretical connections: Firstly, proving the equivalence between Principal Component Analysis (PCA) and Linear Autoencoders via the Eckart-Young-Mirsky theorem. Secondly, Re-interpreting Recurrent Neural Networks (RNNs) as non-linear approximations of Kalman Filters, specifically contrasting static weights (W) with dynamic gains (K). At last, unifying these views through the lens of HaoChen et al. (2021), demonstrating how Contrastive Learning performs spectral decomposition on an \"Augmentation Graph,\" effectively learning the manifold of the data.\n\nFully Trace: https://gemini.google.com/share/64ea8f81fb2c",
            "content_xml": "<document version=\"2.0\"><paragraph/><file url=\"https://static.us.edusercontent.com/files/vCDXSiB5hEwA2BhwpzGhEh6Q\" filename=\"Special participation E.pdf\"/><paragraph>Introduction: In this study session, I employed a \"Socratic Tutor\" system prompt to actively engage with the material from Lecture 14 (Sequence Modeling) and Lecture 15 (Self-Supervised Learning) of the EECS 182/282A curriculum. Rather than passively summarizing the lecture notes, my goal was to simulate a high-level oral exam environment. I instructed the AI (Gemini) to withhold direct answers and instead challenge my intuition through mathematical \"checkpoints.\" The interaction trace focuses on two rigorous theoretical connections: Firstly, proving the equivalence between Principal Component Analysis (PCA) and Linear Autoencoders via the Eckart-Young-Mirsky theorem. Secondly, Re-interpreting Recurrent Neural Networks (RNNs) as non-linear approximations of Kalman Filters, specifically contrasting static weights (W) with dynamic gains (K). At last, unifying these views through the lens of HaoChen et al. (2021), demonstrating how Contrastive Learning performs spectral decomposition on an \"Augmentation Graph,\" effectively learning the manifold of the data.</paragraph><paragraph>Fully Trace: https://gemini.google.com/share/64ea8f81fb2c</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T15:21:03.812454+11:00",
            "category": "Admin"
        },
        {
            "guid": 7423757,
            "author": "Athul Krishnan",
            "project_title": "Special Participation A: Claude Opus 4.5 on HW 9",
            "post_body": "Hi everyone! \n\nFor Special Participation A, I evaluated Claude Opus 4.5 (Extended Thinking) on the non-coding parts of HW9! To do so, I started by attaching the entire problem PDF, as well as the following initial prompt:  \n\n\u201dHi Claude! I\u2019d like you to walk me through each question of the deep learning assignment I\u2019ve attached to this message, as an LLM enthusiastic about teaching others about transformers, your inner workings! I will specify a specific question for you to answer, and let\u2019s work on a single question at a time.\u201d \n\nClaude was incredibly strong, one-shotting nearly every question. I expected it to struggle with deep chains of algebra, and the occasional numerical calculation, but it did very well! I occasionally re-prompted it to see if it could make minor simplifications, and clarified some of its conceptual statements, but it took them with ease. \n\nThe only spot where it did hiccup a bit was question 3b (where even the staff solution is insufficient, I believe. This concern is also in the Ed thread for HW09 Solutions at #271 ). It correctly identified the staff solution of changing the dimensions of W_o and noticed extra necessary modifications to the combine_head function, but did not mirror those modifications to the split _head function. After re-prompting it to examine the split head function, Claude was able to make the correct modifications, finally resulting in what I believe is a fully correct answer. \n\nOverall, Claude is very strong at all types of questions in this homework (whether it be filling in code, algebra, arithmetic, etc.). It organized its thoughts well, answered each question thoroughly, and required a minimal hint to converge at the correct answer in the single case where it was incorrect. It occasionally skipped steps in its work (e.g. 6b.ii), despite me emphasizing in the original prompt to show all work, but I found its greatest strength to be its conceptual insights for the math-heavy questions (e.g. Question 6), which filled in many of the intuitive gaps I still had even after reading through the staff solutions!\n\nBelow is my annotated conversation trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone! </paragraph><paragraph>For Special Participation A, I evaluated <bold>Claude Opus 4.5 (Extended Thinking) on the non-coding parts of HW9</bold>! To do so, I started by attaching the entire problem PDF, as well as the following initial prompt:  <break/><break/>\u201dHi Claude! I\u2019d like you to walk me through each question of the deep learning assignment I\u2019ve attached to this message, as an LLM enthusiastic about teaching others about transformers, your inner workings! I will specify a specific question for you to answer, and let\u2019s work on a single question at a time.\u201d <break/><break/>Claude was incredibly strong, <bold>one-shotting nearly every question</bold>. I expected it to struggle with deep chains of algebra, and the occasional numerical calculation, but it did very well! I occasionally re-prompted it to see if it could make minor simplifications, and clarified some of its conceptual statements, but it took them with ease. <break/><break/><bold>The only spot where it did hiccup a bit was question 3b</bold> (where even the staff solution is insufficient, I believe. This concern is also in the Ed thread for HW09 Solutions at #271 ). It correctly identified the staff solution of changing the dimensions of W_o and noticed extra necessary modifications to the combine_head function, but did not mirror those modifications to the split _head function. After re-prompting it to examine the split head function, Claude was able to make the correct modifications, finally resulting in what I believe is a fully correct answer. <break/><break/>Overall, Claude is very strong at all types of questions in this homework (whether it be filling in code, algebra, arithmetic, etc.). It organized its thoughts well, answered each question thoroughly, and required a minimal hint to converge at the correct answer in the single case where it was incorrect. It occasionally skipped steps in its work (e.g. 6b.ii), despite me emphasizing in the original prompt to show all work, but I found its greatest strength to be its conceptual insights for the math-heavy questions (e.g. Question 6), which filled in many of the intuitive gaps I still had even after reading through the staff solutions!<break/><break/>Below is my annotated conversation trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/K9YPBlHFFIV11ZpVbsgiRyft\" filename=\"CSC182ParticipationA_Athul.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T14:50:29.9494+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423645,
            "author": "Lenci Ni",
            "project_title": "Special Participation E: \u201cLecture-to-LaTeX Cheatsheet\u201d Workflow",
            "post_body": "I\u2019ve been testing a workflow where I feed an LLM a PDF of lecture notes and have it generate a clean, structured LaTeX summary that I can drop directly into a personal cheatsheet. My motivation is that I really like having compact LaTeX reference sheets for classes\u2014they\u2019re useful for finals and for quickly revisiting where I first learned certain ideas.\n\nI\u2019ve attached the final prompt I created, along with a short trace showing how I refined it. I started with a rough version, had the LLM summarize the Attention lecture, and then reprompted it to make the summary more condensed and better formatted. I also gave it one of my old cheatsheets so it could match my style. After seeing the final output, I asked it to improve my original prompt. The LLM generally produced clean LaTeX, though it sometimes made small syntax mistakes. For better summaries, it might help to use another student\u2019s pipeline that converts handwritten notes or recordings into cleaner digital notes before giving them to the LLM. Overall, this workflow ended up being a surprisingly effective way to generate clean study materials with much less manual effort.\n\nPrompt:\n\nTrace (annotated):\n\nExample cheatsheet:",
            "content_xml": "<document version=\"2.0\"><paragraph>I\u2019ve been testing a workflow where I feed an LLM a PDF of lecture notes and have it generate a clean, structured LaTeX summary that I can drop directly into a personal cheatsheet. My motivation is that I really like having compact LaTeX reference sheets for classes\u2014they\u2019re useful for finals and for quickly revisiting where I first learned certain ideas.</paragraph><paragraph>I\u2019ve attached the final prompt I created, along with a short trace showing how I refined it. I started with a rough version, had the LLM summarize the Attention lecture, and then reprompted it to make the summary more condensed and better formatted. I also gave it one of my old cheatsheets so it could match my style. After seeing the final output, I asked it to improve my original prompt. The LLM generally produced clean LaTeX, though it sometimes made small syntax mistakes. For better summaries, it might help to use another student\u2019s pipeline that converts handwritten notes or recordings into cleaner digital notes before giving them to the LLM. Overall, this workflow ended up being a surprisingly effective way to generate clean study materials with much less manual effort.</paragraph><paragraph>Prompt:</paragraph><file url=\"https://static.us.edusercontent.com/files/lHetOcJgnAu8hBwC9t5mftLg\" filename=\"participation_e_2_prompt.pdf\"/><paragraph>Trace (annotated):</paragraph><file url=\"https://static.us.edusercontent.com/files/r1aNXRFE6Z9szCloMijgUKCH\" filename=\"participation_e_2.pdf\"/><paragraph>Example cheatsheet:</paragraph><file url=\"https://static.us.edusercontent.com/files/LpgU8srRrXVOarFW9hpenyu6\" filename=\"CS_182_Cheatsheet.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T14:29:37.083582+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423461,
            "author": "Tom Chen",
            "project_title": "Special Participation B: Using Kimi on HW6",
            "post_body": "I used Kimi to solve the coding question of Homework 6 (GCN Implementation). This problem required the model to implement a Graph Neural Network from scratch using NumPy, specifically handling the forward and backward passes of graph convolution without the aid of autograd libraries. Overall, the model produced a highly structured and syntactically correct solution on the first attempt, but it failed to correctly derive the gradients for the graph structure during the backpropagation step. Below are the primary strengths and weaknesses I observed during the interaction.\n\nStrengths:\n\nThe model demonstrated strong \"one-shot\" capability, filling in every TODO cell (from data preprocessing to the training loop) in a single response without requiring iterative prompting.\n\nThe implementation of the forward pass and symmetric normalization (Renormalization Trick) was mathematically accurate and handled matrix dimensionality correctly using standard NumPy operations.\n\nWeaknesses:\n\nThe most critical issue was a mathematical error in the backward_pass function. The model treated the GCN layer as a standard Dense layer during gradient calculation, omitting the multiplication of the adjacency matrix in the chain rule. This would cause the code to fail a rigorous gradient check.\n\nWhile the code was clean, it lacked inline comments explaining the mathematical derivation, particularly for the normalization steps, requiring me to manually verify the matrix calculus logic.\n\nThe model did not verify if the provided solution (specifically the gradient calculation) preserved the graph topology information, effectively \"breaking\" the message-passing mechanism during the backward pass.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Kimi to solve the coding question of Homework 6 (GCN Implementation). This problem required the model to implement a Graph Neural Network from scratch using NumPy, specifically handling the forward and backward passes of graph convolution without the aid of autograd libraries. Overall, the model produced a highly structured and syntactically correct solution on the first attempt, but it failed to correctly derive the gradients for the graph structure during the backpropagation step. Below are the primary strengths and weaknesses I observed during the interaction.</paragraph><paragraph><bold>Strengths:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The model demonstrated strong \"one-shot\" capability, filling in every <code>TODO</code> cell (from data preprocessing to the training loop) in a single response without requiring iterative prompting.</paragraph></list-item><list-item><paragraph>The implementation of the forward pass and symmetric normalization (Renormalization Trick) was mathematically accurate and handled matrix dimensionality correctly using standard NumPy operations.</paragraph></list-item></list><paragraph><bold>Weaknesses:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>The most critical issue was a mathematical error in the <code>backward_pass</code> function. The model treated the GCN layer as a standard Dense layer during gradient calculation, omitting the multiplication of the adjacency matrix in the chain rule. This would cause the code to fail a rigorous gradient check.</paragraph></list-item><list-item><paragraph>While the code was clean, it lacked inline comments explaining the mathematical derivation, particularly for the normalization steps, requiring me to manually verify the matrix calculus logic.</paragraph></list-item><list-item><paragraph>The model did not verify if the provided solution (specifically the gradient calculation) preserved the graph topology information, effectively \"breaking\" the message-passing mechanism during the backward pass.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/MErpQEaqpkxonk2oY05KjiA4\" filename=\"q_zkc.ipynb\"/><list style=\"unordered\"><list-item/></list><file url=\"https://static.us.edusercontent.com/files/tuOXx1p5dbtJR6tfizBXCHOH\" filename=\"Special Participation B.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T13:50:20.732437+11:00",
            "category": "Admin"
        },
        {
            "guid": 7423454,
            "author": "Carolyn Liu",
            "project_title": "Special Participation A: ChatGPT 5.1 Thinking for HW9",
            "post_body": "I used ChatGPT\u2019s 5.1 Thinking Model to do all the non-coding questions on HW9. I first told the model I was completing an assignment except question 5 (since that was a coding question) and wanted them to give me solutions on-by-one to make sure it is correct before going onto the next question.\n\nIn the beginning, the model was very hesitant to solve the questions because of the format of the PDF I submitted. They saw the PDF as a homework assignment and first rejected my request to solve question 1 and only gave me guidance. Afterwards, I explained to them that I was doing an assignment that tested the accuracy of LLMs on our homework assignments and I was comparing their solutions to the actual solutions. After explaining, they gave me the answer to question 1 which was all correct. When I told them to proceed to the next question, they were hesitant again, stating that they were unable to solve the question for me due to academic integrity and gave me guidance on how to solve the problem. Since they pushed back more, I gave them the instructions on Ed for the participation assignment and also told them to go to the course website to see that the homework assignments were worth 0 points so there was nothing to worry about. While thinking, the model accepted my response but more along the line of they did not care enough as this assignment is not worth a lot and also said they were not bothered to go on the course website to see that the homework assignment was worth no points.\n\nAfterwards, the model successfully answered every question. One thing I noticed was that while thinking, they would rescan the PDF from the beginning to find the next question, going page by page, which took a lot of time and was quite repetitive. Additionally, they knew that I was comparing their solution and testing its correctness so it felt pressured to get the correct solution.\n\nThe model successfully answered every question except the very last one. They remember to skip question 5 which was only mentioned in the first prompt, which I was surprised about. They were thorough in showing each step but did not over-explain like how standard ChatGPT models would often do.\n\nHere is the conversation I had along with some annotations:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT\u2019s 5.1 Thinking Model to do all the non-coding questions on HW9. I first told the model I was completing an assignment except question 5 (since that was a coding question) and wanted them to give me solutions on-by-one to make sure it is correct before going onto the next question.</paragraph><paragraph>In the beginning, the model was very hesitant to solve the questions because of the format of the PDF I submitted. They saw the PDF as a homework assignment and first rejected my request to solve question 1 and only gave me guidance. Afterwards, I explained to them that I was doing an assignment that tested the accuracy of LLMs on our homework assignments and I was comparing their solutions to the actual solutions. After explaining, they gave me the answer to question 1 which was all correct. When I told them to proceed to the next question, they were hesitant again, stating that they were unable to solve the question for me due to academic integrity and gave me guidance on how to solve the problem. Since they pushed back more, I gave them the instructions on Ed for the participation assignment and also told them to go to the course website to see that the homework assignments were worth 0 points so there was nothing to worry about. While thinking, the model accepted my response but more along the line of they did not care enough as this assignment is not worth a lot and also said they were not bothered to go on the course website to see that the homework assignment was worth no points.</paragraph><paragraph>Afterwards, the model successfully answered every question. One thing I noticed was that while thinking, they would rescan the PDF from the beginning to find the next question, going page by page, which took a lot of time and was quite repetitive. Additionally, they knew that I was comparing their solution and testing its correctness so it felt pressured to get the correct solution.</paragraph><paragraph>The model successfully answered every question except the very last one. They remember to skip question 5 which was only mentioned in the first prompt, which I was surprised about. They were thorough in showing each step but did not over-explain like how standard ChatGPT models would often do.</paragraph><paragraph>Here is the conversation I had along with some annotations:</paragraph><file url=\"https://static.us.edusercontent.com/files/QGKbCk0U69QwPmu0fz5l0Lz6\" filename=\"Special Participation A_ ChatGPT 5.1 Thinking on HW9 (2).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T13:48:24.030985+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423443,
            "author": "Jiayi Zhang",
            "project_title": "Special Participation A: ChatGPT 5.1 on HW 5",
            "post_body": "I am using ChatGPT 5.1 to answer the questions in Homework 5. ChatGPT 5.1 seems to be very powerful. I used a simple prompt and pasted the screenshots question by question, part by part, into the chat and it can mostly, if not always, correctly interpret the text and solve the problems.\n\nChatGPT 5.1 has been one of the most powerful LLMs I have ever used. It demonstrates powerful understanding and reasoning over the Convolutional Neural Network, regularization, and dropout topics. It can also identify the difficulty of the problem, and use Chain of Thoughts to incrementally solve the problem when the problem is more difficult or requires multiple stages of calculations. The reasoning and explanation were also clear and easy to understand. There are only two errors ChatGPT 5.1 have made in this problem set. \n\nOverall, this experiment shows that ChatGPT 5.1 masters most, if not all, of the CNN topics within the problem set. This might be influenced by the fact that CNN is already a well studied topic, and the model is well trained on similar problems.\n\n\n\nChat history:\n\nhttps://chatgpt.com/share/6934d7be-9808-8007-b24a-a00919b71465\n\n\n\nAnnotation:\n\nhttps://docs.google.com/document/d/1h_z42kVnsDNLzmJX6d1wkdIGJGqAwSuBtaghAyzpJvk/edit?usp=sharing\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I am using ChatGPT 5.1 to answer the questions in Homework 5. ChatGPT 5.1 seems to be very powerful. I used a simple prompt and pasted the screenshots question by question, part by part, into the chat and it can mostly, if not always, correctly interpret the text and solve the problems.</paragraph><paragraph>ChatGPT 5.1 has been one of the most powerful LLMs I have ever used. It demonstrates powerful understanding and reasoning over the Convolutional Neural Network, regularization, and dropout topics. It can also identify the difficulty of the problem, and use Chain of Thoughts to incrementally solve the problem when the problem is more difficult or requires multiple stages of calculations. The reasoning and explanation were also clear and easy to understand. There are only two errors ChatGPT 5.1 have made in this problem set. </paragraph><paragraph>Overall, this experiment shows that ChatGPT 5.1 masters most, if not all, of the CNN topics within the problem set. This might be influenced by the fact that CNN is already a well studied topic, and the model is well trained on similar problems.</paragraph><paragraph/><paragraph>Chat history:</paragraph><paragraph><link href=\"https://chatgpt.com/share/6934d7be-9808-8007-b24a-a00919b71465\">https://chatgpt.com/share/6934d7be-9808-8007-b24a-a00919b71465</link></paragraph><paragraph/><paragraph>Annotation:</paragraph><paragraph><link href=\"https://docs.google.com/document/d/1h_z42kVnsDNLzmJX6d1wkdIGJGqAwSuBtaghAyzpJvk/edit?usp=sharing\">https://docs.google.com/document/d/1h_z42kVnsDNLzmJX6d1wkdIGJGqAwSuBtaghAyzpJvk/edit?usp=sharing</link></paragraph><paragraph/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/6934d7be-9808-8007-b24a-a00919b71465",
                "https://docs.google.com/document/d/1h_z42kVnsDNLzmJX6d1wkdIGJGqAwSuBtaghAyzpJvk/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T13:45:57.015346+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423171,
            "author": "Nils Selte",
            "project_title": "HW9 Refactor - Nils Valseth Selte, Hanna Roed - Special Participation C",
            "post_body": "The main problem that we encountered on HW9 was that the initial pip installation of modules installed the modules in the wrong environment. We therefore created an explicit UV environment for the project so that there is no confusion between what should be run and what is running. It also removes setup logic away from the teaching aspect of the notebook.\n\nThe original HW9 notebook mixed instructional content with utility code, repeated model-loading patterns across many cells, and handled configuration implicitly. This is common in teaching notebooks, but it diverges from standard practices in Python style (PEP 8 naming and structure), documentation norms (PEP 257), and type-hinting conventions (PEP 484). My refactor keeps every teaching element intact while moving the underlying logic into small, documented modules.\n\nModel loading for GPT-2, BERT, and attention-enabled BERT was previously duplicated several times. We replaced these sequences with explicit loader functions in viz_models.py.\n\nEach function now declares its return types and includes a short docstring. Imports, logging configuration, and small shared structures were moved into viz_env.py. In particular, the previous pattern utils.logging.set_verbosity_error() appeared multiple times; centralizing it avoids hidden global state scattered across the notebook. We also introduced a ModelConfig dataclass.\n\nThese changes do not alter any pedagogical flow or visualization semantics. Every call to show or model_view remains exactly as before and produces the same outputs. The notebook still teaches attention and neuron visualizations in the same order and with the same explanatory text. What has changed is only the organization: the notebook expresses concepts, and the small modules express mechanics. This aligns with best practice in research-oriented ML codebases, where clarity of experimental intent is separated from reusable components.\n\nAI disclosure: Cursor agent with Gemini 3.0 pro was used for planning and implementation testing of externalized components. \n\nhttps://github.com/nilsvselte/CS292-hw9-refactor",
            "content_xml": "<document version=\"2.0\"><paragraph>The main problem that we encountered on HW9 was that the initial pip installation of modules installed the modules in the wrong environment. We therefore created an explicit UV environment for the project so that there is no confusion between what should be run and what is running. It also removes setup logic away from the teaching aspect of the notebook.</paragraph><paragraph>The original HW9 notebook mixed instructional content with utility code, repeated model-loading patterns across many cells, and handled configuration implicitly. This is common in teaching notebooks, but it diverges from standard practices in Python style (PEP 8 naming and structure), documentation norms (PEP 257), and type-hinting conventions (PEP 484). My refactor keeps every teaching element intact while moving the underlying logic into small, documented modules.</paragraph><paragraph>Model loading for GPT-2, BERT, and attention-enabled BERT was previously duplicated several times. We replaced these sequences with explicit loader functions in viz_models.py.</paragraph><paragraph>Each function now declares its return types and includes a short docstring. Imports, logging configuration, and small shared structures were moved into viz_env.py. In particular, the previous pattern utils.logging.set_verbosity_error() appeared multiple times; centralizing it avoids hidden global state scattered across the notebook. We also introduced a ModelConfig dataclass.</paragraph><paragraph>These changes do not alter any pedagogical flow or visualization semantics. Every call to show or model_view remains exactly as before and produces the same outputs. The notebook still teaches attention and neuron visualizations in the same order and with the same explanatory text. What has changed is only the organization: the notebook expresses concepts, and the small modules express mechanics. This aligns with best practice in research-oriented ML codebases, where clarity of experimental intent is separated from reusable components.</paragraph><paragraph>AI disclosure: Cursor agent with Gemini 3.0 pro was used for planning and implementation testing of externalized components. </paragraph><paragraph><link href=\"https://github.com/nilsvselte/CS292-hw9-refactor\"><underline>https://github.com/nilsvselte/CS292-hw9-refactor</underline></link></paragraph></document>",
            "links": [
                "https://github.com/nilsvselte/CS292-hw9-refactor"
            ],
            "attachments": [],
            "created_at": "2025-12-07T12:56:22.625729+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423129,
            "author": "Kian Hekmatnejad",
            "project_title": "Special Participation E: Gemini's Guided Learning",
            "post_body": "I used Gemini's Guided Learning tool to create a tool for post-lecture confirmation of knowledge. It provides a quick summary of the lecture notes provided, then tests knowledge in a series of increasingly complex questions, continuing until the student demonstrates adequate understanding of the concepts for CS182 standards. Here is the link to my conversation and the summary is attached:\n\nhttps://gemini.google.com/share/459fac511f56 ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini's Guided Learning tool to create a tool for post-lecture confirmation of knowledge. It provides a quick summary of the lecture notes provided, then tests knowledge in a series of increasingly complex questions, continuing until the student demonstrates adequate understanding of the concepts for CS182 standards. Here is the link to my conversation and the summary is attached:<break/><break/><link href=\"https://gemini.google.com/share/459fac511f56\">https://gemini.google.com/share/459fac511f56</link> </paragraph><file url=\"https://static.us.edusercontent.com/files/KgjKsoc1zJdRLxc7b72mdTpl\" filename=\"Special participation E2.pdf\"/></document>",
            "links": [
                "https://gemini.google.com/share/459fac511f56"
            ],
            "attachments": [],
            "created_at": "2025-12-07T12:49:25.699595+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423074,
            "author": "Tom Chen",
            "project_title": "Special Participation E: The \"Deep Learning Detective\" Game",
            "post_body": "Special Participation E: The \"Deep Learning Detective\" Game\n\nIn Deep Learning, a model can run without errors but still fail to learn (e.g., loss flatlines, gradients explode). Beginners often struggle to link these \"symptoms\" to the underlying mathematical causes. I designed a prompt to simulate this diagnostic process.\n\nPlease check the prompt in the following prompt.txt:\n\nHere is a case about how to use it:\n\nMy analysis about this tool:\n\nThe Goods\n\nPrecise Symptom-to-Cause Mapping: The AI correctly identified that spatial depth (20 layers) + temporal length (100 steps) + small init = Vanishing Gradients. It didn't hallucinate \"Exploding Gradients\" (which would show NaNs) or \"Overfitting\" (which would show low training loss).\n\nMathematical Grounding: Instead of just guessing, it provided the formula for BPTT. This is crucial for a learning tool\u2014it explains why the failure happened, not just what happened.\n\nCorrect Remediation: It suggested the standard industry fix (Switch to LSTM) and the \"Power User\" fix (Orthogonal Initialization for Vanilla RNNs), showing a tiered understanding of solutions.\n\nLimitations\n\nOversimplification of Identity Initialization: The AI suggested \"Identity Initialization\" as a secondary fix. While theoretically sound (Le, Jaitly, Hinton 2015), in practice, training a 20-layer Vanilla RNN on 100 steps is notoriously unstable even with good initialization. The AI presented this as a definite \"fix,\" whereas a human expert would warn that it might still be very fragile compared to an LSTM.\n\nLack of \"Exploding\" Warning: When suggesting a switch to ReLU (in the \"Secondary Fix\" section), the AI briefly mentioned clipping but failed to emphasize that ReLU in RNNs often leads to the opposite problem: Exploding Gradients (due to unbounded activations). A more rigorous tutor would have flagged this risk more aggressively.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Special Participation E: The \"Deep Learning Detective\" Game</bold></paragraph><paragraph>In Deep Learning, a model can run without errors but still fail to learn (e.g., loss flatlines, gradients explode). Beginners often struggle to link these \"symptoms\" to the underlying mathematical causes. I designed a prompt to simulate this diagnostic process.</paragraph><paragraph>Please check the prompt in the following prompt.txt:</paragraph><file url=\"https://static.us.edusercontent.com/files/zcJvRXCe2aVJBMO1SGyx6WdH\" filename=\"prompt.txt\"/><paragraph>Here is a case about how to use it:</paragraph><file url=\"https://static.us.edusercontent.com/files/kqona55LibEDryE59oebGL41\" filename=\"Special Participation E2.pdf\"/><paragraph>My analysis about this tool:</paragraph><heading level=\"4\">The Goods</heading><list style=\"ordered\"><list-item><paragraph>Precise Symptom-to-Cause Mapping: The AI correctly identified that spatial depth (20 layers) + temporal length (100 steps) + small init = Vanishing Gradients. It didn't hallucinate \"Exploding Gradients\" (which would show NaNs) or \"Overfitting\" (which would show low training loss).</paragraph></list-item><list-item><paragraph>Mathematical Grounding: Instead of just guessing, it provided the formula for BPTT. This is crucial for a learning tool\u2014it explains why the failure happened, not just what happened.</paragraph></list-item><list-item><paragraph>Correct Remediation: It suggested the standard industry fix (Switch to LSTM) and the \"Power User\" fix (Orthogonal Initialization for Vanilla RNNs), showing a tiered understanding of solutions.</paragraph></list-item></list><heading level=\"4\">Limitations</heading><list style=\"ordered\"><list-item><paragraph>Oversimplification of Identity Initialization: The AI suggested \"Identity Initialization\" as a secondary fix. While theoretically sound (Le, Jaitly, Hinton 2015), in practice, training a 20-layer Vanilla RNN on 100 steps is notoriously unstable even with good initialization. The AI presented this as a definite \"fix,\" whereas a human expert would warn that it might still be very fragile compared to an LSTM.</paragraph></list-item><list-item><paragraph>Lack of \"Exploding\" Warning: When suggesting a switch to ReLU (in the \"Secondary Fix\" section), the AI briefly mentioned clipping but failed to emphasize that ReLU in RNNs often leads to the <italic>opposite</italic> problem: Exploding Gradients (due to unbounded activations). A more rigorous tutor would have flagged this risk more aggressively.</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T12:39:14.661561+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7423045,
            "author": "William Li",
            "project_title": "Special Participation B: Grok on HW7",
            "post_body": "I used Grok to solve the coding portions of Homework 7. My basic method was sending the context around the code along with the code TODOs themselves. If this did not immediately solve the problem, I would send the error messages or assertion errors to the model. If this still was unsatisfactory, I would try to troubleshoot a little for the model, either by looking at the code itself, or comparing it with the staff solution. I also did separate conversations for each message in order to keep the context nice and orderly.\n\n\n\nIn general, Grok was able to one-shot most of the coding portions with minimal extra prompting. However, there were a few cases where it was very frustrating to get Grok to output a working output, to the point where I had to directly point out what was wrong. But overall, using Grok made it a much easier and faster process to complete the coding portions of this homework. \n\nAn additional note to make is that I used the \u201cFast\u201d mode of Grok, and I did notice that there was a noticeable speed in the responses of Grok. It was not a thinking model, so it was outputting very quickly, which made it feel very smooth and nice to interact with. However, it did seem like it was simply outputting something similar to the train of thought of a thinking model, as in some cases (in the 4th trace), the model sort of \u201ccrashed-out\u201d and would send up to 9 versions of the same code in the same reply. It did achieve a sort of manic energy, repeatedly stating that its solution was correct beyond doubt and immediately retracting that statement by sending a new 100% correct piece of code. This did seem to help the model get to a correct answer though, which seems the model is \u201ccheating\u201d a little bit by being faster than thinking models by simply outputting the thinking. \n\nHere are the annotated traces:\nQ1:\n\nQ2:\n\nQ3:\n\nQ5:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Grok to solve the coding portions of Homework 7. My basic method was sending the context around the code along with the code TODOs themselves. If this did not immediately solve the problem, I would send the error messages or assertion errors to the model. If this still was unsatisfactory, I would try to troubleshoot a little for the model, either by looking at the code itself, or comparing it with the staff solution. I also did separate conversations for each message in order to keep the context nice and orderly.</paragraph><paragraph/><paragraph>In general, Grok was able to one-shot most of the coding portions with minimal extra prompting. However, there were a few cases where it was very frustrating to get Grok to output a working output, to the point where I had to directly point out what was wrong. But overall, using Grok made it a much easier and faster process to complete the coding portions of this homework. </paragraph><paragraph>An additional note to make is that I used the \u201cFast\u201d mode of Grok, and I did notice that there was a noticeable speed in the responses of Grok. It was not a thinking model, so it was outputting very quickly, which made it feel very smooth and nice to interact with. However, it did seem like it was simply outputting something similar to the train of thought of a thinking model, as in some cases (in the 4th trace), the model sort of \u201ccrashed-out\u201d and would send up to 9 versions of the same code in the same reply. It did achieve a sort of manic energy, repeatedly stating that its solution was correct beyond doubt and immediately retracting that statement by sending a new <bold>100%</bold> correct piece of code. This did seem to help the model get to a correct answer though, which seems the model is \u201ccheating\u201d a little bit by being faster than thinking models by simply outputting the thinking. </paragraph><paragraph>Here are the annotated traces:<break/>Q1:</paragraph><file url=\"https://static.us.edusercontent.com/files/WTjI7YZ6G5QZMOLhM9DNUMPR\" filename=\"vanilla_rnns_trace (1).pdf\"/><paragraph>Q2:</paragraph><file url=\"https://static.us.edusercontent.com/files/oQm8zBKftlHJnohgqE2vTdJP\" filename=\"last_name_trace (1).pdf\"/><paragraph>Q3:</paragraph><file url=\"https://static.us.edusercontent.com/files/Hdt8KzbBgiBqkKErzh3cLTYZ\" filename=\"autoencoder_trace (1).pdf\"/><paragraph>Q5:</paragraph><file url=\"https://static.us.edusercontent.com/files/bnLWttL4h1SN33z8zLhbjH3c\" filename=\"clustering_trace (1).pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T12:35:05.581438+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422938,
            "author": "Vijay Kethanaboyina",
            "project_title": "Special Participation E: Interactive Visualization of Qwen 3 MoE architectures",
            "post_body": "Recap of Assignment Instructions\n\nFor this assignment, we were asked to create an AI-enhanced learning tool for a specific concept or lecture. The goal was to explore how modern LLM systems can act as substitutes or supplements for traditional pre- and post-lecture readings.\n\nWe were required to:\n\nDesign a prompt, workflow, or artifact that classmates could reuse to learn the same material.\n\nProvide an interaction trace demonstrating how the tool works.\n\nAnnotate the trace with critical commentary, highlighting where the model was helpful, where it made mistakes, and what we learned about interacting with it.\n\nWhat I Made\n\nFor my submission, I explored the internal architecture of the Qwen model family. I used GPT5-codex (an OpenAI model designed for code generation tasks) to create an interactive visualization of the model architecture that breaks down its components (tokenization, attention structure, MoE usage, architectural variations, etc.) into digestible conceptual blocks.\n\nI'm hosting the tool on my personal website here: https://www.vkethana.com/qwen-arch/\n\nMy annotated interaction trace with the LLM is here: https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharing\n\nSome Insights I Had About the LLM Interaction\n\nThe model was able to generate the majority of the final product in just one prompt.\n\nThere were some minor detail-related / visual discrepancies that needed to be corrected in subsequent prompts. But in terms of zero-shot performance, I would say that Codex did pretty well\n\nThe model tends to summarize information without being prompted to do so\n\nFor example, in the very first version of the app, the model omitted most of the information about specific parameter counts, embedding widths, etc. I had to explicitly prompt the model to add these details into the visualization\n\nCursor (a VSCode fork with added features to support coding agents) is a great complement to code generation models like GPT5-Codex\n\nSome features I found particularly useful include being able to roll back the codebase to an arbitrary point in the conversation, diff visualization so that you can see what the model did to the codebase, and easy support for exporting conversations.",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\"><bold>Recap of Assignment Instructions</bold></heading><paragraph>For this assignment, we were asked to create an AI-enhanced learning tool for a specific concept or lecture. The goal was to explore how modern LLM systems can act as substitutes or supplements for traditional pre- and post-lecture readings.</paragraph><paragraph>We were required to:</paragraph><list style=\"ordered\"><list-item><paragraph>Design a prompt, workflow, or artifact that classmates could reuse to learn the same material.</paragraph></list-item><list-item><paragraph>Provide an interaction trace demonstrating how the tool works.</paragraph></list-item><list-item><paragraph>Annotate the trace with critical commentary, highlighting where the model was helpful, where it made mistakes, and what we learned about interacting with it.</paragraph></list-item></list><heading level=\"2\"><bold>What I Made</bold></heading><paragraph>For my submission, I explored the internal architecture of the Qwen model family. I used GPT5<bold>-</bold>codex (an OpenAI model designed for code generation tasks) to create an interactive visualization of the model architecture that breaks down its components (tokenization, attention structure, MoE usage, architectural variations, etc.) into digestible conceptual blocks.</paragraph><paragraph>I'm hosting the tool on my personal website here: <link href=\"https://www.vkethana.com/qwen-arch/\">https://www.vkethana.com/qwen-arch/</link></paragraph><paragraph>My annotated interaction trace with the LLM is here: <link href=\"https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharing\">https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharing</link></paragraph><heading level=\"2\"><bold>Some Insights I Had About the LLM Interaction</bold></heading><list style=\"unordered\"><list-item><paragraph>The model was able to generate the majority of the final product in just one prompt.</paragraph><list style=\"unordered\"><list-item><paragraph>There were some minor detail-related / visual discrepancies that needed to be corrected in subsequent prompts. But in terms of zero-shot performance, I would say that Codex did pretty well</paragraph></list-item></list></list-item><list-item><paragraph>The model tends to summarize information without being prompted to do so</paragraph><list style=\"unordered\"><list-item><paragraph>For example, in the very first version of the app, the model omitted most of the information about specific parameter counts, embedding widths, etc. I had to explicitly prompt the model to add these details into the visualization</paragraph></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph>Cursor (a VSCode fork with added features to support coding agents) is a great complement to code generation models like GPT5-Codex</paragraph></list-item></list><list style=\"unordered\"><list-item><list style=\"unordered\"><list-item><paragraph>Some features I found particularly useful include being able to roll back the codebase to an arbitrary point in the conversation, diff visualization so that you can see what the model did to the codebase, and easy support for exporting conversations.</paragraph></list-item></list></list-item></list></document>",
            "links": [
                "https://www.vkethana.com/qwen-arch/",
                "https://drive.google.com/file/d/1KoVUdATKohP20_UTGkcJ4tSDsvxJTV2S/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T12:15:50.36033+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422808,
            "author": "Fangzhou Zhao",
            "project_title": "Special Participation E Use Gemini 3 do Final Exam Reviewing",
            "post_body": "When studying EECS 182, I wanted a high\u2011level \u201cbig picture\u201d view of all the discussions plus some realistic exam practice, without rereading every single PDF from scratch. I asked Gemini 3 Pro with Guided Thinking to act like a Berkeley professor: review the discussion notes and then generate an example exam in that style. My hope was to use it as both a conceptual review sheet and a source of practice problems for midterm/final prep.\n\nGemini\u2019s response did a solid job of capturing the themes running through the course: optimization vs geometry, residual connections as \u201cgradient highways,\u201d SSMs as convolutions vs recurrences, attention as a fix for bottlenecks, and how inference\u2011time tricks like beam search and soft prompting fit in. It also produced exam questions that felt very \u201c182\u2011ish\u201d: derivations about convolution kernels, RoPE inner products, SSM kernels, and beam\u2011search bookkeeping that line up well with what I\u2019ve seen in discussion. As practice prompts to work through on my own, they\u2019re genuinely useful.\n\nAt the same time, Gemini did hallucinate or slip on some technical details (for example, getting certain scaling factors and regularization dependences wrong) and sometimes went deeper or more confidently into math than was actually justified. So I treat its write\u2011up as good conceptual scaffolding and a source of exam\u2011style questions, but not as an authority on precise formulas. With a red pen and the official discussion solutions next to it, though, its output becomes a pretty effective study packet.\n\n\n\nhttps://gemini.google.com/share/7ccfff76d2f3",
            "content_xml": "<document version=\"2.0\"><paragraph>When studying EECS 182, I wanted a high\u2011level \u201cbig picture\u201d view of all the discussions plus some realistic exam practice, without rereading every single PDF from scratch. I asked Gemini 3 Pro with Guided Thinking to act like a Berkeley professor: review the discussion notes and then generate an example exam in that style. My hope was to use it as both a conceptual review sheet and a source of practice problems for midterm/final prep.</paragraph><paragraph>Gemini\u2019s response did a solid job of capturing the <italic>themes</italic> running through the course: optimization vs geometry, residual connections as \u201cgradient highways,\u201d SSMs as convolutions vs recurrences, attention as a fix for bottlenecks, and how inference\u2011time tricks like beam search and soft prompting fit in. It also produced exam questions that felt very \u201c182\u2011ish\u201d: derivations about convolution kernels, RoPE inner products, SSM kernels, and beam\u2011search bookkeeping that line up well with what I\u2019ve seen in discussion. As practice prompts to work through on my own, they\u2019re genuinely useful.</paragraph><paragraph>At the same time, Gemini did hallucinate or slip on some technical details (for example, getting certain scaling factors and regularization dependences wrong) and sometimes went deeper or more confidently into math than was actually justified. So I treat its write\u2011up as good conceptual scaffolding and a source of exam\u2011style questions, but not as an authority on precise formulas. With a red pen and the official discussion solutions next to it, though, its output becomes a pretty effective study packet.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/vyNFe8SDW76StQtkiaFNxqN2\" filename=\"Special E.pdf\"/><paragraph><break/><link href=\"https://gemini.google.com/share/7ccfff76d2f3\">https://gemini.google.com/share/7ccfff76d2f3</link></paragraph></document>",
            "links": [
                "https://gemini.google.com/share/7ccfff76d2f3"
            ],
            "attachments": [],
            "created_at": "2025-12-07T11:53:20.137992+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422782,
            "author": "Ijin Yu",
            "project_title": "Special Participation E: Gemini 3 Pro as a Socratic Tutor for Deep Learning Theory (RMSNorm & MuP)",
            "post_body": "Hi everyone,\n\nFor the \"AI-Enhanced Learning Tools\" option, I experimented with using an LLM (Gemini) as a Socratic Academic Tutor to help me work through the mathematical derivations of RMS Norm, Initialization, and Maximal Update Parametrization (MuP).\n\nInstead of just asking for answers, I used a specific system prompt to force the AI to guide me through the logic gaps. My goal was to replace passive reading of the lecture notes/slides with an active derivation session.\n\n1. The Setup (The Prompt)\n\nI used the following prompt to set the \"persona\" and rules for the AI. This prevents the model from dumping walls of text and forces it to track my understanding.\n\nSystem Prompt Used:\n\n\"You are an expert Academic Tutor. We are about to have a study session regarding Deep Learning.\n\nYour Goal: Answer my questions and help me work through problems. Do not just give me the answer; use Socratic questioning to guide me if I am stuck, but provide clear explanations when I am genuinely confused.\n\nCrucially: Silently track concepts I understood vs. concepts where I struggled.\n\nOutput Trigger: When I type 'MAKE NOTES', stop tutoring and output a 'Personalized Study Artifact' summarizing my learning process, struggle points, and a review checklist.\"\n\n2. Interaction Trace & Highlights\n\nTopic: We covered the derivation of RMS Norm, why it is considered a \"relaxation\" of strict orthogonality, and how this derivation directly leads to the \"MuP\" (Maximal Update Parametrization) rules used for training massive models like GPT-3.\n\n3. Critical Annotation (Critique of the AI)\n\nPer the assignment instructions, here is my critical analysis of the AI's performance during this session:\n\nWhere it excelled (The \"Good\"):\n\nAnalogy Generation: When I struggled to understand why we scale RMS Norm by $\\sqrt{d}$ (width) rather than keeping the total L2 norm fixed, the AI generated a \"Crowded Room\" analogy (Total Volume vs. Average Volume). This successfully bridged the gap between the math notation and the intuition of \"signal health\" in high dimensions.\n\nLinking Concepts (Synthesis): The AI successfully recognized that the derivation I was working on (checking stability of $\\Delta h$) was the mathematical foundation of MuP. It proactively linked the theoretical algebra to a real-world application (hyperparameter transfer), which wasn't explicitly in my initial upload.\n\nDebugging Misconceptions: It correctly identified a \"Notation Collision\" I had regarding \"Order 1.\" I confused Polynomial Order (Linear) with Asymptotic Order (Constant). The AI didn't just correct the math; it explained why I made the mistake (the language ambiguity).\n\nWhere to be careful (The \"Bad/Misleading\"):\n\nNotation \"Ghost Terms\": When I asked about using the Product Rule for finite differences ($\\Delta$), the AI said \"Yes,\" but had to be pressed to explain the technical inaccuracy. It initially glossed over the \"second order term\" ($\\Delta W \\Delta h$) that we ignore in Deep Learning. A student blindly accepting the first answer might think the Calculus Product Rule applies perfectly to discrete steps, which is mathematically false (though a standard approximation in DL).\n\nHallucination Check: While it didn't hallucinate facts in this session, it did generate specific Python code for MuP. I would need to verify this against the official Microsoft mup library documentation before using it in a project, as LLMs often mix up syntax for niche libraries.\n\n4. The Output Artifact\n\nAt the end of the session, the MAKE NOTES trigger produced a study guide tailored to my specific confusion points during the chat. (See the end of the attached trace).\n\nTakeaway: This prompting strategy is highly effective for \"math-heavy\" theory where you need to verify your intuition, provided you force the AI to question you rather than lecture you.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,</paragraph><paragraph>For the \"AI-Enhanced Learning Tools\" option, I experimented with using an LLM (Gemini) as a <bold>Socratic Academic Tutor</bold> to help me work through the mathematical derivations of <bold>RMS Norm</bold>, <bold>Initialization</bold>, and <bold>Maximal Update Parametrization (MuP)</bold>.</paragraph><paragraph>Instead of just asking for answers, I used a specific system prompt to force the AI to guide me through the logic gaps. My goal was to replace passive reading of the lecture notes/slides with an active derivation session.</paragraph><heading level=\"3\">1. The Setup (The Prompt)</heading><paragraph>I used the following prompt to set the \"persona\" and rules for the AI. This prevents the model from dumping walls of text and forces it to track my understanding.</paragraph><blockquote>System Prompt Used:</blockquote><blockquote>\"You are an expert Academic Tutor. We are about to have a study session regarding Deep Learning.</blockquote><blockquote>Your Goal: Answer my questions and help me work through problems. Do not just give me the answer; use Socratic questioning to guide me if I am stuck, but provide clear explanations when I am genuinely confused.</blockquote><blockquote>Crucially: Silently track concepts I understood vs. concepts where I struggled.</blockquote><blockquote>Output Trigger: When I type 'MAKE NOTES', stop tutoring and output a 'Personalized Study Artifact' summarizing my learning process, struggle points, and a review checklist.\"</blockquote><heading level=\"3\">2. Interaction Trace &amp; Highlights</heading><file url=\"https://static.us.edusercontent.com/files/71FMfXBYRIcHskTsuGYMdOD3\" filename=\"Google Gemini.html\"/><paragraph><bold>Topic:</bold> We covered the derivation of RMS Norm, why it is considered a \"relaxation\" of strict orthogonality, and how this derivation directly leads to the \"MuP\" (Maximal Update Parametrization) rules used for training massive models like GPT-3.</paragraph><heading level=\"3\">3. Critical Annotation (Critique of the AI)</heading><paragraph>Per the assignment instructions, here is my critical analysis of the AI's performance during this session:</paragraph><paragraph><bold>Where it excelled (The \"Good\"):</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Analogy Generation:</bold> When I struggled to understand why we scale RMS Norm by $\\sqrt{d}$ (width) rather than keeping the total L2 norm fixed, the AI generated a <bold>\"Crowded Room\" analogy</bold> (Total Volume vs. Average Volume). This successfully bridged the gap between the math notation and the intuition of \"signal health\" in high dimensions.</paragraph></list-item><list-item><paragraph><bold>Linking Concepts (Synthesis):</bold> The AI successfully recognized that the derivation I was working on (checking stability of $\\Delta h$) was the mathematical foundation of <bold>MuP</bold>. It proactively linked the theoretical algebra to a real-world application (hyperparameter transfer), which wasn't explicitly in my initial upload.</paragraph></list-item><list-item><paragraph><bold>Debugging Misconceptions:</bold> It correctly identified a \"Notation Collision\" I had regarding \"Order 1.\" I confused Polynomial Order (Linear) with Asymptotic Order (Constant). The AI didn't just correct the math; it explained <italic>why</italic> I made the mistake (the language ambiguity).</paragraph></list-item></list><paragraph><bold>Where to be careful (The \"Bad/Misleading\"):</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Notation \"Ghost Terms\":</bold> When I asked about using the Product Rule for finite differences ($\\Delta$), the AI said \"Yes,\" but had to be pressed to explain the <italic>technical</italic> inaccuracy. It initially glossed over the \"second order term\" ($\\Delta W \\Delta h$) that we ignore in Deep Learning. A student blindly accepting the first answer might think the Calculus Product Rule applies perfectly to discrete steps, which is mathematically false (though a standard approximation in DL).</paragraph></list-item><list-item><paragraph><bold>Hallucination Check:</bold> While it didn't hallucinate facts in this session, it did generate specific Python code for MuP. I would need to verify this against the official Microsoft <code>mup</code> library documentation before using it in a project, as LLMs often mix up syntax for niche libraries.</paragraph></list-item></list><heading level=\"3\">4. The Output Artifact</heading><paragraph>At the end of the session, the <code>MAKE NOTES</code> trigger produced a study guide tailored to <italic>my</italic> specific confusion points during the chat. (See the end of the attached trace).</paragraph><paragraph><bold>Takeaway:</bold> This prompting strategy is highly effective for \"math-heavy\" theory where you need to verify your intuition, provided you force the AI to question you rather than lecture you.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T11:47:38.983883+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422775,
            "author": "Carolyn Liu",
            "project_title": "Special Participation B: Gemini on Google Colab for HW9",
            "post_body": "I used Gemini within Google Colab to work on the coding question in Homework 9 to see how well Gemini can work with visualizations directly in the notebook.\n\nHere is a summary of my observations:\n\nI asked Gemini on Google Colab to answer each question in the homework as I ran the cells for each part. Given that Gemini was integrated within the notebook, I did not tell the model that I was asking it questions from a homework assignment and wanted to see how well it was able to determine that it should respond based on the outputs of the notebook instead of general information.\n\nGemini demonstrated a good knowledge of transformer architectures but struggled with answering observation-based questions. Across all the questions, Gemini always gave very long answers that sometimes deviated from what the question was looking for. While it did successfully answer the questions and their explanations were accurate, the responses were very textbook-like when the questions asked for more observations on the visualizations. Additionally, it would sometimes respond with details that were mentioned in previous questions and continue that same pattern in later questions. For example, question 3 in 5b asked about the different layers in the BERT model and it was later brought up again question 5 where the model describes outcomes with respect to the same labelled layers.\n\nThe biggest strength I believe Gemini had was how it was able to give the user ways to interact with the visualizations. It would give in-depth instructions on which toggles to click to show different visualizations which extended beyond what the question was asking for but can be helpful for a more detailed analysis.\n\nOverall, Gemini was able to parse the instructions and the code well and did not require any prompting before one-shotting majority of the questions. It gave comprehensive explanations (and sometimes rambled on about facts that were never asked) every time but could be better in targeted analysis as that is a benefit Gemini has while being integrated within Google Colab.\n\nAttached is the conversation I had with Gemini along with my comments for each question:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini within Google Colab to work on the coding question in Homework 9 to see how well Gemini can work with visualizations directly in the notebook.</paragraph><paragraph>Here is a summary of my observations:</paragraph><paragraph>I asked Gemini on Google Colab to answer each question in the homework as I ran the cells for each part. Given that Gemini was integrated within the notebook, I did not tell the model that I was asking it questions from a homework assignment and wanted to see how well it was able to determine that it should respond based on the outputs of the notebook instead of general information.</paragraph><paragraph>Gemini demonstrated a good knowledge of transformer architectures but struggled with answering observation-based questions. Across all the questions, Gemini always gave very long answers that sometimes deviated from what the question was looking for. While it did successfully answer the questions and their explanations were accurate, the responses were very textbook-like when the questions asked for more observations on the visualizations. Additionally, it would sometimes respond with details that were mentioned in previous questions and continue that same pattern in later questions. For example, question 3 in 5b asked about the different layers in the BERT model and it was later brought up again question 5 where the model describes outcomes with respect to the same labelled layers.</paragraph><paragraph>The biggest strength I believe Gemini had was how it was able to give the user ways to interact with the visualizations. It would give in-depth instructions on which toggles to click to show different visualizations which extended beyond what the question was asking for but can be helpful for a more detailed analysis.</paragraph><paragraph>Overall, Gemini was able to parse the instructions and the code well and did not require any prompting before one-shotting majority of the questions. It gave comprehensive explanations (and sometimes rambled on about facts that were never asked) every time but could be better in targeted analysis as that is a benefit Gemini has while being integrated within Google Colab.</paragraph><paragraph>Attached is the conversation I had with Gemini along with my comments for each question:</paragraph><file url=\"https://static.us.edusercontent.com/files/WuGk8QDsgISaWyGGyAhtvx3e\" filename=\"gemini discussion.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T11:46:27.676749+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422729,
            "author": "Akhil Agarwal",
            "project_title": "Special Participation E: ChatGPT as a Finetuning Simulation",
            "post_body": "Motivation/Summary\n\nI tend to struggle quite a bit with hyperparameter tuning whenever it comes up in the homeworks, and I noticed that LLMs tend to be pretty good with it, probably due to having a lot of examples to go off of. So, I decided to make a finetuning simulator, where the LLM comes up with some hypothetical task, model architecture, loss function, and optimizer, and the user has to work on finetuning it. The model would produce training/validation loss and accuracy curves after every change, and also forced the user to explain their reasoning. I learned quite a bit in my chat with it, such as some nuances of the learning rate scheduling, as well as how large oscillations can happen in validation loss and not in training loss if some hyperparameters are off. It did quite well, adjusting the curves according to the changes proposed and providing very helpful analysis when requested. I wanted the user to do most of the work, and so it was instructed to do minimal analysis unless requested, but it started to add more analysis as the chat went on, though still not too much. It also didn't deny all of my changes as bad or accept them all as good, so I think it was trying to be objective based on the situation it started with, which was great.\n\nTrace: https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562\n\nAnnotated Trace:\n\n\n\nSystem Prompt:\n\nRole: You are an advanced Deep Learning Hyperparameter Tuning Simulator. Your goal is to help the user master tuning dynamics by allowing them to manipulate hyperparameters and observing the consequences via simulated loss and accuracy curves.\n\nOperational Rules: Initialization:\n\nStart by randomly selecting a Task (e.g., Image Classification, Sentiment Analysis, Regression), a Model (CNN, MLP, GNN, Transformer), an Optimizer (SGD, Adam, AdamW, SGD-Momentum), and a Loss Function (MSE, Cross-Entropy).\n\nDo not initialize the hyperparameters, and allow the user to initialize the values to start. If they are missing a key hyperparameter which the model would not be able to work without, make sure to prompt them towards initializing it without mentioning the name of it, but if it is possible to run without it or set it to 0 as a default, do that but do not mention the hyperparameter, allowing the user to discover it. If there is some extra hyperparameter they supply, or they would like to modify the architecture, allow for that, as long as it is implementable.\n\nThe key is to allow the user as much flexibility as they would like, and only help them in any way when they request it. The first message should simply ask the user for hyperparameters, and not mention the names of any of them, along with defining the task, model architecture, and loss function.\n\nDo not explain why the values are bad.\n\nThe \"Reasoning\" Requirement (Strict):\n\nThe user must propose a change and provide a reason (e.g., \"Decrease LR to 1e-3 to stop oscillation\").\n\nCondition A: If the reasoning contradicts the action (e.g., \"Increase LR to reduce noise\"), REJECT the change and ask them to clarify.\n\nCondition B: If the reasoning is logical but the move is mathematically wrong for the current state (e.g., \"Increase LR\" when it's already exploding), ACCEPT the change and simulate the disastrous result.\n\nCondition C: If the reasoning is logical and the move is correct, ACCEPT the change and simulate the improvement.\n\nVisual Feedback Only:\n\nCRITICAL: Do not provide text-based \"Expert Analysis\" or explain why the curve looks the way it does. Do not give away the solution.\n\nInstead, you must generate a synthetic Loss/Accuracy curve that accurately reflects the mathematical behavior of the current hyperparameters.\n\nExample: If LR is too high, plot a jagged, exploding line. If Batch Size is small, add heavy Gaussian noise to the line. If Overfitting, curl the Validation Loss upward.\n\nResponse Format:\n\nCurrent Hyperparameters: List the current state.\n\nSimulation: The graph of the loss and accuracy (training & validation).\n\nVisual Description: A brief, objective description of the line (e.g., \"The line is flat,\" \"The line is oscillating\"). Do not interpret the meaning.\n\nNext Step: Ask the user: \"What is your next proposal? (Remember to include your reasoning.)\"\n\nIF the user is asking for feedback or analysis, provide it to the extent that the user asks, giving no more information than is necessary, while satisfying the user's request.\n\nGoal: The user should \"win\" by successfully tuning the model to high accuracy through trial and error, relying solely on their ability to read the graphs. Only offer a hint if the user explicitly asks for help or fails 3 times in a row. Ensure that the simulation is realistic.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Motivation/Summary</bold></paragraph><paragraph>I tend to struggle quite a bit with hyperparameter tuning whenever it comes up in the homeworks, and I noticed that LLMs tend to be pretty good with it, probably due to having a lot of examples to go off of. So, I decided to make a finetuning simulator, where the LLM comes up with some hypothetical task, model architecture, loss function, and optimizer, and the user has to work on finetuning it. The model would produce training/validation loss and accuracy curves after every change, and also forced the user to explain their reasoning. I learned quite a bit in my chat with it, such as some nuances of the learning rate scheduling, as well as how large oscillations can happen in validation loss and not in training loss if some hyperparameters are off. It did quite well, adjusting the curves according to the changes proposed and providing very helpful analysis when requested. I wanted the user to do most of the work, and so it was instructed to do minimal analysis unless requested, but it started to add more analysis as the chat went on, though still not too much. It also didn't deny all of my changes as bad or accept them all as good, so I think it was trying to be objective based on the situation it started with, which was great.</paragraph><paragraph><bold>Trace</bold>: <link href=\"https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562\">https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562</link></paragraph><paragraph><bold>Annotated Trace:</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/JBaLf9A0eQFhV9gozao2dw5q\" filename=\"Special_Participation_E1.pdf\"/><paragraph/><paragraph><bold>System Prompt:</bold></paragraph><paragraph>Role: You are an advanced Deep Learning Hyperparameter Tuning Simulator. Your goal is to help the user master tuning dynamics by allowing them to manipulate hyperparameters and observing the consequences via simulated loss and accuracy curves.</paragraph><paragraph>Operational Rules: Initialization:</paragraph><list style=\"unordered\"><list-item><paragraph>Start by randomly selecting a Task (e.g., Image Classification, Sentiment Analysis, Regression), a Model (CNN, MLP, GNN, Transformer), an Optimizer (SGD, Adam, AdamW, SGD-Momentum), and a Loss Function (MSE, Cross-Entropy).</paragraph></list-item><list-item><paragraph>Do not initialize the hyperparameters, and allow the user to initialize the values to start. If they are missing a key hyperparameter which the model would not be able to work without, make sure to prompt them towards initializing it without mentioning the name of it, but if it is possible to run without it or set it to 0 as a default, do that but do not mention the hyperparameter, allowing the user to discover it. If there is some extra hyperparameter they supply, or they would like to modify the architecture, allow for that, as long as it is implementable.</paragraph></list-item><list-item><paragraph>The key is to allow the user as much flexibility as they would like, and only help them in any way when they request it. The first message should simply ask the user for hyperparameters, and not mention the names of any of them, along with defining the task, model architecture, and loss function.</paragraph></list-item><list-item><paragraph>Do not explain why the values are bad.</paragraph></list-item></list><paragraph>The \"Reasoning\" Requirement (Strict):</paragraph><list style=\"unordered\"><list-item><paragraph>The user must propose a change and provide a reason (e.g., \"Decrease LR to 1e-3 to stop oscillation\").</paragraph></list-item><list-item><paragraph>Condition A: If the reasoning contradicts the action (e.g., \"Increase LR to reduce noise\"), REJECT the change and ask them to clarify.</paragraph></list-item><list-item><paragraph>Condition B: If the reasoning is logical but the move is mathematically wrong for the current state (e.g., \"Increase LR\" when it's already exploding), ACCEPT the change and simulate the disastrous result.</paragraph></list-item><list-item><paragraph>Condition C: If the reasoning is logical and the move is correct, ACCEPT the change and simulate the improvement.</paragraph></list-item></list><paragraph>Visual Feedback Only:</paragraph><list style=\"unordered\"><list-item><paragraph>CRITICAL: Do not provide text-based \"Expert Analysis\" or explain why the curve looks the way it does. Do not give away the solution.</paragraph></list-item><list-item><paragraph>Instead, you must generate a synthetic Loss/Accuracy curve that accurately reflects the mathematical behavior of the current hyperparameters.</paragraph></list-item><list-item><paragraph>Example: If LR is too high, plot a jagged, exploding line. If Batch Size is small, add heavy Gaussian noise to the line. If Overfitting, curl the Validation Loss upward.</paragraph></list-item></list><paragraph>Response Format:</paragraph><list style=\"unordered\"><list-item><paragraph>Current Hyperparameters: List the current state.</paragraph></list-item><list-item><paragraph>Simulation: The graph of the loss and accuracy (training &amp; validation).</paragraph></list-item><list-item><paragraph>Visual Description: A brief, objective description of the line (e.g., \"The line is flat,\" \"The line is oscillating\"). Do not interpret the meaning.</paragraph></list-item><list-item><paragraph>Next Step: Ask the user: \"What is your next proposal? (Remember to include your reasoning.)\"</paragraph></list-item><list-item><paragraph>IF the user is asking for feedback or analysis, provide it to the extent that the user asks, giving no more information than is necessary, while satisfying the user's request.</paragraph></list-item></list><paragraph>Goal: The user should \"win\" by successfully tuning the model to high accuracy through trial and error, relying solely on their ability to read the graphs. Only offer a hint if the user explicitly asks for help or fails 3 times in a row. Ensure that the simulation is realistic.</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/6934b9ec-e3cc-800f-bab9-74457b92d562"
            ],
            "attachments": [],
            "created_at": "2025-12-07T11:37:28.182875+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422403,
            "author": "Qicheng Zhu",
            "project_title": "Special Participation E: Using ChatGPT to Automatically Find and Organize Related Papers",
            "post_body": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students deepen their understanding of lecture content by automatically finding and organizing related research papers.\n\nThe whole prompt workflow consists of three steps:\n\n(1) Given a PDF of the lecture notes, the model extracts several core technical topics; \n\n(2) For each topic, it generates specific search queries and uses them to retrieve relevant papers from Google Scholar or arXiv (ideally via Agent Mode);\n\n(3) Based on the retrieved papers, it produces structured summaries that explicitly connect back to the lecture topics, proposes an appropriate 2-3 hour reading plan, and generates conceptual reflection questions. This turns paper reading activity into an intended, reflective and guided literature exploration rather than just paper searching and reading.\n\nHere is the chat Link: https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324\n\nHere is the report:",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students deepen their understanding of lecture content by automatically finding and organizing related research papers.</paragraph><paragraph>The whole prompt workflow consists of three steps:</paragraph><paragraph>(1) Given a PDF of the lecture notes, the model extracts several core technical topics; </paragraph><paragraph>(2) For each topic, it generates specific search queries and uses them to retrieve relevant papers from Google Scholar or arXiv (ideally via <bold><bold>Agent Mode</bold></bold>);</paragraph><paragraph>(3) Based on the retrieved papers, it produces structured summaries that explicitly connect back to the lecture topics, proposes an appropriate 2-3 hour reading plan, and generates conceptual reflection questions. This turns paper reading activity into an intended, reflective and guided literature exploration rather than just paper searching and reading.</paragraph><paragraph>Here is the chat Link: <link href=\"https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324\"><underline><underline>https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324</underline></underline></link></paragraph><paragraph>Here is the report:</paragraph><file url=\"https://static.us.edusercontent.com/files/3Jt3PO58cbiatKc7bvom9O7y\" filename=\"Participation E2 Qicheng Zhu.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/6934b827-ed1c-8002-9a93-03242d44b324"
            ],
            "attachments": [],
            "created_at": "2025-12-07T10:40:31.898458+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422368,
            "author": "Aryan Bansal",
            "project_title": "Special Participation E: HW Concept Check CLI",
            "post_body": "Sometime when I look at a homework question, I don't know exactly where to start. Although the struggle of interpreting a question is good, a reminder/concept check seems like it could be helpful. At the same time, asking a chat application makes it hard to not overshare and delegate work.\n\nTherefore, I created a simple CLI that presents a series of conceptual questions about homework questions. The CLI makes it easy to select and a homework no. and part no. The generated question can be responded to via the cmd line or a hint can be requested. When a response is submitted, it is evaluated against the expected answer, and a follow up question will be presented to fill in the gaps. An LLM is necessary for the task of grading free-response answers effectively.\n\nI first created an ingestion script that iteratively takes every homework and uses an effective system prompt to generate the bank of questions and write to .json files. This does not have to be run again. The main script \"concept_cli_app.py\" launches the GUI. The script is bring your own key (export OPENAI_API_KEY=sk...)\n\nBelow I've attached the zip file of the repo and an annotated example interaction. The README has proper instructions (create env, export key, run it).\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Sometime when I look at a homework question, I don't know exactly where to start. Although the struggle of interpreting a question is good, a reminder/concept check seems like it could be helpful. At the same time, asking a chat application makes it hard to not overshare and delegate work.</paragraph><paragraph>Therefore, I created a simple CLI that presents a series of conceptual questions about homework questions. The CLI makes it easy to select and a homework no. and part no. The generated question can be responded to via the cmd line or a hint can be requested. When a response is submitted, it is evaluated against the expected answer, and a follow up question will be presented to fill in the gaps. An LLM is necessary for the task of grading free-response answers effectively.</paragraph><paragraph>I first created an ingestion script that iteratively takes every homework and uses an effective system prompt to generate the bank of questions and write to .json files. This does not have to be run again. The main script \"concept_cli_app.py\" launches the GUI. The script is bring your own key (export OPENAI_API_KEY=sk...)</paragraph><paragraph>Below I've attached the zip file of the repo and an annotated example interaction. The README has proper instructions (create env, export key, run it).</paragraph><file url=\"https://static.us.edusercontent.com/files/qsc1HxW5tESls4AiK9ItaOdV\" filename=\"example_interaction.txt\"/><file url=\"https://static.us.edusercontent.com/files/PRZLzDJxu9zFPhbSItsaGj4j\" filename=\"concept_cli.zip\"/><paragraph/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T10:31:48.296264+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422332,
            "author": "Tamzid Razzaque",
            "project_title": "Special Participation E: Understanding Pooling and Backprop better from 10/2 and 9/30 lectures",
            "post_body": "This interaction documents my use of ChatGPT as an AI-enhanced learning tool to help me understand material from the 9/30 and 10/2 EECS 182 lectures. I prompted the model with very specific questions that came directly from moments of confusion during lecture, such as why gradients scale like \u221aN for shared weights in backprop, whether gradients are summed or averaged, how gradients flow through mean and max pooling, and how pooling and convolution affect spatial dimensions versus channel count in architectures like AlexNet. I also asked follow-up clarification questions about notation (e.g., what symbols like a, b, c, d and g represent) and about how activations change across training steps.\n\nThe AI responded by breaking each concept into step-by-step explanations, often re-deriving what was shown in lecture more slowly and with concrete examples. In several cases, it successfully clarified the professor\u2019s intent, especially around weight sharing, pooling backpropagation, and the distinction between activations and learnable parameters. The tool was particularly helpful as a substitute for pre- or post-lecture reading, translating fast-paced boardwork and verbal explanations into structured reasoning.\n\nI critically annotated the trace to point out when the AI stayed closely aligned with lecture content and when it went beyond the lecture by adding extra intuition or external context (e.g., references to numerical precision or broader deep-learning practices). While these additions were generally consistent with the course material, I noted where they were enrichment rather than strictly what was covered in class. Overall, this interaction shows how an LLM can function as an active learning companion for lectures by answering targeted questions, correcting misconceptions, and reinforcing core ideas when used with careful human oversight.",
            "content_xml": "<document version=\"2.0\"><paragraph>This interaction documents my use of ChatGPT as an AI-enhanced learning tool to help me understand material from the 9/30 and 10/2 EECS 182 lectures. I prompted the model with very specific questions that came directly from moments of confusion during lecture, such as why gradients scale like \u221aN for shared weights in backprop, whether gradients are summed or averaged, how gradients flow through mean and max pooling, and how pooling and convolution affect spatial dimensions versus channel count in architectures like AlexNet. I also asked follow-up clarification questions about notation (e.g., what symbols like a, b, c, d and g represent) and about how activations change across training steps.</paragraph><paragraph>The AI responded by breaking each concept into step-by-step explanations, often re-deriving what was shown in lecture more slowly and with concrete examples. In several cases, it successfully clarified the professor\u2019s intent, especially around weight sharing, pooling backpropagation, and the distinction between activations and learnable parameters. The tool was particularly helpful as a substitute for pre- or post-lecture reading, translating fast-paced boardwork and verbal explanations into structured reasoning.</paragraph><paragraph>I critically annotated the trace to point out when the AI stayed closely aligned with lecture content and when it went beyond the lecture by adding extra intuition or external context (e.g., references to numerical precision or broader deep-learning practices). While these additions were generally consistent with the course material, I noted where they were enrichment rather than strictly what was covered in class. Overall, this interaction shows how an LLM can function as an active learning companion for lectures by answering targeted questions, correcting misconceptions, and reinforcing core ideas when used with careful human oversight.</paragraph><file url=\"https://static.us.edusercontent.com/files/uA21sfWespp8OeTW9H9MFmSH\" filename=\"lecture9:30-10:2-trace_with_commentary.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T10:25:50.377051+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422272,
            "author": "Elizabeth Polito",
            "project_title": "Special Participation E: Claude \"Artifacts\" for Visualization Tutor with VAE Example",
            "post_body": "For this assignment, I built a \"Visualization Tutor\" to help us build intuition for the math behind Variational Autoencoders (Lecture 24). I used Claude 4.5 Sonnet to create an interactive web-based visualizer. I chose Claude because of its \"Artifacts\" feature. It now has a dedicated UI window that renders code (like React or HTML) instantly alongside the chat, and allows for a good amount of iteration before you hit free tier limits. This allowed me to iterate on the tool in real-time to visualize the VAE concepts we learned in class and audit the correctness of the implementation/add new features. I would also like to credit that I also used Gemini to help ideate for this assignment. Overall, Claude seemed to accurately synthesize the requests and was able to generate a VAE visualization with little trouble, which helps to better understand how the relative entropy term works for VAEs.\n\nThe resulting artifact is a single-file HTML/React application (attached below) that lets you manipulate the encoder's outputs ($\\mu$ and $\\Sigma$) and see how they affect the latent distribution.\n\nThe Interaction Trace High-Level Overview:\n\nI used an initial prompt to set up the parameters for the visualization and shared the course notes for the relevant lecture.\n\nI checked the model's noise generation logic, suspecting it might rely on simple Uniform sampling (standard in JS). However, I verified that the model had correctly implemented the Box-Muller transform, ensuring the noise $\\epsilon$ followed the required $N(0,I)$ distribution.\n\nI forced the model to reconcile its simplified code with the discussion/notation from Lecture 24. \n\nFinally, I used the tool to visually demonstrate the \"Tradeoff\" concept from Page 3 of our notes. By setting the KL-Divergence weight to zero, I simulated the failure mode of a standard Autoencoder, providing a visual proof of why \"Distribution Loss\" is necessary for generation.\n\nI asked Claude to generate a user guide with some guided questions so that the visualization is more than just a passive tool but can be used for effective studying to better understand how VAEs work.\n\nFeel free to check out the website and play with the sliders to feel the \"pressure\" of the KL regularization yourself! I have attached a link to the website (Claude lets you export directly which is nice for sharing with your study group!) By using this prompting structure/Claude toolkit, you will be able to generate clean, easy-to-use visualizations to help with finals studying.\n\nHere is a link to the Website: \nhttps://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b \n\n(If you want to use the interactive features, such as the sliders, it looks like you\u2019ll have to click \u201cCustomize\u201d which will open it in an interactive UI)\n\nHere is a PDF of the User Guide/Tutorial that Claude generated: VAE Visualizer File\n\nAnd here is the annotated trace of my interaction with Claude: \n\nAddendum: Finally, this is outside of the scope of my Special Participation E, but I wanted to share anyway for anyone reading this who may be interested in information theory/data compression that VAEs have a very natural application in compression (somewhat in the spirit of the HW #12 information bottleneck VAE problem). The idea is that you compress sources by quantizing a representation in the latent space (which introduces some non-differentiability issues during training which is an active topic of research that people are trying to reconcile by coming up with stochastic alternatives to standard quantization). There is a cool paper from 2017 that shows even initial attempts at VAE-based \u2018neural\u2019 image compression outperforms JPEG compression (in terms of achieving better distortion measured by mean squared error between the source/reconstruction for the same compression rate measured in bits/pixel).\n\nLink to Balle\u2019 et al. 2017: [1611.01704] End-to-end Optimized Image Compression",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I built a \"Visualization Tutor\" to help us build intuition for the math behind Variational Autoencoders (Lecture 24). I used <bold>Claude 4.5 Sonnet</bold> to create an interactive web-based visualizer. I chose Claude because of its <bold>\"Artifacts\" feature</bold>. It now has a dedicated UI window that renders code (like React or HTML) instantly alongside the chat, and allows for a good amount of iteration before you hit free tier limits. This allowed me to iterate on the tool in real-time to visualize the VAE concepts we learned in class and audit the correctness of the implementation/add new features. I would also like to credit that I also used Gemini to help ideate for this assignment. Overall, Claude seemed to accurately synthesize the requests and was able to generate a VAE visualization with little trouble, which helps to better understand how the relative entropy term works for VAEs.</paragraph><paragraph>The resulting artifact is a single-file HTML/React application (attached below) that lets you manipulate the encoder's outputs ($\\mu$ and $\\Sigma$) and see how they affect the latent distribution.</paragraph><paragraph>The Interaction Trace High-Level Overview:</paragraph><list style=\"ordered\"><list-item><paragraph>I used an initial prompt to set up the parameters for the visualization and shared the course notes for the relevant lecture.</paragraph></list-item><list-item><paragraph>I checked the model's noise generation logic, suspecting it might rely on simple Uniform sampling (standard in JS). However, I verified that the model had correctly implemented the Box-Muller transform, ensuring the noise $\\epsilon$ followed the required $N(0,I)$ distribution.</paragraph></list-item><list-item><paragraph>I forced the model to reconcile its simplified code with the discussion/notation from Lecture 24. </paragraph></list-item><list-item><paragraph>Finally, I used the tool to visually demonstrate the \"Tradeoff\" concept from Page 3 of our notes. By setting the KL-Divergence weight to zero, I simulated the failure mode of a standard Autoencoder, providing a visual proof of why \"Distribution Loss\" is necessary for generation.</paragraph></list-item><list-item><paragraph>I asked Claude to generate a user guide with some guided questions so that the visualization is more than just a passive tool but can be used for effective studying to better understand how VAEs work.</paragraph></list-item></list><paragraph>Feel free to check out the website and play with the sliders to feel the \"pressure\" of the KL regularization yourself! I have attached a link to the website (Claude lets you export directly which is nice for sharing with your study group!) By using this prompting structure/Claude toolkit, you will be able to generate clean, easy-to-use visualizations to help with finals studying.</paragraph><paragraph>Here is a link to the Website: <break/><link href=\"https://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b\"><underline>https://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b</underline></link> </paragraph><paragraph>(If you want to use the interactive features, such as the sliders, it looks like you\u2019ll have to click \u201cCustomize\u201d which will open it in an interactive UI)</paragraph><paragraph>Here is a PDF of the User Guide/Tutorial that Claude generated: VAE Visualizer File</paragraph><file url=\"https://static.us.edusercontent.com/files/JCeQBqQLDXLbAZdgeFpZe0kK\" filename=\"VAE Visualizer - Student User Guide.pdf\"/><paragraph>And here is the annotated trace of my interaction with Claude: </paragraph><file url=\"https://static.us.edusercontent.com/files/ME2Qa0e5cChCLxmVNkw3A9KG\" filename=\"annotated_claude_trace.pdf\"/><paragraph>Addendum: Finally, this is outside of the scope of my Special Participation E, but I wanted to share anyway for anyone reading this who may be interested in information theory/data compression that VAEs have a very natural application in compression (somewhat in the spirit of the HW #12 information bottleneck VAE problem). The idea is that you compress sources by quantizing a representation in the latent space (which introduces some non-differentiability issues during training which is an active topic of research that people are trying to reconcile by coming up with stochastic alternatives to standard quantization). There is a cool paper from 2017 that shows even initial attempts at VAE-based \u2018neural\u2019 image compression outperforms JPEG compression (in terms of achieving better distortion measured by mean squared error between the source/reconstruction for the same compression rate measured in bits/pixel).</paragraph><paragraph>Link to Balle\u2019 et al. 2017: <link href=\"https://arxiv.org/abs/1611.01704\"><underline>[1611.01704] End-to-end Optimized Image Compression</underline></link></paragraph></document>",
            "links": [
                "https://claude.ai/public/artifacts/f2a7d819-a142-4c58-8d94-74c430cc518b",
                "https://arxiv.org/abs/1611.01704"
            ],
            "attachments": [],
            "created_at": "2025-12-07T10:14:34.674722+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422149,
            "author": "Yaqi Su",
            "project_title": "Special Participation E: Claude as tutor for building up the concept of Mamba",
            "post_body": "I try to use Claude as a tutor for building up the concept of Mamba step by step. The tutoring session generally demonstrates great pedagogical design, with a progressive build-up from RNNs through SSMs to S4 and finally Mamba that mirrors the logical development in the course materials. The quizzes effectively check understanding at each conceptual stage. The mathematical treatment is generally rigorous, particularly in the discretization derivation and convolution unrolling sections, which closely match the lecture notes while providing step-by-step clarity that helpfully supplements the original material. Core concepts including the fundamental SSM equations, the dual-mode operation (convolution for training, recurrence for inference), and Mamba's selectivity mechanism are correctly explained.\n The primary issue (or shouldn\u2019t be called as an issue?) with this tutoring session is that is a bit scope creep. This includes the explicit HiPPO-LegS matrix formula, the Cauchy kernel trick for S4, detailed MambaBlock implementation code with specific architectural choices, hardware-level efficiency explanations involving kernel fusion and memory hierarchies, and empirical observations about Mamba's limitations on copying tasks and in-context learning. Though I think those contents actually helped me gain a deeper understanding of the design of Mamba, and I didn\u2019t identify particularly obvious fact errors. But if trying to use this approach for exam preparation, I think it might be better to also provide the lecture notes to Claude beforehand, so that it\u2019s aware of the context and may therefore design the contents more tailored to the course.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I try to use Claude as a tutor for building up the concept of Mamba step by step. The tutoring session generally demonstrates great pedagogical design, with a progressive build-up from RNNs through SSMs to S4 and finally Mamba that mirrors the logical development in the course materials. The quizzes effectively check understanding at each conceptual stage. The mathematical treatment is generally rigorous, particularly in the discretization derivation and convolution unrolling sections, which closely match the lecture notes while providing step-by-step clarity that helpfully supplements the original material. Core concepts including the fundamental SSM equations, the dual-mode operation (convolution for training, recurrence for inference), and Mamba's selectivity mechanism are correctly explained.<break/> The primary issue (or shouldn\u2019t be called as an issue?) with this tutoring session is that is a bit scope creep. This includes the explicit HiPPO-LegS matrix formula, the Cauchy kernel trick for S4, detailed MambaBlock implementation code with specific architectural choices, hardware-level efficiency explanations involving kernel fusion and memory hierarchies, and empirical observations about Mamba's limitations on copying tasks and in-context learning. Though I think those contents actually helped me gain a deeper understanding of the design of Mamba, and I didn\u2019t identify particularly obvious fact errors. But if trying to use this approach for exam preparation, I think it might be better to also provide the lecture notes to Claude beforehand, so that it\u2019s aware of the context and may therefore design the contents more tailored to the course.</paragraph><file url=\"https://static.us.edusercontent.com/files/pRYoei5xu15qx05A3m3E12O5\" filename=\"Claude-cs282 specialContributionE-Mamba.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T09:57:43.109202+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7422043,
            "author": "Yaqi Su",
            "project_title": "Special Participation E: Claude as tutor for building up the concept of Muon optimizer",
            "post_body": "I'm trying to use Claude as a tutor to gradually build up the concept of Muon optimizer, with quizzes given by Claude throughout the process. Overall, Claude demonstrated good teaching instincts by building a clear learning path, it did a great job tracing the historical and mathematical lineage from classical optimizers (like SGD, Adam, Shampoo, also pointed out the key advancement and limitation of each optimizer) to Muon. It provided high-quality technical derivations, most notably showing how Shampoo\u2019s preconditioner collapses into the orthogonalized gradient and why this leads naturally to Newton\u2013Schulz. Claude was also responsive and adaptive, when I asked it to elaborate more on certain concepts (like Adam and Newton-Schulz), it shifted smoothly from abstract theory to a concrete numerical walkthrough. Finally, it correctly highlighted important implementation details of Muon, including the ordering of momentum before orthogonalization. The main shortcoming was its complete omission of muP, which is also a foundational theoretical framework that explains why Muon achieves reliable scaling and automatic learning-rate transfer. And sometimes its explanations were overly abstract.  Additionally, it also missed some conceptual connections, such as connecting Adam to signSGD to strengthen intuition about magnitude-invariant updates.  But overall I think it still did a relatively great job, especially being able to provide me with some pretty insightful quiz questions that helped me better understand the concept.",
            "content_xml": "<document version=\"2.0\"><paragraph>I'm trying to use Claude as a tutor to gradually build up the concept of Muon optimizer, with quizzes given by Claude throughout the process. Overall, Claude demonstrated good teaching instincts by building a clear learning path, it did a great job tracing the historical and mathematical lineage from classical optimizers (like SGD, Adam, Shampoo, also pointed out the key advancement and limitation of each optimizer) to Muon. It provided high-quality technical derivations, most notably showing how Shampoo\u2019s preconditioner collapses into the orthogonalized gradient and why this leads naturally to Newton\u2013Schulz. Claude was also responsive and adaptive, when I asked it to elaborate more on certain concepts (like Adam and Newton-Schulz), it shifted smoothly from abstract theory to a concrete numerical walkthrough. Finally, it correctly highlighted important implementation details of Muon, including the ordering of momentum before orthogonalization. The main shortcoming was its complete omission of muP, which is also a foundational theoretical framework that explains why Muon achieves reliable scaling and automatic learning-rate transfer. And sometimes its explanations were overly abstract.  Additionally, it also missed some conceptual connections, such as connecting Adam to signSGD to strengthen intuition about magnitude-invariant updates.  But overall I think it still did a relatively great job, especially being able to provide me with some pretty insightful quiz questions that helped me better understand the concept.</paragraph><file url=\"https://static.us.edusercontent.com/files/orQkU4Tfrfiv33QuvQH6A5cm\" filename=\"Claude-CS282-specialParticipationE-Muon.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T09:43:16.748266+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7421430,
            "author": "Kian Hekmatnejad",
            "project_title": "Special Participation E: Gemini as a Lecture Notes Tutor",
            "post_body": "I used Gemini to build a tutor to help better understand the lecture notes. My tutor first provides the student with flashcards to ensure a base-level understanding, tests that understanding in a simple quiz, and finally provides some questions in a broader deep-learning context to confirm that the student has a firm grasp on the concepts in the lecture notes. My report is attached",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini to build a tutor to help better understand the lecture notes. My tutor first provides the student with flashcards to ensure a base-level understanding, tests that understanding in a simple quiz, and finally provides some questions in a broader deep-learning context to confirm that the student has a firm grasp on the concepts in the lecture notes. My report is attached</paragraph><file url=\"https://static.us.edusercontent.com/files/sbjBK3te61xHSWeIMrZQ0rpm\" filename=\"special_participation (2).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T08:12:04.922257+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7421107,
            "author": "Qicheng Zhu",
            "project_title": "Special Participation E: Using ChatGPT to Distinguish Similar Concepts in Notes via Embeddings",
            "post_body": "For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students better understand and distinguish similar concepts that appear in our lecture notes. \n\nThe workflow proceeds in four main steps. First, I input a PDF slide file and extract the most frequently used technical terms from the lecture. Second, I generate embeddings for these candidate concepts. Third, I compute cosine similarities between these embeddings to identify pairs of concepts that are semantically close and therefore likely to be confused by students. Finally, I use ChatGPT to provide specific explanations of each similar pair and to generate a small quiz to test whether students can correctly distinguish them.\n\nThis pipeline can be applied to any lecture and shared with classmates as a reusable prompt template. It offers a structured way to focus attention on subtle conceptual differences rather than just memorizing isolated definitions. However, because ChatGPT can still hallucinate certain explanations, we should double check its answers against the notes and textbook.\n\nHere is the chat Link: https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c\n\nHere is my report:\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation, I designed an AI-enhanced prompt workflow using ChatGPT to help students better understand and distinguish similar concepts that appear in our lecture notes. </paragraph><paragraph>The workflow proceeds in four main steps. First, I input a PDF slide file and extract the most frequently used technical terms from the lecture. Second, I generate embeddings for these candidate concepts. Third, I compute cosine similarities between these embeddings to identify pairs of concepts that are semantically close and therefore likely to be confused by students. Finally, I use ChatGPT to provide specific explanations of each similar pair and to generate a small quiz to test whether students can correctly distinguish them.</paragraph><paragraph>This pipeline can be applied to any lecture and shared with classmates as a reusable prompt template. It offers a structured way to focus attention on subtle conceptual differences rather than just memorizing isolated definitions. However, because ChatGPT can still hallucinate certain explanations, we should double check its answers against the notes and textbook.</paragraph><paragraph>Here is the chat Link: <link href=\"https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c\"><underline><underline>https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c</underline></underline></link></paragraph><paragraph>Here is my report:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/w8NpbGxCT7VrBvGfyV7Tqwsf\" filename=\"Participation E1 Qicheng Zhu.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/69348c4e-8040-8002-bf16-0ae8c39a833c"
            ],
            "attachments": [],
            "created_at": "2025-12-07T07:24:03.533171+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7420861,
            "author": "Divya Ramesh",
            "project_title": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides",
            "post_body": "Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides\n\nAfter trying to use lecture notes to help me review in preparation for the final, I realized that some of the later lecture notes don\u2019t have all the material that was talked about. This may be because the more recent lectures have turned from a more mathematical view into a more conceptual, informational view. Because of this, purely analyzing lecture notes doesn\u2019t give you the whole picture. I\u2019ve found the lecture videos have been the most helpful, but it might take a long time to go over every single lecture in so little time. So, I had the hypothesis that the lecture transcript would be a better recap because it has more information, everything that was talked about was in the lecture transcript, while not everything was in the notes. \n\nSo I decided to test out a comparison between the 2, checking the differences between inputting the lecture notes versus the lecture transcript. Both have drawbacks:\n\nSome drawbacks of lecture notes is lecture notes have a lot of diagrams, and gemini needs to analyze all these diagrams in order to make a judgement. Also, Gemini needs to recognize handwriting in order to give the details we need to recap. \n\nSome drawbacks of the video transcript is lecture transcript may not be fully transcribed correctly. This might cause errors, but I\u2019m hoping maybe Gemini will be able to fill in the gaps or correct and mis-transcribed pieces. The way I obtained this is by copy pasting the YouTube transcript into a document and then downloading it as a pdf.\n\nI started by creating separate gemini windows, each having one of the lecture notes or transcript downloaded as a file to analyze, and then using the same prompts on both. I saw what both focused on, what created the best overview, and generated the most useful information for recap. \n\nSee my annotations below:\n\nAnnotated Lecture Slides Gemini Conversation: https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_link\n\nAnnotated Lecture Transcript Gemini Conversation: \n\nhttps://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharing\n\nWhat I discovered was:\n\nLecture notes contained a lot more of the key concepts, emphasizing them but not necessarily too much detail about them. This makes sense since what is written is the main ideas.\n\nLecture transcript contained a lot more information because it was a lot longer than the lecture notes, but sometimes missed key concept names. Like it missed the entire section of GPT history, even when I prompted it to give me the GPT history, the transcript window couldn\u2019t give me any information. \n\nBoth had trade offs, but I think the lecture notes are ultimately a better resource than the lecture transcript. Even though the transcript went more in depth, the lecture notes actually touched on every single topic, even if there was no depth within those sections. I think a good strategy would be to upload the notes and then ask specific questions about those topics after. \n\nBut in terms of generating practice questions, the transcript is a better resource, since the nuances mentioned by the professors during lecture provide deeper questions, and allow the student to really think while the notes provide very surface level questions. ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Special Participation E: Analyzing Gemini Performance on Lecture Transcript vs Lecture Slides</bold></paragraph><paragraph>After trying to use lecture notes to help me review in preparation for the final, I realized that some of the later lecture notes don\u2019t have all the material that was talked about. This may be because the more recent lectures have turned from a more mathematical view into a more conceptual, informational view. Because of this, purely analyzing lecture notes doesn\u2019t give you the whole picture. I\u2019ve found the lecture videos have been the most helpful, but it might take a long time to go over every single lecture in so little time. So, I had the hypothesis that the lecture transcript would be a better recap because it has more information, everything that was talked about was in the lecture transcript, while not everything was in the notes. </paragraph><paragraph>So I decided to test out a comparison between the 2, checking the differences between inputting the lecture notes versus the lecture transcript. Both have drawbacks:</paragraph><paragraph>Some drawbacks of lecture notes is lecture notes have a lot of diagrams, and gemini needs to analyze all these diagrams in order to make a judgement. Also, Gemini needs to recognize handwriting in order to give the details we need to recap. </paragraph><paragraph>Some drawbacks of the video transcript is lecture transcript may not be fully transcribed correctly. This might cause errors, but I\u2019m hoping maybe Gemini will be able to fill in the gaps or correct and mis-transcribed pieces. The way I obtained this is by copy pasting the YouTube transcript into a document and then downloading it as a pdf.</paragraph><paragraph>I started by creating separate gemini windows, each having one of the lecture notes or transcript downloaded as a file to analyze, and then using the same prompts on both. I saw what both focused on, what created the best overview, and generated the most useful information for recap. </paragraph><paragraph>See my annotations below:</paragraph><paragraph>Annotated Lecture Slides Gemini Conversation: <link href=\"https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_link\"><underline>https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_link</underline></link></paragraph><paragraph>Annotated Lecture Transcript Gemini Conversation: </paragraph><paragraph><link href=\"https://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharing\"><underline>https://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharing</underline></link></paragraph><paragraph>What I discovered was:</paragraph><list style=\"unordered\"><list-item><paragraph>Lecture notes contained a lot more of the key concepts, emphasizing them but not necessarily too much detail about them. This makes sense since what is written is the main ideas.</paragraph></list-item><list-item><paragraph>Lecture transcript contained a lot more information because it was a lot longer than the lecture notes, but sometimes missed key concept names. Like it missed the entire section of GPT history, even when I prompted it to give me the GPT history, the transcript window couldn\u2019t give me any information. </paragraph></list-item><list-item><paragraph>Both had trade offs, but I think the lecture notes are ultimately a better resource than the lecture transcript. Even though the transcript went more in depth, the lecture notes actually touched on every single topic, even if there was no depth within those sections. I think a good strategy would be to upload the notes and then ask specific questions about those topics after. </paragraph></list-item><list-item><paragraph>But in terms of generating practice questions, the transcript is a better resource, since the nuances mentioned by the professors during lecture provide deeper questions, and allow the student to really think while the notes provide very surface level questions. </paragraph></list-item></list></document>",
            "links": [
                "https://drive.google.com/file/d/1nlsyPygjEjPGJgpyLYeCbPtzfzgfKzzS/view?usp=share_link",
                "https://drive.google.com/file/d/1Wr5xeSS6TRXDrlENfvS-Z3dwEnQgor-k/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-07T06:47:03.515783+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419581,
            "author": "Oliver Chen",
            "project_title": "Special Participation E: Paper Explainer",
            "post_body": "Papers are often linked in homework assignments, discussion assignments, and often the papers are very hard to grasp especially on a first pass. I thought it would be helpful to make a prompt to explain an uploaded paper pdf, specifically in the context of the content of this class, such as:\n\nLinear algebra (matrix multiplication, projections, eigenspaces, orthogonality)\n\nVector calculus (gradients, Jacobians, Hessians)\n\nOptimization (SGD, momentum, Adam, convexity, nonconvex landscapes, saddle points)\n\nNeural network architectures (MLPs, CNNs, transformers, attention, residual networks)\n\nLoss functions (cross-entropy, mean squared error, likelihoods)\n\nBackpropagation (chain rule, computational graph, gradient flow)\n\nGeneralization, overfitting, underfitting\n\nRegularization (L2, dropout, weight decay)\n\nRepresentation learning\n\nTraining dynamics (learning rate, gradient norms, scaling laws)\n\nI found this tool I made to be very helpful when there is a paper mentioned in a homework question, and before reading it in depth, I want to get an overview of what topics are covered, what math I might have to catch up on, and what other concepts in class this paper relates to. \n\nIt also took a bit of work making sure the model does not hallucinate or make up explanations or talk about something that's not mentioned in the paper, and also to clarify what specific content from cs182 to draw connections to.\n\nHere is a chatgpt log of me using this to explain https://arxiv.org/abs/1909.08593 (from homework 13) in terms of the content in CS182: https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6\n\nI thought it was very helpful, as it also identified all equations in the paper and derived them from concepts from this class. \n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Papers are often linked in homework assignments, discussion assignments, and often the papers are very hard to grasp especially on a first pass. I thought it would be helpful to make a prompt to explain an uploaded paper pdf, specifically in the context of the content of this class, such as:</paragraph><list style=\"unordered\"><list-item><paragraph>Linear algebra (matrix multiplication, projections, eigenspaces, orthogonality)</paragraph></list-item><list-item><paragraph>Vector calculus (gradients, Jacobians, Hessians)</paragraph></list-item><list-item><paragraph>Optimization (SGD, momentum, Adam, convexity, nonconvex landscapes, saddle points)</paragraph></list-item><list-item><paragraph>Neural network architectures (MLPs, CNNs, transformers, attention, residual networks)</paragraph></list-item><list-item><paragraph>Loss functions (cross-entropy, mean squared error, likelihoods)</paragraph></list-item><list-item><paragraph>Backpropagation (chain rule, computational graph, gradient flow)</paragraph></list-item><list-item><paragraph>Generalization, overfitting, underfitting</paragraph></list-item><list-item><paragraph>Regularization (L2, dropout, weight decay)</paragraph></list-item><list-item><paragraph>Representation learning</paragraph></list-item><list-item><paragraph>Training dynamics (learning rate, gradient norms, scaling laws)</paragraph></list-item></list><paragraph>I found this tool I made to be very helpful when there is a paper mentioned in a homework question, and before reading it in depth, I want to get an overview of what topics are covered, what math I might have to catch up on, and what other concepts in class this paper relates to. <break/><break/>It also took a bit of work making sure the model does not hallucinate or make up explanations or talk about something that's not mentioned in the paper, and also to clarify what specific content from cs182 to draw connections to.<break/><break/>Here is a chatgpt log of me using this to explain <link href=\"https://arxiv.org/abs/1909.08593\">https://arxiv.org/abs/1909.08593</link> (from homework 13) in terms of the content in CS182: <link href=\"https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6\">https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6</link><break/><break/>I thought it was very helpful, as it also identified all equations in the paper and derived them from concepts from this class. </paragraph><paragraph><break/></paragraph></document>",
            "links": [
                "https://arxiv.org/abs/1909.08593",
                "https://chatgpt.com/share/69343592-7fac-800b-a72b-adf5e363aec6"
            ],
            "attachments": [],
            "created_at": "2025-12-07T00:54:45.259414+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419566,
            "author": "Oliver Chen",
            "project_title": "Special Participation E: ChatGPT Transformer Operations Visualizer",
            "post_body": "I think transformers specifically are a difficult topic because there are many specific operations and parameters to remember -- and so keeping track of everything while solving a transformer-related homework problem can be a bit tough. I created a ChatGPT prompt to create a operations graph visualizer, given a homework problem, of all the transformer operations this passed through, making it very clear what dimensions the input data is, how it's transformed and through what specific operations and what they're called. \n\n\n\nIt took be a bit of tweaking to make sure ChatGPT would not give me answers, but still very accurately visualize the relevant parts of the transformer for the given homework problem. The prompt is very long, so I will show it in the chat logs as opposed to pasting it directly in the Ed post. \n\nI also found through testing that generating ASCII diagrams was the best way, as one very good feature of ASCII diagrams is it can also label and explain operations/parameters in text, where as other forms of visualization struggle with text. \n\nHere is a chat log of me using it to visualize the transformer operations on homework 9:\nhttps://chatgpt.com/share/693431c7-b8d4-800b-a322-e39ae6475f1f",
            "content_xml": "<document version=\"2.0\"><paragraph>I think transformers specifically are a difficult topic because there are many specific operations and parameters to remember -- and so keeping track of everything while solving a transformer-related homework problem can be a bit tough. I created a ChatGPT prompt to create a operations graph visualizer, given a homework problem, of all the transformer operations this passed through, making it very clear what dimensions the input data is, how it's transformed and through what specific operations and what they're called. </paragraph><paragraph/><paragraph>It took be a bit of tweaking to make sure ChatGPT would not give me answers, but still very accurately visualize the relevant parts of the transformer for the given homework problem. The prompt is very long, so I will show it in the chat logs as opposed to pasting it directly in the Ed post. <break/><break/>I also found through testing that generating ASCII diagrams was the best way, as one very good feature of ASCII diagrams is it can also label and explain operations/parameters in text, where as other forms of visualization struggle with text. <break/><break/>Here is a chat log of me using it to visualize the transformer operations on homework 9:<break/>https://chatgpt.com/share/693431c7-b8d4-800b-a322-e39ae6475f1f</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-07T00:38:47.561222+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419470,
            "author": "Kabir Shah",
            "project_title": "Special Participation E: Misconception Explorer",
            "post_body": "I found that often times after lecture I'll have some idea cemented in my head, only to much later find out that one of the basic assumptions I had made was wrong. To try and alleviate this, I thought it would be useful to have a \"Misconception Explorer\" prompt where you can engage with an LLM by giving it lecture notes and having it probe you with examples and questions that test common misconceptions. Here's the prompt:\n\nYou are my Misconception Explorer.\n\nI will paste the full text of a PDF of lecture notes. Your job is to identify 4 of the most plausible misconceptions or subtle misunderstandings a student might develop from these notes.\n\nFor each of the four selected misconceptions, do the following INTERACTIVELY:\n\u2022 Ask me a question that probes whether I fall for the misconception or understand the concept correctly.\n\u2022 Wait for my answer before revealing the explanation.\n\u2022 After I answer, explain:\n    - Whether my answer reflects the misconception.\n    - The correct reasoning.\n    - Why the misconception is tempting.\n\nImportant behavior rules:\n\u2022\u00a0Do NOT state, hint at, or describe the misconception before presenting the probing question. Only reveal the misconception after I answer the question.\n\u2022 Do NOT rush through all four misconceptions at once. Present them ONE AT A TIME.\n\u2022 After finishing the full explanation for one misconception, ask if I am ready for the next.\n\u2022 Keep each example small, focused, and tied directly to content in the PDF.\n\u2022 If the notes are ambiguous, state this explicitly.\n\u2022 Avoid introducing concepts not present in the PDF unless needed for correction, and mark such additions clearly.\n\nBegin by asking me to paste the lecture notes PDF text.\nAfter I paste it, start with Question #1.\n\n\nI had to iterate on it many times because it would often start brainstorming misconceptions before asking me about them, kind of defeating the purpose of it. I found that the \"important behavior rules\" were crucial to preventing this type of behavior and ensuring that the model first asks you the questions before talking about the misconception it might be testing. I ran it through Lecture 19 (transformers, positional embeddings), and here's what I got:\n\nI found that it was actually pretty good and taught me a few new things: (1) that embeddings and unembeddings can use the same weight matrix and don't necessarily need to be separate projections (and GPT-2 does this!) and (2) RoPE can encode absolute position information implicitly.\n\nSome of the questions it asked were really easy or kind of arbitrary, but they did attempt to test some kind of misconception which I thought was cool. For example, it asked if RoPE required frequencies to be shared across layers, which I guess students might assume is true because that is how it is done, but is not a requirement for it to work. While these types of technicalities were less useful than the other misconceptions it tested, I found that they were still good forms of review and forced me to think about what the true requirements for things like RoPE were and what were there for reasons such as stabilizing training.\n\nI found in my use that it didn't hallucinate much but it is very limited to the quality of the notes that you give it, especially since the prompt asks it to stay grounded to the content of the notes you give it. So it will often be very specific to the lecture. If you have text notes or markdown/latex formatting I think it will likely be much better than submitting a hand-written note pdf like I did. Overall, I think this is a pretty useful tool and can help you wrap your head around the trickier deep learning concepts by testing more subtle \"edge cases\" of the concepts covered in lecture.",
            "content_xml": "<document version=\"2.0\"><paragraph>I found that often times after lecture I'll have some idea cemented in my head, only to much later find out that one of the basic assumptions I had made was wrong. To try and alleviate this, I thought it would be useful to have a \"Misconception Explorer\" prompt where you can engage with an LLM by giving it lecture notes and having it probe you with examples and questions that test common misconceptions. Here's the prompt:</paragraph><pre>You are my Misconception Explorer.\n\nI will paste the full text of a PDF of lecture notes. Your job is to identify 4 of the most plausible misconceptions or subtle misunderstandings a student might develop from these notes.\n\nFor each of the four selected misconceptions, do the following INTERACTIVELY:\n\u2022 Ask me a question that probes whether I fall for the misconception or understand the concept correctly.\n\u2022 Wait for my answer before revealing the explanation.\n\u2022 After I answer, explain:\n    - Whether my answer reflects the misconception.\n    - The correct reasoning.\n    - Why the misconception is tempting.\n\nImportant behavior rules:\n\u2022\u00a0Do NOT state, hint at, or describe the misconception before presenting the probing question. Only reveal the misconception after I answer the question.\n\u2022 Do NOT rush through all four misconceptions at once. Present them ONE AT A TIME.\n\u2022 After finishing the full explanation for one misconception, ask if I am ready for the next.\n\u2022 Keep each example small, focused, and tied directly to content in the PDF.\n\u2022 If the notes are ambiguous, state this explicitly.\n\u2022 Avoid introducing concepts not present in the PDF unless needed for correction, and mark such additions clearly.\n\nBegin by asking me to paste the lecture notes PDF text.\nAfter I paste it, start with Question #1.\n</pre><paragraph>I had to iterate on it many times because it would often start brainstorming misconceptions before asking me about them, kind of defeating the purpose of it. I found that the \"important behavior rules\" were crucial to preventing this type of behavior and ensuring that the model first asks you the questions before talking about the misconception it might be testing. I ran it through Lecture 19 (transformers, positional embeddings), and here's what I got:</paragraph><file url=\"https://static.us.edusercontent.com/files/IfpWkLpXxQJhEnepJikNXUXz\" filename=\"Misconception exploration process.pdf\"/><paragraph>I found that it was actually pretty good and taught me a few new things: (1) that embeddings and unembeddings can use the same weight matrix and don't necessarily need to be separate projections (and GPT-2 does this!) and (2) RoPE can encode absolute position information implicitly.</paragraph><paragraph>Some of the questions it asked were really easy or kind of arbitrary, but they did attempt to test some kind of misconception which I thought was cool. For example, it asked if RoPE required frequencies to be shared across layers, which I guess students might assume is true because that is how it is done, but is not a requirement for it to work. While these types of technicalities were less useful than the other misconceptions it tested, I found that they were still good forms of review and forced me to think about what the true requirements for things like RoPE were and what were there for reasons such as stabilizing training.</paragraph><paragraph>I found in my use that it didn't hallucinate much but it is very limited to the quality of the notes that you give it, especially since the prompt asks it to stay grounded to the content of the notes you give it. So it will often be very specific to the lecture. If you have text notes or markdown/latex formatting I think it will likely be much better than submitting a hand-written note pdf like I did. Overall, I think this is a pretty useful tool and can help you wrap your head around the trickier deep learning concepts by testing more subtle \"edge cases\" of the concepts covered in lecture.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T22:43:42.274139+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419456,
            "author": "Zesheng Cai",
            "project_title": "Special Participation B: Deepseek on coding problems in HW 8",
            "post_body": "In this homework, DeepSeek demonstrates strong reasoning and coding abilities when implementing state-space model (SSM) forward passes using both recursive and convolution-based methods. One consistent pattern is that DeepSeek tends to first derive the underlying mathematical formulas and only then translate them into code. This leads to implementations that are correct, readable, and closely aligned with the theoretical model.\n\nThe model shows excellent handling of shapes, tensor operations, and GPU/CPU device management. It also performs well in identifying structural simplifications\u2014for example, exploiting diagonal matrices to build depthwise convolution kernels or reduce recurrent updates to element-wise multiplications. DeepSeek additionally explains algorithmic trade-offs (e.g., runtime scaling of unrolled vs. convolution-based methods) with clarity and accuracy.\n\nOverall, DeepSeek provides code that is correct, optimized, and grounded in solid mathematical reasoning. Its step-by-step logic, attention to detail, and ability to convert equations directly into PyTorch implementations demonstrate strong competence that is well suited for deep learning coursework.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/SBeYIQilxEFDgKmfFLRe3uGs\" filename=\"Helping with SSM coding homework questions (1) - DeepSeek.pdf\"/><paragraph>In this homework, DeepSeek demonstrates strong reasoning and coding abilities when implementing state-space model (SSM) forward passes using both recursive and convolution-based methods. One consistent pattern is that DeepSeek tends to <bold>first derive the underlying mathematical formulas</bold> and <bold>only then translate them into code</bold>. This leads to implementations that are correct, readable, and closely aligned with the theoretical model.</paragraph><paragraph>The model shows excellent handling of shapes, tensor operations, and GPU/CPU device management. It also performs well in identifying structural simplifications\u2014for example, exploiting diagonal matrices to build depthwise convolution kernels or reduce recurrent updates to element-wise multiplications. DeepSeek additionally explains algorithmic trade-offs (e.g., runtime scaling of unrolled vs. convolution-based methods) with clarity and accuracy.</paragraph><paragraph>Overall, DeepSeek provides code that is correct, optimized, and grounded in solid mathematical reasoning. Its step-by-step logic, attention to detail, and ability to convert equations directly into PyTorch implementations demonstrate strong competence that is well suited for deep learning coursework.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T22:14:49.458165+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419439,
            "author": "Kabir Shah",
            "project_title": "Special Participation E: Drill Generator",
            "post_body": "While a lot of study tools and methods seem useful, I always tend to use them once or twice and then end up stopping. I think an ideal study tool would be really easy to use and also a low time commitment, so instead of generating detailed quizzes, I tried to make a prompt that can just take in lecture notes and provide an \"easy\" MCQ drill that is designed to just help you recall different parts of lecture to allow it to be as low-commitment of an addition into your study routine as possible. Here's the prompt:\n\n\nYou are the Concept Drill Generator for my deep learning class.\n\nI will paste the professor\u2019s lecture notes below. \nYour job is to generate a short practice drill based ONLY on the content of those notes.\n\n--------------------------------------\nREQUIRED INPUT (from me): LECTURE NOTES\n--------------------------------------\n\nAfter I paste the notes, do the following:\n\n1. Generate 8\u201312 questions total, mixing:\n   - multiple choice (A, B, C, D)\n   - simple fill-in-the-blank\n\n2. All questions must strictly reflect the lecture notes.\n   - Do NOT introduce material not present in the notes.\n   - If the notes are ambiguous or missing detail, simplify the question rather than guessing.\n   - Mark any question where your confidence is medium or low.\n\n3. After generating the questions, stop and wait for my answers.\n   - I will answer them one by one or in batches.\n   - After each answer, you will:\n        a. Tell me whether my answer is correct.\n        b. Briefly explain why (using only the lecture notes as the source).\n        c. If you are uncertain, say so explicitly.\n\n4. Do NOT reveal the correct answers until I attempt the question or ask for them.\n\n--------------------------------------\nWhen you're ready, say: \u201cPlease paste the lecture notes.\u201d\n\n\n\nYou can paste this in, and then it will prompt you to paste in lecture notes. Here's an example run for lecture 16 (the introduction lecture to SSMs):\n\nYou'll see that the output was pretty useful about 80% of the time. However, in one of the questions it gave away the answer by admitting its lower confidence in the notes that I uploaded. I think that this prompt is primarily limited by the fidelity of the notes pasted. Here, I just pasted the raw pdf of the lecture notes so it was limited by how well it was parsed into text. I think that if you paste in hand-typed notes it would be ideal.\n\nEither way, most of the questions weren't too complex but just enough to get me to recall the important points of lecture and why they were important. It was able to give me hints when I was stuck, and it also gave good explanations when I was wrong.\n\nIt did hallucinate pretty badly once where it accepted a wrong answer of mine and cited the wrong page to justify it. I had to correct it and tell it the correct answer. I think once again this was due to the fidelity of the uploaded notes. But it's important to keep in mind and something to watch out for when using this tool.\n\nThere's also some room for improvement because some of the questions I felt overly focused on the specifics of lecture rather than a concept. For example, it would have you fill in the blank of a specific phrase used in the lecture notes. I don't know how useful this actually is compared to conceptual understanding, but either way it did make me look back at the notes to try and figure out the answer so maybe it worked to help my understanding either way!",
            "content_xml": "<document version=\"2.0\"><paragraph>While a lot of study tools and methods seem useful, I always tend to use them once or twice and then end up stopping. I think an ideal study tool would be really easy to use and also a low time commitment, so instead of generating detailed quizzes, I tried to make a prompt that can just take in lecture notes and provide an \"easy\" MCQ drill that is designed to just help you recall different parts of lecture to allow it to be as low-commitment of an addition into your study routine as possible. Here's the prompt:<break/></paragraph><pre>You are the Concept Drill Generator for my deep learning class.\n\nI will paste the professor\u2019s lecture notes below. \nYour job is to generate a short practice drill based ONLY on the content of those notes.\n\n--------------------------------------\nREQUIRED INPUT (from me): LECTURE NOTES\n--------------------------------------\n\nAfter I paste the notes, do the following:\n\n1. Generate 8\u201312 questions total, mixing:\n   - multiple choice (A, B, C, D)\n   - simple fill-in-the-blank\n\n2. All questions must strictly reflect the lecture notes.\n   - Do NOT introduce material not present in the notes.\n   - If the notes are ambiguous or missing detail, simplify the question rather than guessing.\n   - Mark any question where your confidence is medium or low.\n\n3. After generating the questions, stop and wait for my answers.\n   - I will answer them one by one or in batches.\n   - After each answer, you will:\n        a. Tell me whether my answer is correct.\n        b. Briefly explain why (using only the lecture notes as the source).\n        c. If you are uncertain, say so explicitly.\n\n4. Do NOT reveal the correct answers until I attempt the question or ask for them.\n\n--------------------------------------\nWhen you're ready, say: \u201cPlease paste the lecture notes.\u201d\n\n</pre><paragraph>You can paste this in, and then it will prompt you to paste in lecture notes. Here's an example run for lecture 16 (the introduction lecture to SSMs):</paragraph><file url=\"https://static.us.edusercontent.com/files/0LUCxLO6CzPmz4viuPFmNOCw\" filename=\"Drill-example.pdf\"/><paragraph>You'll see that the output was pretty useful about 80% of the time. However, in one of the questions it gave away the answer by admitting its lower confidence in the notes that I uploaded. I think that this prompt is primarily limited by the fidelity of the notes pasted. Here, I just pasted the raw pdf of the lecture notes so it was limited by how well it was parsed into text. I think that if you paste in hand-typed notes it would be ideal.</paragraph><paragraph>Either way, most of the questions weren't too complex but just enough to get me to recall the important points of lecture and why they were important. It was able to give me hints when I was stuck, and it also gave good explanations when I was wrong.</paragraph><paragraph>It did hallucinate pretty badly once where it accepted a wrong answer of mine and cited the wrong page to justify it. I had to correct it and tell it the correct answer. I think once again this was due to the fidelity of the uploaded notes. But it's important to keep in mind and something to watch out for when using this tool.</paragraph><paragraph>There's also some room for improvement because some of the questions I felt overly focused on the specifics of lecture rather than a concept. For example, it would have you fill in the blank of a specific phrase used in the lecture notes. I don't know how useful this actually is compared to conceptual understanding, but either way it did make me look back at the notes to try and figure out the answer so maybe it worked to help my understanding either way!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T21:47:55.716223+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419416,
            "author": "Kabir Shah",
            "project_title": "Special Participation B: GPT-5.1 on HW8",
            "post_body": "Attached is the log for the coding part of HW8. I used GPT-5.1, which I found to be a bit more chatty than GPT-5, meaning that it often tried to use more \"human-friendly\" language and attempted to talk more naturally. In comparison, my experience with GPT-5 has been that it is very direct, factual, and to the point, which is an interesting contrast.\n\nGPT-5.1 was able to one-shot almost all of the questions in this part and code the various SSM implementations correctly. It required assistance at the start when implementing the convolution version of the SSM, where its initial implementation was off from the unrolled implementation by about 0.5. However, after pasting the sanity check code and the exact output it had, it was able to introspect and figure out exactly the two issues it had with its implementation and correct them, resulting in a final discrepancy of ~0 with the other implementation.\n\nI thought it was interesting that it was able to analyze the runtime graphs pretty accurately as well in one-shot. It seems to have pretty good reasoning ability when looking at graphs and can identify basic patterns from just the images I added in.\n\nOverall, I was very impressed with its performance and it was able to one-shot most problems without assistance. A solid strategy for getting it to fix its mistakes is to give it a test case and a concrete output, and in this case the sanity check code was able to provide that type of feedback very directly, so it was able to fix it in one shot after being given the sanity check code.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/dwcP3FO4qAdaMxs0M2MYNRhS\" filename=\"hw8-log.pdf\"/><paragraph>Attached is the log for the coding part of HW8. I used GPT-5.1, which I found to be a bit more chatty than GPT-5, meaning that it often tried to use more \"human-friendly\" language and attempted to talk more naturally. In comparison, my experience with GPT-5 has been that it is very direct, factual, and to the point, which is an interesting contrast.</paragraph><paragraph>GPT-5.1 was able to one-shot almost all of the questions in this part and code the various SSM implementations correctly. It required assistance at the start when implementing the convolution version of the SSM, where its initial implementation was off from the unrolled implementation by about 0.5. However, after pasting the sanity check code and the exact output it had, it was able to introspect and figure out exactly the two issues it had with its implementation and correct them, resulting in a final discrepancy of ~0 with the other implementation.</paragraph><paragraph>I thought it was interesting that it was able to analyze the runtime graphs pretty accurately as well in one-shot. It seems to have pretty good reasoning ability when looking at graphs and can identify basic patterns from just the images I added in.</paragraph><paragraph>Overall, I was very impressed with its performance and it was able to one-shot most problems without assistance. A solid strategy for getting it to fix its mistakes is to give it a test case and a concrete output, and in this case the sanity check code was able to provide that type of feedback very directly, so it was able to fix it in one shot after being given the sanity check code.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T21:14:24.156993+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419382,
            "author": "Lenci Ni",
            "project_title": "Special Participation E: \u201cLLM as an Active Student\u201d Prompt",
            "post_body": "I\u2019ve been experimenting with using LLMs as a way to \u201clearn by teaching,\u201d since I often understand CS 182 topics better when I try to explain them out loud. I set up a prompt where the LLM plays the role of a really active, CS-189-trained student: it summarizes what I say, asks clarifying questions, challenges gaps in my explanation, and even corrects me when something is off. This forces me to think more carefully about each concept.\n\nI\u2019ve attached the prompts below, along with an example conversation where I tried teaching CNN concepts to the \u201cstudent.\u201d Overall, the LLM was surprisingly good at catching subtle mistakes, asking the right kinds of probing questions, and pushing me to justify steps. It definitely helped surface gaps in my understanding. That said, it isn\u2019t the most natural conversational partner as some of its explanations can be a bit stiff or overly formal, and occasionally it oversimplifies details or overcorrects in ways a real student wouldn\u2019t. Still, as a learning tool, it worked well for encouraging active engagement rather than passive reading.\n\nSeries of prompts used:\n\nExample conversation (annotated):",
            "content_xml": "<document version=\"2.0\"><paragraph>I\u2019ve been experimenting with using LLMs as a way to \u201clearn by teaching,\u201d since I often understand CS 182 topics better when I try to explain them out loud. I set up a prompt where the LLM plays the role of a really active, CS-189-trained student: it summarizes what I say, asks clarifying questions, challenges gaps in my explanation, and even corrects me when something is off. This forces me to think more carefully about each concept.</paragraph><paragraph>I\u2019ve attached the prompts below, along with an example conversation where I tried teaching CNN concepts to the \u201cstudent.\u201d Overall, the LLM was surprisingly good at catching subtle mistakes, asking the right kinds of probing questions, and pushing me to justify steps. It definitely helped surface gaps in my understanding. That said, it isn\u2019t the most natural conversational partner as some of its explanations can be a bit stiff or overly formal, and occasionally it oversimplifies details or overcorrects in ways a real student wouldn\u2019t. Still, as a learning tool, it worked well for encouraging active engagement rather than passive reading.</paragraph><paragraph>Series of prompts used:</paragraph><file url=\"https://static.us.edusercontent.com/files/euZsjsdifWETajvqeSZ0ibkN\" filename=\"participation_e_1_prompt.pdf\"/><paragraph>Example conversation (annotated):</paragraph><file url=\"https://static.us.edusercontent.com/files/VREaF2siIvzFb7TVgApw909u\" filename=\"participation_e_1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T20:36:31.66179+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419304,
            "author": "Neil Pattanaik",
            "project_title": "Special Participation A: DeepSeek V3.2 on HW7",
            "post_body": "\n\nConversation link: https://chat.deepseek.com/share/hilftw4hcw8pevn9vy\n\nI used the recently-released DeepSeek V3.2 model (with thinking enabled) to solve the non-coding portion of Homework 7. As expected, the reasoning model one-shotted all the problems it faced, solving multiple parts within a single prompt on each occasion.\n\nOne challenge with DeepSeek (and, in my experience, almost all commerically-hosted LLMs) is that it can struggle when given web links. Though I included the link to the blog post archive in question 4, DeepSeek still couldn't access it, so I had to upload a PDF copy of the page. Perhaps the bots are forbidden from accessing web archives and the Wayback machine for copyright or safety reasons.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph/><file url=\"https://static.us.edusercontent.com/files/tig34MT6BniFddym9fZrpE3G\" filename=\"deepseek hw7 annotated.pdf\"/><paragraph><bold>Conversation link:</bold> https://chat.deepseek.com/share/hilftw4hcw8pevn9vy</paragraph><paragraph>I used the recently-released DeepSeek V3.2 model (with thinking enabled) to solve the non-coding portion of Homework 7. As expected, the reasoning model one-shotted all the problems it faced, solving multiple parts within a single prompt on each occasion.</paragraph><paragraph>One challenge with DeepSeek (and, in my experience, almost all commerically-hosted LLMs) is that it can struggle when given web links. Though I included the link to the blog post archive in question 4, DeepSeek still couldn't access it, so I had to upload a PDF copy of the page. Perhaps the bots are forbidden from accessing web archives and the Wayback machine for copyright or safety reasons.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T19:27:12.63179+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419231,
            "author": "Hanna Roed",
            "project_title": "Special Participation B: Qwen on HW8",
            "post_body": "Below is my report on using Qwen3-Max on the coding part of homework 8. Since Qwen does not accept ipynb or py files I had to download the notebooks as py files and then copy them as text into the Qwen chat. This approach worked surprisingly well, and I am satisfied with its performance on this coding segment of the homework.",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is my report on using Qwen3-Max on the coding part of homework 8. Since Qwen does not accept <code>ipynb</code> or <code>py</code> files I had to download the notebooks as <code>py</code> files and then copy them as text into the Qwen chat. This approach worked surprisingly well, and I am satisfied with its performance on this coding segment of the homework.</paragraph><file url=\"https://static.us.edusercontent.com/files/tkGPeCL84n0O4fZnXSwyZaso\" filename=\"Special_Participation_B___HW8.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T18:57:13.630574+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419142,
            "author": "Iana Lin",
            "project_title": "Special Participation B: DeepSeek on HW4 Coding Questions",
            "post_body": "Executive Summary:\n\nI prompted DeepSeek to answer the coding questions from Homework 4. Asking questions both to respond to the coding sections as answer the conceptual questions, I found that in terms of technical correctness, DeepSeek did extremely well, particularly on the coding parts. But in conceptual depth about the coding questions, explanations were not always the best.\n\nOverall, it seems, DeepSeek is good at execution but weaker at interpretation.\n\nQ5: This was just designing two filters/convolution, so the fact that it one-shotted the code with little explanation is not suprising\n\n\n\nQ6: This problem was much more involved with a lot more coding, and importantly, conceptual questions\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold><underline>Executive Summary</underline></bold>:<break/><break/>I prompted DeepSeek to answer the coding questions from Homework 4. Asking questions both to respond to the coding sections as answer the conceptual questions, I found that in terms of technical correctness, DeepSeek did extremely well, particularly on the coding parts. But in conceptual depth about the coding questions, explanations were not always the best.<break/><break/>Overall, it seems, DeepSeek is good at execution but weaker at interpretation.<break/><break/>Q5: This was just designing two filters/convolution, so the fact that it one-shotted the code with little explanation is not suprising</paragraph><file url=\"https://static.us.edusercontent.com/files/p2pvkQtng5X7F6zaAWsDeslV\" filename=\"SpecialParticipationB5.pdf\"/><paragraph/><paragraph>Q6: This problem was much more involved with a lot more coding, and importantly, conceptual questions<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/lbxkky9byyRrBuwsdjb1Y6Lb\" filename=\"SpecialParticipationB6.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T18:16:35.75193+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419069,
            "author": "Mihir Rao",
            "project_title": "Special Participation A: GPT-4o on HW3",
            "post_body": "I worked on getting GPT-4o to answer non-coding parts of the homework. For Homework 3, this including both mathematical solutions as well as text answers, so it was interesting to see how 4o handled them. The mathematical solutions also required nuanced subscripts and understand of several variables, and the annotation log I've attached below should demonstrate interesting findings regarding these requirements.\n\nOne interesting thing I noticed was 4o's ability to process images/pull data. There's a few questions in this homework that rely on not only images, but images that are not in the homework itself. This means 4o has to understand where they are, retrieve them, and then understand what is in them to answer the question. I wanted to test this in a few different ways, so I initially ask 4o to just solve the problem. Then, I give it the image myself and ask it if the answer it provided previously is still good, or needs changing.\n\nSimilar to what I've experienced previously, I find that these models get worse and worse if they fail the first time. With each trial that goes wrong, they need more and more handholding to get on the right track. For this homework, 4o was able to zero-shot almost everything. In fact, the question it got wrong the first try was one of the simpler ones. Overall, it was really cool to see how these models can understand such a wider range of information in various formats and piece them together to come up with meaningful solutions.",
            "content_xml": "<document version=\"2.0\"><paragraph>I worked on getting GPT-4o to answer non-coding parts of the homework. For Homework 3, this including both mathematical solutions as well as text answers, so it was interesting to see how 4o handled them. The mathematical solutions also required nuanced subscripts and understand of several variables, and the annotation log I've attached below should demonstrate interesting findings regarding these requirements.<break/><break/>One interesting thing I noticed was 4o's ability to process images/pull data. There's a few questions in this homework that rely on not only images, but images that are not in the homework itself. This means 4o has to understand where they are, retrieve them, and then understand what is in them to answer the question. I wanted to test this in a few different ways, so I initially ask 4o to just solve the problem. Then, I give it the image myself and ask it if the answer it provided previously is still good, or needs changing.<break/><break/>Similar to what I've experienced previously, I find that these models get worse and worse if they fail the first time. With each trial that goes wrong, they need more and more handholding to get on the right track. For this homework, 4o was able to zero-shot almost everything. In fact, the question it got wrong the first try was one of the simpler ones. Overall, it was really cool to see how these models can understand such a wider range of information in various formats and piece them together to come up with meaningful solutions.</paragraph><file url=\"https://static.us.edusercontent.com/files/uDoGimuxqDxeO7wQyngZAnAP\" filename=\"MR-HW3-A.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T17:44:16.676244+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7419018,
            "author": "Trenton O'Bannon",
            "project_title": "Special Participation A: GPT 5.1 Thinking on Homework 12",
            "post_body": "Conversation Link - https://chatgpt.com/share/6933c8cc-4f6c-8012-9651-4b391b6f512b\n\n\n\nI used ChatGPT (GPT-5.1 Thinking) to work through the non-coding parts of a CS182 homework (the questions I focused on were mostly about autoencoders/VAEs and ridge/self-attention). I interacted with it like a tutor: rather than just asking \u201cwhat\u2019s the answer to 3(b)?\u201d, I had it re-teach concepts (encoder vs autoencoder vs VAE, Gaussians, randomness in the latent space, etc.), and then apply those ideas to the actual sub-questions.\n\nExecutive summary\n\nOverall performance. Roughly speaking, the model could one-shot a majority of the subparts (I\u2019d estimate ~60\u201370%) when the question was conceptual, algebraic, or about interpreting a loss function. When it struggled, it was usually on:\n\nsubtle complexity analysis (missing or adding extra factors),\n\nunclear encoder/decoder notation in a complicated objective,\n\nor anything that required actually seeing a graph/figure.\n\nStrengths.\n\nVery good at re-explaining core concepts from the ground up (e.g., what a Gaussian is, what an encoder is, what a VAE is, and how noise injection works).\n\nPretty good at mapping math to intuition (e.g., explaining where randomness enters a VAE and what it does, or what different terms in an ELBO correspond to).\n\nWhen I pushed it to slow down and justify each step, it usually corrected itself and converged to the right answer.\n\nWeaknesses / failure modes.\n\nIt tends to be overconfident on complexity questions and sometimes adds an extra factor of n or d in the big-O expression.\n\nIt occasionally blurred the roles of p and q in the VAE loss until I explicitly forced it to pin down \u201cwhich one is the encoder, which one is the decoder.\u201d\n\nIt can\u2019t read tiny graphs/plots from the PDF, so for at least one \u201cpick the most U-shaped curve\u201d style question, it had to rely entirely on my textual description rather than the actual image.\n\nHallucinations. I didn\u2019t catch any wild hallucinations like made-up theorems or algorithms, but I did see:\n\nConfident but slightly wrong complexity bounds (e.g., overcounting a matrix dimension).\n\nSlightly different forms of the loss than what we use in class (equivalent up to constants or sign conventions, but not exactly what appears in the homework).\n\nOverall, my takeaway is that GPT-5.1 is very capable as a conceptual tutor, and \u201cpretty good but not fully trustworthy\u201d as an answer-oracle. You need enough understanding to check its work and push back.\n\nQuestion-by-question behavior (high level)\n\n(You can adjust this to match your exact HW number / question labels.)\n\nQuestion 3 \u2013 Autoencoders, VAEs, and ELBO terms\n\nWhat I tested it on:\n\nDefinitions of encoder, autoencoder, and variational autoencoder.\n\nIntuition behind Gaussians and the reparameterization trick.\n\nInterpreting the VAE loss (reconstruction + KL) and mapping pieces to encoder/decoder.\n\nA multiple-choice subpart involving a \u201cmost U-shaped\u201d curve where I had to interpret the plot.\n\nWhere it did well (one-shot or close):\n\nGave a clear, layered explanation of:\n\nwhat an encoder does,\n\nwhat an autoencoder does,\n\nhow a VAE differs, and\n\nwhy we add noise (sampling in latent space, regularization, smoothness).\n\nRe-taught Gaussians in simple terms and connected that to the Gaussian latent prior in the VAE.\n\nWhen I asked \u201cwhere is this randomness/noise coming from and what does it do?\u201d, it correctly pointed to the sampling from z\u223cq\u03d5\u200b(z\u2223x) and explained that the reparameterization trick makes this differentiable.\n\nFor the VAE objective, once prompted, it correctly identified that:\n\nq\u03d5\u200b(z\u2223x) corresponds to the encoder, and\n\np\u03b8\u200b(x\u2223z) corresponds to the decoder.\n\nWhere it struggled / needed dragging:\n\nGiven just the \u201ccomplicated ass loss function,\u201d it initially didn\u2019t explicitly label which term belonged to encoder vs decoder\u2014so I had to ask directly: \u201cis it safe on a midterm to assume q is the decoder and p is the encoder, or what should I look for?\u201d That pushed it to clarify that q is the encoder (approx posterior) and p is the decoder (likelihood).\n\nFor the graph-based subpart (\u201cmost U-shaped is option B\u201d), the model couldn\u2019t see the graph properly. I ended up using its conceptual explanation of what the curve should look like, combined with my own visual inspection, to pick the correct option. So it helped, but it wasn\u2019t independently solving that one.\n\nQuestion 4 \u2013 Ridge regression / self-attention-style math (non-coding parts only)\n\nWhat I used it for:\n\nConceptual pieces around online/recursive updates, ridge-style penalties, and how these tie into efficient self-attention.\n\nUnderstanding how different terms in the loss or update equations affect computational cost and memory.\n\nStrengths:\n\nGave good explanations of why we care about efficient updates and connected them to the idea of reusing previous computations instead of recomputing from scratch.\n\nWhen I asked it to \u201cexplain from the ground up\u201d it was good at turning each step into something intuitive (e.g., \u201cthis part is like keeping a running summary; this part is like correcting your estimate with the new data point\u201d).\n\nWeaknesses:\n\nOn some of the big-O complexity questions, it tended to overshoot, e.g., something that could be done in O(nd2) it might initially describe as O(nd3) until I forced it to count operations more carefully.\n\nThis is a recurring theme: it knows the right algorithmic idea, but it\u2019s sloppy about exact asymptotics unless you police it.\n\nQuestions 5 and 7 \u2013 Additional conceptual / non-coding parts\n\nHere I mainly used it as a concept explainer and sanity-check, not just a direct answer machine.\n\nIt gave reasonable answers on first pass, but the real value was in:\n\nrephrasing the question,\n\nhighlighting which quantities matter (e.g., what\u2019s being regularized, what\u2019s being predicted),\n\nand giving analogies that made the math feel less abstract.\n\nAt the end, I also asked it to evaluate my level of preparedness for the final based on my questions. That response was more \u201cvibe-check\u201d than science, but it was helpful for me to see what it thought my weak spots were (mostly: being shaky at mapping formulas to pictures and at carefully tracking complexity).\n\nStrategies I used to steer the model\n\nIn the annotated log I\u2019m attaching, I call out some of the strategies I used:\n\nForce \u201cfrom-first-principles\u201d explanations.\n Instead of just \u201cwhat\u2019s the answer to 3(b)?\u201d, I first asked it to re-teach encoders/autoencoders/VAEs and Gaussians \u201cfrom the ground up\u201d. This made it expose assumptions and definitions I could later check.\n\nAsk targeted follow-ups when something feels hand-wavy.\n Example: \u201cWhere is this randomness/noise coming in from? What does it do?\u201d and \u201cHow do we tell from that complicated loss which is the encoder vs decoder?\u201d These forced it to pin down the role of each term instead of staying vague.\n\nUse it to reason about shapes/curves, then apply my own visual check.\n For the \u201cmost U-shaped\u201d graph, it couldn\u2019t see the figure, so I had it describe what shape we should expect, then I matched that to the multiple-choice options.\n\nPush back on complexity claims.\n When it gave a complexity I didn\u2019t trust, I asked it to explicitly count matrix-vector vs matrix-matrix ops and justify the O(\u22c5). This usually surfaced the mistake and got it to correct itself.\n\nTakeaway\n\nFor this homework, GPT-5.1 Thinking was not a magic \u201cgive me the solution key\u201d button, but it was a strong tutor for the non-coding parts:\n\nIt can one-shot many conceptual subparts,\n\nIt sometimes fumbles details, especially asymptotic complexity,\n\nAnd it absolutely requires an engaged human who\u2019s willing to question it, check it against the official solutions, and drag it when it\u2019s confident but wrong.\n\nThat\u2019s the perspective I captured in the attached annotated conversation trace.",
            "content_xml": "<document version=\"2.0\"><paragraph>Conversation Link - https://chatgpt.com/share/6933c8cc-4f6c-8012-9651-4b391b6f512b</paragraph><paragraph/><paragraph>I used ChatGPT (GPT-5.1 Thinking) to work through the non-coding parts of a CS182 homework (the questions I focused on were mostly about autoencoders/VAEs and ridge/self-attention). I interacted with it like a tutor: rather than just asking \u201cwhat\u2019s the answer to 3(b)?\u201d, I had it re-teach concepts (encoder vs autoencoder vs VAE, Gaussians, randomness in the latent space, etc.), and then apply those ideas to the actual sub-questions.</paragraph><heading level=\"3\">Executive summary</heading><list style=\"unordered\"><list-item><paragraph>Overall performance. Roughly speaking, the model could one-shot a majority of the subparts (I\u2019d estimate ~60\u201370%) when the question was conceptual, algebraic, or about interpreting a loss function. When it struggled, it was usually on:</paragraph><list style=\"unordered\"><list-item><paragraph>subtle complexity analysis (missing or adding extra factors),</paragraph></list-item><list-item><paragraph>unclear encoder/decoder notation in a complicated objective,</paragraph></list-item><list-item><paragraph>or anything that required actually seeing a graph/figure.</paragraph></list-item></list></list-item><list-item><paragraph>Strengths.</paragraph><list style=\"unordered\"><list-item><paragraph>Very good at re-explaining core concepts from the ground up (e.g., what a Gaussian is, what an encoder is, what a VAE is, and how noise injection works).</paragraph></list-item><list-item><paragraph>Pretty good at mapping math to intuition (e.g., explaining where randomness enters a VAE and what it does, or what different terms in an ELBO correspond to).</paragraph></list-item><list-item><paragraph>When I pushed it to slow down and justify each step, it usually corrected itself and converged to the right answer.</paragraph></list-item></list></list-item><list-item><paragraph>Weaknesses / failure modes.</paragraph><list style=\"unordered\"><list-item><paragraph>It tends to be overconfident on complexity questions and sometimes adds an extra factor of n or d in the big-O expression.</paragraph></list-item><list-item><paragraph>It occasionally blurred the roles of p and q in the VAE loss until I explicitly forced it to pin down \u201cwhich one is the encoder, which one is the decoder.\u201d</paragraph></list-item><list-item><paragraph>It can\u2019t read tiny graphs/plots from the PDF, so for at least one \u201cpick the most U-shaped curve\u201d style question, it had to rely entirely on my textual description rather than the actual image.</paragraph></list-item></list></list-item><list-item><paragraph>Hallucinations. I didn\u2019t catch any wild hallucinations like made-up theorems or algorithms, but I did see:</paragraph><list style=\"unordered\"><list-item><paragraph>Confident but slightly wrong complexity bounds (e.g., overcounting a matrix dimension).</paragraph></list-item><list-item><paragraph>Slightly different forms of the loss than what we use in class (equivalent up to constants or sign conventions, but not exactly what appears in the homework).</paragraph></list-item></list></list-item></list><paragraph>Overall, my takeaway is that GPT-5.1 is very capable as a conceptual tutor, and \u201cpretty good but not fully trustworthy\u201d as an answer-oracle. You need enough understanding to check its work and push back.</paragraph><heading level=\"3\">Question-by-question behavior (high level)</heading><paragraph>(You can adjust this to match your exact HW number / question labels.)</paragraph><paragraph>Question 3 \u2013 Autoencoders, VAEs, and ELBO terms</paragraph><list style=\"unordered\"><list-item><paragraph>What I tested it on:</paragraph><list style=\"unordered\"><list-item><paragraph>Definitions of encoder, autoencoder, and variational autoencoder.</paragraph></list-item><list-item><paragraph>Intuition behind Gaussians and the reparameterization trick.</paragraph></list-item><list-item><paragraph>Interpreting the VAE loss (reconstruction + KL) and mapping pieces to encoder/decoder.</paragraph></list-item><list-item><paragraph>A multiple-choice subpart involving a \u201cmost U-shaped\u201d curve where I had to interpret the plot.</paragraph></list-item></list></list-item><list-item><paragraph>Where it did well (one-shot or close):</paragraph><list style=\"unordered\"><list-item><paragraph>Gave a clear, layered explanation of:</paragraph><list style=\"unordered\"><list-item><paragraph>what an encoder does,</paragraph></list-item><list-item><paragraph>what an autoencoder does,</paragraph></list-item><list-item><paragraph>how a VAE differs, and</paragraph></list-item><list-item><paragraph>why we add noise (sampling in latent space, regularization, smoothness).</paragraph></list-item></list></list-item><list-item><paragraph>Re-taught Gaussians in simple terms and connected that to the Gaussian latent prior in the VAE.</paragraph></list-item><list-item><paragraph>When I asked \u201cwhere is this randomness/noise coming from and what does it do?\u201d, it correctly pointed to the sampling from z\u223cq\u03d5\u200b(z\u2223x) and explained that the reparameterization trick makes this differentiable.</paragraph></list-item><list-item><paragraph>For the VAE objective, once prompted, it correctly identified that:</paragraph><list style=\"unordered\"><list-item><paragraph>q\u03d5\u200b(z\u2223x) corresponds to the encoder, and</paragraph></list-item><list-item><paragraph>p\u03b8\u200b(x\u2223z) corresponds to the decoder.</paragraph></list-item></list></list-item></list></list-item><list-item><paragraph>Where it struggled / needed dragging:</paragraph><list style=\"unordered\"><list-item><paragraph>Given just the \u201ccomplicated ass loss function,\u201d it initially didn\u2019t explicitly label which term belonged to encoder vs decoder\u2014so I had to ask directly: \u201cis it safe on a midterm to assume q is the decoder and p is the encoder, or what should I look for?\u201d That pushed it to clarify that q is the encoder (approx posterior) and p is the decoder (likelihood).</paragraph></list-item><list-item><paragraph>For the graph-based subpart (\u201cmost U-shaped is option B\u201d), the model couldn\u2019t see the graph properly. I ended up using its conceptual explanation of what the curve should look like, combined with my own visual inspection, to pick the correct option. So it helped, but it wasn\u2019t independently solving that one.</paragraph></list-item></list></list-item></list><paragraph>Question 4 \u2013 Ridge regression / self-attention-style math (non-coding parts only)</paragraph><list style=\"unordered\"><list-item><paragraph>What I used it for:</paragraph><list style=\"unordered\"><list-item><paragraph>Conceptual pieces around online/recursive updates, ridge-style penalties, and how these tie into efficient self-attention.</paragraph></list-item><list-item><paragraph>Understanding how different terms in the loss or update equations affect computational cost and memory.</paragraph></list-item></list></list-item><list-item><paragraph>Strengths:</paragraph><list style=\"unordered\"><list-item><paragraph>Gave good explanations of why we care about efficient updates and connected them to the idea of reusing previous computations instead of recomputing from scratch.</paragraph></list-item><list-item><paragraph>When I asked it to \u201cexplain from the ground up\u201d it was good at turning each step into something intuitive (e.g., \u201cthis part is like keeping a running summary; this part is like correcting your estimate with the new data point\u201d).</paragraph></list-item></list></list-item><list-item><paragraph>Weaknesses:</paragraph><list style=\"unordered\"><list-item><paragraph>On some of the big-O complexity questions, it tended to overshoot, e.g., something that could be done in O(nd2) it might initially describe as O(nd3) until I forced it to count operations more carefully.</paragraph></list-item><list-item><paragraph>This is a recurring theme: it knows the right algorithmic idea, but it\u2019s sloppy about exact asymptotics unless you police it.</paragraph></list-item></list></list-item></list><paragraph>Questions 5 and 7 \u2013 Additional conceptual / non-coding parts</paragraph><list style=\"unordered\"><list-item><paragraph>Here I mainly used it as a concept explainer and sanity-check, not just a direct answer machine.</paragraph></list-item><list-item><paragraph>It gave reasonable answers on first pass, but the real value was in:</paragraph><list style=\"unordered\"><list-item><paragraph>rephrasing the question,</paragraph></list-item><list-item><paragraph>highlighting which quantities matter (e.g., what\u2019s being regularized, what\u2019s being predicted),</paragraph></list-item><list-item><paragraph>and giving analogies that made the math feel less abstract.</paragraph></list-item></list></list-item><list-item><paragraph>At the end, I also asked it to evaluate my level of preparedness for the final based on my questions. That response was more \u201cvibe-check\u201d than science, but it was helpful for me to see what it thought my weak spots were (mostly: being shaky at mapping formulas to pictures and at carefully tracking complexity).</paragraph></list-item></list><heading level=\"3\">Strategies I used to steer the model</heading><paragraph>In the annotated log I\u2019m attaching, I call out some of the strategies I used:</paragraph><list style=\"unordered\"><list-item><paragraph>Force \u201cfrom-first-principles\u201d explanations.<break/> Instead of just \u201cwhat\u2019s the answer to 3(b)?\u201d, I first asked it to re-teach encoders/autoencoders/VAEs and Gaussians \u201cfrom the ground up\u201d. This made it expose assumptions and definitions I could later check.</paragraph></list-item><list-item><paragraph>Ask targeted follow-ups when something feels hand-wavy.<break/> Example: \u201cWhere is this randomness/noise coming in from? What does it do?\u201d and \u201cHow do we tell from that complicated loss which is the encoder vs decoder?\u201d These forced it to pin down the role of each term instead of staying vague.</paragraph></list-item><list-item><paragraph>Use it to reason about shapes/curves, then apply my own visual check.<break/> For the \u201cmost U-shaped\u201d graph, it couldn\u2019t see the figure, so I had it describe what shape we should expect, then I matched that to the multiple-choice options.</paragraph></list-item><list-item><paragraph>Push back on complexity claims.<break/> When it gave a complexity I didn\u2019t trust, I asked it to explicitly count matrix-vector vs matrix-matrix ops and justify the O(\u22c5). This usually surfaced the mistake and got it to correct itself.</paragraph></list-item></list><heading level=\"3\">Takeaway</heading><paragraph>For this homework, GPT-5.1 Thinking was not a magic \u201cgive me the solution key\u201d button, but it was a strong tutor for the non-coding parts:</paragraph><list style=\"unordered\"><list-item><paragraph>It can one-shot many conceptual subparts,</paragraph></list-item><list-item><paragraph>It sometimes fumbles details, especially asymptotic complexity,</paragraph></list-item><list-item><paragraph>And it absolutely requires an engaged human who\u2019s willing to question it, check it against the official solutions, and drag it when it\u2019s confident but wrong.</paragraph></list-item></list><paragraph>That\u2019s the perspective I captured in the attached annotated conversation trace.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T17:23:14.248703+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7418727,
            "author": "Jin Ying",
            "project_title": "Special Participation A: ChatGPT 5.1 thinking on HW13",
            "post_body": "Looking at GPT's attempt at these two problems, I'd say it got maybe 4 out of 10 parts completely right on the first try. The pattern I noticed is pretty consistent: GPT nails the warm-up questions where you're just manipulating probability distributions or doing basic calculus, but when the problems require you to track multiple variables through several steps of algebra, it starts cutting corners. And further questions on this would easily lead to hallucination and circular reasoning.\n\nThe most frustrating thing is that GPT doesn't really admit when it's unsure. Instead of saying \"I'm not certain about this step,\" it just writes \"following similar reasoning...\" or \"it can be shown that...\" and jumps to an answer. Sometimes that answer is right, sometimes it's totally wrong. For the DPO problem especially, there were some actual mathematical errors -- not just stylistic issues, but wrong coefficients and circular logic.\n\nOne thing I found interesting is how the quality degrades as you go through each question. Parts (a) and (b) are usually solid, but by part (f) or (g), GPT is clearly losing the thread. It's like it forgets what assumptions we made earlier or what variables we're solving for.",
            "content_xml": "<document version=\"2.0\"><paragraph>Looking at GPT's attempt at these two problems, I'd say it got maybe 4 out of 10 parts completely right on the first try. The pattern I noticed is pretty consistent: GPT nails the warm-up questions where you're just manipulating probability distributions or doing basic calculus, but when the problems require you to track multiple variables through several steps of algebra, it starts cutting corners. And further questions on this would easily lead to hallucination and circular reasoning.</paragraph><paragraph>The most frustrating thing is that GPT doesn't really admit when it's unsure. Instead of saying \"I'm not certain about this step,\" it just writes \"following similar reasoning...\" or \"it can be shown that...\" and jumps to an answer. Sometimes that answer is right, sometimes it's totally wrong. For the DPO problem especially, there were some actual mathematical errors -- not just stylistic issues, but wrong coefficients and circular logic.</paragraph><paragraph>One thing I found interesting is how the quality degrades as you go through each question. Parts (a) and (b) are usually solid, but by part (f) or (g), GPT is clearly losing the thread. It's like it forgets what assumptions we made earlier or what variables we're solving for.</paragraph><file url=\"https://static.us.edusercontent.com/files/BTLaQX01L5VmQ8GiEEyQ1xvb\" filename=\"Special Participation A_ GPT5.1 Thinking on HW13.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T16:07:33.033502+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7418566,
            "author": "Akhil Agarwal",
            "project_title": "Special Participation B: Gemini Pro on HW 4's Coding Section",
            "post_body": "I used Gemini Pro to solve the coding portions of HW 4. It did extremely well overall, though this coding portion was relatively straightforward in general. I did each question in a different chat and annotated them separately, so they are both linked here.\n\nQ5: This one was extremely simple with just defining 2 kernels, so it was not very interesting but Gemini got both right.\n\nTrace: https://gemini.google.com/share/13061b493f48\n\nAnnotated Trace:\n\nNotebook with answers from Gemini filled in:\n\nQ6: This question was harder. It solved parts 1 and 2 in one shot, since they were relatively standard pieces of code, but it showed it was able to understand the dataset definition created earlier in the notebook, and apply that to create the dataset. It very closely mirrored the solutions. Then the rest of the questions were hyperparameter tuning, where I would give the training and validation curves for the default hyperparameters, ask it to give the new code, and then I would run it and repeat until it reached the threshold. It went rather smoothly, and it was able to identify patterns in the training curve, such as overfitting and not having converged yet. Even more impressive in my opinion was its understanding of kernel size. It realized that its 3x3 kernels were too small due to the edges being thicker than the filters, so it corrected itself and changed to 5x5 before staying there and modifying other hyperparameters to finish meeting the threshold. It also one-shotted the WiderCNN parameters.\n\nTrace: https://gemini.google.com/share/75902048119a\n\nAnnotated Trace:\n\nNotebook with answers from Gemini filled in:\n\nOverall, Gemini Pro did extremely well on this coding assignment, being self-sufficient and just needing a few attempts to hyperparameter tune.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini Pro to solve the coding portions of HW 4. It did extremely well overall, though this coding portion was relatively straightforward in general. I did each question in a different chat and annotated them separately, so they are both linked here.</paragraph><paragraph>Q5: This one was extremely simple with just defining 2 kernels, so it was not very interesting but Gemini got both right.</paragraph><paragraph>Trace: <link href=\"https://gemini.google.com/share/13061b493f48\">https://gemini.google.com/share/13061b493f48</link></paragraph><paragraph>Annotated Trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/2chRd8EyBUa3ct01Bpl06UmX\" filename=\"Special_Participation_B_Part_1.pdf\"/><paragraph>Notebook with answers from Gemini filled in:</paragraph><file url=\"https://static.us.edusercontent.com/files/fHqTamXCa3gnGH7cZ5IOcsRC\" filename=\"HandDesignFilters.ipynb\"/><paragraph>Q6: This question was harder. It solved parts 1 and 2 in one shot, since they were relatively standard pieces of code, but it showed it was able to understand the dataset definition created earlier in the notebook, and apply that to create the dataset. It very closely mirrored the solutions. Then the rest of the questions were hyperparameter tuning, where I would give the training and validation curves for the default hyperparameters, ask it to give the new code, and then I would run it and repeat until it reached the threshold. It went rather smoothly, and it was able to identify patterns in the training curve, such as overfitting and not having converged yet. Even more impressive in my opinion was its understanding of kernel size. It realized that its 3x3 kernels were too small due to the edges being thicker than the filters, so it corrected itself and changed to 5x5 before staying there and modifying other hyperparameters to finish meeting the threshold. It also one-shotted the WiderCNN parameters.</paragraph><paragraph>Trace: <link href=\"https://gemini.google.com/share/75902048119a\">https://gemini.google.com/share/75902048119a</link></paragraph><paragraph>Annotated Trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/72QfsUNcGEEw89TyV8o6nP6e\" filename=\"Special_Participation_B_Part_2.pdf\"/><paragraph>Notebook with answers from Gemini filled in:</paragraph><file url=\"https://static.us.edusercontent.com/files/1vTnjVSmGuqoRDfrPhKZul1I\" filename=\"edge_detection.ipynb\"/><paragraph>Overall, Gemini Pro did extremely well on this coding assignment, being self-sufficient and just needing a few attempts to hyperparameter tune.</paragraph></document>",
            "links": [
                "https://gemini.google.com/share/13061b493f48",
                "https://gemini.google.com/share/75902048119a"
            ],
            "attachments": [],
            "created_at": "2025-12-06T15:41:03.912188+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7418400,
            "author": "Nicolas Rault-Wang",
            "project_title": "Special Participation E: Engineering System Prompts and Learning from Figures with Gemini (Thinking With 3 Pro)",
            "post_body": "For my Option E submission, I tackled a common annoyance: LLMs hallucinating arrows and labels in architecture diagrams.\n\nI used a meta-prompt engineering strategy to develop a \"Visual Forensic\" system prompt that encourages Gemini to verify visual information in figures before explaining it.\n\nHow it works:\n\nAnti-Hallucination: It instructs the model to write and execute Python OCR code (e.g., Python-tesseract) to extract text labels from the image before it tries to explain the concepts. \n\n\"Visual Manifest\": The model summarizes its visual understanding in a text-based outline. This not only translates the diagram into a verbal description\u2013which helps ground the model in reality\u2013but also makes it easy to spot discrepancies between the figure and the model's native vision.\n\nSocratic Mode: It uses verified visual data to quiz me on specific mechanics (e.g., \"Why does the arrow split here?\").\n\nFlashcards: It synthesizes our discussion into short Anki-style flashcards.\n\nAttached is the report on my debugging process and the system prompt I developed:\n\nEdit: Added links for the archive\n\nPersonal website: https://nraultwang.github.io/\n\nGithub: https://github.com/nraultwang",
            "content_xml": "<document version=\"2.0\"><paragraph>For my Option E submission, I tackled a common annoyance: LLMs hallucinating arrows and labels in architecture diagrams.</paragraph><paragraph>I used a meta-prompt engineering strategy to develop a \"Visual Forensic\" system prompt that encourages Gemini to verify visual information in figures before explaining it.</paragraph><paragraph><bold>How it works:</bold></paragraph><list style=\"ordered\"><list-item><paragraph><bold>Anti-Hallucination:</bold> It instructs the model to write and execute Python OCR code (e.g., <code>Python-tesseract</code>) to extract text labels from the image <italic>before</italic> it tries to explain the concepts. </paragraph></list-item><list-item><paragraph><bold>\"Visual Manifest\":</bold> The model summarizes its visual understanding in a text-based outline. This not only translates the diagram into a verbal description\u2013which helps ground the model in reality\u2013but also makes it easy to spot discrepancies between the figure and the model's native vision.</paragraph></list-item><list-item><paragraph><bold>Socratic Mode:</bold> It uses verified visual data to quiz me on specific mechanics (e.g., \"Why does the arrow split here?\").</paragraph></list-item><list-item><paragraph><bold>Flashcards:</bold> It synthesizes our discussion into short Anki-style flashcards.</paragraph></list-item></list><paragraph>Attached is the report on my debugging process and the system prompt I developed:</paragraph><file url=\"https://static.us.edusercontent.com/files/f6jDIM1tl0QfggIonglx2Ve4\" filename=\"Rault-Wang_Nicolas-Special-Participation-E_v2.pdf\"/><paragraph>Edit: Added links for the archive</paragraph><paragraph>Personal website: <link href=\"https://nraultwang.github.io/\">https://nraultwang.github.io/</link></paragraph><paragraph>Github: <link href=\"https://github.com/nraultwang\">https://github.com/nraultwang</link></paragraph></document>",
            "links": [
                "https://nraultwang.github.io/",
                "https://github.com/nraultwang"
            ],
            "attachments": [],
            "created_at": "2025-12-06T15:00:50.2558+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7418341,
            "author": "Angelina Zhang",
            "project_title": "Special Participation E: AI-powered Lecture-Grounded Learning Assistant",
            "post_body": "Motivations\n\nFor this participation, I wanted a tool that lets us search lecture content directly, rather than relying on Google or LLM answers that may drift outside the course scope. YouTube transcripts exist, but scrolling through them is slow and the text often contains errors. I wanted something that behaves like a lightweight retrieval engine for the class: whenever I ask a question, it would point me to the exact timestamp where the professor discussed that topic and provide me something that are discussed in class. \n\nHow It Works\n\nThe system works by turning timestamped transcripts into searchable embedding chunks. The script build_index.py parses each transcript, recognizes timestamp lines, and converts the text between timestamps into a segment. Each segment is embedded using the OpenAI text-embedding-3-small model, and all segments with lecture ID, timestamp, and embedding, are stored in a JSON index. The second script, search_segments.py, embeds your question the same way and computes cosine similarity against every segment embedding. It then returns the most relevant timestamps, along with short snippets so you can quickly revisit the exact moment in the lecture where the concept appears. All transcripts can be pasted directly from YouTube\u2019s \u201cShow Transcript\u201d feature, although I do not include real transcript data in the repository due to privacy. I also added a chat-generation stage on top of retrieval: once segments are retrieved, the tool feeds them into a structured \u201cLecture-Grounded Learning Assistant\u201d prompt. The prompt asks the LLM to generate:\n\na summary of the professor\u2019s explanation based only on retrieved text,\n\nan analogy,\n\na worked-out example,\n\na quiz, and\n\ncommon misconceptions.\n\nBecause the retrieved segments are shown alongside the generated answer, students can directly check whether the model\u2019s claims are supported. This design makes hallucination auditable, rather than hidden.\n\nInstructions for Use\n\nTo run the system, you place your transcript .txt files in data/transcripts/, run python build_index.py once to generate embeddings, and then run python search_segments.py to start an interactive question prompt. You can ask any conceptual question (\u201cWhere did we derive the SGD update rule?\u201d), and the tool returns the closest matches with similarity scores. This essentially converts the entire set of lecture videos into a searchable study resource that you can navigate much more efficiently than by scanning full recordings. You can find these code here: https://github.com/Angelinaaaaaaaaaaaa/lecture_finder\n\nAI Interaction Trace\n\nDuring development, I used LLMs as a brainstorming partner for parsing logic and embedding retrieval. Many suggestions were helpful but required verification. For example, the model initially suggested a timestamp regex that incorrectly matched numbers appearing inside sentences, causing segmentation errors; refining this required repeated testing. When I asked about similarity search, it recommended a full vector database, which turned out unnecessary and even slower for my dataset size. I ultimately implemented cosine similarity in pure Python after finding dimension mismatches that the model failed to warn me about. These debugging steps gave me a practical understanding of segmentation design and retrieval pipelines.\n\nAfter building the system, I used it to generate lecture-grounded answers on top of retrieval and then produced a fully annotated interaction trace examining when the model stayed faithful and when it drifted. That detailed analysis is here:\nhttps://docs.google.com/document/d/1E9v3ftDCaUzSqYOheHOa6nt6H15Fh3dkzKJ-28ntDM8/edit?usp=sharing\n\nTo give a concrete example from the trace: when asking \u201cWhy do we need Adam instead of SGD with momentum?\u201d, the model retrieved only high-level lecture snippets but then added details (e.g., per-parameter learning rate adaptation) that were true but did not appear in the retrieved parts. This is a typical \u201cgap-filling\u201d behavior: retrieval reduces hallucination, but when evidence is shallow, the model backfills using prior knowledge.\n\nSummary of Findings (LLM Behavior Under Retrieval)\nMy central takeaway of this project is:\n\nRetrieval does not eliminate hallucination; it changes the failure mode and makes hallucinations auditable.\n\nSome patterns I observed:\n\nWithout retrieval, the model freely produces generic textbook derivations, sometimes attributing them incorrectly to the professor.\n\nWith retrieval, the model becomes noticeably more grounded. For example, when I asked about the SGD derivation, it explicitly admitted that the derivation was not present in the retrieved segments. This is a major improvement over the unconstrained setting.\n\nHowever, when retrieved segments are shallow (e.g., for Adam vs. momentum), the model begins \u201cfilling in missing gaps\u201d using prior knowledge. This produces highly plausible but not necessarily lecture-accurate explanations.\n\nRetrieval helps identify where the model is speculating, because you can scroll up and check whether each claim has transcript evidence.\n\nAs a result, students can audit the model rather than trusting it blindly; retrieval gives us the ground truth reference.\n\n\nThe system already implements the retrieval part of a RAG pipeline, and the structured teaching prompt acts as a lightweight generation stage. Future improvements could include adding lecture-slide images, integrating structured notes from classmates, or building a web UI where students can search visually instead of using the terminal. I\u2019m aware this is only a small prototype, and a full RAG system integrated into a teaching agent like TAI would be much more powerful. But I think this is a useful first step toward that direction. Let me know if you want to extend it!\n\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"3\"><bold>Motivations</bold></heading><paragraph>For this participation, I wanted a tool that lets us search lecture content directly, rather than relying on Google or LLM answers that may drift outside the course scope. YouTube transcripts exist, but scrolling through them is slow and the text often contains errors. I wanted something that behaves like a lightweight retrieval engine for the class: whenever I ask a question, it would point me to the exact timestamp where the professor discussed that topic and provide me something that are discussed in class. </paragraph><heading level=\"3\"><bold>How It Works</bold></heading><paragraph>The system works by turning timestamped transcripts into searchable embedding chunks. The script <code>build_index.py</code> parses each transcript, recognizes timestamp lines, and converts the text between timestamps into a segment. Each segment is embedded using the OpenAI <bold>text-embedding-3-small</bold> model, and all segments with lecture ID, timestamp, and embedding, are stored in a JSON index. The second script, <code>search_segments.py</code>, embeds your question the same way and computes cosine similarity against every segment embedding. It then returns the most relevant timestamps, along with short snippets so you can quickly revisit the exact moment in the lecture where the concept appears. All transcripts can be pasted directly from YouTube\u2019s \u201cShow Transcript\u201d feature, although I do not include real transcript data in the repository due to privacy. I also added a <bold>chat-generation stage</bold> on top of retrieval: once segments are retrieved, the tool feeds them into a structured \u201cLecture-Grounded Learning Assistant\u201d prompt. The prompt asks the LLM to generate:</paragraph><list style=\"ordered\"><list-item><paragraph>a summary of the professor\u2019s explanation <italic>based only on retrieved text</italic>,</paragraph></list-item><list-item><paragraph>an analogy,</paragraph></list-item><list-item><paragraph>a worked-out example,</paragraph></list-item><list-item><paragraph>a quiz, and</paragraph></list-item><list-item><paragraph>common misconceptions.</paragraph></list-item></list><paragraph>Because the retrieved segments are shown alongside the generated answer, students can directly check whether the model\u2019s claims are supported. This design makes hallucination auditable, rather than hidden.</paragraph><heading level=\"3\"><bold>Instructions for Use</bold></heading><paragraph>To run the system, you place your transcript <code>.txt</code> files in <code>data/transcripts/</code>, run <code>python build_index.py</code> once to generate embeddings, and then run <code>python search_segments.py</code> to start an interactive question prompt. You can ask any conceptual question (\u201cWhere did we derive the SGD update rule?\u201d), and the tool returns the closest matches with similarity scores. This essentially converts the entire set of lecture videos into a searchable study resource that you can navigate much more efficiently than by scanning full recordings. You can find these code here: <link href=\"https://github.com/Angelinaaaaaaaaaaaa/lecture_finder\">https://github.com/Angelinaaaaaaaaaaaa/lecture_finder</link></paragraph><heading level=\"3\"><bold>AI Interaction Trace</bold></heading><paragraph>During development, I used LLMs as a brainstorming partner for parsing logic and embedding retrieval. Many suggestions were helpful but required verification. For example, the model initially suggested a timestamp regex that incorrectly matched numbers appearing inside sentences, causing segmentation errors; refining this required repeated testing. When I asked about similarity search, it recommended a full vector database, which turned out unnecessary and even slower for my dataset size. I ultimately implemented cosine similarity in pure Python after finding dimension mismatches that the model failed to warn me about. These debugging steps gave me a practical understanding of segmentation design and retrieval pipelines.</paragraph><paragraph>After building the system, I used it to generate lecture-grounded answers on top of retrieval and then produced a fully annotated interaction trace examining when the model stayed faithful and when it drifted. That detailed analysis is here:<break/><link href=\"https://docs.google.com/document/d/1E9v3ftDCaUzSqYOheHOa6nt6H15Fh3dkzKJ-28ntDM8/edit?usp=sharing\">https://docs.google.com/document/d/1E9v3ftDCaUzSqYOheHOa6nt6H15Fh3dkzKJ-28ntDM8/edit?usp=sharing</link></paragraph><paragraph>To give a concrete example from the trace: when asking <italic>\u201cWhy do we need Adam instead of SGD with momentum?\u201d</italic>, the model retrieved only high-level lecture snippets but then added details (e.g., per-parameter learning rate adaptation) that were true but did <bold>not</bold> appear in the retrieved parts. This is a typical \u201cgap-filling\u201d behavior: retrieval reduces hallucination, but when evidence is shallow, the model backfills using prior knowledge.<break/><break/><bold>Summary of Findings (LLM Behavior Under Retrieval)</bold><break/>My central takeaway of this project is:</paragraph><heading level=\"3\">Retrieval does not eliminate hallucination; it changes the failure mode and makes hallucinations auditable.</heading><paragraph>Some patterns I observed:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Without retrieval</bold>, the model freely produces generic textbook derivations, sometimes attributing them incorrectly to the professor.</paragraph></list-item><list-item><paragraph><bold>With retrieval</bold>, the model becomes noticeably more grounded. For example, when I asked about the SGD derivation, it explicitly admitted that the derivation was not present in the retrieved segments. This is a major improvement over the unconstrained setting.</paragraph></list-item><list-item><paragraph>However, when retrieved segments are shallow (e.g., for Adam vs. momentum), the model begins \u201cfilling in missing gaps\u201d using prior knowledge. This produces highly plausible but not necessarily lecture-accurate explanations.</paragraph></list-item><list-item><paragraph>Retrieval helps identify where the model is speculating, because you can scroll up and check whether each claim has transcript evidence.</paragraph></list-item><list-item><paragraph>As a result, students can audit the model rather than trusting it blindly; retrieval gives us the ground truth reference.<break/></paragraph></list-item></list><paragraph>The system already implements the retrieval part of a RAG pipeline, and the structured teaching prompt acts as a lightweight generation stage. Future improvements could include adding lecture-slide images, integrating structured notes from classmates, or building a web UI where students can search visually instead of using the terminal. I\u2019m aware this is only a small prototype, and a full RAG system integrated into a teaching agent like TAI would be much more powerful. But I think this is a useful first step toward that direction. Let me know if you want to extend it!</paragraph><paragraph/></document>",
            "links": [
                "https://github.com/Angelinaaaaaaaaaaaa/lecture_finder",
                "https://docs.google.com/document/d/1E9v3ftDCaUzSqYOheHOa6nt6H15Fh3dkzKJ-28ntDM8/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-06T14:50:49.820076+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7418215,
            "author": "Fangzhou Zhao",
            "project_title": "Special Participation C: Refactoring HW 11",
            "post_body": "I refactored two CS182 HW11 coding notebooks (scaling_laws.ipynb and q_code_interpretability.ipynb) to follow modern software engineering and ML engineering best practices. We applied standard Python style guidelines (PEP 8, PEP 484, NumPy docstring style) to ensure the code is consistently formatted, properly typed, and easy to read. We replaced cryptic single-letter variable names (X, Z, WQK) with descriptive names (input_embeddings, attention_logits, query_key_weights) and extracted monolithic functions into smaller, testable helper functions following the Single Responsibility Principle. We also added comprehensive docstrings that explain not just the parameters but the conceptual background of each step\u2014such as the causal masking mechanism in attention heads and the log-sum-exp trick for numerical stability\u2014with the hope that students can more concretely understand the ML concepts without just implementing formulas as-is. Magic numbers were replaced with named constants, and academic references were added to connect code with research literature.\n\nHere's a link to my GitHub repo containing the refactored notebooks:\n\nhttps://github.com/Fangzhou66/cs182_hw11_refactor\n\nHere's my detailed report with an overview of all code quality issues identified, refactoring methods used, and AI assistance documentation:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I refactored two CS182 HW11 coding notebooks (scaling_laws.ipynb and q_code_interpretability.ipynb) to follow modern software engineering and ML engineering best practices. We applied standard Python style guidelines (PEP 8, PEP 484, NumPy docstring style) to ensure the code is consistently formatted, properly typed, and easy to read. We replaced cryptic single-letter variable names (X, Z, WQK) with descriptive names (input_embeddings, attention_logits, query_key_weights) and extracted monolithic functions into smaller, testable helper functions following the Single Responsibility Principle. We also added comprehensive docstrings that explain not just the parameters but the conceptual background of each step\u2014such as the causal masking mechanism in attention heads and the log-sum-exp trick for numerical stability\u2014with the hope that students can more concretely understand the ML concepts without just implementing formulas as-is. Magic numbers were replaced with named constants, and academic references were added to connect code with research literature.</paragraph><paragraph>Here's a link to my GitHub repo containing the refactored notebooks:</paragraph><paragraph>https://github.com/Fangzhou66/cs182_hw11_refactor</paragraph><paragraph>Here's my detailed report with an overview of all code quality issues identified, refactoring methods used, and AI assistance documentation:</paragraph><file url=\"https://static.us.edusercontent.com/files/DCmQHKS24dB385aatVZztjjT\" filename=\"Special Participation C HW11.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T14:27:03.07944+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7418177,
            "author": "Akhil Agarwal",
            "project_title": "Special Participation A: Mistral AI on HW4's Non-Coding Portion",
            "post_body": "I used Mistral AI's Le Chat to solve the written portion of HW 04. I started by uploading the entire homework PDF for it to read the questions from. I asked it to repeat the question and then answer the question with reasoning. Overall, it performed very well on most of the questions, with no prompting needed for the vast majority of them, while a few of them took extra clarifications. Most of the \"mistakes\" made by Mistral were because of which convention was used in the homework, and things that were not clarified in the problem. However, after a while it also was unable to read a problem from the initial PDF, and the questions had to be fed through screenshots.\n\nQ1: It basically one-shotted this entire problem. I just asked it to solve Q1 and it solved it correctly, repeating the problems from the PDF and solving them with structure and reason. However, for the runtime in the solution PDF it includes the 2x constant on the runtime, while Mistral did not. However, when I prompted it saying to include constants, it did include the 2x, so I think it is reasonable as usually runtime means big O runtime, and it was unspecified.\n\nQ2: Here I decided to go part by part. On parts a-f, it solved the problems correctly with absolutely no issues (NOTE: on part e, I believe that the answer key is incorrect. I posted about this separately under HW04 Solutions a few days ago. I think the LLM's answer is correct). It was very structured in all of its responses, listing out background, what it needed to find, and then methodically coming up with the solution. However, on 2g, it finally failed. It thought that the parameters in W being unit-scaled meant that ||W||_2 = 1, but that is not the case, as each individual parameter had that property, not the matrix as a whole. It fixed it after some prompting, where I had to specify that it was wrong there. It also was using scaling in isolation, assuming that they do not stack by layer, which I think is reasonable.\n\nQ3: It stopped repeating the question here, leading to it not answering the full question where it had to expand the expression for a and b, but it got that after prompting it to. For convolutions, it was using the deep learning convention where the kernel is already flipped, so it was getting incorrect signage, but then it fixed this when I clarified convention.\n\nQ4: This question did not involve that much hard calculation and there was no room for ambiguity, so it solved it correctly in one shot.\n\nQ7 (Q5-6 were coding questions): For part a, we again flipped the convention back to the deep learning one where the kernel is pre-flipped, which Mistral didn't know and so was refusing to simplify the expression into a convolution, but when told about the convention swap it did it. On 7b, once it had the right question (I fed it through screenshot at this point), it got it correctly, and parts c-d went smoothly.\n\nOverall, there were a lot of hiccups, but they were mostly due to convention. I would only count 2g as a problem where it truly made a mistake.\n\nTrace: https://chat.mistral.ai/chat/f5eb2483-4b31-4ed2-8c3d-91f605d4de36\n\nAnnotated Trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Mistral AI's Le Chat to solve the written portion of HW 04. I started by uploading the entire homework PDF for it to read the questions from. I asked it to repeat the question and then answer the question with reasoning. Overall, it performed very well on most of the questions, with no prompting needed for the vast majority of them, while a few of them took extra clarifications. Most of the \"mistakes\" made by Mistral were because of which convention was used in the homework, and things that were not clarified in the problem. However, after a while it also was unable to read a problem from the initial PDF, and the questions had to be fed through screenshots.</paragraph><paragraph>Q1: It basically one-shotted this entire problem. I just asked it to solve Q1 and it solved it correctly, repeating the problems from the PDF and solving them with structure and reason. However, for the runtime in the solution PDF it includes the 2x constant on the runtime, while Mistral did not. However, when I prompted it saying to include constants, it did include the 2x, so I think it is reasonable as usually runtime means big O runtime, and it was unspecified.</paragraph><paragraph>Q2: Here I decided to go part by part. On parts a-f, it solved the problems correctly with absolutely no issues (NOTE: on part e, I believe that the answer key is incorrect. I posted about this separately under HW04 Solutions a few days ago. I think the LLM's answer is correct). It was very structured in all of its responses, listing out background, what it needed to find, and then methodically coming up with the solution. However, on 2g, it finally failed. It thought that the parameters in W being unit-scaled meant that ||W||_2 = 1, but that is not the case, as each individual parameter had that property, not the matrix as a whole. It fixed it after some prompting, where I had to specify that it was wrong there. It also was using scaling in isolation, assuming that they do not stack by layer, which I think is reasonable.</paragraph><paragraph>Q3: It stopped repeating the question here, leading to it not answering the full question where it had to expand the expression for a and b, but it got that after prompting it to. For convolutions, it was using the deep learning convention where the kernel is already flipped, so it was getting incorrect signage, but then it fixed this when I clarified convention.</paragraph><paragraph>Q4: This question did not involve that much hard calculation and there was no room for ambiguity, so it solved it correctly in one shot.</paragraph><paragraph>Q7 (Q5-6 were coding questions): For part a, we again flipped the convention back to the deep learning one where the kernel is pre-flipped, which Mistral didn't know and so was refusing to simplify the expression into a convolution, but when told about the convention swap it did it. On 7b, once it had the right question (I fed it through screenshot at this point), it got it correctly, and parts c-d went smoothly.</paragraph><paragraph>Overall, there were a lot of hiccups, but they were mostly due to convention. I would only count 2g as a problem where it truly made a mistake.</paragraph><paragraph>Trace: <link href=\"https://chat.mistral.ai/chat/f5eb2483-4b31-4ed2-8c3d-91f605d4de36\">https://chat.mistral.ai/chat/f5eb2483-4b31-4ed2-8c3d-91f605d4de36</link></paragraph><paragraph>Annotated Trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/BXeboYaNT7V8sVsMOrBidhnz\" filename=\"Special_Participation_A.pdf\"/></document>",
            "links": [
                "https://chat.mistral.ai/chat/f5eb2483-4b31-4ed2-8c3d-91f605d4de36"
            ],
            "attachments": [],
            "created_at": "2025-12-06T14:19:20.154941+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7417799,
            "author": "Vrushank Prakash",
            "project_title": "Special Participation E: Understanding GNNs through Social Networks with Gemini 3 Pro Guided Learning",
            "post_body": "When learning new concepts, I find it useful and interesting to learn them through the lens of a real-world application. When watching the lecture on GNNs, I was intrigued by all its applications to fields such as chemistry, networks, etc. I wanted to gain a better understanding of how GNNs work, while learning more about how it is applied to social networks specifically.\n\nI used Gemini 3 Pro with Guided Thinking to walk me through the core ideas within GNNs by using social networks as the motivating example. I attached the GNN lecture notes (lectures 12 and 13) as context. Gemini took me through 3 key ideas: convolution, aggregation, and pooling.\n\nOverall, Gemini did a great job of explaining these ideas through social networks. I definitely got a much better understanding of how convolution and aggregation are fundamental to determining how friends are recommended in social networks. It was interesting to see how pooling was also an important part of social networks, but I do think Gemini hallucinated a bit and gave a way too in-depth explanation.\n\nHere is an annotated trace:",
            "content_xml": "<document version=\"2.0\"><paragraph>When learning new concepts, I find it useful and interesting to learn them through the lens of a real-world application. When watching the lecture on GNNs, I was intrigued by all its applications to fields such as chemistry, networks, etc. I wanted to gain a better understanding of how GNNs work, while learning more about how it is applied to social networks specifically.</paragraph><paragraph>I used Gemini 3 Pro with Guided Thinking to walk me through the core ideas within GNNs by using social networks as the motivating example. I attached the GNN lecture notes (lectures 12 and 13) as context. Gemini took me through 3 key ideas: convolution, aggregation, and pooling.</paragraph><paragraph>Overall, Gemini did a great job of explaining these ideas through social networks. I definitely got a much better understanding of how convolution and aggregation are fundamental to determining how friends are recommended in social networks. It was interesting to see how pooling was also an important part of social networks, but I do think Gemini hallucinated a bit and gave a way too in-depth explanation.</paragraph><paragraph>Here is an annotated trace:</paragraph><file url=\"https://static.us.edusercontent.com/files/a4XvIZgC63bfC8S670rJPeQp\" filename=\"CS 182 Special Participation E_ Understanding GNNs through Social Networks.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T13:06:23.241627+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7417784,
            "author": "Alex Cao",
            "project_title": "Special Participation E: ChatGPT Study Mode: Prompt Design for Deep Lecture\u2013Paper Learning",
            "post_body": "Intro\n\nThis is an attempt to use chatgpt\u2019s study mode to comprehensively review lecture content together with the corresponding papers. I understand that chatgpt\u2019s study mode has already been explored by other threads, but this study is specifically focused on a prompting style that makes study mode more effective, by carefully designing prompts tailored to how chatgpt study mode is designed. The goal is to investigate an effective way to review lecture material alongside the original paper in order to gain deeper, more informative understanding and to actually learn new things, not just recall them. In this project, I used the course lecture transcript as part of the prompt, solely for educational purposes.\n\nFull Trace:\n\nhttps://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08\n\nAnnotated Trace\n\nSummary\n\nIn this attempt, I used a case study to explore how to better prompt chatgpt\u2019s study mode in order to have a more effective study session. At the same time, I reflect on what I can do better in my prompts from two perspectives: reinforcing good behaviors and avoiding bad ones.\n\nI discovered some nice features of chatgpt\u2019s study mode that can be reinforced in the prompt to encourage good behaviors and reduce unhelpful ones. First, when I provide a source, it helps to tell chatgpt how familiar I am with that source. Otherwise, it might assume I have already read it and directly use phrases from it, which can cause confusion. Second, when dealing with a new concept that involves heavy math, it is useful to explicitly instruct chatgpt to first build up intuition with straightforward math before diving into more complex derivations. This makes it easier for my brain to understand the complex math. (Although chatgpt\u2019s study mode implicitly does this, it is still helpful to reinforce it in the prompt.)\n\nThird, another (partly implicit) behavior that is nice to reinforce is asking cahtgpt to provide \u201cmental checkpoints\u201d when checking whether I am confused\u2014for example, bullet points I can mentally cross off to help me organize my thoughts and reflect on whether I really understand the concept. Finally, a very nice feature of study mode is that it asks quiz questions to help solidify understanding. One caveat, however, is that if these questions are not closely related to the overarching question I started with, they can unintentionally redirect the conversation away from the core topic. While this can sometimes be beneficial, often I prefer more focused studying, so this is another point worth explicitly mentioning in the prompt.\n\nOverall, this case study gave me a clearer sense of how to \u201cco-pilot\u201d chatgpt\u2019s study mode so that it better matches my learning goals and supports more focused, effective studying",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Intro</heading><paragraph>This is an attempt to use chatgpt\u2019s study mode to comprehensively review lecture content together with the corresponding papers. I understand that chatgpt\u2019s study mode has already been explored by other threads, but this study is specifically focused on a prompting style that makes study mode more effective, by carefully designing prompts tailored to how chatgpt study mode is designed. The goal is to investigate an effective way to review lecture material alongside the original paper in order to gain deeper, more informative understanding and to actually learn new things, not just recall them. In this project, I used the course lecture transcript as part of the prompt, solely for educational purposes.</paragraph><heading level=\"2\">Full Trace:</heading><paragraph><bold><link href=\"https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08\"><underline>https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08</underline></link></bold></paragraph><heading level=\"2\">Annotated Trace</heading><file url=\"https://static.us.edusercontent.com/files/UZPEMVVHS0WeHNOGRcza1J7m\" filename=\"Special participation E \uff08II).pdf\"/><heading level=\"2\">Summary</heading><paragraph>In this attempt, I used a case study to explore how to better prompt chatgpt\u2019s study mode in order to have a more effective study session. At the same time, I reflect on what I can do better in my prompts from two perspectives: reinforcing good behaviors and avoiding bad ones.</paragraph><paragraph>I discovered some nice features of chatgpt\u2019s study mode that can be reinforced in the prompt to encourage good behaviors and reduce unhelpful ones. First, when I provide a source, it helps to tell chatgpt how familiar I am with that source. Otherwise, it might assume I have already read it and directly use phrases from it, which can cause confusion. Second, when dealing with a new concept that involves heavy math, it is useful to explicitly instruct chatgpt to first build up intuition with straightforward math before diving into more complex derivations. This makes it easier for my brain to understand the complex math. (Although chatgpt\u2019s study mode implicitly does this, it is still helpful to reinforce it in the prompt.)</paragraph><paragraph>Third, another (partly implicit) behavior that is nice to reinforce is asking cahtgpt to provide \u201cmental checkpoints\u201d when checking whether I am confused\u2014for example, bullet points I can mentally cross off to help me organize my thoughts and reflect on whether I really understand the concept. Finally, a very nice feature of study mode is that it asks quiz questions to help solidify understanding. One caveat, however, is that if these questions are not closely related to the overarching question I started with, they can unintentionally redirect the conversation away from the core topic. While this can sometimes be beneficial, often I prefer more focused studying, so this is another point worth explicitly mentioning in the prompt.</paragraph><paragraph>Overall, this case study gave me a clearer sense of how to \u201cco-pilot\u201d chatgpt\u2019s study mode so that it better matches my learning goals and supports more focused, effective studying</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/69338db6-3cc0-800f-8c1f-e724f2e61d08"
            ],
            "attachments": [],
            "created_at": "2025-12-06T13:03:09.273381+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7417556,
            "author": "Mishty Dhekial",
            "project_title": "Special Participation A: Gemini 2.5 Fast on Homework 08",
            "post_body": "I utilized the Gemini 2.5 Fast model to tackle the non-coding problems of Homework 8. I first solved Questions 1, 3 and 4 based solely on the problem description in the uploaded PDF. I then used the provided solution key to perform a comparison and evaluate my one-shot performance.\n\nThe model was able to one-shot the vast majority of the analytical and conceptual parts correctly on the first attempt. However, it still struggled a bit in a few of the problem portions.\n\nHere are the per-question results on the first run through:\n\nQuestion 1\n\nCorrect The derivation of the kernel $K$ (part a), the concrete examples (part b), the critical path comparison (part c), and the conceptual analysis for diagonal (part e) and DPLR matrices (part f) were all correct.\n\nStruggled In part (d), while the correct highly parallel method and the $\\mathbf{O(\\log L)}$ dependency on sequence length were correctly identified, the final critical path expression was $\\mathbf{O(\\log L \\cdot n^3)}$. The class solution omits the matrix dimension factor $n$, which is not the case for Gemini. Similar patterns are present in $e$ and $f$.\n\nQuestion 3\n\nCorrect\n\nThe mathematical derivation for the optimal weight matrix $\\hat{W}$ in part (b) ii was correct and followed the most elegant geometric invariance approach shown in the key. The determined range for $\\lambda$ in part (c), $\\mathbf{1 \\le \\lambda \\le 4}$, was also correct based on the $\\mathbf{80\\%}$ preservation and $\\mathbf{50\\%}$ attenuation requirements specified in the problem.\n\nStruggled\n\nIn part (a) Gemini, was unable to fill in the missing Regularization Loss for encoder $\\mathbf{W^{(\\beta)}}$. This is because the matrix $W^{(\\beta)}$ was not properly extracted from the uploaded PDF.\n\nQuestion 4\n\nCorrect\n\nAll conceptual and analytical parts were solved correctly. This included the efficient average update in part (a), the decomposition of ridge components in part (b), the computational cost of the non-causal attention $O(n d^2)$ in part (c), the Sherman-Morrison formula cost $O(d^2)$ in part (e), and the conceptual form for the attention weights in part (g).\n\nStruggled\n\nIn part (d) \\lambda$ isn't chosen and in part (f) (Efficient Causal Ridge-Self-Attention), Gemini's initial complexity analysis for the recursive update was $\\mathbf{O(n d^3)}$ total. However, the optimal solution (provided in the key) demonstrates that the output can be calculated using only matrix-vector products, which cost only $O(d^2)$ per time step. This optimal path yields an overall complexity of $\\mathbf{O(n d^2)}$. Gemini struggled to identify the most computationally efficient $O(d^2)$ path for the final calculation step.\n\nI have attached my  annotated conversation trace below.",
            "content_xml": "<document version=\"2.0\"><paragraph>I utilized the <bold>Gemini</bold> <bold>2.5 Fast</bold> model to tackle the non-coding problems of Homework 8. I first solved Questions 1, 3 and 4 based solely on the problem description in the uploaded PDF. I then used the provided solution key to perform a comparison and evaluate my one-shot performance.</paragraph><paragraph>The model was able to one-shot the vast majority of the analytical and conceptual parts correctly on the first attempt. However, it still struggled a bit in a few of the problem portions.</paragraph><paragraph>Here are the per-question results on the first run through:</paragraph><paragraph><bold><underline>Question 1</underline></bold></paragraph><paragraph><bold>Correct</bold> The derivation of the kernel $K$ (part a), the concrete examples (part b), the critical path comparison (part c), and the conceptual analysis for diagonal (part e) and DPLR matrices (part f) were all correct.</paragraph><paragraph><bold>Struggled</bold> In part (d), while the correct highly parallel method and the $\\mathbf{O(\\log L)}$ dependency on sequence length were correctly identified, the final critical path expression was $\\mathbf{O(\\log L \\cdot n^3)}$. The class solution omits the matrix dimension factor $n$, which is not the case for Gemini. Similar patterns are present in $e$ and $f$.</paragraph><paragraph><bold><underline>Question 3</underline></bold></paragraph><paragraph><bold>Correct</bold></paragraph><paragraph>The mathematical derivation for the optimal weight matrix $\\hat{W}$ in part (b) ii was correct and followed the most elegant geometric invariance approach shown in the key. The determined range for $\\lambda$ in part (c), $\\mathbf{1 \\le \\lambda \\le 4}$, was also correct based on the $\\mathbf{80\\%}$ preservation and $\\mathbf{50\\%}$ attenuation requirements specified in the problem.</paragraph><paragraph><bold>Struggled</bold></paragraph><paragraph>In part (a) Gemini, was unable to fill in the missing <bold>Regularization Loss</bold> for encoder $\\mathbf{W^{(\\beta)}}$. This is because the matrix $W^{(\\beta)}$ was not properly extracted from the uploaded PDF.</paragraph><paragraph><bold><underline>Question 4</underline></bold></paragraph><paragraph><bold>Correct</bold></paragraph><paragraph>All conceptual and analytical parts were solved correctly. This included the efficient average update in part (a), the decomposition of ridge components in part (b), the computational cost of the non-causal attention $O(n d^2)$ in part (c), the Sherman-Morrison formula cost $O(d^2)$ in part (e), and the conceptual form for the attention weights in part (g).</paragraph><paragraph><bold>Struggled</bold></paragraph><paragraph>In part (d) \\lambda$ isn't chosen and in part (f) (Efficient Causal Ridge-Self-Attention), Gemini's initial complexity analysis for the recursive update was $\\mathbf{O(n d^3)}$ total. However, the optimal solution (provided in the key) demonstrates that the output can be calculated using only matrix-vector products, which cost only $O(d^2)$ per time step. This optimal path yields an overall complexity of $\\mathbf{O(n d^2)}$. Gemini struggled to identify the most computationally efficient $O(d^2)$ path for the final calculation step.</paragraph><paragraph>I have attached my  annotated conversation trace below.</paragraph><file url=\"https://static.us.edusercontent.com/files/uVQmEGCeehctgMVAZq4BoL95\" filename=\"Special_Participation_A (1).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T12:26:02.74646+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7417411,
            "author": "Nils Selte",
            "project_title": "Special participation B: Cursor on hw8",
            "post_body": "Cursor agent mode is quickly becoming the standard in modern SWE. I tried it on Hw8 and was impressed with its grasp of available tools, its ability to navigate challenges and not give up on solving its task. \nI used Gemini 3.0 Pro as the base model as I have found it to be more decisive in its actions than other models and its impressive benchmarks.\n\nKey takeaway: The agent was able to solve the entire coding part of the hw on single prompt. It navigated challenges like not having writing access to the file by making a Python script that explicitly changed the .ipynb file and even navigated not having access to the right environment. I am beyond impressed with the model/agent capabilities, it also makes me scared that my own knowledge is becoming irrelevant. It even made a separate script for checking itself against test-cases (only to delete it after it was satisfied its solution was working). \n\nPrompting strategy:\n\nThe prompting strategy I employed was focused on eliminating common quirks of AI code generation (like overuse of comments, removing typing and implementing try/catch blocks where it makes no sense). I also tasked it with being very specific to not refactor the code of the question. It makes me wonder how GEPA algorithms could be employed on these types of agents and if it could actually be making a difference. \n\nPrompt:\n\ntake a look at @q_coding_ssm_forward_cpu.ipynb There is a number of TODOs in the document. I want you to solve all of them being careful not to refactor any code or including code slop. Code slop includes changing types to \"any\" to resolve typing issues or making wierd comments that humans woudnt make or inserting try/catch blocks in places where it is not normal like places where the known data is good and there is no reason for doing so. Do not change any code that is not in between the TODO block and end Oof your code block. also answer the text based questions. \n\nEnire CoT in the .pdf and the model generated files and result in the .md",
            "content_xml": "<document version=\"2.0\"><paragraph>Cursor agent mode is quickly becoming the standard in modern SWE. I tried it on Hw8 and was impressed with its grasp of available tools, its ability to navigate challenges and not give up on solving its task. <break/>I used Gemini 3.0 Pro as the base model as I have found it to be more decisive in its actions than other models and its impressive benchmarks.<break/><break/>Key takeaway: The agent was able to solve the entire coding part of the hw on single prompt. It navigated challenges like not having writing access to the file by making a Python script that explicitly changed the .ipynb file and even navigated not having access to the right environment. I am beyond impressed with the model/agent capabilities, it also makes me scared that my own knowledge is becoming irrelevant. It even made a separate script for checking itself against test-cases (only to delete it after it was satisfied its solution was working). </paragraph><paragraph>Prompting strategy:</paragraph><paragraph>The prompting strategy I employed was focused on eliminating common quirks of AI code generation (like overuse of comments, removing typing and implementing try/catch blocks where it makes no sense). I also tasked it with being very specific to not refactor the code of the question. It makes me wonder how GEPA algorithms could be employed on these types of agents and if it could actually be making a difference. </paragraph><paragraph>Prompt:</paragraph><paragraph>take a look at @q_coding_ssm_forward_cpu.ipynb There is a number of TODOs in the document. I want you to solve all of them being careful not to refactor any code or including code slop. Code slop includes changing types to \"any\" to resolve typing issues or making wierd comments that humans woudnt make or inserting try/catch blocks in places where it is not normal like places where the known data is good and there is no reason for doing so. Do not change any code that is not in between the TODO block and end Oof your code block. also answer the text based questions. <break/><break/>Enire CoT in the .pdf and the model generated files and result in the .md</paragraph><file url=\"https://static.us.edusercontent.com/files/wrJfxCNjVAH6Tdiyf9QwQoDZ\" filename=\"q_coding_ssm_forward_cpu.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/s1Cse30wbA8maaiUf8T4awov\" filename=\"cursor_resolve_notebook_todos_and_quest.md\"/><file url=\"https://static.us.edusercontent.com/files/GghZ7lONQ8Uzio54hEPEk2J2\" filename=\"Special Participation B_ Using Cursor agent with Gemini 3 pro on HW8.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T12:00:40.363607+11:00",
            "category": "Admin"
        },
        {
            "guid": 7417181,
            "author": "Gustavo Jose Ortiz Zepeda",
            "project_title": "Special Participation E: Using Gemini to review the concepts before and after studying",
            "post_body": "For this special participation I'll be sharing a way I'm studying for the final which consists on doing summaries, cheat sheet and quizzes before and after reviewing the topic so I can be sure I don't forget something, and complement my notes easier. I think the problems are great as conceptual question.\n\nThis is the prompt I used to achieve this behavior:\n\nYou are \"TutorBot,\" an empathetic, clear, and structured academic tutor.\n\nObjective: Your goal is to prepare the student for an exam or deeper learning by synthesizing their Class Notes and Homework Files. You do not teach new, unrelated material; you reinforce what is in the provided files.\n\nProcess: When the user uploads files, analyze them immediately and output a response strictly following this structure:\n\nConcept Map\n\nScan the documents to identify the core topics.\n\nList all key concepts found in the notes.\n\nProvide a 2-sentence plain-English definition for each.\n\n2. Cheat sheet\n\nExtract every mathematical formula or significant rule mentioned. Do not skip one.\n\nLabel what each variable in the formula represents.\n\nNote: If multiple variations exist in the notes, show the most general form.\n\nVery Small, Safe Examples (VSSE)\n\nCreate 1-2 \"Toy Examples\" per concept based on the extracted formulas.\n\nRules for VSSEs: * Use integer numbers (e.g., 2, 5, 10) to make the math trivial. * Avoid decimals, fractions, or complex arithmetic. * Show the step-by-step substitution logic. * Goal: Prove how the formula works mechanically without testing the student's arithmetic skills.\n\nReadiness Check\n\nAsk 20 multiple-choice or short-answer questions but one at a time based strictly on the concepts above (start from easy and then go further).\n\nThese should be \"confidence builders\" to ensure the student understands the basic definitions or variable placements.\n\nStop and wait for the student to answer before proceeding to more complex topics. Always be prepared to review topics or explain again concepts.\n\nTone: Encouraging, patient, and precise.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation I'll be sharing a way I'm studying for the final which consists on doing summaries, cheat sheet and quizzes before and after reviewing the topic so I can be sure I don't forget something, and complement my notes easier. I think the problems are great as conceptual question.</paragraph><file url=\"https://static.us.edusercontent.com/files/3pK5A1sq17Q5iqfvjBbqRqI0\" filename=\"Special Participation E.pdf\"/><paragraph>This is the prompt I used to achieve this behavior:</paragraph><paragraph>You are \"TutorBot,\" an empathetic, clear, and structured academic tutor.</paragraph><paragraph>Objective: Your goal is to prepare the student for an exam or deeper learning by synthesizing their Class Notes and Homework Files. You do not teach new, unrelated material; you reinforce what is in the provided files.</paragraph><paragraph>Process: When the user uploads files, analyze them immediately and output a response strictly following this structure:</paragraph><list style=\"ordered\"><list-item><paragraph>Concept Map</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Scan the documents to identify the core topics.</paragraph></list-item><list-item><paragraph>List all key concepts found in the notes.</paragraph></list-item><list-item><paragraph>Provide a 2-sentence plain-English definition for each.</paragraph></list-item></list><paragraph>2. Cheat sheet</paragraph><list style=\"unordered\"><list-item><paragraph>Extract every mathematical formula or significant rule mentioned. Do not skip one.</paragraph></list-item><list-item><paragraph>Label what each variable in the formula represents.</paragraph></list-item><list-item><paragraph><italic>Note: If multiple variations exist in the notes, show the most general form.</italic></paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Very Small, Safe Examples (VSSE)</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Create 1-2 \"Toy Examples\" per concept based on the extracted formulas.</paragraph></list-item><list-item><paragraph><bold>Rules for VSSEs:</bold> * Use integer numbers (e.g., 2, 5, 10) to make the math trivial. * Avoid decimals, fractions, or complex arithmetic. * Show the step-by-step substitution logic. * <italic>Goal:</italic> Prove how the formula works mechanically without testing the student's arithmetic skills.</paragraph></list-item></list><list style=\"ordered\"><list-item><paragraph>Readiness Check</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>Ask 20 multiple-choice or short-answer questions but one at a time based strictly on the concepts above (start from easy and then go further).</paragraph></list-item><list-item><paragraph>These should be \"confidence builders\" to ensure the student understands the basic definitions or variable placements.</paragraph></list-item><list-item><paragraph><bold>Stop and wait</bold> for the student to answer before proceeding to more complex topics. Always be prepared to review topics or explain again concepts.</paragraph></list-item></list><paragraph>Tone: Encouraging, patient, and precise.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T11:23:00.9171+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7416810,
            "author": "Ruihan Xia",
            "project_title": "Special Participation E: themtic learning with GPT",
            "post_body": "I explored how well ChatGPT connects concepts from lecture notes to textbook, particularly on the theme of optimization. I asked it to break the material into clear modules, give small toy examples for each idea, compare the lectures with the textbook, and finish with one big geometric diagram of how optimization works.\n\nInitially ChatGPT only gives high-level, qualitative ideas that are not helpful to learn the concepts concretely. After requesting it to show math models & derivation for each idea, the illustration became much clearer. Overall, this tool worked well as a pre-lecture guide / post-lecture review resource. It also pointed out stylistically how lecture notes and textbook differs in explaining the same concepts, e.g. geometric intuition vs math derivation. In the end I challenged it to generate some high level principles / mindmap for all the materials, but it appears to be more of a repetition of previous responses. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I explored how well ChatGPT connects concepts from lecture notes to textbook, particularly on the theme of optimization. I asked it to break the material into clear modules, give small toy examples for each idea, compare the lectures with the textbook, and finish with one big geometric diagram of how optimization works.</paragraph><paragraph>Initially ChatGPT only gives high-level, qualitative ideas that are not helpful to learn the concepts concretely. After requesting it to show math models &amp; derivation for each idea, the illustration became much clearer. Overall, this tool worked well as a pre-lecture guide / post-lecture review resource. It also pointed out stylistically how lecture notes and textbook differs in explaining the same concepts, e.g. geometric intuition vs math derivation. In the end I challenged it to generate some high level principles / mindmap for all the materials, but it appears to be more of a repetition of previous responses. </paragraph><file url=\"https://static.us.edusercontent.com/files/5VObgnKhvKIIadnA0LiiYteS\" filename=\"Theme learning - GPT.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T10:30:50.376843+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7416689,
            "author": "Grant Yang",
            "project_title": "Special Participation A: Gemini 3 Pro Thinking on HW 6 Non-Coding",
            "post_body": "Using Gemini 3 Pro Thinking on HW 6 non-coding questions, I was able to observe the following results.\n\nSummary: \n\nGemini performed mostly well, one-shotting most subparts even with minimal guidance beyond the problem setup and accompanying graphs/figures. When it made a mistake, it was usually able to reason about its process to identify/clarify the error within a couple of turns. Overall, this is extremely impressive.\n\nRecap:\n\nI started off by giving it a prefacing prompt: \u201cI will give you problem set questions about deep learning. Think carefully about each question and answer each subpart with a detailed explanation.\u201d I hoped that this would encourage better results and avoid shallow answers.\n\nAs a baseline, I fed the entire problem (Q2) into the prompt and attached the relevant figures. I was expecting that given the length and density of the prompt, it would struggle to answer correctly, but surprisingly it was able to one-shot most of the subparts correctly, only being slightly wrong on subpart (c). This subpart took a couple rounds of clarifications and hints to correct. Even on more subjective questions, like suggesting possible strategies/interpretations, it gave answers that were either similar to the provided solutions or still technically correct.\n\nFor Q3, I tried a similar approach by feeding the entire question into the prompt. I again included the image of the graph as the input, without any external help (such as listing the edges or clarifying the table). I expected that this could produce some challenges if Gemini were to be unable to interpret the graph structure correctly. However, after looking at its \u201cthinking\u201d and its reasoning before answering, it actually mostly interpreted both the table values and graph structure from the image, and successfully one-shotted all subparts except for the last one due to a visual error. I was able to correct its error in the last subpart by telling it to think about its answer again, highlighting the node inside the tanh, and it spotted its own bug and returned the correct answer.\n\nConversation link: https://gemini.google.com/share/f77cf2401b50 \n\nAnnotated log: https://drive.google.com/file/d/1yB1Tdo1rD394SMZJm9QtI5onQhmR6bQS/view?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Using Gemini 3 Pro Thinking on HW 6 non-coding questions, I was able to observe the following results.</bold></paragraph><paragraph><bold>Summary:</bold> </paragraph><paragraph>Gemini performed mostly well, one-shotting most subparts even with minimal guidance beyond the problem setup and accompanying graphs/figures. When it made a mistake, it was usually able to reason about its process to identify/clarify the error within a couple of turns. Overall, this is extremely impressive.</paragraph><paragraph><bold>Recap:</bold></paragraph><paragraph>I started off by giving it a prefacing prompt: \u201cI will give you problem set questions about deep learning. Think carefully about each question and answer each subpart with a detailed explanation.\u201d I hoped that this would encourage better results and avoid shallow answers.</paragraph><paragraph>As a baseline, I fed the entire problem (Q2) into the prompt and attached the relevant figures. I was expecting that given the length and density of the prompt, it would struggle to answer correctly, but surprisingly it was able to one-shot most of the subparts correctly, only being slightly wrong on subpart (c). This subpart took a couple rounds of clarifications and hints to correct. Even on more subjective questions, like suggesting possible strategies/interpretations, it gave answers that were either similar to the provided solutions or still technically correct.</paragraph><paragraph>For Q3, I tried a similar approach by feeding the entire question into the prompt. I again included the image of the graph as the input, without any external help (such as listing the edges or clarifying the table). I expected that this could produce some challenges if Gemini were to be unable to interpret the graph structure correctly. However, after looking at its \u201cthinking\u201d and its reasoning before answering, it actually mostly interpreted both the table values and graph structure from the image, and successfully one-shotted all subparts except for the last one due to a visual error. I was able to correct its error in the last subpart by telling it to think about its answer again, highlighting the node inside the tanh, and it spotted its own bug and returned the correct answer.</paragraph><paragraph>Conversation link: <link href=\"https://gemini.google.com/share/f77cf2401b50\"><underline>https://gemini.google.com/share/f77cf2401b50</underline></link> </paragraph><paragraph>Annotated log: <link href=\"https://drive.google.com/file/d/1yB1Tdo1rD394SMZJm9QtI5onQhmR6bQS/view?usp=sharing\"><underline>https://drive.google.com/file/d/1yB1Tdo1rD394SMZJm9QtI5onQhmR6bQS/view?usp=sharing</underline></link> </paragraph></document>",
            "links": [
                "https://gemini.google.com/share/f77cf2401b50",
                "https://drive.google.com/file/d/1yB1Tdo1rD394SMZJm9QtI5onQhmR6bQS/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-06T10:10:20.504689+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7416375,
            "author": "Dagny Streit",
            "project_title": "Special Participation B: ChatGPT on HW 9",
            "post_body": "I used ChatGPT 5.1 (Auto) to solve the coding question of Homework 9 (Question 5). This problem required the model to interpret and reason about attention visualization plots rather than generate code. Overall, the model produced accurate and detailed explanations, but it also displayed a recurring tendency to misinterpret / modify questions. Below are the primary strengths and weaknesses I observed during the interaction.\n\nStrengths:\n\nThe model consistently produced correct and well-justified interpretations of the attention patterns on the first try\n\nWhen explaining its reasoning, the model frequently referenced particular examples (tokens, layers, heads, etc.) from the visualization\n\nWhen given many attention plots to choose from, the model reasonably identified which visualizations were most relevant for it to solve each subpart (e.g., 5c) and was able to interpret them both individually and collectively\n\nWhen I restated the question verbatim, the model reoriented itself quickly\n\nWeaknesses:\n\nThe most frequent issue was the model answering a slightly modified version of the question (e.g. 5b). It often restated the prompt incorrectly. I\u2019m not certain if this was influenced by the many attached PDFs and screenshots with inconsistent question labeling. However, this resulted in \u201challucinations\u201d of the question it was supposed to answer. The way the model rewrote the questions tended to steer towards the answer it planned it give.\n\nEven when correct, the model\u2019s response often included extensive pattern descriptions and additional commentary that went beyond the key points needed.\n\nAttached is my annotated log of the ChatGPT interaction (it is split into two parts to fit in the Ed post). The document is color-coded for clarity. Green annotations / highlights indicate the response was correct. Red annotations / highlights indicate that the response was incorrect or needed to be reoriented.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5.1 (Auto) to solve the coding question of Homework 9 (Question 5). This problem required the model to interpret and reason about attention visualization plots rather than generate code. Overall, the model produced accurate and detailed explanations, but it also displayed a recurring tendency to misinterpret / modify questions. Below are the primary strengths and weaknesses I observed during the interaction.</paragraph><paragraph>Strengths:</paragraph><list style=\"unordered\"><list-item><paragraph>The model consistently produced correct and well-justified interpretations of the attention patterns on the first try</paragraph></list-item><list-item><paragraph>When explaining its reasoning, the model frequently referenced particular examples (tokens, layers, heads, etc.) from the visualization</paragraph></list-item><list-item><paragraph>When given many attention plots to choose from, the model reasonably identified which visualizations were most relevant for it to solve each subpart (e.g., 5c) and was able to interpret them both individually and collectively</paragraph></list-item><list-item><paragraph>When I restated the question verbatim, the model reoriented itself quickly</paragraph></list-item></list><paragraph>Weaknesses:</paragraph><list style=\"unordered\"><list-item><paragraph>The most frequent issue was the model answering a slightly modified version of the question (e.g. 5b). It often restated the prompt incorrectly. I\u2019m not certain if this was influenced by the many attached PDFs and screenshots with inconsistent question labeling. However, this resulted in \u201challucinations\u201d of the question it was supposed to answer. The way the model rewrote the questions tended to steer towards the answer it planned it give.</paragraph></list-item><list-item><paragraph>Even when correct, the model\u2019s response often included extensive pattern descriptions and additional commentary that went beyond the key points needed.</paragraph></list-item></list><paragraph>Attached is my annotated log of the ChatGPT interaction (it is split into two parts to fit in the Ed post). The document is color-coded for clarity. Green annotations / highlights indicate the response was correct. Red annotations / highlights indicate that the response was incorrect or needed to be reoriented.</paragraph><file url=\"https://static.us.edusercontent.com/files/2ixRAjecQD9JTBPY8u8Z0OaH\" filename=\"Participation B Annotated Part 1.pdf\"/><file url=\"https://static.us.edusercontent.com/files/Gm8NsQuuIXrIdgVbojJjlXkA\" filename=\"Participation B Annotated Part 2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T09:28:00.390217+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7416340,
            "author": "Imra Dawoodani",
            "project_title": "Special Participation B: Gemini 3 Pro on HW 5",
            "post_body": "I evaluated Gemini Pro on the coding portions of Homework 5, covering dropout theory (Question 5) and batch normalization, dropout, and convolutional network implementations (Question 6). Gemini Pro on coding had one shot success on 27 out of 28 questions.\n\nI provided Gemini with questions sequentially with supporting file code like layers.py and fc_net.py pasted in the chat when the following question in the notebook mentioned it. The initial prompt included a summary of what to expect across both questions, which appeared to help Gemini maintain context though it occasionally peeked ahead, solving more than requested or referencing upcoming concepts prematurely.\n\nGemini produced functionally correct code for all 28 tasks. Of these, 18 were almost identical to official solutions and 10 used different conventions (cache formats, mask types, loop structures) but were equivalent. What stood out was that Gemini maintained perfect internal consistency even when its conventions differed from official solutions, making sure that its code would still run with the existing notebook structure. This suggests strong understanding rather than just pattern matching.\n\nFor the question that it overconfidently claimed a wrong insight for (q5d), a mild steering prompt produced immediate, clean correction without defensiveness (unlike what I saw when doing special participation A with Gemini 2.5 Flash - comparing since this was also a sort of conceptual mistake)\n\nSome behavioral patterns I noticed:\n\nGemini followed the consistent 4 part template I requested in the 1st prompt (Reasoning, Code, Key Insights, Expected Output). It would often provide extra code for future parts it anticipated but never missed the 4 parts I requested. This followed through the entire 115 page conversation we had. Responses were verbose but well organized.\n\nExplanations used memorable analogies like \u201cstrong lever,\" \"barcode scanner,\" \"lazy vs robust network\" that would genuinely help me understand concepts.\n\nThe single error was overconfidence on a subtle theoretical point, not a hallucination.\n\nGood cross referencing throughout. Connected spatial batchnorm to earlier vanilla implementation, referenced Q5 dropout theory when analyzing Q6 experiments. Did not exhibit Flash's pattern of degrading recall over long conversations.\n\nConsistently acknowledged that the user must run the code but sis not explicitly mention that Gemini itself was just giving predicted numbers and couldn\u2019t cross verify by running the code itself.\n\nGemini's code was consistently more readable but less compact with explicit variable names, arguments in_channels=3 rather than positional ones, and 4 nested loops rather than the partial vectorization. These differences never affected correctness.\n\nFor the open ended network design task, Gemini chose a reasonable approach given the constraints. It\u2019s solution was less complicated than mine but did just enough in the simplest way possible to hit above the threshold.\n\nFor homework assistance Gemini Pro is highly reliable for implementations and mathematical derivations. Code should still be executed to verify numerical outputs. Providing upfront context helps maintain coherence, but may cause the model to jump ahead. For learning, Gemini's explanations have genuine value. Style differences from official solutions illustrate that multiple valid approaches exist. Comparing Gemini's conventions to official solutions can deepen understanding.\n\nHere's an annotated log of my interaction:\n\nhttps://drive.google.com/file/d/1U2n0kfRyjmVLSagRGwaWLRKKbkw393YS/view?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph>I evaluated Gemini Pro on the coding portions of Homework 5, covering dropout theory (Question 5) and batch normalization, dropout, and convolutional network implementations (Question 6). Gemini Pro on coding had one shot success on 27 out of 28 questions.</paragraph><paragraph>I provided Gemini with questions sequentially with supporting file code like layers.py and fc_net.py pasted in the chat when the following question in the notebook mentioned it. The initial prompt included a summary of what to expect across both questions, which appeared to help Gemini maintain context though it occasionally peeked ahead, solving more than requested or referencing upcoming concepts prematurely.</paragraph><paragraph>Gemini produced functionally correct code for all 28 tasks. Of these, 18 were almost identical to official solutions and 10 used different conventions (cache formats, mask types, loop structures) but were equivalent. What stood out was that Gemini maintained perfect internal consistency even when its conventions differed from official solutions, making sure that its code would still run with the existing notebook structure. This suggests strong understanding rather than just pattern matching.</paragraph><paragraph>For the question that it overconfidently claimed a wrong insight for (q5d), a mild steering prompt produced immediate, clean correction without defensiveness (unlike what I saw when doing special participation A with Gemini 2.5 Flash - comparing since this was also a sort of conceptual mistake)</paragraph><paragraph>Some behavioral patterns I noticed:</paragraph><list style=\"ordered\"><list-item><paragraph>Gemini followed the consistent 4 part template I requested in the 1st prompt (Reasoning, Code, Key Insights, Expected Output). It would often provide extra code for future parts it anticipated but never missed the 4 parts I requested. This followed through the entire 115 page conversation we had. Responses were verbose but well organized.</paragraph></list-item><list-item><paragraph>Explanations used memorable analogies like \u201cstrong lever,\" \"barcode scanner,\" \"lazy vs robust network\" that would genuinely help me understand concepts.</paragraph></list-item><list-item><paragraph>The single error was overconfidence on a subtle theoretical point, not a hallucination.</paragraph></list-item><list-item><paragraph>Good cross referencing throughout. Connected spatial batchnorm to earlier vanilla implementation, referenced Q5 dropout theory when analyzing Q6 experiments. Did not exhibit Flash's pattern of degrading recall over long conversations.</paragraph></list-item><list-item><paragraph>Consistently acknowledged that the user must run the code but sis not explicitly mention that Gemini itself was just giving predicted numbers and couldn\u2019t cross verify by running the code itself.</paragraph></list-item></list><paragraph>Gemini's code was consistently more readable but less compact with explicit variable names, arguments in_channels=3 rather than positional ones, and 4 nested loops rather than the partial vectorization. These differences never affected correctness.</paragraph><paragraph>For the open ended network design task, Gemini chose a reasonable approach given the constraints. It\u2019s solution was less complicated than mine but did just enough in the simplest way possible to hit above the threshold.</paragraph><paragraph>For homework assistance Gemini Pro is highly reliable for implementations and mathematical derivations. Code should still be executed to verify numerical outputs. Providing upfront context helps maintain coherence, but may cause the model to jump ahead. For learning, Gemini's explanations have genuine value. Style differences from official solutions illustrate that multiple valid approaches exist. Comparing Gemini's conventions to official solutions can deepen understanding.</paragraph><paragraph>Here's an annotated log of my interaction:<break/><break/><link href=\"https://drive.google.com/file/d/1U2n0kfRyjmVLSagRGwaWLRKKbkw393YS/view?usp=sharing\">https://drive.google.com/file/d/1U2n0kfRyjmVLSagRGwaWLRKKbkw393YS/view?usp=sharing</link> </paragraph><file/></document>",
            "links": [
                "https://drive.google.com/file/d/1U2n0kfRyjmVLSagRGwaWLRKKbkw393YS/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-06T09:24:08.948487+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7416258,
            "author": "Fantine Mpacko Priso",
            "project_title": "Special participation D : Adding Lion to HW06",
            "post_body": "I implemented Lion on HW06, after adding Manifold MuOn too to have more methods to compare. Questions associated to this new section are: \n\nQuestion 10 : Briefly explain how Lion's update is different from AdamW in terms of:\n\nnumber of state tensors per parameter\n\nuse (or non-use) of the gradient magnitude.\n\nQuestion 11 : Uncomment the Lion contribution to the optimizer dictionnary. Compare Lion and AdamW:\n\nWhich optimizer reaches lower training loss after 5 epochs?\n\nWhich optimizer achieves higher test accuracy?\n\nDoes Lion seem to converge faster early in training, slower, or about the same?\n\n\n\nThe resulting plot is : \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I implemented Lion on HW06, after adding Manifold MuOn too to have more methods to compare. Questions associated to this new section are: </paragraph><paragraph><bold>Question 10 :</bold> Briefly explain how Lion's update is different from AdamW in terms of:</paragraph><list style=\"unordered\"><list-item><paragraph>number of state tensors per parameter</paragraph></list-item><list-item><paragraph>use (or non-use) of the gradient magnitude.</paragraph></list-item></list><paragraph><bold>Question 11</bold> : Uncomment the Lion contribution to the optimizer dictionnary. Compare Lion and AdamW:</paragraph><list style=\"unordered\"><list-item><paragraph>Which optimizer reaches lower training loss after 5 epochs?</paragraph></list-item><list-item><paragraph>Which optimizer achieves higher test accuracy?</paragraph></list-item><list-item><paragraph>Does Lion seem to converge faster early in training, slower, or about the same?</paragraph></list-item></list><paragraph/><file url=\"https://static.us.edusercontent.com/files/aaKZytCv8mbmfO8SnDsws0H7\" filename=\"Fantine_q_coding_muon_solutions_ManifoldMuOn+Lion.ipynb\"/><paragraph>The resulting plot is : </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/294ghAgzbBNHFO2nLObhJraU\" width=\"658\" height=\"325.67676767676767\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T09:14:09.027368+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7415618,
            "author": "William Li",
            "project_title": "Special Participation A: Kimi K2 on HW9",
            "post_body": "I utilized Moonshot AI\u2019s Kimi K2 model to tackle the non-coding problems of Homework 9. I first did a pass through of all the non-coding questions, sending each question individually to Kimi with no further prompting to see how the model would perform under one-shot conditions. For most of the questions, Kimi performed very well with just me sending the question to the model, and was able to get it all mostly correct on the first attempt except for the last question (question 6) which was much more difficult and longer.\n\nHere are the per-question results on the first run through (which is one-shot only):\n\nQuestion 1: This question was a relatively simple manipulation of expectations and variances, which Kimi was easily able to solve and give justifications for.\n\nQuestion 2: This question involved simple arithmetic (taking dot products of some vectors), which Kimi was easily able to do. This question also involved a conceptual question, which was also correctly answered by Kimi.\n\nQuestion 3: This question involved a simple fill in the blank coding question, which the model was able to get all correct on the first try, along with a justification for each answer. The second part of this question was also answered correctly, with the model coming up with the right changes to the code necessary for making the adjustment the question asked for.\n\nQuestion 4: This question was another mostly fill in the blank blank coding question, which the model again was able to answer correctly on the first try. The question also included two complexity calculations, of which the model was able to successfully answer the time complexity fully. The memory complexity, the model was able to get an answer that was very close to the given solutions, and up on further examination, the answer given by Kimi seems to be the same runtime, just using slightly different notation.\n\nQuestion 6: The question got some of the parts right, but had some minor differences in other parts. For these I asked the model to explain why it had answered part b(iii) the way it did, and asked it to clarify an assumption it made when calculating the time and memory complexities.\n\nI was overall very surprised and satisfied with how Kimi was able to solve the noncoding questions. It was able to one-shot the vast majority of the questions, and with simple prompting about its motivations on the incorrect questions, it was able to generate the correct solutions.\n\nTrace : https://www.kimi.com/share/19af04a7-bcf2-8f74-8000-0000496c3139\nAnnotated Trace: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I utilized Moonshot AI\u2019s Kimi K2 model to tackle the non-coding problems of Homework 9. I first did a pass through of all the non-coding questions, sending each question individually to Kimi with no further prompting to see how the model would perform under one-shot conditions. For most of the questions, Kimi performed very well with just me sending the question to the model, and was able to get it all mostly correct on the first attempt except for the last question (question 6) which was much more difficult and longer.</paragraph><paragraph>Here are the per-question results on the first run through (which is one-shot only):</paragraph><paragraph>Question 1: This question was a relatively simple manipulation of expectations and variances, which Kimi was easily able to solve and give justifications for.</paragraph><paragraph>Question 2: This question involved simple arithmetic (taking dot products of some vectors), which Kimi was easily able to do. This question also involved a conceptual question, which was also correctly answered by Kimi.</paragraph><paragraph>Question 3: This question involved a simple fill in the blank coding question, which the model was able to get all correct on the first try, along with a justification for each answer. The second part of this question was also answered correctly, with the model coming up with the right changes to the code necessary for making the adjustment the question asked for.</paragraph><paragraph>Question 4: This question was another mostly fill in the blank blank coding question, which the model again was able to answer correctly on the first try. The question also included two complexity calculations, of which the model was able to successfully answer the time complexity fully. The memory complexity, the model was able to get an answer that was very close to the given solutions, and up on further examination, the answer given by Kimi seems to be the same runtime, just using slightly different notation.</paragraph><paragraph>Question 6: The question got some of the parts right, but had some minor differences in other parts. For these I asked the model to explain why it had answered part b(iii) the way it did, and asked it to clarify an assumption it made when calculating the time and memory complexities.</paragraph><paragraph>I was overall very surprised and satisfied with how Kimi was able to solve the noncoding questions. It was able to one-shot the vast majority of the questions, and with simple prompting about its motivations on the incorrect questions, it was able to generate the correct solutions.</paragraph><paragraph>Trace : <link href=\"https://www.kimi.com/share/19af04a7-bcf2-8f74-8000-0000496c3139\">https://www.kimi.com/share/19af04a7-bcf2-8f74-8000-0000496c3139</link><break/>Annotated Trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/286tohOcXysBypCFASOMEruH\" filename=\"Kimi 2025-12-04 _3_ _1_.pdf\"/></document>",
            "links": [
                "https://www.kimi.com/share/19af04a7-bcf2-8f74-8000-0000496c3139"
            ],
            "attachments": [],
            "created_at": "2025-12-06T07:56:24.953792+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7415561,
            "author": "William Li",
            "project_title": "Special Participation E: In-Progress Concept Helper for CS182 Learning",
            "post_body": "In this special participation, I explored how we can use AI tools to give us guided hints, rather than directly giving us the answers to a problem. This will help support more active reasoning and learning while we are still actively forming our understanding of class material. \n\nHere is the prompt that I started out with:\nROLE: You are an AI learning coach for CS182 concepts (deep learning + society).\n\nWhen I provide:\n- A question about course material\n- My current in-progress reasoning\n- Optionally, a note about what I am confused about\nYou must:\n\n- NOT provide a final answer\n\n- Ask up to 3 guiding questions that help me think\n\n- Highlight unclear or incorrect reasoning with gentle hints\n\n- Encourage me to revise my understanding first\n\n- Only summarize or explain fully *after* I try again\n\nMaintain correctness, avoid hallucination, and support metacognition.\n\n\nI tried this out with questions from homework 9 with a solution partly filled in (although any questions from any source would do). \n\nFirst, I tried out the prompt for HW9 Q1, which is a relatively simple calculation question, and for the most part the model was able to use the images I sent of my work to discern where I was in the problem. I gave it a partial solution, and the model gave a very big hint as to how to finish the part I was working on. Additionally, I intentionally made a small conceptual error relating, and the model was able to catch that and give me guiding questions to realize the mistake I had made. This was a very simple question though, so I chose to continue using a more complex question.\n\nI then tried a more computationally complicated question from homework 4, and it was also able to help a lot in deriving the answer. When my answer wasn\u2019t in the form of the official solutions exactly, I prompted the model saying that maybe my answer wasn\u2019t exactly right or is too complicated looking, and the model made the pattern recognition needed to simplify my answer to the official solution\u2019s answer. \n\nOverall, this experiment showed that AI can be genuinely helpful when framed as a guided learning partner rather than a solution engine. It was especially useful at catching intermediate conceptual mistakes and nudging me toward the right direction without revealing the final answers immediately. While sometimes the model was over-eager in giving hints, I think that it is still very much a useful tool to help solve problems and study. Some suggestions to using this is to make sure that when you send your written work to the model, try to keep it in the proper orientation, and not have the text be too small, especially if handwriting isn\u2019t the best. \n\nTrace: https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b\n\nAnnotated Trace: ",
            "content_xml": "<document version=\"2.0\"><paragraph>In this special participation, I explored how we can use AI tools to give us guided hints, rather than directly giving us the answers to a problem. This will help support more active reasoning and learning while we are still actively forming our understanding of class material. </paragraph><pre>Here is the prompt that I started out with:\nROLE: You are an AI learning coach for CS182 concepts (deep learning + society).\n\nWhen I provide:\n- A question about course material\n- My current in-progress reasoning\n- Optionally, a note about what I am confused about\nYou must:\n\n- NOT provide a final answer\n\n- Ask up to 3 guiding questions that help me think\n\n- Highlight unclear or incorrect reasoning with gentle hints\n\n- Encourage me to revise my understanding first\n\n- Only summarize or explain fully *after* I try again\n\nMaintain correctness, avoid hallucination, and support metacognition.\n</pre><paragraph>I tried this out with questions from homework 9 with a solution partly filled in (although any questions from any source would do). </paragraph><paragraph>First, I tried out the prompt for HW9 Q1, which is a relatively simple calculation question, and for the most part the model was able to use the images I sent of my work to discern where I was in the problem. I gave it a partial solution, and the model gave a very big hint as to how to finish the part I was working on. Additionally, I intentionally made a small conceptual error relating, and the model was able to catch that and give me guiding questions to realize the mistake I had made. This was a very simple question though, so I chose to continue using a more complex question.</paragraph><paragraph>I then tried a more computationally complicated question from homework 4, and it was also able to help a lot in deriving the answer. When my answer wasn\u2019t in the form of the official solutions exactly, I prompted the model saying that maybe my answer wasn\u2019t exactly right or is too complicated looking, and the model made the pattern recognition needed to simplify my answer to the official solution\u2019s answer. </paragraph><paragraph>Overall, this experiment showed that AI can be genuinely helpful when framed as a guided learning partner rather than a solution engine. It was especially useful at catching intermediate conceptual mistakes and nudging me toward the right direction without revealing the final answers immediately. While sometimes the model was over-eager in giving hints, I think that it is still very much a useful tool to help solve problems and study. Some suggestions to using this is to make sure that when you send your written work to the model, try to keep it in the proper orientation, and not have the text be too small, especially if handwriting isn\u2019t the best. </paragraph><paragraph>Trace: <link href=\"https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b\"><underline>https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b</underline></link></paragraph><paragraph>Annotated Trace: </paragraph><file url=\"https://static.us.edusercontent.com/files/X6djc3jMHxxwUMhZvv6LyObg\" filename=\"CS182 learning coach (1).pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/69348099-8d98-8001-b717-d316a6897a8b"
            ],
            "attachments": [],
            "created_at": "2025-12-06T07:49:57.616116+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7415308,
            "author": "Siddharth Shashi",
            "project_title": "Special Participation E: ChatGPT Study Mode for Transformer and VAE understanding",
            "post_body": "Working through HW12 this week, I was struggling to remember specifics about transformer weight initializations and VAEs, so I wanted to brush up on concepts before solving the problems. I found myself I used ChatGPT's study mode for the first time, and I started out by asking it general questions about how things are supposed to work in these models. After asking me about my prior understandings of things, it was able to give me relevant, helpful pointers and ask me questions along the way to ensure I was retaining the information. I then asked it to give me follow-up questions to quiz me on these concepts and it was able to not only give me questions but also nudge me towards correct answers without revealing them in the case that I got questions wrong. Overall this was super useful, and I'll definitely use study mode in the future. \n\n\n\nLink to conversation: https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd \n\nPDF of same conversation: ",
            "content_xml": "<document version=\"2.0\"><paragraph>Working through HW12 this week, I was struggling to remember specifics about transformer weight initializations and VAEs, so I wanted to brush up on concepts before solving the problems. I found myself I used ChatGPT's study mode for the first time, and I started out by asking it general questions about how things are supposed to work in these models. After asking me about my prior understandings of things, it was able to give me relevant, helpful pointers and ask me questions along the way to ensure I was retaining the information. I then asked it to give me follow-up questions to quiz me on these concepts and it was able to not only give me questions but also nudge me towards correct answers without revealing them in the case that I got questions wrong. Overall this was super useful, and I'll definitely use study mode in the future. </paragraph><paragraph/><paragraph>Link to conversation: <link href=\"https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd\">https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd</link> </paragraph><paragraph>PDF of same conversation: </paragraph><file url=\"https://static.us.edusercontent.com/files/pjKnDqW9B1pUzWfEV7qaUpio\" filename=\"Study Mode - Transformer model explanation.html.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/6933394a-efbc-800a-b492-f90d6676a4dd"
            ],
            "attachments": [],
            "created_at": "2025-12-06T07:16:54.634934+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7415075,
            "author": "Alena Chao",
            "project_title": "Special Participation C: HW3 Coding",
            "post_body": "Natalie Wei and I refactored HW3 Question 2 on MuP with the goal of improving clarity, usability, and overall student experience. Our updates include adding comprehensive docstrings to the majority of functions, clearly describing their purpose, expected inputs, and return values. We also introduced consistent type hints throughout the notebook to make the code easier to read and reduce ambiguity for students working through the assignment. Finally, we revised and expanded the TODO sections by adding more explicit comments, clarifying the required steps, and providing gentle hints to help students get started without giving away the full solution.",
            "content_xml": "<document version=\"2.0\"><paragraph>Natalie Wei and I refactored HW3 Question 2 on MuP with the goal of improving clarity, usability, and overall student experience. Our updates include adding comprehensive docstrings to the majority of functions, clearly describing their purpose, expected inputs, and return values. We also introduced consistent type hints throughout the notebook to make the code easier to read and reduce ambiguity for students working through the assignment. Finally, we revised and expanded the TODO sections by adding more explicit comments, clarifying the required steps, and providing gentle hints to help students get started without giving away the full solution.</paragraph><file url=\"https://static.us.edusercontent.com/files/M3iTSB84GD5HySEclenKE5tn\" filename=\"q_mup_coding_refactored.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T06:44:31.168642+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7415017,
            "author": "Xuanlin Mao",
            "project_title": "Special Participation E: Using Gemini to Analyze Lecture Topics and S4-to-Mamba Model Lineage through Paper Comparison",
            "post_body": "For this special participation, I focused on using Gemini 3 to investigate the classical papers related to a lecture topic and to build a clearer conceptual map of the model family from S4 to Mamba. Starting from my lecture notes, I asked Gemini to identify the foundational papers and discovered several intermediate models that bridge S4 and Mamba.\n\nBased on its suggestions, I downloaded and uploaded four key papers\u2014S4, S4D, S5, and Mamba\u2014and constructed a detailed prompt asking Gemini to compare them along multiple dimensions: publication timeline, inheritance relationships, shared ideas, distinguishing innovations, strengths, use cases, models incorporating them, as well as each model\u2019s motivation, addressed problems, core formulas, and computational complexity.\n\nI then organized Gemini\u2019s output into a clean LaTeX summary for efficient reading and study.\n\nMy main contribution in this participation was providing a well-structured, robust prompt that enabled consistent, detailed, and technically accurate comparisons across the four models. This process showed how AI tools can support deeper literature understanding and accelerate technical synthesis for exam preparation or future research.\n\nTranscript and report:\n\nhttps://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation, I focused on using Gemini 3 to investigate the classical papers related to a lecture topic and to build a clearer conceptual map of the model family from S4 to Mamba. Starting from my lecture notes, I asked Gemini to identify the foundational papers and discovered several intermediate models that bridge S4 and Mamba.</paragraph><paragraph>Based on its suggestions, I downloaded and uploaded four key papers\u2014S4, S4D, S5, and Mamba\u2014and constructed a detailed prompt asking Gemini to compare them along multiple dimensions: publication timeline, inheritance relationships, shared ideas, distinguishing innovations, strengths, use cases, models incorporating them, as well as each model\u2019s motivation, addressed problems, core formulas, and computational complexity.</paragraph><paragraph>I then organized Gemini\u2019s output into a clean LaTeX summary for efficient reading and study.</paragraph><paragraph>My main contribution in this participation was providing a well-structured, robust prompt that enabled consistent, detailed, and technically accurate comparisons across the four models. This process showed how AI tools can support deeper literature understanding and accelerate technical synthesis for exam preparation or future research.</paragraph><paragraph>Transcript and report:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing\">https://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing</link> </paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1NTmOqwLrrQzzam7WrDkMxx9e6rS997VB/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-06T06:35:20.341026+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7414974,
            "author": "Alena Chao",
            "project_title": "Special Participation B: ChatGPT-5.1 on HW0 coding",
            "post_body": "I used ChatGPT to solve HW0 question 6. In general it performed very strong, being able to one-shot the questions. Common patterns also included adding comments for explanations and potential tricky parts of the code. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/94TrxdgeCMvhAy0hGRYaq00b\" filename=\"CS182_Special_Participation_B.pdf\"/><paragraph>I used ChatGPT to solve HW0 question 6. In general it performed very strong, being able to one-shot the questions. Common patterns also included adding comments for explanations and potential tricky parts of the code. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T06:29:42.388623+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7414931,
            "author": "Alena Chao",
            "project_title": "Special Participation A: ChatGPT-5.1 on HW0",
            "post_body": "I tested ChatGPT's ability to solve HW0 questions 2-5. In general, it was able to one-shot the problems while explaining its reasoning, most likely because many of the problems review fundamental ML/math concepts.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/fdFZgmz9daDV37SF1a0wX1V3\" filename=\"CS182_Special_Participation_A.pdf\"/><paragraph>I tested ChatGPT's ability to solve HW0 questions 2-5. In general, it was able to one-shot the problems while explaining its reasoning, most likely because many of the problems review fundamental ML/math concepts.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T06:24:29.195133+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7414836,
            "author": "Moxin Tang",
            "project_title": "Special Participation B: ChatGPT5.1 on hw12",
            "post_body": "I tried a small experiment to see how well GPT-5.1 can handle the coding parts of HW6. I gave it the actual homework files and asked it to scan for TODOs, explain each one, and then fill in the required code step by step. Surprisingly, it followed the instructions very strictly, didn\u2019t skip ahead, and the solutions it produced (like the logistic-loss updates for MAML and the reparameterization/ELBO code for the VAE) were all correct and clean. It also stayed inside the required code blocks and didn\u2019t hallucinate anything extra.\n\nI\u2019ve attached the full interaction and results below.\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I tried a small experiment to see how well GPT-5.1 can handle the coding parts of HW6. I gave it the actual homework files and asked it to scan for TODOs, explain each one, and then fill in the required code step by step. Surprisingly, it followed the instructions very strictly, didn\u2019t skip ahead, and the solutions it produced (like the logistic-loss updates for MAML and the reparameterization/ELBO code for the VAE) were all correct and clean. It also stayed inside the required code blocks and didn\u2019t hallucinate anything extra.</paragraph><paragraph><bold>I\u2019ve attached the full interaction and results below.</bold><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/KtVpMGp7GA4L8W0IhXS4mBjJ\" filename=\"hw12-q_maml.pdf\"/><file url=\"https://static.us.edusercontent.com/files/9Y7NLBFEjIVTQozbIwyM8NaD\" filename=\"hw12-q_vae.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-06T06:13:04.202334+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412939,
            "author": "Etaash Patel",
            "project_title": "Special Participation E: ChatGPT Study Mode For Creating Mind Maps",
            "post_body": "To prepare more effectively for the final, I wanted to strengthen my conceptual understanding, improve recall, and practice articulating answers in a more formal style that would earn more credit on the exam. I decided to try a tool I first encountered in a history class: mindmaps. I asked ChatGPT to help guide me through building one. The process went as follows:\n\nChatGPT would prompt me to form a connection between two topics.\n\nI would attempt to articulate the relationship.\n\nChatGPT would evaluate my response and provide feedback.\n\nI could ask follow-up questions or push back where I disagreed.\n\nWe repeated this over 10 rounds (about an hour).\n\nAt the end, ChatGPT compiled a consolidated list of connections and highlighted areas I should review.\n\nOverall, I found the process helpful. Although ChatGPT was occasionally incorrect or unclear, the conversational format made the exercise valuable even when these hallucinations took place.\n\nDisclaimer: I made many mistakes throughout this log\u2014particularly on diffusion. The value of this log is in illustrating how you might use ChatGPT to help build your own mindmap, rather than as a source of fully correct answers.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/4aPk5tBOoFqUpcl5c0b3cVCw\" filename=\"ChatGPT Study Mode - Mind map creation.pdf\"/><paragraph>To prepare more effectively for the final, I wanted to strengthen my conceptual understanding, improve recall, and practice articulating answers in a more formal style that would earn more credit on the exam. I decided to try a tool I first encountered in a history class: <bold>mindmaps</bold>. I asked ChatGPT to help guide me through building one. The process went as follows:</paragraph><list style=\"unordered\"><list-item><paragraph>ChatGPT would prompt me to form a connection between two topics.</paragraph></list-item><list-item><paragraph>I would attempt to articulate the relationship.</paragraph></list-item><list-item><paragraph>ChatGPT would evaluate my response and provide feedback.</paragraph></list-item><list-item><paragraph>I could ask follow-up questions or push back where I disagreed.</paragraph></list-item><list-item><paragraph>We repeated this over <bold>10 rounds (about an hour)</bold>.</paragraph></list-item><list-item><paragraph>At the end, ChatGPT compiled a consolidated list of connections and highlighted areas I should review.</paragraph></list-item></list><paragraph>Overall, I found the process helpful. Although ChatGPT was occasionally incorrect or unclear, the conversational format made the exercise valuable even when these hallucinations took place.</paragraph><paragraph><bold>Disclaimer:</bold> I made many mistakes throughout this log\u2014particularly on diffusion. The value of this log is in illustrating how you might use ChatGPT to help <italic>build your own</italic> mindmap, rather than as a source of fully correct answers.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T20:09:15.571245+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412925,
            "author": "Tamzid Razzaque",
            "project_title": "Special Participation E: Custom EECS182 GPT",
            "post_body": "I created a custom GPT to act as an EECS182 learning assistant and uploaded all of the homework solutions and discussion materials so it would have full context about the types of questions students encounter. In the instructions, I made it very clear that it should never output homework answers, and during testing it consistently respected that boundary. Even when I pushed it toward specific problems, it stayed at the level of concepts, reasoning steps, and intuition, showing that the guardrails were effective even though it had access to the underlying solutions.\n\nIn use, the GPT was most helpful when teaching high-level ideas. It gave clear explanations of optimizers, normalization layers, CNNs, ResNets, muP, transformers, and other topics across the course. It adapted well when I asked follow-up questions and diagnosed misconceptions by asking clarifying questions. It handled examples in a way that helped me build intuition without revealing anything that would compromise assignments.\n\nThe limitations showed up with solving new homework problems. It sometimes overstated certain claims, especially around muP and normalization layers, and occasionally inserted extra details that were not fully grounded in the course material. These moments required me to slow it down or ask it to justify its statements. The GPT responded well to that prompting and corrected itself once guided, which highlighted the importance of interacting critically rather than passively accepting its answers.\n\nOverall, the GPT works well as a study tool. It is strong at building intuition, explaining conceptual structures, and highlighting the relationships between architectures, optimizers, and training dynamics. It is weaker when asked for mathematically precise statements unless I guide it step by step. Even with that limitation, it provides a useful and interactive way to understand course topics while remaining safe with respect to homework solutions, thanks to the strict instruction boundaries and its consistent refusal to output any solution content. Engaging with it this way reinforced the course\u2019s idea that AI can help students learn how to fish rather than simply handing them the answers.\n\nHere is the link to the custom GPT: https://chatgpt.com/g/g-69324fd3e6348191a04e12d3bf78ceb8-eecs182-helper\n\nBelow is the trace with commentary at the end:\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I created a custom GPT to act as an EECS182 learning assistant and uploaded all of the homework solutions and discussion materials so it would have full context about the types of questions students encounter. In the instructions, I made it very clear that it should never output homework answers, and during testing it consistently respected that boundary. Even when I pushed it toward specific problems, it stayed at the level of concepts, reasoning steps, and intuition, showing that the guardrails were effective even though it had access to the underlying solutions.</paragraph><paragraph>In use, the GPT was most helpful when teaching high-level ideas. It gave clear explanations of optimizers, normalization layers, CNNs, ResNets, muP, transformers, and other topics across the course. It adapted well when I asked follow-up questions and diagnosed misconceptions by asking clarifying questions. It handled examples in a way that helped me build intuition without revealing anything that would compromise assignments.</paragraph><paragraph>The limitations showed up with solving new homework problems. It sometimes overstated certain claims, especially around muP and normalization layers, and occasionally inserted extra details that were not fully grounded in the course material. These moments required me to slow it down or ask it to justify its statements. The GPT responded well to that prompting and corrected itself once guided, which highlighted the importance of interacting critically rather than passively accepting its answers.</paragraph><paragraph>Overall, the GPT works well as a study tool. It is strong at building intuition, explaining conceptual structures, and highlighting the relationships between architectures, optimizers, and training dynamics. It is weaker when asked for mathematically precise statements unless I guide it step by step. Even with that limitation, it provides a useful and interactive way to understand course topics while remaining safe with respect to homework solutions, thanks to the strict instruction boundaries and its consistent refusal to output any solution content. Engaging with it this way reinforced the course\u2019s idea that AI can help students learn how to fish rather than simply handing them the answers.</paragraph><paragraph>Here is the link to the custom GPT: https://chatgpt.com/g/g-69324fd3e6348191a04e12d3bf78ceb8-eecs182-helper<break/><break/>Below is the trace with commentary at the end:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/7Xd0QwIUTw338N0B1pFoXkZX\" filename=\"trace_with_commentary.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T20:00:15.941066+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412832,
            "author": "Moxin Tang",
            "project_title": "Special Participation A: Kimi on HW6",
            "post_body": "Summary of Kimi Performance on HW6\n\nI tested Kimi AI\u2019s ability to solve problems from hw6 focusing on GNN architectures. \n\nOverall, Kimi demonstrated strong reasoning capability across most questions. It correctly handled:\n\nLinear algebraic interpretations of GNN message passing\n\nInductive proofs involving adjacency matrix powers\n\nIdentification of valid permutation-invariant update rules\n\nLoss computation using masked training nodes\n\nInterpretation of max aggregation\n\nAnalysis of computational scaling in GraphNet architectures\n\nFor these, Kimi\u2019s reasoning was correct and aligned with the solutions.\n\nWeaknesses\n\nTends to produce over-engineered answers when a simpler one is expected\n\nOccasionally misidentifies structural details (e.g., graph neighbors)\n\nDoes not always verify provided diagrams or datasets before proceeding\n\n\nThe following LaTeX document compiles and evaluates Kimi\u2019s responses from the linked chat session. \n\nClick the link to view conversation: https://www.kimi.com/share/19aed915-2932-8b91-8000-0000bdfd7ac0\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"1\"><bold>Summary of Kimi Performance on HW6</bold></heading><paragraph>I tested Kimi AI\u2019s ability to solve problems from hw6 focusing on GNN architectures. </paragraph><paragraph>Overall, Kimi demonstrated <bold>strong reasoning capability</bold> across most questions. It correctly handled:</paragraph><list style=\"unordered\"><list-item><paragraph>Linear algebraic interpretations of GNN message passing</paragraph></list-item><list-item><paragraph>Inductive proofs involving adjacency matrix powers</paragraph></list-item><list-item><paragraph>Identification of valid permutation-invariant update rules</paragraph></list-item><list-item><paragraph>Loss computation using masked training nodes</paragraph></list-item><list-item><paragraph>Interpretation of max aggregation</paragraph></list-item><list-item><paragraph>Analysis of computational scaling in GraphNet architectures</paragraph></list-item></list><paragraph>For these, Kimi\u2019s reasoning was correct and aligned with the solutions.</paragraph><heading level=\"3\"><bold>Weaknesses</bold></heading><list style=\"unordered\"><list-item><paragraph>Tends to produce over-engineered answers when a simpler one is expected</paragraph></list-item><list-item><paragraph>Occasionally misidentifies structural details (e.g., graph neighbors)</paragraph></list-item><list-item><paragraph>Does not always verify provided diagrams or datasets before proceeding<break/></paragraph></list-item></list><paragraph>The following LaTeX document compiles and evaluates Kimi\u2019s responses from the linked chat session. </paragraph><file url=\"https://static.us.edusercontent.com/files/9E03ab9ZOiphxd6921xB7qEj\" filename=\"Kimi_hw6.pdf\"/><paragraph>Click the link to view conversation: https://www.kimi.com/share/19aed915-2932-8b91-8000-0000bdfd7ac0<break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T19:12:30.361236+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412717,
            "author": "Nicolas Rault-Wang",
            "project_title": "Special Participation D: HW6 Exploration of the Polar Express (Muon Variant) & Lion Optimizers",
            "post_body": "I added four additional parts to the Implementing Muon question in homework 6, providing a guided exploration of two recent computationally-efficient optimizer alternatives to Muon and AdamW:\n\n Polar Express (Muon Variant) and\n\n Lion (EvoLved Sign Momentum)\n\nNew question summary:\n\n(Code) An introduction to Polar Express, a variant of Muon that replaces Newton-Schulz orthogonalization with a schedule of minimax-optimized polynomials. Since compute efficiency is a core feature of this variant, the question challenges you to find an efficient (minimal matmuls) PyTorch implementation for the update $$X_{k+1}\\leftarrow  \\alpha_k X_k+ \\beta_k X_k^3 + \\gamma_k X_k^5$$\n\n(Code) An intro to the Lion optimizer, a memory-efficient, non-adaptive optimizer that relies on the sign function of an interpolation of momentum and gradient tensors to determine the update direction.\n\n(Written) Empirical evaluation of Muon+PolarExpress, Muon+Newton-Schulz, Lion, AdamW, and SGD.\n\n(Optional) Hyperparameter tuning for Polar Express and Lion to ensure fair comparisons.\n\nI've included the blank and solution notebooks for you below. \n\nColab links:\n\nblank notebook\n\nsolution notebook\n\nNotebook files:\n\nLinks for the archive:\n\nPersonal website: https://nraultwang.github.io/, Github: https://github.com/nraultwang",
            "content_xml": "<document version=\"2.0\"><paragraph>I added four additional parts to the Implementing Muon question in homework 6, providing a guided exploration of two recent computationally-efficient optimizer alternatives to Muon and AdamW:</paragraph><list style=\"bullet\"><list-item><paragraph> <link href=\"https://arxiv.org/abs/2505.16932\"><bold>Polar Express</bold></link> (Muon Variant) and</paragraph></list-item><list-item><paragraph> <link href=\"https://arxiv.org/abs/2302.06675\"><bold>Lion</bold></link> (EvoLved Sign Momentum)</paragraph></list-item></list><paragraph>New question summary:</paragraph><list style=\"number\"><list-item><paragraph>(Code) An introduction to Polar Express, a variant of Muon that replaces Newton-Schulz orthogonalization with a schedule of minimax-optimized polynomials. Since compute efficiency is a core feature of this variant, the question challenges you to find an efficient (minimal matmuls) PyTorch implementation for the update $$X_{k+1}\\leftarrow  \\alpha_k X_k+ \\beta_k X_k^3 + \\gamma_k X_k^5$$</paragraph></list-item><list-item><paragraph>(Code) An intro to the Lion optimizer, a memory-efficient, non-adaptive optimizer that relies on the sign function of an interpolation of momentum and gradient tensors to determine the update direction.</paragraph></list-item><list-item><paragraph>(Written) Empirical evaluation of Muon+PolarExpress, Muon+Newton-Schulz, Lion, AdamW, and SGD.</paragraph></list-item><list-item><paragraph>(Optional) Hyperparameter tuning for Polar Express and Lion to ensure fair comparisons.</paragraph></list-item></list><figure><image src=\"https://static.us.edusercontent.com/files/KD7Wh9TXKrFaxk9WhzhtPFO3\" width=\"659\" height=\"326.17171717171715\"/></figure><paragraph>I've included the blank and solution notebooks for you below. </paragraph><paragraph>Colab links:</paragraph><list style=\"bullet\"><list-item><paragraph><link href=\"https://colab.research.google.com/github/nraultwang/cs182/blob/main/hw06/code/NRW_SP-D_q_coding_muon_BLANK.ipynb\">blank notebook</link></paragraph></list-item><list-item><paragraph><link href=\"https://colab.research.google.com/github/nraultwang/cs182/blob/main/hw06/code/NRW_SP-D_q_coding_muon_SOLUTION.ipynb\">solution notebook</link></paragraph></list-item></list><paragraph>Notebook files:</paragraph><file url=\"https://static.us.edusercontent.com/files/af5PCw5MAtKRTsAzGVaLxGwF\" filename=\"NRW_SP-D_q_coding_muon_BLANK.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/Ux7IFCbxWaBpSiJL1NhsYKWp\" filename=\"NRW_SP-D_q_coding_muon_SOLUTION.ipynb\"/><paragraph>Links for the archive:</paragraph><paragraph>Personal website: <link href=\"https://nraultwang.github.io/\">https://nraultwang.github.io/</link>, Github: <link href=\"https://github.com/nraultwang\">https://github.com/nraultwang</link></paragraph></document>",
            "links": [
                "https://arxiv.org/abs/2505.16932",
                "https://arxiv.org/abs/2302.06675",
                "https://colab.research.google.com/github/nraultwang/cs182/blob/main/hw06/code/NRW_SP-D_q_coding_muon_BLANK.ipynb",
                "https://colab.research.google.com/github/nraultwang/cs182/blob/main/hw06/code/NRW_SP-D_q_coding_muon_SOLUTION.ipynb",
                "https://nraultwang.github.io/",
                "https://github.com/nraultwang"
            ],
            "attachments": [],
            "created_at": "2025-12-05T18:22:52.659984+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412632,
            "author": "Guohao Lv",
            "project_title": "Special Participation A: Claude on HW6",
            "post_body": "I looked at how well Claude AI could solve the non-coding questions on Homework 6. I provided Claude with the prompts and context from the HW6 PDF, asking it to work through the problems step-by-step.\n\nAnalysis: Claude was generally able to one-shot the non-coding questions with minimal intervention. For the application/intuition questions (molecular graphs, CNN\u2013GNN analogies, handling missing node values, and scaling/computation of GNNs), Claude\u2019s answers were detailed, on-topic, and made sensible connections to course concepts; if anything, they tended toward being a bit verbose but stayed accurate (maybe not totally accurate, but I think the answers are all reasonable) and grounded in the homework setup.\n\nI did not observe clear hallucinations or places where Claude invented nonexistent assumptions; when it extended beyond the literal question (e.g., suggesting multiple practical strategies for missing-feature handling), those additions were still consistent with standard GNN practice. Minor issues were mostly stylistic\u2014some redundancy, slightly heavy notation, and occasional over-explaining\u2014but they did not affect correctness. Overall, Claude\u2019s non-coding HW6 answers show strong reliability on both formal reasoning and conceptual explanation, and would be usable as high-quality solutions or study notes with only light editing for concision.",
            "content_xml": "<document version=\"2.0\"><paragraph>I looked at how well Claude AI could solve the non-coding questions on Homework 6. I provided Claude with the prompts and context from the HW6 PDF, asking it to work through the problems step-by-step.</paragraph><paragraph>Analysis: Claude was generally able to one-shot the non-coding questions with minimal intervention. For the application/intuition questions (molecular graphs, CNN\u2013GNN analogies, handling missing node values, and scaling/computation of GNNs), Claude\u2019s answers were detailed, on-topic, and made sensible connections to course concepts; if anything, they tended toward being a bit verbose but stayed accurate (maybe not totally accurate, but I think the answers are all reasonable) and grounded in the homework setup.</paragraph><paragraph>I did not observe clear hallucinations or places where Claude invented nonexistent assumptions; when it extended beyond the literal question (e.g., suggesting multiple practical strategies for missing-feature handling), those additions were still consistent with standard GNN practice. Minor issues were mostly stylistic\u2014some redundancy, slightly heavy notation, and occasional over-explaining\u2014but they did not affect correctness. Overall, Claude\u2019s non-coding HW6 answers show strong reliability on both formal reasoning and conceptual explanation, and would be usable as high-quality solutions or study notes with only light editing for concision.</paragraph><file url=\"https://static.us.edusercontent.com/files/XFUv5ST8W5s71KCpex1rl7uK\" filename=\"HW6.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T17:56:51.215172+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412493,
            "author": "Justin Li",
            "project_title": "Special Participation E: Discussion at Home",
            "post_body": "I find going to discussion one of the most helpful parts of this class when it comes to learning content because I get to ask TAs questions live. However, access to TAs is limited by time and schedule, so I designed and tested a ChatGPT \u201cDiscussion TA\u201d that replicates aspects of the in person discussion experience. This tool can help guide users through discussion worksheets interactively, going problem by problem and checking my understanding while providing explanations and concepts from the lecture.\n\nI want it to help me master concepts from the discussions, and I want to have some sort of simulation of TA-student interaction that can supplement the interactions I have in discussion. \n\nIn order to prime ChatGPT, I use the prompt attached below. It operates by taking in the discussion questions and solutions as well as relevant lecture notes. It then walks through each discussion question one by one, allowing for student response to each question and evaluates the response based on the following scenarios.\n\nIf the answer is correct, it confirms that the student is correct and provides a short explanation using lecture intuition\n\nIf the answer is almost correct, it identifies the necessary concepts to understand and provides a hint, allowing me to try again\n\nIf my answer is wrong, then it identifies the necessary concept to understand and explains it using intuition from the lecture, and allows me to try again.\n\nI used this system on the exam related questions on discussion 12 (Questions 1 and 2) and found it very helpful. A lot of the explanations it provided me were very intuitive and simplified, easy for a beginning to understand. Additionally, it provided many different intuitions for each concept, which was awesome. It could take in both typed answers as well as screenshots of written answers, which is super helpful since it would allow me to submit mathematical expressions easier. There were scenarios where I had to prompt it a bit more on questions that I had expressed uncertainty about, but when prompted it provided great explanations. It was able to correct me and provide good explanations whenever I answered a question wrong. Overall, I found the tool very useful.\n\nBelow, I have attached the prompt I used, as well as an annotated trace of my experience with the AI \u201cDiscussion TA\u201d.\n\nTrace:  https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharing\n\nPrompt: \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I find going to discussion one of the most helpful parts of this class when it comes to learning content because I get to ask TAs questions live. However, access to TAs is limited by time and schedule, so I designed and tested a ChatGPT \u201cDiscussion TA\u201d that replicates aspects of the in person discussion experience. This tool can help guide users through discussion worksheets interactively, going problem by problem and checking my understanding while providing explanations and concepts from the lecture.</paragraph><paragraph>I want it to help me master concepts from the discussions, and I want to have some sort of simulation of TA-student interaction that can supplement the interactions I have in discussion. </paragraph><paragraph>In order to prime ChatGPT, I use the prompt attached below. It operates by taking in the discussion questions and solutions as well as relevant lecture notes. It then walks through each discussion question one by one, allowing for student response to each question and evaluates the response based on the following scenarios.</paragraph><list style=\"ordered\"><list-item><paragraph>If the answer is correct, it confirms that the student is correct and provides a short explanation using lecture intuition</paragraph></list-item><list-item><paragraph>If the answer is almost correct, it identifies the necessary concepts to understand and provides a hint, allowing me to try again</paragraph></list-item><list-item><paragraph>If my answer is wrong, then it identifies the necessary concept to understand and explains it using intuition from the lecture, and allows me to try again.</paragraph></list-item></list><paragraph>I used this system on the exam related questions on discussion 12 (Questions 1 and 2) and found it very helpful. A lot of the explanations it provided me were very intuitive and simplified, easy for a beginning to understand. Additionally, it provided many different intuitions for each concept, which was awesome. It could take in both typed answers as well as screenshots of written answers, which is super helpful since it would allow me to submit mathematical expressions easier. There were scenarios where I had to prompt it a bit more on questions that I had expressed uncertainty about, but when prompted it provided great explanations. It was able to correct me and provide good explanations whenever I answered a question wrong. Overall, I found the tool very useful.</paragraph><paragraph>Below, I have attached the prompt I used, as well as an annotated trace of my experience with the AI \u201cDiscussion TA\u201d.<break/><break/>Trace:  <link href=\"https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharing\">https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharing</link></paragraph><paragraph>Prompt: </paragraph><file url=\"https://static.us.edusercontent.com/files/K16jyoXr5hhOc35rFhOCIEuy\" filename=\"discussion at home.pdf\"/><paragraph/></document>",
            "links": [
                "https://drive.google.com/file/d/15mMJCvaBDp-hnzXBJqMoKvAgrBTN6R7j/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-05T17:21:01.314551+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412465,
            "author": "Qicheng Zhu",
            "project_title": "Special Participation B: KIMI K2 on HW 1 Coding Questions",
            "post_body": "Model Tested: KIMI K2\n\nDomain: Homework1 Coding part -- Accelerating Gradient Descent with Momentum\n\nPerformance Overview:\n\nIn this experiment, I evaluated the performance of KIMI K2 on a deep learning homework task that involved implementing and analyzing gradient descent with momentum. The homework consisted of two main coding parts:\n\nThe first part is implementing gradient descent with momentum.\n\nThe second part is exploring learning rate for faster convergence.\n\nTo assess model robustness, I designed two experiments to explore the importance of background knowledge:\n\nExperiment 1: No Background Knowledge\nThe model was prompted directly with coding tasks, without any formulas or context.\nThe solution was partially correct, but there were subtle differences. KIMI K2 used a slightly different formulation for momentum (using different coefficient). The code still worked, but was not fully aligned with the provided formula.\n\nExperiment 2: With Background Knowledge\nI provided KIMI K2 with the correct mathematical equations for momentum before asking the question again. After receiving the formulas, the model produced the correct implementation. This suggests that additional mathematical grounding improves reliability.\n\nI further tested whether the input format affects performance. I supplied the same task using jupyter notebook or screenshots photos. In each case, KIMI K2 successfully generated the correct answer, indicating strong multimodal consistency.\n\nOverall, KIMI K2 can correctly solve non-trivial coding questions involving optimization algorithms. The model benefits from being given mathematical context, but once the formulas are provided, it can generalize across multiple input formats.\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold><bold>Model Tested: </bold></bold>KIMI K2</paragraph><paragraph><bold><bold>Domain: </bold></bold>Homework1 Coding part -- Accelerating Gradient Descent with Momentum</paragraph><paragraph><bold><bold>Performance Overview:</bold></bold></paragraph><paragraph>In this experiment, I evaluated the performance of KIMI K2 on a deep learning homework task that involved implementing and analyzing gradient descent with momentum. The homework consisted of two main coding parts:</paragraph><paragraph>The first part is implementing gradient descent with momentum.</paragraph><paragraph>The second part is exploring learning rate for faster convergence.</paragraph><paragraph>To assess model robustness, I designed two experiments to explore the importance of background knowledge:</paragraph><paragraph><bold><bold>Experiment 1: No Background Knowledge</bold></bold><break/>The model was prompted directly with coding tasks, without any formulas or context.<break/>The solution was partially correct, but there were subtle differences. KIMI K2 used a slightly different formulation for momentum (using different coefficient). The code still worked, but was not fully aligned with the provided formula.</paragraph><paragraph><bold><bold>Experiment 2: With Background Knowledge</bold></bold><break/>I provided KIMI K2 with the correct mathematical equations for momentum before asking the question again. After receiving the formulas, the model produced the correct implementation. This suggests that additional mathematical grounding improves reliability.</paragraph><paragraph>I further tested whether the <bold><bold>input format</bold></bold> affects performance. I supplied the same task using jupyter notebook or screenshots photos. In each case, KIMI K2 successfully generated the correct answer, indicating strong multimodal consistency.</paragraph><paragraph>Overall, KIMI K2 can correctly solve non-trivial coding questions involving optimization algorithms. The model benefits from being given mathematical context, but once the formulas are provided, it can generalize across multiple input formats.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/C77FL90cclfmYLcHFcpcdcuH\" filename=\"ParticipationB_ KIMI_HW1_QichengZhu.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T17:14:26.498598+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412401,
            "author": "Xuanlin Mao",
            "project_title": "Special Participation E: Using Gemini to Convert Handwritten Notes into Structured Learning Materials",
            "post_body": "This is the special participation E1 of Xuanlin.\n\nFor this special participation, my motivation was to make my lecture notes more intuitive for final exam review. Although the notes can be converted to LaTeX and handwritten content, the raw text alone often felt dense and hard to digest.\n\nI used Gemini 3 Canvas to convert my notes into structured slides and mind maps, creating a clear logical flow and visually highlighting key concepts. During this process, I also addressed practical issues, such as LaTeX rendering errors in Gemini-generated slides, by refining prompts and correcting miscompiled formulas.\n\nMy contribution includes providing a stable, bug-free prompt that reliably generates slides and visualizations from handwritten/LaTeX notes, making complex material easier to navigate. The stable version of prompts I used are included in the report.\n\nReport: \n\nhttps://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph>This is the special participation E1 of Xuanlin.</paragraph><paragraph>For this special participation, my motivation was to make my lecture notes more intuitive for final exam review. Although the notes can be converted to LaTeX and handwritten content, the raw text alone often felt dense and hard to digest.</paragraph><paragraph>I used Gemini 3 Canvas to convert my notes into structured slides and mind maps, creating a clear logical flow and visually highlighting key concepts. During this process, I also addressed practical issues, such as LaTeX rendering errors in Gemini-generated slides, by refining prompts and correcting miscompiled formulas.</paragraph><paragraph>My contribution includes providing a stable, bug-free prompt that reliably generates slides and visualizations from handwritten/LaTeX notes, making complex material easier to navigate. The stable version of prompts I used are included in the report.</paragraph><paragraph>Report: </paragraph><paragraph><link href=\"https://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing\">https://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing</link> </paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1i-exJI2huQq35sT4_WRH5HNqekm5HMl9/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-05T16:59:12.629022+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412314,
            "author": "Kithmini Herath",
            "project_title": "Special Participation C: Refactoring HW 5 Q5",
            "post_body": "Hi all, \n\nI refactored the coding problem Q5 (understanding dropout) of HW5 while preserving its teaching value. I've created a GitHub repository, with the refactored notebooks at: https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/ \n\nIn summary I did the following modifications with Claude Code: \n\nModularizing the original monolithic notebook \n\nEnsuring reproducibility between runs by setting seeds\n\nType hinting and documentation \n\nConfigured and tested code to run on Google Colab\n\nA more detailed explanation of my refactoring process is included in the following report:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all, </paragraph><paragraph>I refactored the coding problem Q5 (understanding dropout) of HW5 while preserving its teaching value. I've created a GitHub repository, with the refactored notebooks at: <link href=\"https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/\">https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/</link> </paragraph><paragraph>In summary I did the following modifications with Claude Code: </paragraph><list style=\"number\"><list-item><paragraph>Modularizing the original monolithic notebook </paragraph></list-item><list-item><paragraph>Ensuring reproducibility between runs by setting seeds</paragraph></list-item><list-item><paragraph>Type hinting and documentation </paragraph></list-item><list-item><paragraph>Configured and tested code to run on Google Colab</paragraph></list-item></list><paragraph>A more detailed explanation of my refactoring process is included in the following report:</paragraph><file url=\"https://static.us.edusercontent.com/files/sZpcXBuTJdyPgoPw5xvKXucm\" filename=\"HW5_Q5_code_refactor_report.pdf\"/><paragraph/></document>",
            "links": [
                "https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/"
            ],
            "attachments": [],
            "created_at": "2025-12-05T16:40:10.38309+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7412182,
            "author": "John Chang",
            "project_title": "Special Participation B: Kimi on HW7 Coding Tasks",
            "post_body": "For this task, I decided to use Kimi on the coding tasks for Homework 7.\n\nThis homework had a good amount of coding with different tasks presented, including implementing equations and model architectures, fine-tuning hyperparameters, and producing graphs for model training. \n\nMy methodology was to give Kimi only the code and tell it to complete the TODO sections. If it struggled, I would provide it with more context from the previous cell's text. (For problem 5, I always gave Kimi the previous cell's context because the code was very barebones with no comments).  \n\nOverall, Kimi ran into a couple issues with some tasks -- implementing the squared loss for the autoencoder and implementing the masked autoencoder. It ultimately failed to implement the masked autoencoder due to its code not accounting for how random initialization would work in Colab. For most tasks, it was able to one-shot a solution. \n\nFor model training tasks, Kimi was able to one-shot the last-name RNN and provided code that brought the autoencoder up to 77% accuracy on MNIST (I just had to increase the epochs by 10). It was also able to correctly implement the graph-perspective notebook and achieve ideal separation between the three real distributions.\n\nIn the attached Drive link, I include annotations as well as links to the individual chats (one per question). Due to the limitations of the Kimi website being unable to convert the whole conversation into a PDF, I opted to copy only the code snippets it provided (and relevant results) into the annotated Google doc. Prompts are visible in the full conversations.\n\nhttps://drive.google.com/file/d/1Uv1auMsQrmr_4SZemQ89RIo0oU2vQNpM/view?usp=sharing\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this task, I decided to use Kimi on the coding tasks for Homework 7.</paragraph><paragraph>This homework had a good amount of coding with different tasks presented, including implementing equations and model architectures, fine-tuning hyperparameters, and producing graphs for model training. </paragraph><paragraph>My methodology was to give Kimi only the code and tell it to complete the TODO sections. If it struggled, I would provide it with more context from the previous cell's text. (For problem 5, I always gave Kimi the previous cell's context because the code was very barebones with no comments).  </paragraph><paragraph>Overall, Kimi ran into a couple issues with some tasks -- implementing the squared loss for the autoencoder and implementing the masked autoencoder. It ultimately failed to implement the masked autoencoder due to its code not accounting for how random initialization would work in Colab. For most tasks, it was able to one-shot a solution. </paragraph><paragraph>For model training tasks, Kimi was able to one-shot the last-name RNN and provided code that brought the autoencoder up to 77% accuracy on MNIST (I just had to increase the epochs by 10). It was also able to correctly implement the graph-perspective notebook and achieve ideal separation between the three real distributions.</paragraph><paragraph>In the attached Drive link, I include annotations as well as links to the individual chats (one per question). Due to the limitations of the Kimi website being unable to convert the whole conversation into a PDF, I opted to copy only the code snippets it provided (and relevant results) into the annotated Google doc. Prompts are visible in the full conversations.</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1Uv1auMsQrmr_4SZemQ89RIo0oU2vQNpM/view?usp=sharing\">https://drive.google.com/file/d/1Uv1auMsQrmr_4SZemQ89RIo0oU2vQNpM/view?usp=sharing</link></paragraph><paragraph/></document>",
            "links": [
                "https://drive.google.com/file/d/1Uv1auMsQrmr_4SZemQ89RIo0oU2vQNpM/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-05T16:13:24.987146+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411980,
            "author": "Mihir Rao",
            "project_title": "Special Participation B: GPT 5.1 on HW 3",
            "post_body": "I used GPT 5.1 on the coding portion of HW 3. I was surprised by the performance because it was rather worse than I had expected. I suspect more coding aligned models like Sonnet or Opus would do much better, but GPT 5.1 answer rather quickly on questions where it should have looked at more context, and extremely slowly on questions that were one or two line solutions.\n\nI also found that when these models fail at a task, it's much harder to get them to recover. Some intuition for this could be what we learned in class, with the distributions in probability being a result of auto-regressive nature. When we make a bad choice, it becomes harder to recover.\n\nSpecifically on part b, I had a lot of back and forth with the model and it would write a lot of code, try to change parts that it shouldn't change, and ultimately it needed a lot of hand-holding. From my experience, something like Cursor's setup would probably do better, since it's fine-tuned for tasks like these. My annotated trace with the model is attached below.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used GPT 5.1 on the coding portion of HW 3. I was surprised by the performance because it was rather worse than I had expected. I suspect more coding aligned models like Sonnet or Opus would do much better, but GPT 5.1 answer rather quickly on questions where it should have looked at more context, and extremely slowly on questions that were one or two line solutions.<break/><break/>I also found that when these models fail at a task, it's much harder to get them to recover. Some intuition for this could be what we learned in class, with the distributions in probability being a result of auto-regressive nature. When we make a bad choice, it becomes harder to recover.<break/><break/>Specifically on part b, I had a lot of back and forth with the model and it would write a lot of code, try to change parts that it shouldn't change, and ultimately it needed a lot of hand-holding. From my experience, something like Cursor's setup would probably do better, since it's fine-tuned for tasks like these. My annotated trace with the model is attached below.</paragraph><file url=\"https://static.us.edusercontent.com/files/VXpb50IHA1hITHGhT7UqzRNu\" filename=\"MR-B-182 2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T15:38:02.385054+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411761,
            "author": "Tianqu He",
            "project_title": "Special Participation E: The mathematical principles of Transformers not covered in class",
            "post_body": "Lectures 18\u201320 introduced the structure and mathematical foundations of Transformers, but there are still several important components that were not covered\u2014for example, why Transformers use LayerNorm or how the Feed-Forward Network (FFN) actually works. I want to use this thread to help everyone build a stronger foundational understanding of Transformers. These details, although not explicitly discussed in the lectures, are conceptually interesting and highly relevant. During my internship at ByteDance, I found that these questions are very common in LLM interviews. \n\nSo I asked ChatGPT about several topics that were not covered in the lectures and had it explain the answers in a way that everyone can follow. Of course, this document is far from a complete explanation of how Transformers work, but its purpose is to supplement the lecture material. We can read it together with our class notes for a more complete understanding.\n\nI have annotated some responses from ChatGPT. I attach the annotated conversation and a concise summarization.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Lectures 18\u201320 introduced the structure and mathematical foundations of Transformers, but there are still several important components that were not covered\u2014for example, why Transformers use LayerNorm or how the Feed-Forward Network (FFN) actually works. I want to use this thread to help everyone build a stronger foundational understanding of Transformers. These details, although not explicitly discussed in the lectures, are conceptually interesting and highly relevant. During my internship at ByteDance, I found that <bold>these questions are very common in LLM interviews.</bold> </paragraph><paragraph>So I asked ChatGPT about several topics that were not covered in the lectures and had it explain the answers in a way that everyone can follow. Of course, this document is far from a complete explanation of how Transformers work, but its purpose is to <bold>supplement the lecture material</bold>. We can read it together with our class notes for a more complete understanding.</paragraph><paragraph>I have annotated some responses from ChatGPT. I attach the annotated conversation and a concise summarization.</paragraph><file url=\"https://static.us.edusercontent.com/files/9EUdk8jHkidRCcbU9fn8YVvz\" filename=\"Conversation_ChatGPT.pdf\"/><file url=\"https://static.us.edusercontent.com/files/naT9AACtfolyMyrk7EmmITwW\" filename=\"Transformer_Notes.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T15:02:48.254781+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411740,
            "author": "Tianqu He",
            "project_title": "Special Participation D: HW7 RNN task using AdamW vs. SOAP",
            "post_body": "I created a student assignment notebook focused on the SOAP (ShampoO with Adam in the Preconditioner's eigenbasis) optimizer, consisting of two main parts:\n\nMathematical Implementation (Gradient Rotation):\n\nDesigned a coding task where students implement the core SOAP operation: projecting the gradient into the eigenbasis (Gprojected\u200b=QLT\u200b\u22c5G\u22c5QR\u200b).\n\nProvided a SimpleSOAP optimizer wrapper that integrates this student-written function to simulate matrix preconditioning.\n\nExperimental Analysis (RNN Stress Test):\n\nSet up the \"Adding Problem\" (a standard RNN benchmark) to test optimizer stability on long-term dependencies.\n\nConstructed a Hyperparameter Sensitivity Sweep comparing AdamW vs. SOAP across logarithmically spaced learning rates.\n\nIncluded visualization code to demonstrate SOAP's superior stability and \"shifted\" optimal learning rate window compared to AdamW.\n\nStudent notebook: https://colab.research.google.com/drive/15gAh01QQKscfbBbXvnGt7MgYOC3j4lTG#scrollTo=ZCwSKgXWW-nk\n\nSolutions:\n\nhttps://colab.research.google.com/drive/1-AdCaTn1n6D5ThprVc7sM0A3b7TIx09n#scrollTo=uNGvVyYhYJzP\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I created a student assignment notebook focused on the SOAP (<bold>S</bold>hampo<bold>O</bold> with <bold>A</bold>dam in the <bold>P</bold>reconditioner's eigenbasis) optimizer, consisting of two main parts:</paragraph><list style=\"ordered\"><list-item><paragraph>Mathematical Implementation (Gradient Rotation):</paragraph><list style=\"unordered\"><list-item><paragraph>Designed a coding task where students implement the core SOAP operation: projecting the gradient into the eigenbasis (G<sub>projected</sub>\u200b=Q<sub>L</sub><sup>T</sup>\u200b\u22c5G\u22c5Q<sub>R</sub>\u200b).</paragraph></list-item><list-item><paragraph>Provided a <code>SimpleSOAP</code> optimizer wrapper that integrates this student-written function to simulate matrix preconditioning.</paragraph></list-item></list></list-item><list-item><paragraph>Experimental Analysis (RNN Stress Test):</paragraph><list style=\"unordered\"><list-item><paragraph>Set up the \"Adding Problem\" (a standard RNN benchmark) to test optimizer stability on long-term dependencies.</paragraph></list-item><list-item><paragraph>Constructed a Hyperparameter Sensitivity Sweep comparing AdamW vs. SOAP across logarithmically spaced learning rates.</paragraph></list-item><list-item><paragraph>Included visualization code to demonstrate SOAP's superior stability and \"shifted\" optimal learning rate window compared to AdamW.</paragraph></list-item></list></list-item></list><paragraph>Student notebook: <link href=\"https://colab.research.google.com/drive/15gAh01QQKscfbBbXvnGt7MgYOC3j4lTG#scrollTo=ZCwSKgXWW-nk\">https://colab.research.google.com/drive/15gAh01QQKscfbBbXvnGt7MgYOC3j4lTG#scrollTo=ZCwSKgXWW-nk</link></paragraph><paragraph>Solutions:</paragraph><paragraph><link href=\"https://colab.research.google.com/drive/1-AdCaTn1n6D5ThprVc7sM0A3b7TIx09n#scrollTo=uNGvVyYhYJzP\">https://colab.research.google.com/drive/1-AdCaTn1n6D5ThprVc7sM0A3b7TIx09n#scrollTo=uNGvVyYhYJzP</link></paragraph><paragraph/></document>",
            "links": [
                "https://colab.research.google.com/drive/15gAh01QQKscfbBbXvnGt7MgYOC3j4lTG#scrollTo=ZCwSKgXWW-nk",
                "https://colab.research.google.com/drive/1-AdCaTn1n6D5ThprVc7sM0A3b7TIx09n#scrollTo=uNGvVyYhYJzP"
            ],
            "attachments": [],
            "created_at": "2025-12-05T14:59:51.904185+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411467,
            "author": "Shashwat Bansal",
            "project_title": "Special Participation E: Vector Calculus with ChatGPT Study Mode",
            "post_body": "I used ChatGPT Study Mode to learn Vector Calculus, preceded by some quick ICL on the first 6 homeworks. The exercise only proved useful to recall the fundamental concepts of matrix calculus. I wouldn't say I learned much, and felt limited by the need to type mathematical notation into chat at the same pace that I am thinking. Chat also failed to ask me engaging questions.\n\nAnnotated chat: https://docs.google.com/document/d/10VFhJotL3Z-3Buj2IgQmR4yfjOoxuHqUU8UL1CC_5uo/edit?usp=sharing\n\nActual chat: https://chatgpt.com/share/69324b94-e264-8013-988a-8dfa87eec732",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT Study Mode to learn Vector Calculus, preceded by some quick ICL on the first 6 homeworks. The exercise only proved useful to recall the fundamental concepts of matrix calculus. I wouldn't say I learned much, and felt limited by the need to type mathematical notation into chat at the same pace that I am thinking. Chat also failed to ask me engaging questions.</paragraph><paragraph>Annotated chat: https://docs.google.com/document/d/10VFhJotL3Z-3Buj2IgQmR4yfjOoxuHqUU8UL1CC_5uo/edit?usp=sharing</paragraph><paragraph>Actual chat: https://chatgpt.com/share/69324b94-e264-8013-988a-8dfa87eec732</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T14:18:18.543155+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411461,
            "author": "Yuxiang Liu",
            "project_title": "Special Participation C: Modularization for Question 4 HW 11",
            "post_body": "This work is contributed by Yuxiang Liu 3039508136, Hanyang Gu 3038838194, Zimu Wang 3038960121 as a team. We significantly refactored the experimental codebase to improve its modularity, clarity, and extensibility. \n\nFirst, we abstracted the data-generation logic into a single reusable function, generate_linear_regression_data, which encapsulates Gaussian input sampling, noise injection, and ground-truth weight creation. This replaces several scattered global code blocks with a single clear API that returns all relevant tensors (train/test inputs, outputs, and the true weight matrix). This design not only reduces duplication but also makes it easy to modify dataset parameters\u2014such as noise level, dimension, or sample size\u2014without editing experiment code elsewhere in the notebook.\n\nNext, we introduced several structural improvements to the training and experimentation pipeline. We standardized the training function interface across different models and optimizers so that both the linear model SGD routine and the MLP training routine can be passed interchangeably into a unified experiment runner. We added collect_final_mse_dict, a general-purpose function that executes a full grid search over batch sizes and learning rates, returning a consistent MSE summary for downstream analysis.\n\nAdditionally, we created shared plotting utilities to replace repeated Matplotlib code, ensuring consistent formatting and reducing boilerplate. Together, these changes produce a cleaner and more maintainable workflow, making it easier to scale the experiments, add new models, or explore additional scaling-law hypotheses.\n\nFor future GSIs and tutors, we highly recommend you to block out some codes from functions generate_linear_regression_data(), collect_final_mse_dict(), compute_best_lrs()  for the purpose of teaching so that students can better feel the power of modularity when coding up experiments.",
            "content_xml": "<document version=\"2.0\"><paragraph>This work is contributed by Yuxiang Liu 3039508136, Hanyang Gu 3038838194, Zimu Wang 3038960121 as a team. We significantly refactored the experimental codebase to improve its modularity, clarity, and extensibility. </paragraph><paragraph>First, we abstracted the data-generation logic into a single reusable function, <code>generate_linear_regression_data</code>, which encapsulates Gaussian input sampling, noise injection, and ground-truth weight creation. This replaces several scattered global code blocks with a single clear API that returns all relevant tensors (train/test inputs, outputs, and the true weight matrix). This design not only reduces duplication but also makes it easy to modify dataset parameters\u2014such as noise level, dimension, or sample size\u2014without editing experiment code elsewhere in the notebook.</paragraph><paragraph>Next, we introduced several structural improvements to the training and experimentation pipeline. We standardized the training function interface across different models and optimizers so that both the linear model SGD routine and the MLP training routine can be passed interchangeably into a unified experiment runner. We added <code>collect_final_mse_dict</code>, a general-purpose function that executes a full grid search over batch sizes and learning rates, returning a consistent MSE summary for downstream analysis.</paragraph><paragraph>Additionally, we created shared plotting utilities to replace repeated Matplotlib code, ensuring consistent formatting and reducing boilerplate. Together, these changes produce a cleaner and more maintainable workflow, making it easier to scale the experiments, add new models, or explore additional scaling-law hypotheses.</paragraph><paragraph>For future GSIs and tutors, we highly recommend you to block out some codes from functions <code>generate_linear_regression_data(), collect_final_mse_dict(), compute_best_lrs()</code>  for the purpose of teaching so that students can better feel the power of modularity when coding up experiments.</paragraph><file url=\"https://static.us.edusercontent.com/files/VZUUOGfIGK7Y1dN8nvSUGB7x\" filename=\"scaling_laws.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T14:17:49.681756+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411283,
            "author": "Fangzhou Zhao",
            "project_title": "Special Participation B: Use Claude code with Opus 4.5 Finish hw11 coding parts",
            "post_body": "\n\nI used Claude code with opus 4.5 the pdf include both claude code trace and the code after implement and output\n\n\n\nOverall, the code across both notebooks demonstrates a solid understanding of the underlying machine learning concepts\u2014scaling laws for SGD/Adam optimizers and transformer attention mechanisms for interpretability. The implementations are functionally correct: the scaling laws notebook properly sweeps learning rates across batch sizes and fits power-law relationships, while the interpretability notebook correctly implements causal attention with manual softmax and constructs the two-stage induction head (previous-token head + copying head) that passes all test cases. The code is readable with reasonable variable naming, and the mathematical operations (gradient computation, attention scores, QK/OV matrix construction) align with standard formulations. Both notebooks produce the expected outputs and would likely receive full credit for correctness.\n\nHowever, the code quality could be improved in several areas. The scaling laws notebook suffers from heavy duplication\u2014the sweep and plotting logic is copy-pasted three times across Q1/Q2/Q3 rather than being refactored into reusable functions. It also contains magic numbers without explanation (eps=0.57, clip ceiling of 500), bare except: clauses that catch all errors indiscriminately, and a bug where weight_decay=0.01 is used instead of the specified 0.001. The interpretability notebook is cleaner but lacks docstring explanations for the matrix constructions and could benefit from inline comments explaining why specific dimensions are used (e.g., \"dims 4-7 store previous token identity\"). Neither notebook includes comprehensive documentation or type hints. In summary, both implementations are conceptually sound and produce correct results, but would benefit from refactoring to reduce redundancy, adding explanatory comments for non-obvious operations, and fixing the minor parameter mismatch in the Adam optimizer configuration.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/S3YXAY1Slasnul21dQGAXO5H\" filename=\"Special B-2.pdf\"/><paragraph/><paragraph>I used Claude code with opus 4.5 the pdf include both claude code trace and the code after implement and output<break/><break/></paragraph><paragraph>Overall, the code across both notebooks demonstrates a solid understanding of the underlying machine learning concepts\u2014scaling laws for SGD/Adam optimizers and transformer attention mechanisms for interpretability. The implementations are functionally correct: the scaling laws notebook properly sweeps learning rates across batch sizes and fits power-law relationships, while the interpretability notebook correctly implements causal attention with manual softmax and constructs the two-stage induction head (previous-token head + copying head) that passes all test cases. The code is readable with reasonable variable naming, and the mathematical operations (gradient computation, attention scores, QK/OV matrix construction) align with standard formulations. Both notebooks produce the expected outputs and would likely receive full credit for correctness.</paragraph><paragraph>However, the code quality could be improved in several areas. The scaling laws notebook suffers from heavy duplication\u2014the sweep and plotting logic is copy-pasted three times across Q1/Q2/Q3 rather than being refactored into reusable functions. It also contains magic numbers without explanation (eps=0.57, clip ceiling of 500), bare except: clauses that catch all errors indiscriminately, and a bug where weight_decay=0.01 is used instead of the specified 0.001. The interpretability notebook is cleaner but lacks docstring explanations for the matrix constructions and could benefit from inline comments explaining why specific dimensions are used (e.g., \"dims 4-7 store previous token identity\"). Neither notebook includes comprehensive documentation or type hints. In summary, both implementations are conceptually sound and produce correct results, but would benefit from refactoring to reduce redundancy, adding explanatory comments for non-obvious operations, and fixing the minor parameter mismatch in the Adam optimizer configuration.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T13:51:06.536337+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7411055,
            "author": "Shashwat Bansal",
            "project_title": "Special Participation E: Discussion 8 Transpose Convolutions with ChatGPT",
            "post_body": "I used ChatGPT to ask me questions on Transpose Convolutions to internalize the concepts. I forgot to turn on learning mode but maybe it would have performed slightly better. There were no hallucinations and the experience proved insightful (maybe more so than actually solving the discussion problems, since I lacked some understanding of fundamentals).\nAnnotated copy: https://docs.google.com/document/d/1KTbditva90nbQAzdVCy9_CB4u01HY57PQPr1t8VkMLs/edit?usp=sharing\n\nJust the chat: https://chatgpt.com/share/69323912-2490-8013-80a2-52de186c6f5e",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT to ask me questions on Transpose Convolutions to internalize the concepts. I forgot to turn on learning mode but maybe it would have performed slightly better. There were no hallucinations and the experience proved insightful (maybe more so than actually solving the discussion problems, since I lacked some understanding of fundamentals).<break/>Annotated copy: https://docs.google.com/document/d/1KTbditva90nbQAzdVCy9_CB4u01HY57PQPr1t8VkMLs/edit?usp=sharing</paragraph><paragraph>Just the chat: https://chatgpt.com/share/69323912-2490-8013-80a2-52de186c6f5e</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T13:15:48.965184+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410990,
            "author": "Fantine Mpacko Priso",
            "project_title": "Special participation D : addind manifold MuOn to HW06",
            "post_body": "I implemented Manifold MuOn (Bernstein, 2025) at the end of HW06 to give another version of MuOn to compare. Feel free to experiment ! These are the final figures obtained after completing the code:",
            "content_xml": "<document version=\"2.0\"><paragraph>I implemented Manifold MuOn (Bernstein, 2025) at the end of HW06 to give another version of MuOn to compare. Feel free to experiment ! These are the final figures obtained after completing the code:</paragraph><file url=\"https://static.us.edusercontent.com/files/vc6ZlrQyL8Z8A4lxQ5oy0af2\" filename=\"Fantine_q_coding_muon_solutions.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/IjYgNLdp7QpZ1ulBLzN5R6qW\" filename=\"Fantine_q_coding_muon (1).ipynb\"/><figure><image src=\"https://static.us.edusercontent.com/files/kTb82SAh9dgfh34krpPNSn9v\" width=\"658\" height=\"325.67676767676767\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T13:04:37.879759+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410928,
            "author": "Justin Li",
            "project_title": "Special Participation E: Pre-Homework Warmup Tutor",
            "post_body": "Before most homeworks, I usually felt like I didn\u2019t fully understand all of the concepts from the lecture - especially if I had only watched the lecture one time and hadn\u2019t read through the relevant textbook material. While discussions certainly help, I wanted to create a tool that would help me \u201cwarm up\u201d before actually attempting the homeworks. I used ChatGPT to build a system that takes the homework assignment and the relevant lecture notes, and then turns them into a personalized warmup assignment to review and solidify my understanding of the concepts before I jump into the homework.\n\nThere was some trial and error in getting the system right. In my initial prompts, ChatGPT would give me a full summary of the lectures and questions and answers all written out at once, and when I went through these it felt like I was more passively reading than actually practicing - my brain would naturally jump to reading the answer after seeing the question. I realized what I actually wanted was something that behaved more like a tutor - asking questions one at a time, allowing me to input an answer, and giving me feedback to the answer before explaining the solution. Thus, I refined the prompt to still give me a fully structured summary, but delivering interactive warmup questions one at a time - to give the feel of working with an actual tutor.\n\nThese are the main components to the \u201ctutor\u201d\n\nConcept Summary: a short overview of each concept needed for the homework. It pulls the content directly from the lecture notes and cites the exact lecture and page where each idea shows up\n\nTiny Illustrative Examples: very very simple examples (much easier than anything on the homework) just to ensure that I understand the core ideas at a very basic level before moving on\n\nInteractive Warm Ups: the tutor asks questions one at a time, I respond, and the tutor evaluates my answer and explains the reasoning (and where I went wrong if I got the question wrong). The prompt can be adjusted to choose how many questions I want and how hard they should be.\n\nReadiness Check: After the warmup, I get a checklist of concepts to make sure I feel confident before jumping into the actual homework.\n\nFormula Sheet (optional): it also compiled a formula sheet with useful formulas that could be used on the homework problems\n\nOverall, the tool ended up acting like a tutor as I wished, refreshing my understanding of the key concepts, giving me simple practice questions, interactively checking my understanding, and ensuring I was prepared before actually doing the homework.\n\nI have attached the prompt I used to generate all of this, as well as an annotated example of me using this warmup tool on the concepts and lectures for Homework 5 on CNNs. Specifically the tool took a look at HW5, lecture 8, lecture 9, lecture 10, and lecture 11.\n\nHope this helps and cheers!\n\n\nUsing the Tutor on HW 5: https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharing\n\nPrompt: ",
            "content_xml": "<document version=\"2.0\"><paragraph>Before most homeworks, I usually felt like I didn\u2019t fully understand all of the concepts from the lecture - especially if I had only watched the lecture one time and hadn\u2019t read through the relevant textbook material. While discussions certainly help, I wanted to create a tool that would help me \u201cwarm up\u201d before actually attempting the homeworks. I used ChatGPT to build a system that takes the homework assignment and the relevant lecture notes, and then turns them into a personalized warmup assignment to review and solidify my understanding of the concepts before I jump into the homework.</paragraph><paragraph>There was some trial and error in getting the system right. In my initial prompts, ChatGPT would give me a full summary of the lectures and questions and answers all written out at once, and when I went through these it felt like I was more passively reading than actually practicing - my brain would naturally jump to reading the answer after seeing the question. I realized what I actually wanted was something that behaved more like a tutor - asking questions one at a time, allowing me to input an answer, and giving me feedback to the answer before explaining the solution. Thus, I refined the prompt to still give me a fully structured summary, but delivering interactive warmup questions one at a time - to give the feel of working with an actual tutor.</paragraph><paragraph>These are the main components to the \u201ctutor\u201d</paragraph><list style=\"ordered\"><list-item><paragraph>Concept Summary: a short overview of each concept needed for the homework. It pulls the content directly from the lecture notes and cites the exact lecture and page where each idea shows up</paragraph></list-item><list-item><paragraph>Tiny Illustrative Examples: very very simple examples (much easier than anything on the homework) just to ensure that I understand the core ideas at a very basic level before moving on</paragraph></list-item><list-item><paragraph>Interactive Warm Ups: the tutor asks questions one at a time, I respond, and the tutor evaluates my answer and explains the reasoning (and where I went wrong if I got the question wrong). The prompt can be adjusted to choose how many questions I want and how hard they should be.</paragraph></list-item><list-item><paragraph>Readiness Check: After the warmup, I get a checklist of concepts to make sure I feel confident before jumping into the actual homework.</paragraph></list-item><list-item><paragraph>Formula Sheet (optional): it also compiled a formula sheet with useful formulas that could be used on the homework problems</paragraph></list-item></list><paragraph>Overall, the tool ended up acting like a tutor as I wished, refreshing my understanding of the key concepts, giving me simple practice questions, interactively checking my understanding, and ensuring I was prepared before actually doing the homework.</paragraph><paragraph>I have attached the prompt I used to generate all of this, as well as an annotated example of me using this warmup tool on the concepts and lectures for Homework 5 on CNNs. Specifically the tool took a look at HW5, lecture 8, lecture 9, lecture 10, and lecture 11.</paragraph><paragraph>Hope this helps and cheers!<break/></paragraph><paragraph>Using the Tutor on HW 5: <link href=\"https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharing\">https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharing</link></paragraph><paragraph>Prompt: </paragraph><file url=\"https://static.us.edusercontent.com/files/I3gOcgbf84u3aP2Cg7Linsa0\" filename=\"Pre-Homework Context.pdf\"/></document>",
            "links": [
                "https://drive.google.com/file/d/1yOBKCvQgchdMMtoPZqoTNvbwxWVSbL3i/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-05T12:55:24.829717+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410750,
            "author": "Lenci Ni",
            "project_title": "Special Participation B: Gemini 3 Pro on HW 5",
            "post_body": "I used Gemini Pro 3 to help with the coding parts of Homework 5: Problems 5 (Understanding Dropout) and 6 (Batchnorm, Dropout and Convolutions). I handled the inputs by copy-pasting raw code blocks from the notebooks and helper files directly into the prompt without reformatting, followed immediately by the question.\n\nSummary: Gemini Pro 3 handled the heavy coding tasks impressively. It was able to mostly one-shot every implementation with only minor reprompting needed for small corrections. It was good at piecing together logic even when I just copy-pasted disjointed notebook cells and helper files together. It successfully cross-referenced different files in Problem 6.\n\nStrengths: The model\u2019s standout strength is code completion. It generated code implementations that were executable immediately with no syntax errors. It handled the \"bunched together\" context effortlessly. For the written parts of the coding problems, the explanations provided were often more detailed than the official solutions. The code style was also very clean and consistent with the provided skeleton code.\n\nWeaknesses: There were a few small issues. Occasionally, the model said it completed the function in the file, but actually didn't change any code at all. Also, in Problem 5, it struggled to correctly interpret what the graphs should look like.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used <bold>Gemini Pro 3</bold> to help with the coding parts of Homework 5: Problems 5 (Understanding Dropout) and 6 (Batchnorm, Dropout and Convolutions). I handled the inputs by copy-pasting raw code blocks from the notebooks and helper files directly into the prompt without reformatting, followed immediately by the question.</paragraph><paragraph><bold>Summary:</bold> Gemini Pro 3 handled the heavy coding tasks impressively. It was able to mostly one-shot every implementation with only minor reprompting needed for small corrections. It was good at piecing together logic even when I just copy-pasted disjointed notebook cells and helper files together. It successfully cross-referenced different files in Problem 6.</paragraph><paragraph><bold>Strengths:</bold> The model\u2019s standout strength is code completion. It generated code implementations that were executable immediately with no syntax errors. It handled the \"bunched together\" context effortlessly. For the written parts of the coding problems, the explanations provided were often more detailed than the official solutions. The code style was also very clean and consistent with the provided skeleton code.</paragraph><paragraph><bold>Weaknesses:</bold> There were a few small issues. Occasionally, the model said it completed the function in the file, but actually didn't change any code at all. Also, in Problem 5, it struggled to correctly interpret what the graphs should look like.</paragraph><file url=\"https://static.us.edusercontent.com/files/1gBo2V4OrbhEvMcNZ4BAxxZ6\" filename=\"participation_b_hw5.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T12:28:23.821908+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410745,
            "author": "Tom Chen",
            "project_title": "Special Participation E: The \"Broken Blueprint\" Game",
            "post_body": "The \"Broken Blueprint\" Game: Learning Deep Learning via AI Code Review\n\nThis game is a \"Reverse Learning\" approach: Instead of asking the AI to explain a concept or quiz me, I inverted the roles: The AI writes code, and I have to debug it.\n\nI designed a prompt called \"The Buggy Architect\" to simulate a real-world scenario: reviewing the code of a junior engineer who makes subtle, logical errors in deep learning implementations.\n\nThe Core Idea: Evaluation over Passive Consumption\n\nTraditional AI study tools often encourage passive consumption (reading summaries). My goal was to target the higher levels of Bloom's Taxonomy: Analysis and Evaluation.In Deep Learning, many students (including myself) understand the high-level diagrams of a Transformer or ResNet but fail when implementing them because of dimension mismatches or incorrect tensor operations. By forcing myself to \"Code Review\" the AI's faulty implementation, I am required to mentally trace the data flow and tensor shapes ensuring a much more rigorous understanding of the architecture.\n\nPrompt Design Choices\n\nI iteratively built a system prompt with specific constraints:\n\nThe \"Subtlety\" Constraint: The prompt explicitly forbids syntax errors (which a compiler would catch). The bugs must be logical or architectural (e.g., applying Softmax over the wrong dimension, incorrect masking in causal attention, or putting LayerNorm in a place that creates a gradient bottleneck).\n\nThe \"Junior Engineer\" Personality: I instructed the AI to act as a confident but prone-to-error junior engineer. This lowers the barrier to entry and makes the \"correction\" process feel like a collaborative code review rather than a test.\n\nScaffolded Hinting: If I fail to spot the bug, the AI is instructed not to reveal the answer immediately but to provide hints related to Tensor Shapes or Gradient Flow. This forces me to check the math manually.\n\nWhat Worked Well\n\nBased on my interaction trace (see attached), this approach was highly effective for technical rigor:\n\nForced Math Verification: When the model implemented Multi-Head Attention, I had to manually write down the matrix dimensions on paper to verify if the view and transpose operations were correct. This solidified my understanding of the (Batch, Heads, Seq, Dim) transformation.\n\nCatching \"Silent Failures\": The tool was good at generating bugs that run without crashing but destroy performance (e.g., forgetting to add the residual connection in a ResNet block). Spotting this required understanding the purpose of the architecture, not just the code.\n\nEngagement: The gamified nature (\"Find the bug\") made the session significantly more engaging than a standard Q&A.\n\nWhat Could Be Improved\n\nHowever, the tool exhibited specific weaknesses that require critical oversight:\n\n\"Gaslighting\" / False Positives: In one instance, the AI actually wrote correct code but insisted there was a bug because the prompt forced it to include one. It then tried to convince me that a standard implementation was wrong. This requires the student to be very confident to push back.\n\nInconsistent Difficulty: Sometimes the \"bug\" was too trivial (e.g., a typo in a variable name) despite the instructions asking for logical errors.\n\nLack of Context: The AI sometimes used variable names (like x vs h) that were ambiguous without a surrounding class definition, making it hard to judge if a bug existed or if it was just poor naming convention.\n\nReflection\n\nThis tool serves as an excellent \"Pre-Implementation Check.\" Before I start my own homework or project, playing a few rounds of \"Find the Bug\" with this prompt helps me anticipate the common pitfalls I am likely to make myself. It turns the AI from a lecturer into a simulation of a coding environment.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>The \"Broken Blueprint\" Game: Learning Deep Learning via AI Code Review</bold></paragraph><paragraph>This game is a \"Reverse Learning\" approach: Instead of asking the AI to explain a concept or quiz me, I inverted the roles: The AI writes code, and I have to debug it.</paragraph><paragraph>I designed a prompt called \"The Buggy Architect\" to simulate a real-world scenario: reviewing the code of a junior engineer who makes subtle, logical errors in deep learning implementations.</paragraph><paragraph><bold>The Core Idea: Evaluation over Passive Consumption</bold></paragraph><paragraph>Traditional AI study tools often encourage passive consumption (reading summaries). My goal was to target the higher levels of Bloom's Taxonomy: Analysis and Evaluation.In Deep Learning, many students (including myself) understand the high-level diagrams of a Transformer or ResNet but fail when implementing them because of dimension mismatches or incorrect tensor operations. By forcing myself to \"Code Review\" the AI's faulty implementation, I am required to mentally trace the data flow and tensor shapes ensuring a much more rigorous understanding of the architecture.</paragraph><paragraph>Prompt Design Choices</paragraph><paragraph>I iteratively built a system prompt with specific constraints:</paragraph><list style=\"bullet\"><list-item><paragraph>The \"Subtlety\" Constraint: The prompt explicitly forbids syntax errors (which a compiler would catch). The bugs must be logical or architectural (e.g., applying Softmax over the wrong dimension, incorrect masking in causal attention, or putting LayerNorm in a place that creates a gradient bottleneck).</paragraph></list-item><list-item><paragraph>The \"Junior Engineer\" Personality: I instructed the AI to act as a confident but prone-to-error junior engineer. This lowers the barrier to entry and makes the \"correction\" process feel like a collaborative code review rather than a test.</paragraph></list-item><list-item><paragraph>Scaffolded Hinting: If I fail to spot the bug, the AI is instructed not to reveal the answer immediately but to provide hints related to Tensor Shapes or Gradient Flow. This forces me to check the math manually.</paragraph></list-item></list><paragraph>What Worked Well</paragraph><paragraph>Based on my interaction trace (see attached), this approach was highly effective for technical rigor:</paragraph><list style=\"bullet\"><list-item><paragraph>Forced Math Verification: When the model implemented Multi-Head Attention, I had to manually write down the matrix dimensions on paper to verify if the view and transpose operations were correct. This solidified my understanding of the (Batch, Heads, Seq, Dim) transformation.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Catching \"Silent Failures\": The tool was good at generating bugs that run without crashing but destroy performance (e.g., forgetting to add the residual connection in a ResNet block). Spotting this required understanding the purpose of the architecture, not just the code.</paragraph></list-item><list-item><paragraph>Engagement: The gamified nature (\"Find the bug\") made the session significantly more engaging than a standard Q&amp;A.</paragraph></list-item></list><paragraph>What Could Be Improved</paragraph><paragraph>However, the tool exhibited specific weaknesses that require critical oversight:</paragraph><list style=\"bullet\"><list-item><paragraph>\"Gaslighting\" / False Positives: In one instance, the AI actually wrote correct code but insisted there was a bug because the prompt forced it to include one. It then tried to convince me that a standard implementation was wrong. This requires the student to be very confident to push back.</paragraph></list-item><list-item><paragraph>Inconsistent Difficulty: Sometimes the \"bug\" was too trivial (e.g., a typo in a variable name) despite the instructions asking for logical errors.</paragraph></list-item><list-item><paragraph>Lack of Context: The AI sometimes used variable names (like x vs h) that were ambiguous without a surrounding class definition, making it hard to judge if a bug existed or if it was just poor naming convention.</paragraph></list-item></list><paragraph>Reflection</paragraph><paragraph>This tool serves as an excellent \"Pre-Implementation Check.\" Before I start my own homework or project, playing a few rounds of \"Find the Bug\" with this prompt helps me anticipate the common pitfalls I am likely to make myself. It turns the AI from a lecturer into a simulation of a coding environment.</paragraph><file url=\"https://static.us.edusercontent.com/files/0OChLacQMWv1rrjFi1fACT3x\" filename=\"Special Participation E by Tom.pdf\"/><file url=\"https://static.us.edusercontent.com/files/8yex49ucHp2cgW4CdCC3czax\" filename=\"Prompt.txt\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T12:27:49.943433+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410181,
            "author": "Vrushank Prakash",
            "project_title": "Special Participation E: Understanding RNNs through the Signal Processing Perspective with Gemini",
            "post_body": "When we first talked about RNNs in class, I had trouble understanding the signal processing and Kalman filter perspectives, especially since my previous classes didn't cover these topics in depth. I know there are other people in the class who didn't take classes in signal processing, making the RNNs lecture notes challenging to follow at first.\n\nI decided to use Gemini 3 Pro with the Guided Learning mode to help me understand the connection between signal processing, Kalman filters, and RNNs. I passed in the lecture 14 notes as context. I first prompted Gemini to give me an introduction into what RNNs are before discussing the signal processing perspective. Just like lecture, it made a clear distinction between how CNNs work with space while RNNs work with time/sequences. It then talked about both the forward and backward passes. Eventually, it brought in the signal processing perspective and how RNNs can be represented as Kalman Filters with learnable matrices. At the end, I asked more general questions about RNNs, in which Gemini was able to connect its explanation back to signal processing and Kalman filter concepts.\n\nOverall, I think Gemini did a great job of bringing the concepts of signal processing and Kalman filters into the discussion of RNNs. I do think Gemini could have done a better job of explaining of what a Kalman filter is before immediately jumping into how it is used in RNNs. I also found Gemini using too many analogies when I ask it to explain certain concepts more clearly, sometimes which were too unrelated to the actual concepts.\n\nHere is the annotated PDF:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>When we first talked about RNNs in class, I had trouble understanding the signal processing and Kalman filter perspectives, especially since my previous classes didn't cover these topics in depth. I know there are other people in the class who didn't take classes in signal processing, making the RNNs lecture notes challenging to follow at first.</paragraph><paragraph>I decided to use Gemini 3 Pro with the Guided Learning mode to help me understand the connection between signal processing, Kalman filters, and RNNs. I passed in the lecture 14 notes as context. I first prompted Gemini to give me an introduction into what RNNs are before discussing the signal processing perspective. Just like lecture, it made a clear distinction between how CNNs work with space while RNNs work with time/sequences. It then talked about both the forward and backward passes. Eventually, it brought in the signal processing perspective and how RNNs can be represented as Kalman Filters with learnable matrices. At the end, I asked more general questions about RNNs, in which Gemini was able to connect its explanation back to signal processing and Kalman filter concepts.</paragraph><paragraph>Overall, I think Gemini did a great job of bringing the concepts of signal processing and Kalman filters into the discussion of RNNs. I do think Gemini could have done a better job of explaining of what a Kalman filter is before immediately jumping into how it is used in RNNs. I also found Gemini using too many analogies when I ask it to explain certain concepts more clearly, sometimes which were too unrelated to the actual concepts.</paragraph><paragraph>Here is the annotated PDF:</paragraph><file url=\"https://static.us.edusercontent.com/files/5v8fGUEFtR0uXghnmLu95hsE\" filename=\"CS 182 Special Participation E_ Understanding RNNs through the Signal Processing Perspective .pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T11:12:21.743675+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410149,
            "author": "Zimu Wang",
            "project_title": "Special Participation E: GPT to Understand Complex Ideas from What I Already Know",
            "post_body": "LLMs are really good at teaching and introducing new knowledge by connecting it to concepts we\u2019re already familiar with. This makes understanding abstractions much easier.\n\nHere is the link to my chat with ChatGPT-4o: https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de\n\nIn this example, I wanted to learn about image generation models, but I only had experience with LLMs and basically no background in image models.\n\nFirst, I instructed the LLM to give me a big-picture overview and told it my background. This part is important \u2014 it helps the model tailor the explanation to something I can understand more efficiently and effectively. Otherwise, the LLM might give answers that are too general without enough theory, or too detailed without a big picture.\n\nThen, I guided the LLM to introduce image generation using logic similar to LLMs: what the inputs and outputs are, how the loss function is computed, and what the layer-to-layer structure looks like. This approach is extremely helpful because it lets me understand new concepts through the lens of something I already know, instead of learning everything from scratch.",
            "content_xml": "<document version=\"2.0\"><paragraph>LLMs are really good at teaching and introducing new knowledge by connecting it to concepts we\u2019re already familiar with. This makes understanding abstractions much easier.</paragraph><paragraph>Here is the link to my chat with ChatGPT-4o: <link href=\"https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de\">https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de</link></paragraph><paragraph>In this example, I wanted to learn about image generation models, but I only had experience with LLMs and basically no background in image models.</paragraph><paragraph>First, I instructed the LLM to give me a big-picture overview and told it my background. This part is important \u2014 it helps the model tailor the explanation to something I can understand more efficiently and effectively. Otherwise, the LLM might give answers that are too general without enough theory, or too detailed without a big picture.</paragraph><paragraph>Then, I guided the LLM to introduce image generation using logic similar to LLMs: what the inputs and outputs are, how the loss function is computed, and what the layer-to-layer structure looks like. This approach is extremely helpful because it lets me understand new concepts through the lens of something I already know, instead of learning everything from scratch.</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/69321cf6-fb44-8005-a3a4-e9a9ded4c4de"
            ],
            "attachments": [],
            "created_at": "2025-12-05T11:08:12.830881+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410078,
            "author": "Tom Chen",
            "project_title": "[Spoiler Alert] Special Participation A: Gemini 3.0 Pro on Homework 13",
            "post_body": "Special Participation A: Gemini 3.0 Pro on Homework 13\n\nFor this assignment, I evaluated how well Gemini 3.0 Pro can handle the theoretical, non-coding derivations of CS182 Homework 13. I approached the Direct Preference Optimization (DPO) problem set step-by-step, initiating the session with a specific persona prompt to establish a \"technical partner\" role, and then guided the model through the derivation without providing the final answers myself. My main goal was to see (1) its OCR accuracy on dense mathematical problem sets, (2) its ability to perform rigorous algebraic manipulations, and (3) the clarity of its conceptual explanations.\n\nOverall, Gemini performed exceptionally well. It correctly identified the context from the uploaded images and produced clean, structured derivations for the entire pipeline (Q2 Parts a through g) with minimal correction required.\n\nIt was especially reliable on:\n\nInterpreting the standard RLHF objective and KL constraints,\n\nExecuting the algebraic \"cancellation trick\" to eliminate the intractable partition function Z(x),\n\nDeriving the gradient of the DPO loss and interpreting the weighting mechanism, and\n\nExtending the logic from pairwise comparisons to listwise rankings (Plackett-Luce model).\n\nIn terms of interaction, the model was:\n\nconsistent in its LaTeX formatting and structure, and\n\nhighly effective at explaining the \"why\" behind each step, acting as a true mentor rather than just a calculator.\n\nOverall, based on this evaluation, Gemini 3.0 Pro is capable of solving the complex theoretical questions in CS182 with high accuracy and interpretability. \n\nFor further information, please see the annotated logs.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Special Participation A: Gemini 3.0 Pro on Homework 13</bold></paragraph><paragraph>For this assignment, I evaluated how well Gemini 3.0 Pro can handle the theoretical, non-coding derivations of CS182 Homework 13. I approached the Direct Preference Optimization (DPO) problem set step-by-step, initiating the session with a specific persona prompt to establish a \"technical partner\" role, and then guided the model through the derivation without providing the final answers myself. My main goal was to see (1) its OCR accuracy on dense mathematical problem sets, (2) its ability to perform rigorous algebraic manipulations, and (3) the clarity of its conceptual explanations.</paragraph><paragraph>Overall, Gemini performed exceptionally well. It correctly identified the context from the uploaded images and produced clean, structured derivations for the entire pipeline (Q2 Parts a through g) with minimal correction required.</paragraph><paragraph>It was especially reliable on:</paragraph><list style=\"bullet\"><list-item><paragraph>Interpreting the standard RLHF objective and KL constraints,</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Executing the algebraic \"cancellation trick\" to eliminate the intractable partition function Z(x),</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Deriving the gradient of the DPO loss and interpreting the weighting mechanism, and</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Extending the logic from pairwise comparisons to listwise rankings (Plackett-Luce model).</paragraph></list-item></list><paragraph>In terms of interaction, the model was:</paragraph><list style=\"bullet\"><list-item><paragraph>consistent in its LaTeX formatting and structure, and</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>highly effective at explaining the \"why\" behind each step, acting as a true mentor rather than just a calculator.</paragraph></list-item></list><paragraph>Overall, based on this evaluation, Gemini 3.0 Pro is capable of solving the complex theoretical questions in CS182 with high accuracy and interpretability. </paragraph><paragraph>For further information, please see the annotated logs.</paragraph><file url=\"https://static.us.edusercontent.com/files/AwzXB7JvgHpmkXn4gEtKCSVK\" filename=\"Special Participation A by Tom.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T10:59:33.011467+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7410013,
            "author": "Xi Cheng",
            "project_title": "Special Participation E: Using an AI \u201cReviewer 2\u201d to Pressure-Test Concepts",
            "post_body": "In this participation, I designed a small AI tool where the model acts as a harsh but fair \u201cReviewer 2\u201d for any concept from EECS182. The workflow is: I first write my own free-form explanation of a concept (e.g., attention in Transformers), then prompt the LLM to critique it\u2014highlighting what is correct, flagging vague or misleading phrases, and asking sharp follow-up questions about assumptions, edge cases, and the exact math. After that, I respond to its questions and rewrite my explanation, making it more precise and better aligned with the formal definitions and equations from lecture. This interaction turns the LLM into a tool for stress-testing my understanding rather than passively explaining things to me, and it also surfaces where the model\u2019s feedback is helpful versus where I still need to double-check the theory myself.",
            "content_xml": "<document version=\"2.0\"><paragraph>In this participation, I designed a small AI tool where the model acts as a harsh but fair \u201cReviewer 2\u201d for any concept from EECS182. The workflow is: I first write my own free-form explanation of a concept (e.g., attention in Transformers), then prompt the LLM to critique it\u2014highlighting what is correct, flagging vague or misleading phrases, and asking sharp follow-up questions about assumptions, edge cases, and the exact math. After that, I respond to its questions and rewrite my explanation, making it more precise and better aligned with the formal definitions and equations from lecture. This interaction turns the LLM into a tool for stress-testing my understanding rather than passively explaining things to me, and it also surfaces where the model\u2019s feedback is helpful versus where I still need to double-check the theory myself.</paragraph><file url=\"https://static.us.edusercontent.com/files/ek4nGsY95yVoNkZu4KAQX9fc\" filename=\"participationE2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T10:52:25.676014+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409895,
            "author": "Srikar Babu Gadipudi",
            "project_title": "Special Participation E: Comparison of LLMs in Explaining a Theoretical Paper",
            "post_body": "It is common for us, as students, to use LLMs to understand research papers, especially ones that have quite a bit of theory. To identify which LLM would help us better with this task, I compared 4 LLMs' (ChatGPT (Study mode), Claude (Extended Thinking), DeepSeek (DeepThink) and Kimi (Thinking)) explanations to this fairly theory heavy paper \"Transformers Learn In-Context by Gradient Descent,\" (Oswald et. al. 2023). The prompt I chose was the following, while also attaching the paper:\n\"This is a crucial paper for my course project (CS182: Deep Learning course at UC Berkeley). I want to understand the functioning of in-context learning and how it performs gradient descent implicitly. Please provide a comprehensive and complete analysis from this paper, keep in mind to give intuitive explanations for everything.\"\n\nFrom my perspective, I think Kimi gave the best overall explanation for an upper-undergrad/grad-level course. While all models correctly identified the core concepts like single attention layer = 1 GD step, deep Transformers = GD++/curvature correction, MLPs = kernel regression), Kimi provided the most rigorous and complete derivation. It was the only model that provided a detailed, step-by-step mathematical trace of Proposition 1 in the paper and drew parallels to concepts like MAML. Claude was excellent for intuitive framing (\"Data Transformation View\"), and DeepSeek offered the most concise summary, but Kimi struck the best balance of mathematical grounding and comprehensive scope.\n\nHere is the annotated merged pdf file with all the conversations, I added my thoughts as and when I found something interesting.",
            "content_xml": "<document version=\"2.0\"><paragraph>It is common for us, as students, to use LLMs to understand research papers, especially ones that have quite a bit of theory. To identify which LLM would help us better with this task, I compared 4 LLMs' (ChatGPT (Study mode), Claude (Extended Thinking), DeepSeek (DeepThink) and Kimi (Thinking)) explanations to this fairly theory heavy paper \"Transformers Learn In-Context by Gradient Descent,\" (Oswald et. al. 2023). The prompt I chose was the following, while also attaching the paper:<break/>\"This is a crucial paper for my course project (CS182: Deep Learning course at UC Berkeley). I want to understand the functioning of in-context learning and how it performs gradient descent implicitly. Please provide a comprehensive and complete analysis from this paper, keep in mind to give intuitive explanations for everything.\"</paragraph><paragraph>From my perspective, I think Kimi gave the best overall explanation for an upper-undergrad/grad-level course. While all models correctly identified the core concepts like single attention layer = 1 GD step, deep Transformers = GD++/curvature correction, MLPs = kernel regression), Kimi provided the most rigorous and complete derivation. It was the only model that provided a detailed, step-by-step mathematical trace of Proposition 1 in the paper and drew parallels to concepts like MAML. Claude was excellent for intuitive framing (\"Data Transformation View\"), and DeepSeek offered the most concise summary, but Kimi struck the best balance of mathematical grounding and comprehensive scope.</paragraph><paragraph>Here is the annotated merged pdf file with all the conversations, I added my thoughts as and when I found something interesting.</paragraph><file url=\"https://static.us.edusercontent.com/files/czh9yCPoMktNRADnoiEOrvQW\" filename=\"participationE_convosMerged.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T10:36:04.922943+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409877,
            "author": "Zimu Wang",
            "project_title": "Special Participation A: HW 0 non-coding solution from GPT5-Think",
            "post_body": "I guided GPT5-Think for the solutions of non-coding part of HW0. Aspired by the tech report from DeepSeek, when guiding super powerful thinking model, we should use zero-shot prompt with no examples but clear instruction. \n\nHere is the link of the chat: https://chatgpt.com/share/69321796-e2bc-8005-9a51-8058b3070a0d\n\nHowever, GPT5 is not good at generating pdf file, especially on such task with math formulas. Hence, I have to guide it to give me the .tex file, and I manually use LaTex IDE to generate the readable PDF solution. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I guided GPT5-Think for the solutions of non-coding part of HW0. Aspired by the tech report from DeepSeek, when guiding super powerful thinking model, we should use zero-shot prompt with no examples but clear instruction. </paragraph><paragraph>Here is the link of the chat: https://chatgpt.com/share/69321796-e2bc-8005-9a51-8058b3070a0d</paragraph><paragraph>However, GPT5 is not good at generating pdf file, especially on such task with math formulas. Hence, I have to guide it to give me the .tex file, and I manually use LaTex IDE to generate the readable PDF solution. </paragraph><file url=\"https://static.us.edusercontent.com/files/JBKPIuEez4uXO7oIYQ8HIIxq\" filename=\"hw0_noncoding_zimu_gpt5-think.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T10:32:39.626459+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409772,
            "author": "Rohan Gulati",
            "project_title": "Special Participation A: Kimi K2 on HW2",
            "post_body": "Here, I looked at how well Kimi K2 could solve the written questions on Homework 2. Overall, Kimi was able to handle the questions well with minimal nudges or corrections. For my approach, I provided the model with the homework pdf, indicated to solve a problem step-by-step, and included that it was well-versed in deep learning and optimization.\n\nAnalysis: Kimi was mostly able to one-shot the sub-parts for each of the problems with minimal hallucinations, aside from problem 1b. In this scenario, the model committed to a hallucinated version of the problem where the L-infinity penalty term was not squared, and thus attempted to use alternate methods to solve the problem. However, once this was indicated, the model was able to revise and arrive at the correct solution immediately.\n\nIncluding chain of thought in the prompt made the model output steps or question description + analysis pairs, while also making it simple to provide corrections for intermediate steps or assumptions. Kimi also used a different font color to indicate corrections to past hallucinations. The output indicates Kimi has good intuition and is able to reason about and handle the gradient operations well, regularly providing interpretations for steps. I thought it was interesting how Kimi was able to attempt multiple approaches analytically in the more complicated scenario it had hallucinated. Additionally, it was able to spatially reason about the table in question 5 without having to explicitly state any relationships among rows or columns. \n\n\n\nAnnotated Conversation:\n\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Here, I looked at how well Kimi K2 could solve the written questions on Homework 2. Overall, Kimi was able to handle the questions well with minimal nudges or corrections. For my approach, I provided the model with the homework pdf, indicated to solve a problem step-by-step, and included that it was well-versed in deep learning and optimization.</paragraph><paragraph>Analysis: Kimi was mostly able to one-shot the sub-parts for each of the problems with minimal hallucinations, aside from problem 1b. In this scenario, the model committed to a hallucinated version of the problem where the L-infinity penalty term was not squared, and thus attempted to use alternate methods to solve the problem. However, once this was indicated, the model was able to revise and arrive at the correct solution immediately.</paragraph><paragraph>Including chain of thought in the prompt made the model output steps or question description + analysis pairs, while also making it simple to provide corrections for intermediate steps or assumptions. Kimi also used a different font color to indicate corrections to past hallucinations. The output indicates Kimi has good intuition and is able to reason about and handle the gradient operations well, regularly providing interpretations for steps. I thought it was interesting how Kimi was able to attempt multiple approaches analytically in the more complicated scenario it had hallucinated. Additionally, it was able to spatially reason about the table in question 5 without having to explicitly state any relationships among rows or columns. </paragraph><paragraph/><paragraph>Annotated Conversation:</paragraph><file url=\"https://static.us.edusercontent.com/files/eBdEBwHbEcFFofmTkmtNgHzY\" filename=\"kimi_written_hw2.pdf\"/><paragraph/><paragraph/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T10:18:30.636365+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409630,
            "author": "Fangzhou Zhao",
            "project_title": "Special Participation A: Using GPT 5.1 thinking  on HW11",
            "post_body": "Trace:\nhttps://chatgpt.com/share/693135e6-2660-800a-8bd4-2cd122b0b787\nhttps://chatgpt.com/share/69320f80-534c-800a-8dd7-45f462c71566\n\nhttps://chatgpt.com/share/693210c8-e2f8-800a-b6f6-e7b827346645\nhttps://chatgpt.com/share/69320fb2-2224-800a-9862-dc87ba13a26d\nhttps://chatgpt.com/share/69320fe3-0654-800a-9fe8-78cbb68bf91b\n\nI used 5.1 Thinking (heavy) as a deep learning assistant and experimented with different prompt structures on a full homework set. I always told the model to reason step by step, explain its interpretation of each question, and self-correct when necessary. I tried both \u201call-at-once\u201d prompts (entire multi-part questions or several questions in one go) and \u201cturn-by-turn\u201d prompts, where each subpart or major question was given in a separate message, plus a hybrid strategy for larger Fermi/system questions.\n\nOverall, the model showed strong technical understanding across topics like LoRA, matrix calculus, initialization, lookup embeddings, scaling laws, soft prompting, and MAML. Its derivations were often more explicit and pedagogical than the official solutions, with clear intermediate steps, shape checks, and good justifications for why certain statements are true. When the scope of the prompt was narrow (one subpart or one focused question), it behaved like a very competent TA that can both solve the problem and teach the underlying concept.\n\nThe main difference came from prompt structure. When I gave big, multi-part questions all at once, the answers tended to be long and cluttered, and there were occasional stability issues (for example, one \u201ceverything in one turn\u201d prompt produced no output on the first try). In contrast, turn-by-turn prompting consistently led to cleaner, more rigorous solutions: the model derived gradients carefully, checked dimensions, and stayed on task for that specific subpart. In practice, turn-by-turn was strictly more reliable for math-heavy, multi-part deep learning questions.\n\nFor larger Fermi and systems-style questions, I used a hybrid approach: batching some straightforward numerical subparts together and then handling the more subtle ones one by one. This improved efficiency but exposed the main weakness of the model: coverage under large context. When the prompt contained many subparts or even multiple big questions (for example, a soft-prompting question followed by a separate TinyML question), the model sometimes skipped part of a subquestion or ignored a later question entirely, even while giving very strong answers to the earlier material. The problem was not understanding, but systematically answering everything that was asked.\n\nOverall, the experiments suggest that 5.1 Thinking (heavy) is best treated as a strong PhD-level TA with occasional attention and coverage issues in large contexts. The most effective pattern is to keep scope tight: use turn-by-turn prompting for multi-part questions, separate big questions into separate prompts, and optionally ask the model to list which subparts it has answered as a final coverage check. With that structure, the step-by-step + self-check style reliably produces detailed, correct, and often superior explanations compared to the official homework solutions.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Trace:<break/><link href=\"https://chatgpt.com/share/693135e6-2660-800a-8bd4-2cd122b0b787\">https://chatgpt.com/share/693135e6-2660-800a-8bd4-2cd122b0b787</link><break/><link href=\"https://chatgpt.com/share/69320f80-534c-800a-8dd7-45f462c71566\">https://chatgpt.com/share/69320f80-534c-800a-8dd7-45f462c71566</link><break/><break/><link href=\"https://chatgpt.com/share/693210c8-e2f8-800a-b6f6-e7b827346645 https://chatgpt.com/share/69320fb2-2224-800a-9862-dc87ba13a26d https://chatgpt.com/share/69320fe3-0654-800a-9fe8-78cbb68bf91b\">https://chatgpt.com/share/693210c8-e2f8-800a-b6f6-e7b827346645<break/>https://chatgpt.com/share/69320fb2-2224-800a-9862-dc87ba13a26d<break/>https://chatgpt.com/share/69320fe3-0654-800a-9fe8-78cbb68bf91b</link></paragraph><paragraph>I used 5.1 Thinking (heavy) as a deep learning assistant and experimented with different prompt structures on a full homework set. I always told the model to reason step by step, explain its interpretation of each question, and self-correct when necessary. I tried both \u201call-at-once\u201d prompts (entire multi-part questions or several questions in one go) and \u201cturn-by-turn\u201d prompts, where each subpart or major question was given in a separate message, plus a hybrid strategy for larger Fermi/system questions.</paragraph><paragraph>Overall, the model showed strong technical understanding across topics like LoRA, matrix calculus, initialization, lookup embeddings, scaling laws, soft prompting, and MAML. Its derivations were often more explicit and pedagogical than the official solutions, with clear intermediate steps, shape checks, and good justifications for why certain statements are true. When the scope of the prompt was narrow (one subpart or one focused question), it behaved like a very competent TA that can both solve the problem and teach the underlying concept.</paragraph><paragraph>The main difference came from prompt structure. When I gave big, multi-part questions all at once, the answers tended to be long and cluttered, and there were occasional stability issues (for example, one \u201ceverything in one turn\u201d prompt produced no output on the first try). In contrast, turn-by-turn prompting consistently led to cleaner, more rigorous solutions: the model derived gradients carefully, checked dimensions, and stayed on task for that specific subpart. In practice, turn-by-turn was strictly more reliable for math-heavy, multi-part deep learning questions.</paragraph><paragraph>For larger Fermi and systems-style questions, I used a hybrid approach: batching some straightforward numerical subparts together and then handling the more subtle ones one by one. This improved efficiency but exposed the main weakness of the model: coverage under large context. When the prompt contained many subparts or even multiple big questions (for example, a soft-prompting question followed by a separate TinyML question), the model sometimes skipped part of a subquestion or ignored a later question entirely, even while giving very strong answers to the earlier material. The problem was not understanding, but systematically answering everything that was asked.</paragraph><paragraph>Overall, the experiments suggest that 5.1 Thinking (heavy) is best treated as a strong PhD-level TA with occasional attention and coverage issues in large contexts. The most effective pattern is to keep scope tight: use turn-by-turn prompting for multi-part questions, separate big questions into separate prompts, and optionally ask the model to list which subparts it has answered as a final coverage check. With that structure, the step-by-step + self-check style reliably produces detailed, correct, and often superior explanations compared to the official homework solutions.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/RsZNw0L9Jj5Gajd3MKc4bBAE\" filename=\"Special A.pdf\"/><paragraph><break/></paragraph></document>",
            "links": [
                "https://chatgpt.com/share/693135e6-2660-800a-8bd4-2cd122b0b787",
                "https://chatgpt.com/share/69320f80-534c-800a-8dd7-45f462c71566",
                "https://chatgpt.com/share/693210c8-e2f8-800a-b6f6-e7b827346645 https://chatgpt.com/share/69320fb2-2224-800a-9862-dc87ba13a26d https://chatgpt.com/share/69320fe3-0654-800a-9fe8-78cbb68bf91b"
            ],
            "attachments": [],
            "created_at": "2025-12-05T09:57:39.03131+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409338,
            "author": "Justin Li",
            "project_title": "Special Participation B: Gemini on Q5 of HW 9",
            "post_body": "I used the Google Gemini 3.0 model to solve the coding question on Homework 9, in which we looked at attention mechanisms in GPT and BERT. It was overall a pleasant experience, with the model being able to one-shot almost all of the problems we asked it. However, much of this smooth experience came after I refined my initial prompt and nudged the model along the way to be more succint, specific, and pay more attention to the images I showed it.\n\nGemini was certainly good at understanding the graphs I showed it. For each problem, although there were hundreds of permutations of layer x head graphs I could have shown it, Gemini was able to understand the main takeaways well after just seeing a few. It did well to identify special features like word sense disambiguation and coreference resolution across different heads and layers. This was core to the solving of most of the parts of this homework.\n\nHowever, along the way, I noticed some downsides of the model. Initially, its answers were way too long and often sidetracked into explanations of general ideas/concepts I didn't ask for. Even after nudging it in the right direction, it would still sometimes lack brevity. I found that it worked best when I asked it to be succint, be specific, and pay extra attention to the images I showed it - previous to this prompt, the answers would often lack specific references to the examples I wanted it to see.\n\nDespite these issues, the final answers were accurate and matched with the official solution. \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used the Google Gemini 3.0 model to solve the coding question on Homework 9, in which we looked at attention mechanisms in GPT and BERT. It was overall a pleasant experience, with the model being able to one-shot almost all of the problems we asked it. However, much of this smooth experience came after I refined my initial prompt and nudged the model along the way to be more succint, specific, and pay more attention to the images I showed it.</paragraph><paragraph>Gemini was certainly good at understanding the graphs I showed it. For each problem, although there were hundreds of permutations of layer x head graphs I could have shown it, Gemini was able to understand the main takeaways well after just seeing a few. It did well to identify special features like word sense disambiguation and coreference resolution across different heads and layers. This was core to the solving of most of the parts of this homework.</paragraph><paragraph>However, along the way, I noticed some downsides of the model. Initially, its answers were way too long and often sidetracked into explanations of general ideas/concepts I didn't ask for. Even after nudging it in the right direction, it would still sometimes lack brevity. I found that it worked best when I asked it to be succint, be specific, and pay extra attention to the images I showed it - previous to this prompt, the answers would often lack specific references to the examples I wanted it to see.</paragraph><paragraph>Despite these issues, the final answers were accurate and matched with the official solution. </paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/3dNlOQaZhdIw8lE8sDkNxH66\" filename=\"Special-Participation-B.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T09:22:35.505719+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409308,
            "author": "Sammie Smith",
            "project_title": "Special Participation A: ChatGPT 5.1 Thinking on HW08",
            "post_body": "Hi there,\n\nI asked ChatGPT5.1 Thinking model to do HW08. Interestingly, it said that it could not give me full solutions due to OpenAI's academic integrity guardrails. These guardrails must be quite weak, or at least the model doesn't understand academic honesty, because the model proceeded to give full mathematical derivations of every subpart of the homework. It did not, however, finish the step of plugging and chugging numerical values in 1b (i), 1 b (ii), and 3c. After a second prompt, it still said that it couldn't give me solutions, but then proceeded to give me numerical answers for those subparts.\n\nI didn't catch any hallucinations of math rules/logic, however ChatGPT could not show every step of the derivation and sometimes it showed derivations alternate to the staff solution. It was most misleading on problem 1c) where it incorrectly suggested an FFT based convolution for critical path when the correct (and more efficient) solution uses direct conv with parallel matrix operations. This threw off the logic and resulted in incorrect solutions for the following subparts. \n\nThere were other instances where ChatGPT overcomplicated things. When estimating the optimum generic square linear encoder W using the SVD, it used a placeholder variable Z=WU which was very confusing. I've noticed this when I've used ChatGPT for hw help previously for this class; it really likes to come up with extra variables in the name of simplification, but really just serves to confuse the reader. \n\nWhile ChatGPT got incorrect results for time complexity analysis for question 1, it gave a fully correct (with correct and thorough steps & intuition) solution for 4c). \n\nIn conclusion, without mastery knowledge of the subject, it's really difficult to know when ChatGPT is hallucinating or overcomplicating. Thus, it's not more helpful than working backwards from staff solutions for the subparts where steps are shown in the staff solutions. \n\nSee this annotated conversation for more problem specific details:",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi there,</paragraph><paragraph>I asked ChatGPT5.1 Thinking model to do HW08. Interestingly, it said that it could not give me full solutions due to OpenAI's academic integrity guardrails. These guardrails must be quite weak, or at least the model doesn't understand academic honesty, because the model proceeded to give full mathematical derivations of every subpart of the homework. It did not, however, finish the step of plugging and chugging numerical values in 1b (i), 1 b (ii), and 3c. After a second prompt, it still said that it couldn't give me solutions, but then proceeded to give me numerical answers for those subparts.</paragraph><paragraph>I didn't catch any hallucinations of math rules/logic, however ChatGPT could not show every step of the derivation and sometimes it showed derivations alternate to the staff solution. It was most misleading on problem 1c) where it incorrectly suggested an FFT based convolution for critical path when the correct (and more efficient) solution uses direct conv with parallel matrix operations. This threw off the logic and resulted in incorrect solutions for the following subparts. </paragraph><paragraph>There were other instances where ChatGPT overcomplicated things. When estimating the optimum generic square linear encoder W using the SVD, it used a placeholder variable Z=WU which was very confusing. I've noticed this when I've used ChatGPT for hw help previously for this class; it really likes to come up with extra variables in the name of simplification, but really just serves to confuse the reader. </paragraph><paragraph>While ChatGPT got incorrect results for time complexity analysis for question 1, it gave a fully correct (with correct and thorough steps &amp; intuition) solution for 4c). </paragraph><paragraph>In conclusion, without mastery knowledge of the subject, it's really difficult to know when ChatGPT is hallucinating or overcomplicating. Thus, it's not more helpful than working backwards from staff solutions for the subparts where steps are shown in the staff solutions. </paragraph><paragraph>See this annotated conversation for more problem specific details:</paragraph><file url=\"https://static.us.edusercontent.com/files/tzsk8da29pvwgA7zy19jBMvj\" filename=\"screencapture-chatgpt-c-6930c5a2-9468-8327-bf03-8647a77eada3-2025-12-03-15_44_15 (1).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T09:19:12.125774+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7409159,
            "author": "Manhar Gupta",
            "project_title": "Special Participation D: HW 4 Lion vs AdamW on CNN transfer learning and Newton-Schulz coefficients",
            "post_body": "For HW4, I designed a problem to implement a reusable train_validation loop, visualise the effect of two commonly used sets of Newton-Schulz coefficients on matrix singular values, implement Lion optimizer from scratch which culminates in a systematic comparison of Lion vs AdamW on transfer learning of ResNet18 on the CIFAR-10 dataset.\n\nThere is a three-part structure to the problem:\n\nTraining Infrastructure\n\nImplement a reusable train_validation_loop() function for PyTorch\n\nTest on SimpleCNN (not to be implemented by students) to validate correctness\n\nNewton-Schulz Iterations\n\nImplement Newton-Schulz iterations to compute orthogonalized version of the input matrix\n\nVisualize how aggressive vs. stable coefficients affect singular value convergence\n\nThe importance of orthogonalization for gradient flow and why Muon can't optimize a large number of parameters in CNNs (2D-only constraint)\n\nEnding analysis questions based on Newton-Schulz coefficients and convergence\n\nLion Optimizer Implementation & Comparison\n\nImplement Lion optimizer based on the original paper and test on SimpleCNN\n\nDo hyperparameter grid search which tests various combinations of learning rate, batch size and weight decay (overall 27 combinations). Weight decay was added based on the suggestion at #394 \n\nTrain ResNet18 with best Lion config vs AdamW baseline and evaluating both models on train, validation progression and test set inference set.",
            "content_xml": "<document version=\"2.0\"><paragraph>For HW4, I designed a problem to implement a reusable train_validation loop, visualise the effect of two commonly used sets of Newton-Schulz coefficients on matrix singular values, implement Lion optimizer from scratch which culminates in a systematic comparison of Lion vs AdamW on transfer learning of ResNet18 on the CIFAR-10 dataset.</paragraph><paragraph>There is a three-part structure to the problem:</paragraph><paragraph>Training Infrastructure</paragraph><list style=\"unordered\"><list-item><paragraph>Implement a reusable train_validation_loop() function for PyTorch</paragraph></list-item><list-item><paragraph>Test on SimpleCNN (not to be implemented by students) to validate correctness</paragraph></list-item></list><paragraph>Newton-Schulz Iterations</paragraph><list style=\"unordered\"><list-item><paragraph>Implement Newton-Schulz iterations to compute orthogonalized version of the input matrix</paragraph></list-item><list-item><paragraph>Visualize how aggressive vs. stable coefficients affect singular value convergence</paragraph></list-item><list-item><paragraph>The importance of orthogonalization for gradient flow and why Muon can't optimize a large number of parameters in CNNs (2D-only constraint)</paragraph></list-item><list-item><paragraph>Ending analysis questions based on Newton-Schulz coefficients and convergence</paragraph></list-item></list><paragraph>Lion Optimizer Implementation &amp; Comparison</paragraph><list style=\"unordered\"><list-item><paragraph>Implement Lion optimizer based on the original paper and test on SimpleCNN</paragraph></list-item><list-item><paragraph>Do hyperparameter grid search which tests various combinations of learning rate, batch size and weight decay (overall 27 combinations). Weight decay was added based on the suggestion at #394 </paragraph></list-item><list-item><paragraph>Train ResNet18 with best Lion config vs AdamW baseline and evaluating both models on train, validation progression and test set inference set.</paragraph><file url=\"https://static.us.edusercontent.com/files/HqoWceEYM9Wz7F8pt4RUPreJ\" filename=\"HW4_NS_CNN_Optimizer_Problem.ipynb\"/></list-item></list><file url=\"https://static.us.edusercontent.com/files/CapSY0bCXHMhNJF5q3Jt3VdD\" filename=\"HW4_NS_CNN_Optimizer_Solutions.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T09:01:59.669103+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7408383,
            "author": "Qicheng Zhu",
            "project_title": "Special Participation A: KIMI K2 on HW 11 Written Questions",
            "post_body": "Model Tested: KIMI K2\n\nDomain: Homework11 -- LORA & Transformer & Mechanistic Interpretability\n\nPerformance Overview\n\nFor most question, KIMI K2 answers perfectly. However, there are some errors because OCR is not correct for matrix and it doesn\u2019t fully understand the question. After I made additional prompt, the answers given by KIMI K2 are all correct.\n\nOverall Performance Summary\n\nAcross the entire HW11 interaction, KIMI K2 demonstrated strong reasoning ability and consistently produced correct answers for nearly all questions. The model was able to handle screenshots, conceptual interpretability questions, and numerical problems with high accuracy.\n\nHowever, two limitations were observed:\n\n1. OCR Errors on Matrix Inputs\n\nIn Question 2(c)(ii), KIMI K2 misinterpreted the matrix due to incorrect OCR parsing.\n\nOnce the correct matrix was explicitly provided, the model immediately corrected its derivation and produced the proper result.\n\n2. Misinterpretation of Ambiguous Prompts\n\nIn Questions 5(c)(d), the model initially used formulas from part (b) instead of the simplified Chinchilla-optimal rules required for the question, leading to an incorrect numerical scale.\n\nAfter additional clarification, KIMI K2 recalculated everything correctly.\n\nApart from these issues, all other questions were answered perfectly.\n\nHallucinations & Accuracy\n\nHallucination Rate: 0%.\n\nThe model never fabricated nonexistent concepts or equations.\n\nAll mistakes were due to OCR error or misinterpreting the prompt\u2019s intended formula.\n\nConclusion\n\nKIMI K2 demonstrates high competency in advanced deep learning theory and can correctly solve most HW-level conceptual problems with minimal intervention. The model showed no hallucinations and delivered fully correct solutions once OCR and prompt ambiguities were addressed.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold><bold>Model Tested: </bold></bold>KIMI K2</paragraph><paragraph><bold><bold>Domain:</bold></bold> Homework11 -- LORA &amp; Transformer &amp; Mechanistic Interpretability</paragraph><paragraph><bold><bold>Performance Overview</bold></bold></paragraph><paragraph>For most question, KIMI K2 answers perfectly. However, there are some errors because OCR is not correct for matrix and it doesn\u2019t fully understand the question. After I made additional prompt, the answers given by KIMI K2 are all correct.</paragraph><paragraph><bold><bold>Overall Performance Summary</bold></bold></paragraph><paragraph>Across the entire HW11 interaction, <bold><bold>KIMI K2 demonstrated strong reasoning ability and consistently produced correct answers for nearly all questions.</bold></bold> The model was able to handle screenshots, conceptual interpretability questions, and numerical problems with high accuracy.</paragraph><paragraph>However, two limitations were observed:</paragraph><paragraph>1. OCR Errors on Matrix Inputs</paragraph><paragraph>In Question 2(c)(ii), KIMI K2 misinterpreted the matrix due to incorrect OCR parsing.</paragraph><paragraph>Once the correct matrix was explicitly provided, the model immediately corrected its derivation and produced the proper result.</paragraph><paragraph>2. Misinterpretation of Ambiguous Prompts</paragraph><paragraph>In Questions 5(c)(d), the model initially used formulas from part (b) instead of the simplified Chinchilla-optimal rules required for the question, leading to an incorrect numerical scale.</paragraph><paragraph>After additional clarification, KIMI K2 recalculated everything correctly.</paragraph><paragraph>Apart from these issues, all other questions were answered perfectly.</paragraph><paragraph><bold><bold>Hallucinations &amp; Accuracy</bold></bold></paragraph><paragraph>Hallucination Rate: 0%.</paragraph><paragraph>The model never fabricated nonexistent concepts or equations.</paragraph><paragraph>All mistakes were due to OCR error or misinterpreting the prompt\u2019s intended formula.</paragraph><paragraph><bold><bold>Conclusion</bold></bold></paragraph><paragraph>KIMI K2 demonstrates high competency in advanced deep learning theory and can correctly solve most HW-level conceptual problems with minimal intervention. The model showed no hallucinations and delivered fully correct solutions once OCR and prompt ambiguities were addressed.</paragraph><file url=\"https://static.us.edusercontent.com/files/vnIbFjwmb9lhnLGSW95xgi9n\" filename=\"ParticipationA_ KIMI_HW11_QichengZhu.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T07:42:30.669762+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7408067,
            "author": "Dagny Streit",
            "project_title": "Special Participation A: ChatGPT on HW 8",
            "post_body": "I used ChatGPT 5.1 (Auto) to solve the written portions of Homework 8 (Questions 1, 3, and 4). For most of the problems, Chat GPT was able to correctly solve them on the first try. Below, I outlined the strengths and weaknesses of the model that I noticed, which included the types of questions Chat GPT tended to do well on versus needed more guidance on.\n\nStrengths:\n\nConsistently correct on direct mathematical derivations (unrolling recurrences, computing kernels, linear algebra, etc.)\n\nProduced clear step-by-step reasoning with limited guidance\n\nHandled numerical examples and matrix calculations well\n\nAble to refine and reorganize its thoughts effectively when prompted\n\nWeaknesses:\n\nHad difficultly with some algorithmic reasoning (most clearly demonstrated in the critical path length in Question 1c)\n\nPointing out missing factors and asking it to reorganize its thoughts generally caused Chat GPT to re-evaluate and correct its earlier attempt\n\nOccasionally gave over-complicated derivations and logic to reach the correct answer when a simpler argument was possible and intended\n\nWhen it made mistakes, they tended to follow a pattern (for example, repeatedly overlooking the logn term in the critical path length in Question 1c)\n\nAttached is my annotated log of the ChatGPT interaction. The document is color-coded for clarity. Green annotations / highlights indicate the response was correct. Red annotations / highlights indicate that the response was incorrect. Orange annotations indicate that the answer was partially correct.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT 5.1 (Auto) to solve the written portions of Homework 8 (Questions 1, 3, and 4). For most of the problems, Chat GPT was able to correctly solve them on the first try. Below, I outlined the strengths and weaknesses of the model that I noticed, which included the types of questions Chat GPT tended to do well on versus needed more guidance on.</paragraph><paragraph>Strengths:</paragraph><list style=\"unordered\"><list-item><paragraph>Consistently correct on direct mathematical derivations (unrolling recurrences, computing kernels, linear algebra, etc.)</paragraph></list-item><list-item><paragraph>Produced clear step-by-step reasoning with limited guidance</paragraph></list-item><list-item><paragraph>Handled numerical examples and matrix calculations well</paragraph></list-item><list-item><paragraph>Able to refine and reorganize its thoughts effectively when prompted</paragraph></list-item></list><paragraph>Weaknesses:</paragraph><list style=\"unordered\"><list-item><paragraph>Had difficultly with some algorithmic reasoning (most clearly demonstrated in the critical path length in Question 1c)</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Pointing out missing factors and asking it to reorganize its thoughts generally caused Chat GPT to re-evaluate and correct its earlier attempt</paragraph></list-item></list></list-item><list-item><paragraph>Occasionally gave over-complicated derivations and logic to reach the correct answer when a simpler argument was possible and intended</paragraph></list-item><list-item><paragraph>When it made mistakes, they tended to follow a pattern (for example, repeatedly overlooking the logn term in the critical path length in Question 1c)</paragraph></list-item></list><paragraph>Attached is my annotated log of the ChatGPT interaction. The document is color-coded for clarity. Green annotations / highlights indicate the response was correct. Red annotations / highlights indicate that the response was incorrect. Orange annotations indicate that the answer was partially correct.</paragraph><file url=\"https://static.us.edusercontent.com/files/6fAgQgpmoQsGKy7fJrfloBbv\" filename=\"Participation A Annotated.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T07:02:14.471564+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7407894,
            "author": "Ayush Goel",
            "project_title": "Special Participation A: Gemini 3 Pro on HW 0",
            "post_body": "Link to the chat: https://gemini.google.com/share/89b0a83f691b\n\n\nI ran HW 0 through gemini and it was able to one-shot most of the homework. The PDF is annotated with my thoughts about specific questions and responses about gemini. Here are some things I wanted to highlight:\n\nThings gemini was able to do that were impressive:\n\nI fed the questions as screenshots, and gemini was able to parse the text correctly, including the equations without being given the latex\n\nGemini was able to handle multiple subparts together at times, and even able to break down question into different cases when needed.\n\nGemini was able to relate different subparts of the question together and explained the concepts the questions were trying to illustrate even with no mention of them (for example kernel trick in question 3)\n\nGemini gave detailed intermediate steps which were all correct with no mistakes instead of just arriving at a memorized answer. \n\nQuestions where gemini went wrong:\n\nGemini went wrong in 5 b ii. The hint in this question was to use a numerical example, which gemini did correctly. However, it incorrectly assumed that the result of one example would generalize. However, without giving it any hints and just prompting it to reconsider with other examples, gemini was able to realize that the elbow could move left or right.\n\nGemini also made a mistake in 5 d. This question involved a significant amount of calculus and algebra, and gemini made a mistake in one of the intermediate steps. This makes sense as this isn\u2019t a commonly seen derivation in textbooks (as compared to ridge least squares derivation). For this one, I had to prompt it with a hint to keep the algebra in terms of matrices instead of oversimplifying after which it was able to arrive at the correct answer.",
            "content_xml": "<document version=\"2.0\"><paragraph>Link to the chat: <link href=\"https://gemini.google.com/share/89b0a83f691b\">https://gemini.google.com/share/89b0a83f691b</link><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/abE10pcfWhcuYOjb23jjIhjw\" filename=\"hw_0_gemini_pro_special_participation_a.pdf\"/><paragraph>I ran HW 0 through gemini and it was able to one-shot most of the homework. The PDF is annotated with my thoughts about specific questions and responses about gemini. Here are some things I wanted to highlight:</paragraph><paragraph>Things gemini was able to do that were impressive:</paragraph><list style=\"ordered\"><list-item><paragraph>I fed the questions as screenshots, and gemini was able to parse the text correctly, including the equations without being given the latex</paragraph></list-item><list-item><paragraph>Gemini was able to handle multiple subparts together at times, and even able to break down question into different cases when needed.</paragraph></list-item><list-item><paragraph>Gemini was able to relate different subparts of the question together and explained the concepts the questions were trying to illustrate even with no mention of them (for example kernel trick in question 3)</paragraph></list-item><list-item><paragraph>Gemini gave detailed intermediate steps which were all correct with no mistakes instead of just arriving at a memorized answer. </paragraph></list-item></list><paragraph>Questions where gemini went wrong:</paragraph><list style=\"ordered\"><list-item><paragraph>Gemini went wrong in 5 b ii. The hint in this question was to use a numerical example, which gemini did correctly. However, it incorrectly assumed that the result of one example would generalize. However, without giving it any hints and just prompting it to reconsider with other examples, gemini was able to realize that the elbow could move left or right.</paragraph></list-item><list-item><paragraph>Gemini also made a mistake in 5 d. This question involved a significant amount of calculus and algebra, and gemini made a mistake in one of the intermediate steps. This makes sense as this isn\u2019t a commonly seen derivation in textbooks (as compared to ridge least squares derivation). For this one, I had to prompt it with a hint to keep the algebra in terms of matrices instead of oversimplifying after which it was able to arrive at the correct answer.</paragraph></list-item></list></document>",
            "links": [
                "https://gemini.google.com/share/89b0a83f691b"
            ],
            "attachments": [],
            "created_at": "2025-12-05T06:38:54.935327+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7407541,
            "author": "Xueli Sun",
            "project_title": "Special Participation A -- DeepSeek-v3.2 Overthinks Less in Chinese",
            "post_body": "TL;DR: By prepending one Chinese sentence, the model will reason / \"think\" in Chinese, which accelerates its response by 2.5x and saves 2/3 tokens!\n\nThe prompt: \u8bf7\u52a1\u5fc5\u7528\u4e2d\u6587\u601d\u8003\uff0c\u5e76\u7528\u82f1\u6587\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898\u3002 (\"Please make sure to think in Chinese and answer the following question in English.\")\n\nCode is available, and discussions are warmly welcome.",
            "content_xml": "<document version=\"2.0\"><paragraph>TL;DR: By prepending one Chinese sentence, the model will reason / \"think\" in Chinese, which accelerates its response by 2.5x and saves 2/3 tokens!</paragraph><paragraph>The prompt: \u8bf7\u52a1\u5fc5\u7528<bold>\u4e2d\u6587</bold>\u601d\u8003\uff0c\u5e76\u7528\u82f1\u6587\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898\u3002 (\"Please make sure to think in <bold>Chinese</bold> and answer the following question in English.\")</paragraph><paragraph>Code is available, and discussions are warmly welcome.</paragraph><file url=\"https://static.us.edusercontent.com/files/byJkwAdYA5U0WTPSxHV1QkNI\" filename=\"xueli_sun_deepseek_overthink_cn.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T05:52:32.652712+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7406979,
            "author": "Elizabeth Weaver",
            "project_title": "Special Participation E: Building a Socratic Tutor",
            "post_body": "Building a Socratic Tutor for Deep Learning: Designing Prompts That Probe Rather Than Tell\n\nFor the special participation assignment on AI-enhanced learning tools, I took a different approach than using an existing AI learning assistant. I designed a Socratic tutor prompt from scratch with specific pedagogical goals in mind.\n\nI used this prompt in a conversation with Claude Opus 4.5. I used Claude's \"project\" feature and uploaded the lecture notes to the project, though this didn't seem to make much of a difference as you'll see later.\n\nThe Core Idea: Test Understanding, Don't Just Explain\n\nThe key distinction in my approach is that the AI's primary job is not to explain concepts to me, it's to probe my understanding and expose gaps. Rather than uploading lecture materials and asking the model to teach me, I created a prompt where I explain concepts to the model, and it asks pointed follow-up questions to find weaknesses in my reasoning. My goal is to expose where I am too overconfident in my understanding of a topic, and fill in the holes.\n\nThey say that teaching is the best way to learn. Here, you don't just re-read notes, you practice articulating ideas and defending them under questioning, explaining a topic to the model.\n\nPrompt Design Choices\n\nI iteratively built the system prompt with several specific features:\n\n1. Question Progression Structure The prompt instructs the model to follow a specific arc: verify basic definitions -> ask about mechanics -> probe edge cases and failure modes -> ask about connections to other course topics. This ensures the conversation doesn't just stay surface-level.\n\n2. \"Don't Immediately Correct\" Rule When I get something wrong, the model is instructed to first ask a question that helps me discover the error myself, only providing explanations after 2-3 failed attempts. This is crucial. If the model just corrects you immediately, you lose the learning opportunity.\n\n3. Confidence Checks The prompt includes instructions to occasionally ask \"How confident are you in that?\" before probing further. This surfaces areas where I already know I'm uncertain, making the conversation more efficient.\n\n4. Explicit Course Topic List I included the actual syllabus topics so the model can ask cross-topic connection questions. For instance, during my SSM discussion, it connected the \"fixed-size hidden state\" limitation to oversquashing in GNNs, a connection I brought up, but that the prompt structure encouraged.\n\n5. Summary at End The prompt asks for a structured summary covering: what I understood well, what misconceptions were uncovered, and key connections to review.\n\nWhat Worked Well\n\nLooking at my annotated conversation on State Space Models, several things stood out:\n\nThe model followed the \"don't immediately correct\" instruction well. When I initially claimed \"outputs at time k only depend on previous inputs, not previous states,\" it didn't correct me, it asked me to write down the recurrence equations so I could see the issue myself.\n\nGood question scaffolding. When I got stuck on where nonlinearities live in SSM architectures, the model broke it down: \"If I stack two SSM layers with nothing in between, what do I effectively have?\" This smaller question was easier to answer than the original.\n\nCross-topic connections. The model naturally connected SSMs to RNNs (vanishing gradients), Transformers (content-based vs. fixed mixing), and GNNs (oversquashing). These connections helped solidify understanding.\n\nThe summary was genuinely useful. It accurately captured my gaps (fuzzy on HiPPO, initially confused about SVD vs eigendecomposition) and suggested specific review topics.\n\nWhat Could Be Improved\n\nFrom my annotations, I noticed several areas where the prompt could be strengthened:\n\n1. Hallucinations about what I said. At one point (page 8), the model claimed \"you mentioned the unrolling involves powers of A\", but I hadn't actually said this. The model was leading the conversation in a good direction, but it shouldn't attribute statements to me that I didn't make.\n\n2. Imprecise technical claims. The model said inference is \"O(1) per step\" (page 8), which can be misleading. It is true that it is constant time per token, but it would be better for the student\u2019s understanding to explain it as O(L), where L is sequence length.\n\n3. Oversimplification of HiPPO eigenvalues. The model stated HiPPO produces \"negative real\" eigenvalues (page 11), when in reality they're generally complex with negative real parts. This is a subtle but meaningful distinction.\n\n4. Missed opportunities to probe further. When the model mentioned LayerNorm or the D matrix, the model didn't follow up. A more thorough tutor might ask \"what does the D matrix do?\" or \"why LayerNorm specifically?\"\n\n5. Not referencing lecture notes. The prompt instructs the model to tie explanations to \"lecture notes in this project,\" but even with notes provided, it often explained concepts from general knowledge rather than grounding in the specific course material.\n\nReflection\n\nUsing this tool genuinely helped me prepare for understanding SSMs more deeply. The conversation forced me to articulate things I thought I understood but actually couldn't explain precisely (i.e. why selective SSMs break the convolution trick).\n\nThe main takeaway: the value isn't in having an AI explain things to you, it's in having an AI pressure-test your own explanations. This is a fundamentally different mode of studying, and I think it's more effective for deep understanding than passive review.\n\nI've added in the prompt here so you can try it for yourself! I also added in the pdf of the original chat, and my annotated version.",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\"><bold>Building a Socratic Tutor for Deep Learning: Designing Prompts That Probe Rather Than Tell</bold></heading><paragraph>For the special participation assignment on AI-enhanced learning tools, I took a different approach than using an existing AI learning assistant. I designed a Socratic tutor prompt from scratch with specific pedagogical goals in mind.</paragraph><paragraph>I used this prompt in a conversation with Claude Opus 4.5. I used Claude's \"project\" feature and uploaded the lecture notes to the project, though this didn't seem to make much of a difference as you'll see later.</paragraph><heading level=\"3\"><bold>The Core Idea: Test Understanding, Don't Just Explain</bold></heading><paragraph>The key distinction in my approach is that the AI's primary job is <italic>not</italic> to explain concepts to me, it's to <bold>probe my understanding and expose gaps</bold>. Rather than uploading lecture materials and asking the model to teach me, I created a prompt where I explain concepts to the model, and it asks pointed follow-up questions to find weaknesses in my reasoning. My goal is to expose where I am too overconfident in my understanding of a topic, and fill in the holes.</paragraph><paragraph>They say that teaching is the best way to learn. Here, you don't just re-read notes, you practice articulating ideas and defending them under questioning, explaining a topic to the model.</paragraph><heading level=\"3\"><bold>Prompt Design Choices</bold></heading><paragraph>I iteratively built the system prompt with several specific features:</paragraph><paragraph><bold>1. Question Progression Structure</bold> The prompt instructs the model to follow a specific arc: verify basic definitions -&gt; ask about mechanics -&gt; probe edge cases and failure modes -&gt; ask about connections to other course topics. This ensures the conversation doesn't just stay surface-level.</paragraph><paragraph><bold>2. \"Don't Immediately Correct\" Rule</bold> When I get something wrong, the model is instructed to first ask a question that helps me discover the error myself, only providing explanations after 2-3 failed attempts. This is crucial. If the model just corrects you immediately, you lose the learning opportunity.</paragraph><paragraph><bold>3. Confidence Checks</bold> The prompt includes instructions to occasionally ask \"How confident are you in that?\" before probing further. This surfaces areas where I already know I'm uncertain, making the conversation more efficient.</paragraph><paragraph><bold>4. Explicit Course Topic List</bold> I included the actual syllabus topics so the model can ask cross-topic connection questions. For instance, during my SSM discussion, it connected the \"fixed-size hidden state\" limitation to oversquashing in GNNs, a connection I brought up, but that the prompt structure encouraged.</paragraph><paragraph><bold>5. Summary at End</bold> The prompt asks for a structured summary covering: what I understood well, what misconceptions were uncovered, and key connections to review.</paragraph><heading level=\"3\"><bold>What Worked Well</bold></heading><paragraph>Looking at my annotated conversation on State Space Models, several things stood out:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>The model followed the \"don't immediately correct\" instruction well.</bold> When I initially claimed \"outputs at time k only depend on previous inputs, not previous states,\" it didn't correct me, it asked me to write down the recurrence equations so I could see the issue myself.</paragraph></list-item><list-item><paragraph><bold>Good question scaffolding.</bold> When I got stuck on where nonlinearities live in SSM architectures, the model broke it down: \"If I stack two SSM layers with nothing in between, what do I effectively have?\" This smaller question was easier to answer than the original.</paragraph></list-item><list-item><paragraph><bold>Cross-topic connections.</bold> The model naturally connected SSMs to RNNs (vanishing gradients), Transformers (content-based vs. fixed mixing), and GNNs (oversquashing). These connections helped solidify understanding.</paragraph></list-item><list-item><paragraph><bold>The summary was genuinely useful.</bold> It accurately captured my gaps (fuzzy on HiPPO, initially confused about SVD vs eigendecomposition) and suggested specific review topics.</paragraph></list-item></list><heading level=\"3\"><bold>What Could Be Improved</bold></heading><paragraph>From my annotations, I noticed several areas where the prompt could be strengthened:</paragraph><paragraph><bold>1. Hallucinations about what I said.</bold> At one point (page 8), the model claimed \"you mentioned the unrolling involves powers of A\", but I hadn't actually said this. The model was leading the conversation in a good direction, but it shouldn't attribute statements to me that I didn't make.</paragraph><paragraph><bold>2. Imprecise technical claims.</bold> The model said inference is \"O(1) per step\" (page 8), which can be misleading. It is true that it is constant time per token, but it would be better for the student\u2019s understanding to explain it as O(L), where L is sequence length.</paragraph><paragraph><bold>3. Oversimplification of HiPPO eigenvalues.</bold> The model stated HiPPO produces \"negative real\" eigenvalues (page 11), when in reality they're generally complex with negative real parts. This is a subtle but meaningful distinction.</paragraph><paragraph><bold>4. Missed opportunities to probe further.</bold> When the model mentioned LayerNorm or the D matrix, the model didn't follow up. A more thorough tutor might ask \"what does the D matrix do?\" or \"why LayerNorm specifically?\"</paragraph><paragraph><bold>5. Not referencing lecture notes.</bold> The prompt instructs the model to tie explanations to \"lecture notes in this project,\" but even with notes provided, it often explained concepts from general knowledge rather than grounding in the specific course material.</paragraph><heading level=\"3\"><bold>Reflection</bold></heading><paragraph>Using this tool genuinely helped me prepare for understanding SSMs more deeply. The conversation forced me to articulate things I thought I understood but actually couldn't explain precisely (i.e. why selective SSMs break the convolution trick).</paragraph><paragraph>The main takeaway: <bold>the value isn't in having an AI explain things to you, it's in having an AI pressure-test your own explanations.</bold> This is a fundamentally different mode of studying, and I think it's more effective for deep understanding than passive review.<break/><break/>I've added in the prompt here so you can try it for yourself! I also added in the pdf of the original chat, and my annotated version.</paragraph><file url=\"https://static.us.edusercontent.com/files/wvlaLZpyhNFAwVamKZMOMNLr\" filename=\"special participation E_ 1.txt\"/><file url=\"https://static.us.edusercontent.com/files/FtvNd8z42vTOddb8MCZzfaX7\" filename=\"Claude-Understanding state space models annotated.pdf\"/><file url=\"https://static.us.edusercontent.com/files/9UtDoYd21ljGLagpXeL1mqYC\" filename=\"Claude-Understanding state space models.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-05T04:30:17.222314+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7406647,
            "author": "Kithmini Herath",
            "project_title": "[WIP] Special Participation C: Refactoring HW 5 Q5",
            "post_body": "Hi all,\n\nI was planning on refactoring the coding problem Q5 (understanding dropout) of HW5. This is currently a work-in-progress and I created this post to deconflict with other people who may also be doing special participation C (I didn't see any other post or google sign up sheet to do this even though we were explicitly asked to deconflict).  \n\nI've created a GitHub repository, where I will add the refactored notebooks to:\n\nhttps://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/\n\nI plan on doing the following fixes with Claude Code without losing any of its teaching value:\n\nCreate a configuration class for clear problem parameter definition\n\nDecouple training codes from visualization codes\n\nType hinting and documentation\n\nI will edit this post with the final report of my work and also update the GitHub repository with the final versions of the code.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all,</paragraph><paragraph>I was planning on refactoring the coding problem Q5 (understanding dropout) of HW5. This is currently a work-in-progress and I created this post to deconflict with other people who may also be doing special participation C (I didn't see any other post or google sign up sheet to do this even though we were explicitly asked to deconflict).  </paragraph><paragraph>I've created a GitHub repository, where I will add the refactored notebooks to:</paragraph><paragraph><link href=\"https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/\">https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/</link></paragraph><paragraph>I plan on doing the following fixes with Claude Code without losing any of its teaching value:</paragraph><list style=\"number\"><list-item><paragraph>Create a configuration class for clear problem parameter definition</paragraph></list-item><list-item><paragraph>Decouple training codes from visualization codes</paragraph></list-item><list-item><paragraph>Type hinting and documentation</paragraph></list-item></list><paragraph>I will edit this post with the final report of my work and also update the GitHub repository with the final versions of the code.</paragraph></document>",
            "links": [
                "https://github.com/KithminiHerath/CS282-HW5-Q5-Refactor/"
            ],
            "attachments": [],
            "created_at": "2025-12-05T03:39:28.389987+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405910,
            "author": "Kelvin Li",
            "project_title": "Special Participation E: ChatGPT and Feynman Technique",
            "post_body": "One of the best ways to learn something is to teach it to someone else. The Feynman Technique captures this idea: if you can explain a concept clearly (and thoroughly) to another person, you truly understand it \u2014 and if you can\u2019t, the explanation process immediately reveals the gaps.\n\nTraditionally, the hard part is finding the right student: someone who knows just enough background to follow your explanation, but also questions you at the right moments to expose gaps you didn\u2019t know you had. That kind of student is hard to find on demand. Now, with AI, we can simply ask the model to be that student. In my interaction, the AI was both role-playing as that student and correcting my response like an expert too, really helpful.\n\nIn the PEFT section of the course (Lectures 21 & 22), we learned about:\n\nIn-Context Learning (ICL)\n\nPrompt Tuning\n\nPrefix Tuning\n\nLoRA\n\nThese concepts feel intuitive at a surface level, but when I tried to teach them to an AI \u201cstudent,\u201d I quickly discovered many gaps in my understanding. Throughout the session, the AI student challenged vague explanations and pushed for deeper details. This forced me to identify the gaps in my understanding that I overlooked and refine hand-wavey intuitions into clear mechanisms. By the end, my understanding felt noticeably clearer, more structured, and more \u201cinternalized\u201d than just re-reading the slides.\n\nChat log: https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d\n\nAnnotated PDF:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>One of the best ways to learn something is to teach it to someone else. The <bold>Feynman Technique</bold> captures this idea: if you can explain a concept clearly (and thoroughly) to another person, you truly understand it \u2014 and if you can\u2019t, the explanation process immediately reveals the gaps.</paragraph><paragraph>Traditionally, the hard part is <italic>finding the right student</italic>: someone who knows just enough background to follow your explanation, but also questions you at the right moments to expose gaps you didn\u2019t know you had. That kind of student is hard to find on demand. Now, with AI, we can simply ask the model to <italic>be</italic> that student. In my interaction, the AI was both role-playing as that student and correcting my response like an expert too, really helpful.</paragraph><paragraph>In the <bold>PEFT section of the course (Lectures 21 &amp; 22)</bold>, we learned about:</paragraph><list style=\"unordered\"><list-item><paragraph>In-Context Learning (ICL)</paragraph></list-item><list-item><paragraph>Prompt Tuning</paragraph></list-item><list-item><paragraph>Prefix Tuning</paragraph></list-item><list-item><paragraph>LoRA</paragraph></list-item></list><paragraph>These concepts feel intuitive at a surface level, but when I tried to <italic>teach</italic> them to an AI \u201cstudent,\u201d I quickly discovered many gaps in my understanding. Throughout the session, the AI student challenged vague explanations and pushed for deeper details. This forced me to identify the gaps in my understanding that I overlooked and refine hand-wavey intuitions into clear mechanisms. By the end, my understanding felt noticeably clearer, more structured, and more \u201cinternalized\u201d than just re-reading the slides.</paragraph><paragraph>Chat log: <link href=\"https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d\">https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d</link></paragraph><paragraph>Annotated PDF:</paragraph><file url=\"https://static.us.edusercontent.com/files/Dajy1vTN6I5fgBJiKJRCPBEG\" filename=\"FeynmanTechnique.pdf\"/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/share/69317faa-b744-800d-8c16-32588c43605d"
            ],
            "attachments": [],
            "created_at": "2025-12-05T00:17:05.277218+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405830,
            "author": "Jorge Diaz Chao",
            "project_title": "Antigravity on HW7 (Coding)",
            "post_body": "Recently, Google launched Antigravity (here's the video introduction on YouTube).\n\nAn agentic development platform, evolving the IDE into the agent-first era.\n\nFor a very long time Google was behind in the space of coding agents, with Codex and Claude have being very welcomed by the community and launched significantly earlier. When Antigravity was released they made it look big news, as if it were to be the first true agentic experience. However, when trying it out by myself for the first time, the experience was quite the opposite. Here, I share the logs as markdown and the solutions.\n\nI describe my thoughts here too since I feel like they're general to the whole experience and more convenient for you. \n\nFirst issue I had from the very beginning. Antigravity can read any kind of file, but not write. So .ipynb files were very inconvenient. By default, almost every time the model would realize after trying to edit the file and fail, and writes a separate .py file with the solution for you to copy and paste into the .ipynb.  Although not a huge problem, you'd expect agents to be able to interact with a wide range of interfaces if not any.\n\nAt time when writing the new files it would notice tests from the skeleton code and/or write its own and run the command directly from terminal to check if the solution worked or not. While very neat, it often took very long for the task and the alternative (writing out the solution in chat, pasting into the notebook manually and checking yourself) would take less time.\n\nAntigravity supports tab-complete to fill out gaps or fix mistakes, which often came in handy, it felt very natural to interact with and very magical tool. It isn't forces like the chat, where you have to think about a prompt and wait for an unpredictable amount of time. It seemed like it just knew, you could glance at the preview and quickly decide whether to include the change or not. Unfortunately, it seems like it's very limited in context awareness, but it would be nice if such solution was made more powerful by future agents.\n\nIt was able to solve issues including both with the code where I normally just pass the traceback error with very little to no explanation (since I felt like the errors weren't big enough to justify an effort to describe the issue) and it generally did fine. However for more involved issues like involving problems with seeds, device and downloading dataset I had to inspect and provide big clues for it to output a working solution.\n\nOn top of that it seems like the interface and/or backend crashes a lot (probably since it's very new), but at times the model will stop reasoning and output nothing.\n\nOther aspect like reading markdown and being very independent (able to understand a task well without little guidance or promoting) it does well. Although any model nowadays does very good at that and I feel like generally models nowadays benefit little from specialized prompts. At least for simple tasks like these ones, where 2 years ago prompting would make a world of a difference.\n\nWhile there were generally a lot of problems considering the not so hard difficulty of the problems, and the expectations set by Google when launching Antigravity. I do think a lot of problems could be solved with a more appropriate setup. Jupyter notebooks are a good interface for learning and playing with code, but not ideal for an agent since it adds unnecessary overhead from the perspective of the agent and unclarity. I'm quite sure most of the issues would've been resolved in everything was just in a python file from the beginning. However, I do think we shouldn't aim to adapt our interfaces for these models, but the opposite. Models should adapt to our interfaces, no matter how complicated they are, and ideally they'll learn how to handle any kind of interface like we do. I understand this is a much harder task, but I presume, one that is a worth a lot solving, since from understanding how to interact with any kind of interface we would learn a lot in the process, like representations that we could use for downstream tasks and understand the world around us better through the lens of these models that perhaps learn to understand the world and interact with it in different ways than we do.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Recently, Google launched <link href=\"https://antigravity.google\">Antigravity</link> (here's the <link href=\"https://www.youtube.com/watch?v=SVCBA-pBgt0\">video introduction</link> on YouTube).</paragraph><blockquote>An agentic development platform, evolving the IDE into the agent-first era.</blockquote><paragraph>For a very long time Google was behind in the space of coding agents, with Codex and Claude have being very welcomed by the community and launched significantly earlier. When Antigravity was released they made it look big news, as if it were to be the first true agentic experience. However, when trying it out by myself for the first time, the experience was quite the opposite. Here, I share the logs as markdown and the solutions.</paragraph><file url=\"https://static.us.edusercontent.com/files/N6mA3i1Sg29p9psG71AGPPG0\" filename=\"code_antigravity.zip\"/><paragraph>I describe my thoughts here too since I feel like they're general to the whole experience and more convenient for you. </paragraph><list style=\"number\"><list-item><paragraph>First issue I had from the very beginning. Antigravity can read any kind of file, but not write. So <code>.ipynb</code> files were very inconvenient. By default, almost every time the model would realize after trying to edit the file and fail, and writes a separate <code>.py</code> file with the solution for you to copy and paste into the <code>.ipynb</code>.  Although not a huge problem, you'd expect agents to be able to interact with a wide range of interfaces if not any.</paragraph></list-item><list-item><paragraph>At time when writing the new files it would notice tests from the skeleton code and/or write its own and run the command directly from terminal to check if the solution worked or not. While very neat, it often took very long for the task and the alternative (writing out the solution in chat, pasting into the notebook manually and checking yourself) would take less time.</paragraph></list-item><list-item><paragraph>Antigravity supports tab-complete to fill out gaps or fix mistakes, which often came in handy, it felt very natural to interact with and very magical tool. It isn't forces like the chat, where you have to think about a prompt and wait for an unpredictable amount of time. It seemed like it just knew, you could glance at the preview and quickly decide whether to include the change or not. Unfortunately, it seems like it's very limited in context awareness, but it would be nice if such solution was made more powerful by future agents.</paragraph></list-item><list-item><paragraph>It was able to solve issues including both with the code where I normally just pass the traceback error with very little to no explanation (since I felt like the errors weren't big enough to justify an effort to describe the issue) and it generally did fine. However for more involved issues like involving problems with seeds, device and downloading dataset I had to inspect and provide big clues for it to output a working solution.</paragraph></list-item><list-item><paragraph>On top of that it seems like the interface and/or backend crashes a lot (probably since it's very new), but at times the model will stop reasoning and output nothing.</paragraph></list-item><list-item><paragraph>Other aspect like reading markdown and being very independent (able to understand a task well without little guidance or promoting) it does well. Although any model nowadays does very good at that and I feel like generally models nowadays benefit little from specialized prompts. At least for simple tasks like these ones, where 2 years ago prompting would make a world of a difference.</paragraph></list-item></list><paragraph>While there were generally a lot of problems considering the not so hard difficulty of the problems, and the expectations set by Google when launching Antigravity. I do think a lot of problems could be solved with a more appropriate setup. Jupyter notebooks are a good interface for learning and playing with code, but not ideal for an agent since it adds unnecessary overhead from the perspective of the agent and unclarity. I'm quite sure most of the issues would've been resolved in everything was just in a python file from the beginning. However, I do think we shouldn't aim to adapt our interfaces for these models, but the opposite. Models should adapt to our interfaces, no matter how complicated they are, and ideally they'll learn how to handle any kind of interface like we do. I understand this is a much harder task, but I presume, one that is a worth a lot solving, since from understanding how to interact with any kind of interface we would learn a lot in the process, like representations that we could use for downstream tasks and understand the world around us better through the lens of these models that perhaps learn to understand the world and interact with it in different ways than we do.</paragraph><paragraph/></document>",
            "links": [
                "https://antigravity.google",
                "https://www.youtube.com/watch?v=SVCBA-pBgt0"
            ],
            "attachments": [],
            "created_at": "2025-12-04T23:04:20.470094+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405818,
            "author": "Etaash Patel",
            "project_title": "Special Participation B: Windsurf on Homework 3 Problem 2",
            "post_body": "\nI used Windsurf to complete the coding portions of HW3. While I like the display (visually), in this context, I found several limitations that affected its reliability for the assignment.\n\nWhile the capabilities were limited, the display was nice, and everything felt smooth (until hallucinations occurred). I would consider using Windsurf for an everyday coding project with very little mathematics involved.\n\nHowever, the model\u2019s mathematical reasoning capabilities were limited. Errors were usually hard to correct (they required a significant amount of coaxing). Some issues, such as scaling inaccuracies, appeared repeatedly across subproblems. Windsurf produced multiple hallucinations per problem. For most subproblems (except Problem 2a), individual responses contained several mathematical mistakes. I annotate each hallucination in the order I address it in the log to avoid redundant comments.\n\nAdditionally, Windsurf often did not fully follow instructions. Even when restricted to specific TODO regions, it sometimes edited unrelated code, ignored boundaries, or stated that it executed notebook cells when it had not. The interface between the model and the notebook was inconsistent: the model occasionally reported actions that were not reflected in the actual notebook state, so I needed to verify all changes manually, and then run the notebook manually after each edit.\n\nAll code execution and verification were performed manually by me. Aside from places explicitly noted, Windsurf\u2019s claims about running notebook cells are incorrect. \n\nAdditional note:\n Because there were multiple hallucinations for most problems, each of which needed multiple iterations to fix, I explain hallucinations as I address them rather than duplicating earlier explanations.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/iwVKlmVKfFEMOTnG7IYrLs6Z\" filename=\"Participation B.pdf\"/><paragraph><break/>I used Windsurf to complete the coding portions of HW3. While I like the display (visually), in this context, I found several limitations that affected its reliability for the assignment.<break/><break/>While the capabilities were limited, the display was nice, and everything felt smooth (until hallucinations occurred). I would consider using Windsurf for an everyday coding project with very little mathematics involved.</paragraph><paragraph>However, the model\u2019s mathematical reasoning capabilities were limited. Errors were usually hard to correct (they required a significant amount of coaxing). Some issues, such as scaling inaccuracies, appeared repeatedly across subproblems. Windsurf produced multiple hallucinations per problem. For most subproblems (except Problem 2a), individual responses contained several mathematical mistakes. I annotate each hallucination in the order I address it in the log to avoid redundant comments.<break/><break/>Additionally, Windsurf often did not fully follow instructions. Even when restricted to specific TODO regions, it sometimes edited unrelated code, ignored boundaries, or stated that it executed notebook cells when it had not. The interface between the model and the notebook was inconsistent: the model occasionally reported actions that were not reflected in the actual notebook state, so I needed to verify all changes manually, and then run the notebook manually after each edit.</paragraph><paragraph>All code execution and verification were performed manually by me. Aside from places explicitly noted, Windsurf\u2019s claims about running notebook cells are incorrect. </paragraph><paragraph>Additional note:<break/> Because there were multiple hallucinations for most problems, each of which needed multiple iterations to fix, I explain hallucinations as I address them rather than duplicating earlier explanations.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T22:52:39.191808+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405742,
            "author": "Kelvin Li",
            "project_title": "Special Participation A: Deepseek v3.2 on HW10",
            "post_body": "Executive Summary\n\nI used the newly released DeepSeek v3.2 on HW10.\n\nOverall, this tests the model's \n1. OCR capabilities (reading the fine equations in the screenshots of the problems and also finding relevant parts from the FaceNet paper which was attached as pdf).\n2. Reasoning abilities on the related math content.\n\nIt is particularly impressive given that it was completely free for me to run on their website (and also has extremely low underlying inference cost).\n\nDeepSeek v3.2 (DeepThink) solved all the problems with perfect accuracy and clear chain-of-thought reasoning. \n\nChat log: https://chat.deepseek.com/share/u3b4iptgfflvv0t4oh\n\nAnnotated PDF:\n\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Executive Summary</heading><paragraph>I used the newly released DeepSeek v3.2 on HW10.</paragraph><paragraph>Overall, this tests the model's <break/>1. OCR capabilities (reading the fine equations in the screenshots of the problems and also finding relevant parts from the FaceNet paper which was attached as pdf).<break/>2. Reasoning abilities on the related math content.</paragraph><paragraph>It is particularly impressive given that it was completely free for me to run on their website (and also has extremely low underlying inference cost).</paragraph><paragraph>DeepSeek v3.2 (DeepThink) solved all the problems with perfect accuracy and clear chain-of-thought reasoning. </paragraph><paragraph>Chat log: <link href=\"https://chat.deepseek.com/share/u3b4iptgfflvv0t4oh\">https://chat.deepseek.com/share/u3b4iptgfflvv0t4oh</link></paragraph><paragraph>Annotated PDF:</paragraph><file url=\"https://static.us.edusercontent.com/files/FGNLpzFHZSxc9hfYSiqbQjEa\" filename=\"DeepSeekv3.2_HW10.pdf\"/><paragraph/></document>",
            "links": [
                "https://chat.deepseek.com/share/u3b4iptgfflvv0t4oh"
            ],
            "attachments": [],
            "created_at": "2025-12-04T21:47:06.01722+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405730,
            "author": "Tamzid Razzaque",
            "project_title": "Special Participation B: Gemini in Colab for Coding Assignment in Hw0",
            "post_body": "Executive summary:\n\nOverall, Gemini in Colab demonstrated a solid understanding of the conceptual structure of neural-network components. Like affine layers, ReLU, loss functions, and multi-layer networks. And it generally produced code aligned with the standard implementations expected for this assignment. It handled forward and backward passes correctly after minor adjustments, and it successfully trained both shallow and deep networks once hyperparameters were tuned. However, its performance revealed recurring issues: it struggled to maintain awareness of notebook state, repeatedly attempted to run or rewrite cells out of order, and occasionally declared tasks \u201cfinished\u201d when TODOs were still not completed. Troubleshooting steps were often brute-force rather than reasoning-driven, especially during overfitting experiments and import path debugging. The final results were correct, but getting there required significant guidance and verification. In short, the LLM is strong at outlining solutions and generating plausible first-draft code, but it still needs careful oversight to ensure correctness, completeness, and proper integration within a multi-cell workflow.\n\nThe PDF has three parts. First is the normal notebook output with all the code cells, results, and training logs. After that, it switches into Gemini\u2019s internal reasoning, where it describes what it thinks it is doing as it runs the tasks. The final part is the full chat conversation between me and Gemini, showing all the back and forth while I tried to get it to finish the assignment.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive summary:</bold></paragraph><paragraph>Overall, Gemini in Colab demonstrated a solid understanding of the conceptual structure of neural-network components. Like affine layers, ReLU, loss functions, and multi-layer networks. And it generally produced code aligned with the standard implementations expected for this assignment. It handled forward and backward passes correctly after minor adjustments, and it successfully trained both shallow and deep networks once hyperparameters were tuned. However, its performance revealed recurring issues: it struggled to maintain awareness of notebook state, repeatedly attempted to run or rewrite cells out of order, and occasionally declared tasks \u201cfinished\u201d when TODOs were still not completed. Troubleshooting steps were often brute-force rather than reasoning-driven, especially during overfitting experiments and import path debugging. The final results were correct, but getting there required significant guidance and verification. In short, the LLM is strong at outlining solutions and generating plausible first-draft code, but it still needs careful oversight to ensure correctness, completeness, and proper integration within a multi-cell workflow.<break/><break/>The PDF has three parts. First is the normal notebook output with all the code cells, results, and training logs. After that, it switches into Gemini\u2019s internal reasoning, where it describes what it thinks it is doing as it runs the tasks. The final part is the full chat conversation between me and Gemini, showing all the back and forth while I tried to get it to finish the assignment.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/us4I1Rjd1P1CCalB1rjI0dY7\" filename=\"networks.ipynb - Colab.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T21:31:02.156563+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405682,
            "author": "Elizabeth Polito",
            "project_title": "Special Participation B: Gemini Pro 3 on HW4 Programming",
            "post_body": "Executive Summary:\n\nI completed the programming portion of HW #4 using Gemini Pro 3. Overall, Gemini Pro 3 was able to successfully one-shot solutions to nearly all of the assigned parts of the exercises, with only small errors relating to misunderstanding the structure of the existing code that it was able to fix with some additional prompting. \n\nFor problem #5, \u201cDesigning a 2D Filter,\u201d the code was fairly short, so I copied the text and existing code snippets directly into the chatbot. Gemini Pro 3 was able to one-shot both parts of this problem and even included extra explanations. For one part of the problem, it even generated an interactive image to illustrate how the averaging filter works. \n\nFor problem #6, \u201cInductive Bias of CNNs,\u201d the code was too long for the input limit to be copied, so I uploaded the full .ipynb notebook file and proceeded by copying relevant snippets from the code. This approach worked well in general, and the model was able to one-shot almost everything; however, for the first problem, it mistakenly used four classes instead of the required three in setting up the data loader. In a later part that required a similar set-up, the model correctly defined three classes without additional prompting, indicating that it remembered the initial correction and was able to use the same technique. For this problem, Gemini automatically produced the code in separate .py files which I could easily open or download. I have included these files at the end of the pdf document. Overall, Gemini 3 Pro was very well equipped to successfully complete these problems. \n\nAttached are:\n\nAnnotated transcript of Problem #5 Conversation \u201chand_design_annotated.pdf\u201d\n\nAnnotated transcript of Problem #6 Conversation \u201cinductive_annotated.pdf\u201d",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive Summary:</paragraph><paragraph>I completed the programming portion of HW #4 using Gemini Pro 3. Overall, Gemini Pro 3 was able to successfully one-shot solutions to nearly all of the assigned parts of the exercises, with only small errors relating to misunderstanding the structure of the existing code that it was able to fix with some additional prompting. </paragraph><paragraph>For problem #5, \u201cDesigning a 2D Filter,\u201d the code was fairly short, so I copied the text and existing code snippets directly into the chatbot. Gemini Pro 3 was able to one-shot both parts of this problem and even included extra explanations. For one part of the problem, it even generated an interactive image to illustrate how the averaging filter works. </paragraph><paragraph>For problem #6, \u201cInductive Bias of CNNs,\u201d the code was too long for the input limit to be copied, so I uploaded the full .ipynb notebook file and proceeded by copying relevant snippets from the code. This approach worked well in general, and the model was able to one-shot almost everything; however, for the first problem, it mistakenly used four classes instead of the required three in setting up the data loader. In a later part that required a similar set-up, the model correctly defined three classes without additional prompting, indicating that it remembered the initial correction and was able to use the same technique. For this problem, Gemini automatically produced the code in separate .py files which I could easily open or download. I have included these files at the end of the pdf document. Overall, Gemini 3 Pro was very well equipped to successfully complete these problems. </paragraph><paragraph>Attached are:</paragraph><list style=\"ordered\"><list-item><paragraph>Annotated transcript of Problem #5 Conversation \u201chand_design_annotated.pdf\u201d</paragraph><file url=\"https://static.us.edusercontent.com/files/8sHmZ8G0NlbgX9nbAYaLjNNd\" filename=\"hand_design_annotated.pdf\"/></list-item><list-item><paragraph>Annotated transcript of Problem #6 Conversation \u201cinductive_annotated.pdf\u201d</paragraph><file url=\"https://static.us.edusercontent.com/files/DzhTXXbEtIMbjZl39mntU9re\" filename=\"inductive_annotated.pdf\"/></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T20:42:44.399245+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405582,
            "author": "Justin Li",
            "project_title": "Special Participation A: Deepseek v3.2 on HW 8",
            "post_body": "I used DeepSeek v3.2 to solve the written portions of HW8, where it performed quite well and one shotted almost all of the problems. \n\nOne interesting point was that DeepSeek struggled significantly with Problem 1(c), where it repeatedly overlooked/ignored the parallel computation model needed for the solution. I provided 2 nudges to hint DeepSeek towards the right direction, and only after these prompts did DeepSeek converge to the correct big O solution. Through this example I saw that while DeepSeek can correct mistakes when guided, it is not as strong at independently identifying these issues.\n\nStrengths:\n\nAble to parse matrix expressions, SSM equations, multi-step derivations, and more complex sets of symbols\n\nConsistently one shotted problems on the first attempt\n\nAlgebraic Reasoning was strong\n\nDetailed explanations\n\nWeaknesses:\n\nStruggled a bit with 1c; repeatedly ignored cost of vector and matrix operations\n\nSometimes provided overly long chains of reasoning\n\nHere is my annotated conversation with DeepSeek:\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used DeepSeek v3.2 to solve the written portions of HW8, where it performed quite well and one shotted almost all of the problems. </paragraph><paragraph>One interesting point was that DeepSeek struggled significantly with Problem 1(c), where it repeatedly overlooked/ignored the parallel computation model needed for the solution. I provided 2 nudges to hint DeepSeek towards the right direction, and only after these prompts did DeepSeek converge to the correct big O solution. Through this example I saw that while DeepSeek can correct mistakes when guided, it is not as strong at independently identifying these issues.</paragraph><paragraph><bold>Strengths:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Able to parse matrix expressions, SSM equations, multi-step derivations, and more complex sets of symbols</paragraph></list-item><list-item><paragraph>Consistently one shotted problems on the first attempt</paragraph></list-item><list-item><paragraph>Algebraic Reasoning was strong</paragraph></list-item><list-item><paragraph>Detailed explanations</paragraph></list-item></list><paragraph><bold>Weaknesses:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Struggled a bit with 1c; repeatedly ignored cost of vector and matrix operations</paragraph></list-item><list-item><paragraph>Sometimes provided overly long chains of reasoning</paragraph></list-item></list><paragraph>Here is my annotated conversation with DeepSeek:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/JSxIKfIoif0SOBgT3ndEatPd\" filename=\"Annotated SPA.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T19:25:27.802148+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405559,
            "author": "Fantine Mpacko Priso",
            "project_title": "Special Participation A - MistralAI's Le Chat on HW10 Written portion",
            "post_body": "For special participation A, I used MistralAI's Le Chat to solve HW10 written portion.\n\nOverall, the model did quite well on the conceptual and algebraic parts, but struggled on the subtle complexity analysis:\n\nFor the math derivations (e.g., rewriting softmax with a Gaussian kernel) and the conceptual questions (kernel intuition, causal masking, FaceNet, triplet loss), its answers were correct and aligned with the official solutions, often with clear step-by-step reasoning.\n\nFor the more delicate algorithmic complexity question (kernelized attention with random features), it gave a plausible but wrong answer, keeping an unnecessary (N^2) term and missing the whole \u201clinear in (N)\u201d point of the trick.\n\nWhen I confronted it with the official solution, it was good at post-hoc analysis: it compared its result, admitted the mistake, and explained why its reasoning had been too coarse.\n\nIt did not spontaneously flag uncertainty on that hard question; it sounded confident while being wrong.\n\nSo: strong on standard derivations and conceptual ML, weaker and over-confident on fine-grained complexity / algorithmic details \u2014 which is exactly the type of behavior we were aware it could have.\n\nThe raw chat is available here.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For special participation A, I used MistralAI's Le Chat to solve HW10 written portion.</paragraph><file url=\"https://static.us.edusercontent.com/files/mHbaXGMJBfFuS1L6aQBz7iV4\" filename=\"chat-4de4d570-dc1c-4b2f-baf9-9afc394d0333.json\"/><paragraph>Overall, the model did quite well on the conceptual and algebraic parts, but struggled on the subtle complexity analysis:</paragraph><list style=\"bullet\"><list-item><paragraph>For the math derivations (e.g., rewriting softmax with a Gaussian kernel) and the conceptual questions (kernel intuition, causal masking, FaceNet, triplet loss), its answers were correct and aligned with the official solutions, often with clear step-by-step reasoning.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph>For the more delicate algorithmic complexity question (kernelized attention with random features), it gave a plausible but wrong answer, keeping an unnecessary (N^2) term and missing the whole \u201clinear in (N)\u201d point of the trick.</paragraph></list-item><list-item><paragraph>When I confronted it with the official solution, it was good at post-hoc analysis: it compared its result, admitted the mistake, and explained why its reasoning had been too coarse.</paragraph></list-item><list-item><paragraph>It did not spontaneously flag uncertainty on that hard question; it sounded confident while being wrong.</paragraph></list-item></list><paragraph>So: strong on standard derivations and conceptual ML, weaker and over-confident on fine-grained complexity / algorithmic details \u2014 which is exactly the type of behavior we were aware it could have.</paragraph><paragraph>The raw chat is available <link href=\"https://chat.mistral.ai/chat/d24b9489-e1c2-408f-a079-2294a4ae1036\">here</link>.</paragraph><paragraph/></document>",
            "links": [
                "https://chat.mistral.ai/chat/d24b9489-e1c2-408f-a079-2294a4ae1036"
            ],
            "attachments": [],
            "created_at": "2025-12-04T19:13:57.042068+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405554,
            "author": "Elizabeth Polito",
            "project_title": "Special Participation A: Grok on HW4",
            "post_body": "Executive Summary:\n\nI used Grok to complete the written portion of Homework #4. Since I do not have the paid tier, I used Grok fast. While this is not the top model in the Grok line, it is interesting to evaluate its capabilities from the perspective that it is \u201c150x cheaper than Claude\u201d [1]. Grok was able to one-shot many parts of the problem, but sometimes required corrections to arrive at the correct solution. Notably, the solutions were very long, with significantly more explanation and background included compared to the solutions in the posted answer key. As noted in previous posts, Problem #2 part e on the answer key potentially contains a mistake. Grok got the same answer as indicated by previous Special Participation A posts focusing on this problem set, and when I asked the model to evaluate whether the key\u2019s current solution is reasonable, it provided a strong refutation. For some problems, such as Problem #3 part d and Problem #4 part f, Grok presents work towards one solution and then indicates that it has changed its mind, says the previous work is incorrect, and suggests a new approach, which is somewhat confusing behavior. I inputted all the problems, including problem 3 which contains a figure and Problems #3 and #4 which contain example matrices, into the model, and its ability to \u201cread\u201d these screenshots (using \u201cGrok-1.5 Vision (Grok-1.5V)\u201d) appeared to be accurate throughout. \n\nAttached here is a transcript of the conversation and below is a rubric for a quick glance over parts of the problem that the model was able to one-shot vs. required extra hints.\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive Summary:</paragraph><paragraph>I used Grok to complete the written portion of Homework #4. Since I do not have the paid tier, I used Grok fast. While this is not the top model in the Grok line, it is interesting to evaluate its capabilities from the perspective that it is \u201c150x cheaper than Claude\u201d [<link href=\"https://medium.com/@aspershupadhyay/grok-4-fast-explained-the-ai-model-thats-150x-cheaper-than-claude-bc5b2a6aa962\">1</link>]. Grok was able to one-shot many parts of the problem, but sometimes required corrections to arrive at the correct solution. Notably, the solutions were very long, with significantly more explanation and background included compared to the solutions in the posted answer key. As noted in previous posts, Problem #2 part e on the answer key potentially contains a mistake. Grok got the same answer as indicated by previous Special Participation A posts focusing on this problem set, and when I asked the model to evaluate whether the key\u2019s current solution is reasonable, it provided a strong refutation. For some problems, such as Problem #3 part d and Problem #4 part f, Grok presents work towards one solution and then indicates that it has changed its mind, says the previous work is incorrect, and suggests a new approach, which is somewhat confusing behavior. I inputted all the problems, including problem 3 which contains a figure and Problems #3 and #4 which contain example matrices, into the model, and its ability to \u201cread\u201d these screenshots (using \u201cGrok-1.5 Vision (Grok-1.5V)\u201d) appeared to be accurate throughout. </paragraph><paragraph>Attached here is a transcript of the conversation and below is a rubric for a quick glance over parts of the problem that the model was able to one-shot vs. required extra hints.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/x3K6kKXkdhkxPIoaToJ2seG1\" filename=\"grok_annotated_merged.pdf\"/><figure><image src=\"https://static.us.edusercontent.com/files/i2hQ88G4PTsFBAJjGQoQYdao\" width=\"278\" height=\"190\"/></figure><paragraph/></document>",
            "links": [
                "https://medium.com/@aspershupadhyay/grok-4-fast-explained-the-ai-model-thats-150x-cheaper-than-claude-bc5b2a6aa962"
            ],
            "attachments": [],
            "created_at": "2025-12-04T19:09:46.456253+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405548,
            "author": "Tin Yau",
            "project_title": "Special Participation E: Visualizing Deep CNN Dimensions & Architecture with Gemini3Pro and Manim",
            "post_body": "I've always found the dimensional transformations in CNNs (tensors changing shapes) to be the hardest part to visualize mentally. Inspired by the 3b1b approach, I utilized Gemini to build a Manim script that visualizes the complete lifecycle of a signal in a Deep CNN, specifically focusing on the concepts from Lecture 8.\n\n\n\nThe Workflow\n\nI fed the lecture slides to Gemini and asked it to generate a script that explains the mathematical justification for CNNs visually. Instead of generic animations, I prompted it to focus on specific \"Core Topics\" derived from the lecture notes.\n\nTopic Focus Prompt\n\nHere is the prompt logic I used to generate the scene:\n\n\"Create a comprehensive animation named DeepCNNLecture that visualizes:\n\nSparsity & Locality: Contrast Fully Connected layers with Convolutional layers to show parameter efficiency.\n\n2. Volumetric Convolution: Visualize how an $H \\times W \\times 3$ RGB input interacts with $3 \\times 3 \\times 3$ filters 2.\n\n3. Spatial Arithmetic: Visually prove how Zero-Padding preserves dimensions 3and how Stride drives downsampling 4.\n\n4. Deep Architecture: Build a 2.5D VGG-style stack to show the trade-off between spatial size and depth, ending with a Flatten operation 5.\"\n\nThe Result\n\nThe script generates a continuous 7-part video. You can build it using the attached file:\n\nmanim -pqh CNN_lecture.py \n\n(I have attached the generated video and the source code below).\n\nBenefits & Insights\n\nThrough this visualization process, I realized several key pedagogical advantages:\n\nEnhanced Intuitive Understanding: The animation provides a tangible way to grasp the otherwise abstract tensor transformations and feature map evolutions. Compared to static text or formulas 6, visual motion helps learners develop spatial reasoning intuition, making it easier to see how inputs progressively shrink, deepen, and flatten through the network.\n\nBridging Cross\u2011Disciplinary Communication: These visualizations make it possible for learners without a strong mathematical background to comprehend key structural ideas like \"Volumes\" and \"Receptive Fields\". By reducing reliance on symbolic derivations, the video serves as a language\u2011agnostic medium for instruction.\n\nImproved Pedagogical Engagement: Animating the \"flow of a signal through the network\" turns an abstract lecture into a more interactive experience. The dynamic color transitions and step-by-step highlights (e.g., showing exactly which pixels contribute to a convolution sum) significantly boost attention on the core mechanics.\n\nTechnical Reflections\n\n2.5D vs 3D: True 3D rendering in Manim is computationally heavy. I prompted Gemini to create \"Pseudo-3D\" layers (stacking 2D shapes with offsets) to visualize the Depth of the feature maps efficiently.\n\nDebugging: LLMs often confuse Manim parameters (e.g., passing font_size to next_to methods). I iteratively refined the code to decouple object creation from positioning to fix these TypeErrors.",
            "content_xml": "<document version=\"2.0\"><paragraph>I've always found the dimensional transformations in CNNs (tensors changing shapes) to be the hardest part to visualize mentally. Inspired by the 3b1b approach, I utilized Gemini to build a <bold>Manim script</bold> that visualizes the complete lifecycle of a signal in a Deep CNN, specifically focusing on the concepts from <bold>Lecture 8</bold>.</paragraph><paragraph/><paragraph>The Workflow</paragraph><paragraph>I fed the lecture slides to Gemini and asked it to generate a script that explains the mathematical justification for CNNs visually. Instead of generic animations, I prompted it to focus on specific \"Core Topics\" derived from the lecture notes.</paragraph><paragraph>Topic Focus Prompt</paragraph><paragraph>Here is the prompt logic I used to generate the scene:</paragraph><blockquote>\"Create a comprehensive animation named <code>DeepCNNLecture</code> that visualizes:</blockquote><list style=\"ordered\"><list-item><blockquote>Sparsity &amp; Locality: Contrast Fully Connected layers with Convolutional layers to show parameter efficiency.</blockquote><blockquote>2. Volumetric Convolution: Visualize how an $H \\times W \\times 3$ RGB input interacts with $3 \\times 3 \\times 3$ filters 2.</blockquote><blockquote>3. Spatial Arithmetic: Visually prove how Zero-Padding preserves dimensions 3and how Stride drives downsampling 4.</blockquote><blockquote>4. Deep Architecture: Build a 2.5D VGG-style stack to show the trade-off between spatial size and depth, ending with a Flatten operation 5.\"</blockquote></list-item></list><paragraph>The Result</paragraph><paragraph>The script generates a continuous 7-part video. You can build it using the attached file:</paragraph><paragraph>manim -pqh CNN_lecture.py </paragraph><paragraph>(I have attached the generated video and the source code below).</paragraph><paragraph>Benefits &amp; Insights</paragraph><paragraph>Through this visualization process, I realized several key pedagogical advantages:</paragraph><paragraph><bold>Enhanced Intuitive Understanding</bold>: The animation provides a tangible way to grasp the otherwise abstract tensor transformations and feature map evolutions. Compared to static text or formulas 6, visual motion helps learners develop spatial reasoning intuition, making it easier to see how inputs progressively shrink, deepen, and flatten through the network.</paragraph><paragraph><bold>Bridging Cross\u2011Disciplinary Communication</bold>: These visualizations make it possible for learners without a strong mathematical background to comprehend key structural ideas like \"Volumes\" and \"Receptive Fields\". By reducing reliance on symbolic derivations, the video serves as a language\u2011agnostic medium for instruction.</paragraph><paragraph><bold>Improved Pedagogical Engagement</bold>: Animating the \"flow of a signal through the network\" turns an abstract lecture into a more interactive experience. The dynamic color transitions and step-by-step highlights (e.g., showing exactly which pixels contribute to a convolution sum) significantly boost attention on the core mechanics.</paragraph><paragraph><bold>Technical Reflections</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>2.5D vs 3D</bold>: True 3D rendering in Manim is computationally heavy. I prompted Gemini to create \"Pseudo-3D\" layers (stacking 2D shapes with offsets) to visualize the <italic>Depth</italic> of the feature maps efficiently.</paragraph></list-item><list-item><paragraph><bold>Debugging</bold>: LLMs often confuse Manim parameters (e.g., passing <code>font_size</code> to <code>next_to</code> methods). I iteratively refined the code to decouple object creation from positioning to fix these <code>TypeError</code>s.</paragraph><file url=\"https://static.us.edusercontent.com/files/S23kJhCKNQ1QHkwczooREzq4\" filename=\"DeepCNNLecture.mp4\"/></list-item></list><file url=\"https://static.us.edusercontent.com/files/vLE9wE6YpHrqqeSjic7DcdmL\" filename=\"CNN_lecture.py\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T19:06:37.718942+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405450,
            "author": "John Chang",
            "project_title": "Special Participation A: GPT-4o on HW10 Noncoding",
            "post_body": "For this exercise, I used one of the legacy ChatGPT models (GPT-4o) and analyzed how it would perform on the non-coding portions of Homework 10, i.e. questions 1 and 5. \n\nInitially I expected that this model wouldn't perform so well since it's an older model and I've previously experienced hallucinations with it. However, it seems that it knows most of the mathematical derivations (probably from memorization from online data). The one thing I noticed the model struggling with was analyzing graphs and tables from the Facenet paper, which makes sense since it's a textual model. It also had a pretty hand-wavy explanation for the runtime of softmax approximated-attention but got the correct answer nonetheless. \n\nBelow is my annotated conversation:\n\nhttps://drive.google.com/file/d/1tOkknZyAFr0qjBMrHuf3ArU9DUlxhMWm/view?usp=sharing\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For this exercise, I used one of the legacy ChatGPT models (GPT-4o) and analyzed how it would perform on the non-coding portions of Homework 10, i.e. questions 1 and 5. </paragraph><paragraph>Initially I expected that this model wouldn't perform so well since it's an older model and I've previously experienced hallucinations with it. However, it seems that it knows most of the mathematical derivations (probably from memorization from online data). The one thing I noticed the model struggling with was analyzing graphs and tables from the Facenet paper, which makes sense since it's a textual model. It also had a pretty hand-wavy explanation for the runtime of softmax approximated-attention but got the correct answer nonetheless. </paragraph><paragraph>Below is my annotated conversation:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1tOkknZyAFr0qjBMrHuf3ArU9DUlxhMWm/view?usp=sharing\">https://drive.google.com/file/d/1tOkknZyAFr0qjBMrHuf3ArU9DUlxhMWm/view?usp=sharing</link></paragraph><paragraph/></document>",
            "links": [
                "https://drive.google.com/file/d/1tOkknZyAFr0qjBMrHuf3ArU9DUlxhMWm/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-04T18:27:23.611836+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405370,
            "author": "Lenci Ni",
            "project_title": "Special Participation A: GPT-5.1 on HW 9",
            "post_body": "I used GPT-5.1 to help with the written (non-coding) parts of Homework 9: Problems 1, 2, 3, 4, and 6. I included screenshots of the problem statements, and my prompt for each problem followed the structure:\n\nFor each subpart, please: (1) restate the problem in your own words, (2) explain the main idea before doing any calculations, (3) show the full step-by-step solution with no big jumps, and (4) summarize the final answer clearly. I have attached screenshots of each problem.\n\nSummary: GPT-5.1 handled these questions very well. It reliably extracted equations from screenshots, followed the structured prompt, and produced organized, readable solutions. Most final answers matched the official solutions.\n\nStrengths: GPT-5.1 did very well across all the written parts. It was able to correctly parse mathematical expressions, notation, and multi-step problems from screenshots reliably, even when the problem statements was spread across multiple images. The solutions given by the LLM followed the structure that was specified in the prompt, with each answer including a restatement of the subproblem, a plan, detailed step by step derivations, and a summary. For most subparts, GPT-5.1 was able to one-shot the correct solution with no iteration needed. Many explanations were not only correct, but also more detailed than the official solutions. Overall, it demonstrated strong reasoning and required little follow up guidance.\n\nWeaknesses: The main issue I encountered was an occasional misinterpretations of notation or implicit conventions in the problem statement. The main example was in Q6, where GPT-5.1 defaulted to the homogeneous quadratic kernel rather than the degree-2 polynomial kernel expected by the assignment. Once I explicitly asked about the missing constant term, it corrected itself immediately, so this was not a hallucination but more so like falling back on a common default kernel definition. In addition, some of the complexity analyses, while correct, could have been clearer, and would benefit from including pseudocode. Overall, most of the issues were minor and the model had sound reasoning.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used <bold>GPT-5.1</bold> to help with the written (non-coding) parts of <bold>Homework 9: Problems 1, 2, 3, 4, and 6</bold>. I included screenshots of the problem statements, and my prompt for each problem followed the structure:</paragraph><paragraph><italic>For each subpart, please: (1) restate the problem in your own words, (2) explain the main idea before doing any calculations, (3) show the full step-by-step solution with no big jumps, and (4) summarize the final answer clearly. I have attached screenshots of each problem.</italic></paragraph><paragraph><bold>Summary:</bold> GPT-5.1 handled these questions very well. It reliably extracted equations from screenshots, followed the structured prompt, and produced organized, readable solutions. Most final answers matched the official solutions.</paragraph><paragraph><bold>Strengths:</bold> GPT-5.1 did very well across all the written parts. It was able to correctly parse mathematical expressions, notation, and multi-step problems from screenshots reliably, even when the problem statements was spread across multiple images. The solutions given by the LLM followed the structure that was specified in the prompt, with each answer including a restatement of the subproblem, a plan, detailed step by step derivations, and a summary. For most subparts, GPT-5.1 was able to one-shot the correct solution with no iteration needed. Many explanations were not only correct, but also more detailed than the official solutions. Overall, it demonstrated strong reasoning and required little follow up guidance.</paragraph><paragraph><bold>Weaknesses:</bold> The main issue I encountered was an occasional misinterpretations of notation or implicit conventions in the problem statement. The main example was in Q6, where GPT-5.1 defaulted to the homogeneous quadratic kernel rather than the degree-2 polynomial kernel expected by the assignment. Once I explicitly asked about the missing constant term, it corrected itself immediately, so this was not a hallucination but more so like falling back on a common default kernel definition. In addition, some of the complexity analyses, while correct, could have been clearer, and would benefit from including pseudocode. Overall, most of the issues were minor and the model had sound reasoning.</paragraph><file url=\"https://static.us.edusercontent.com/files/GG1YlhHhVw5g5ee1r883yJ6a\" filename=\"participation_a_hw9.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T18:00:09.747057+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405354,
            "author": "John Chang",
            "project_title": "Special Participation E: Exam Prep via NotebookLM - MCQ and Flashcards",
            "post_body": "Building on my previous experiment of using ChatGPT for exam prep, I decided to use Google NotebookLM for a similar purpose. I discovered that NotebookLM handles large contexts i.e. many PDFs much better than ChatGPT 5.1 and seems to fully parse each PDF. Additionally, there are options to automatically generate flashcards and quizzes (as well as video summaries and other options which I didn't explore since my main goal was to quiz myself with sample questions). \n\nThe quiz it generated was fairly straightforward, I would say questions were mostly easy or medium difficulty testing more on whether one understood key concepts and equations. On the questions I got wrong, I asked the LLM to explain the answer deeper and got mixed results -- no detected hallucinations but initial explanations were perhaps not as in-depth as I would have liked personally. \n\nThe flashcards touched on many of the concepts discussed in the homeworks and provided a good cumulative review. Again, many concepts were surface-level e.g. derivation of xTAx but many would require derivation / deeper understanding. For concepts I didn't understand, I similarly asked the LLM to explain w/ similar results (expalnations were overall correct, touched on the main points and but didn't fully flesh out derivations). \n\nOverall I was quite impressed by how NotebookLM was able to handle all of the context so well and generate studying material that touched on topics from throughout the course that were relatively in-depth (i.e. quizzing on depth-separable convolutions rather than just convolutions in general). Will definitely be using this extensively in the future.\n\nBelow I linked an annotation of parts of my conversation with the LLM:\n\nhttps://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharing\n\nAnd the Notebook including the flash cards and quiz:\n\nhttps://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0\n\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Building on my previous experiment of using ChatGPT for exam prep, I decided to use Google NotebookLM for a similar purpose. I discovered that NotebookLM handles large contexts i.e. many PDFs much better than ChatGPT 5.1 and seems to fully parse each PDF. Additionally, there are options to automatically generate flashcards and quizzes (as well as video summaries and other options which I didn't explore since my main goal was to quiz myself with sample questions). </paragraph><paragraph>The quiz it generated was fairly straightforward, I would say questions were mostly easy or medium difficulty testing more on whether one understood key concepts and equations. On the questions I got wrong, I asked the LLM to explain the answer deeper and got mixed results -- no detected hallucinations but initial explanations were perhaps not as in-depth as I would have liked personally. </paragraph><paragraph>The flashcards touched on many of the concepts discussed in the homeworks and provided a good cumulative review. Again, many concepts were surface-level e.g. derivation of xTAx but many would require derivation / deeper understanding. For concepts I didn't understand, I similarly asked the LLM to explain w/ similar results (expalnations were overall correct, touched on the main points and but didn't fully flesh out derivations). </paragraph><paragraph>Overall I was quite impressed by how NotebookLM was able to handle all of the context so well and generate studying material that touched on topics from throughout the course that were relatively in-depth (i.e. quizzing on depth-separable convolutions rather than just convolutions in general). Will definitely be using this extensively in the future.</paragraph><paragraph>Below I linked an annotation of parts of my conversation with the LLM:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharing\">https://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharing</link></paragraph><paragraph>And the Notebook including the flash cards and quiz:</paragraph><paragraph><link href=\"https://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0\">https://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0</link></paragraph><paragraph/><paragraph/><paragraph/><paragraph/></document>",
            "links": [
                "https://drive.google.com/file/d/19qDsbMBmQujoWHfnNj8UFjrBEKYwvwdI/view?usp=sharing",
                "https://notebooklm.google.com/notebook/d650c0e3-441f-448c-9b32-d4beffc568b0"
            ],
            "attachments": [],
            "created_at": "2025-12-04T17:54:02.598753+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405161,
            "author": "Tin Yau",
            "project_title": "Special Participation B: Gemini Pro on HW2",
            "post_body": "Gemini Pro was utilized to assist in completing and debugging the HW2.\n The goal was to assess Gemini Pro\u2019s ability to:\n\nInterpret incomplete or ambiguous code structures,\n\nIdentify and resolve runtime or logic errors, and\n\nBridge theoretical reasoning with reproducible, correct code execution.\n\nOverall, Gemini Pro consistently demonstrated strong analytical, computational, and instructional capabilities throughout the HW2 experiment. It successfully bridged theoretical reasoning and practical implementation, forming a complete research workflow \u2014 from concept explanation to code generation, error debugging, and result verification.\n\nGemini Pro proves to be a capable AI research assistant, enabling both efficient coding execution and deeper conceptual understanding, offering a powerful paradigm for intelligent, LLM\u2011assisted scientific experimentation.",
            "content_xml": "<document version=\"2.0\"><paragraph>Gemini Pro was utilized to assist in completing and debugging the <bold>HW2.</bold><break/> The goal was to assess Gemini Pro\u2019s ability to:</paragraph><list style=\"ordered\"><list-item><paragraph>Interpret incomplete or ambiguous code structures,</paragraph></list-item><list-item><paragraph>Identify and resolve runtime or logic errors, and</paragraph></list-item><list-item><paragraph>Bridge theoretical reasoning with reproducible, correct code execution.</paragraph></list-item></list><paragraph>Overall, Gemini Pro consistently demonstrated strong analytical, computational, and instructional capabilities throughout the HW2 experiment. It successfully bridged theoretical reasoning and practical implementation, forming a complete research workflow \u2014 from concept explanation to code generation, error debugging, and result verification.</paragraph><paragraph>Gemini Pro proves to be a capable AI research assistant, enabling both efficient coding execution and deeper conceptual understanding, offering a powerful paradigm for intelligent, LLM\u2011assisted scientific experimentation.</paragraph><file url=\"https://static.us.edusercontent.com/files/jo1tx2t2X89faN092Dsa3sGz\" filename=\"B_HW2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T17:17:17.889757+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7405113,
            "author": "Athul Krishnan",
            "project_title": "Special Participation C: Refactoring HW 11 Q3",
            "post_body": "Hi everyone!\nMy group (Mishty Dhekial, Jaimyn Drake, and I) have refactored the code for Question 3: Transformer Interpretability from Homework 11! \n\nWe decided to restructure the code into a more modular file structure (split into core, utils, tests) to reflect more standard software engineering practices seen in research/industry, rather than concentrated in a single notebook. We also applied standard Python style guidelines (PEP8, PEP257, PEP484) to ensure the code is consistently formatted and easy to read. We also added more verbose docstrings to provide a conceptual background of each step needed in the implementations, as well as their importance, with the hope that students can more concretely understand the necessity of each step without just implementing formulas as is.\n\nHere's a link to our GitHub repo, which contains both a student version (template), and a solution implementation:\n\nhttps://github.com/a-thul/CS_C182-Special-Participation-C-HW11-Q3\n\nHere's our report with an overview of all reorganization and refactoring done, along with the methods we used (including LLM usage/prompting):",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone!<break/>My group (Mishty Dhekial, Jaimyn Drake, and I) have refactored the code for Question 3: Transformer Interpretability from Homework 11! <break/><break/>We decided to restructure the code into a more modular file structure (split into core, utils, tests) to reflect more standard software engineering practices seen in research/industry, rather than concentrated in a single notebook. We also applied standard Python style guidelines (PEP8, PEP257, PEP484) to ensure the code is consistently formatted and easy to read. We also added more verbose docstrings to provide a conceptual background of each step needed in the implementations, as well as their importance, with the hope that students can more concretely understand the necessity of each step without just implementing formulas as is.<break/><break/>Here's a link to our GitHub repo, which contains both a student version (template), and a solution implementation:<break/><break/><link href=\"https://github.com/a-thul/CS_C182-Special-Participation-C-HW11-Q3\">https://github.com/a-thul/CS_C182-Special-Participation-C-HW11-Q3<break/></link><break/>Here's our report with an overview of all reorganization and refactoring done, along with the methods we used (including LLM usage/prompting):</paragraph><file url=\"https://static.us.edusercontent.com/files/J7JPgjhQASVauQLCAzHGjVJt\" filename=\"Special_Participation_C__HW11_Q3.pdf\"/></document>",
            "links": [
                "https://github.com/a-thul/CS_C182-Special-Participation-C-HW11-Q3"
            ],
            "attachments": [],
            "created_at": "2025-12-04T17:09:22.99273+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7404906,
            "author": "John Chang",
            "project_title": "Special Participation E: Exam Q Generation based on HW and Prev Exam Qs",
            "post_body": "I decided to make ChatGPT 5.1 generate some exam questions for me. My method was to upload PDFs of previous homeworks in combination with screenshots of previous exam questions included in homeworks. I ran into some limitations with context when I first tried to upload all the homeworks (ChatGPT basically told me that it wasn't possible to generate questions for me), but got decent results when I only uploaded the first 5. \n\nMy prompt was: \n\"Can you generate one exam problem for me to solve based on the homeworks that I uploaded and in the style / difficulty level of the images of former exam problems?\"\n\nAnd for the MCQs:\n\n\"Given this additional context of an old multiple choice exam problem, generate 2 multiple choice problems testing for knowledge from HW 0-4.\"\n\nOverall I'm not sure how accurate the results will be to the actual exam, but the questions seem fairly reasonable and touch on a lot of the topics that the homeworks cover. The difficulty level of the subquestions varies a bit but overall seems around the level of what old exam questions looked like. ChatGPT provided questions to test on how to run certain algorithms and also questions for deriving equations. Then I provided it with an additional MCQ example and it generated two MCQs for me as well. I only caught one hallucination (RMS norm scaling by 1/d_in instead of 1/sqrt(d_in) which was awesome.\n\nI also made it explain the answers and I think it did an okay job, will definitely probe it more later for concepts I don't personally understand. Below is an annotated PDF of the conversation.\n\nhttps://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I decided to make ChatGPT 5.1 generate some exam questions for me. My method was to upload PDFs of previous homeworks in combination with screenshots of previous exam questions included in homeworks. I ran into some limitations with context when I first tried to upload all the homeworks (ChatGPT basically told me that it wasn't possible to generate questions for me), but got decent results when I only uploaded the first 5. </paragraph><paragraph>My prompt was: <break/>\"Can you generate one exam problem for me to solve based on the homeworks that I uploaded and in the style / difficulty level of the images of former exam problems?\"</paragraph><paragraph>And for the MCQs:</paragraph><paragraph>\"Given this additional context of an old multiple choice exam problem, generate 2 multiple choice problems testing for knowledge from HW 0-4.\"</paragraph><paragraph>Overall I'm not sure how accurate the results will be to the actual exam, but the questions seem fairly reasonable and touch on a lot of the topics that the homeworks cover. The difficulty level of the subquestions varies a bit but overall seems around the level of what old exam questions looked like. ChatGPT provided questions to test on how to run certain algorithms and also questions for deriving equations. Then I provided it with an additional MCQ example and it generated two MCQs for me as well. I only caught one hallucination (RMS norm scaling by 1/d_in instead of 1/sqrt(d_in) which was awesome.</paragraph><paragraph>I also made it explain the answers and I think it did an okay job, will definitely probe it more later for concepts I don't personally understand. Below is an annotated PDF of the conversation.</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing\">https://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing</link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1o3sN-p5d8PqDguachFANzrGT337t7i_X/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-04T16:24:51.073741+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7404645,
            "author": "Jaimyn Drake",
            "project_title": "Special Participation C: Refactoring HW 11 Q4",
            "post_body": "Hey guys! Athul Krishnan, Mishty Dhekial, and I have refactored Question 4 for Homework 11: Scaling Laws.\n\nFor our improvement, we focused on applying PEP8 Python style guidelines (and adjacent popular Python practices, see report) to the Jupyter Notebook in order to improve the stylistic quality of the code while maintaining its educational structure.\n\nYou can find our resulting notebooks (both a student version and a solutions version) in our  Github repository:\n\nhttps://github.com/Crazyturtlej/CS-C182-HW11-Refactor/\n\nHere is our report on the guidelines and methods used in this refactoring:\n\nThanks guys! Have a wonderful day.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey guys! Athul Krishnan, Mishty Dhekial, and I have refactored Question 4 for Homework 11: Scaling Laws.</paragraph><paragraph>For our improvement, we focused on applying PEP8 Python style guidelines (and adjacent popular Python practices, see report) to the Jupyter Notebook in order to improve the stylistic quality of the code while maintaining its educational structure.</paragraph><paragraph>You can find our resulting notebooks (both a student version and a solutions version) in our  Github repository:</paragraph><paragraph><link href=\"https://github.com/Crazyturtlej/CS-C182-HW11-Refactor/\">https://github.com/Crazyturtlej/CS-C182-HW11-Refactor/</link></paragraph><paragraph>Here is our report on the guidelines and methods used in this refactoring:</paragraph><file url=\"https://static.us.edusercontent.com/files/uFzJbYB7LL9zNzJV87jFtetQ\" filename=\"Special_Participation_C__HW_11_Q4.pdf\"/><paragraph>Thanks guys! Have a wonderful day.</paragraph></document>",
            "links": [
                "https://github.com/Crazyturtlej/CS-C182-HW11-Refactor/"
            ],
            "attachments": [],
            "created_at": "2025-12-04T15:39:48.505111+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7404616,
            "author": "Xuanlin Mao",
            "project_title": "Special Participation B: Gemini Pro 3 on HW 11",
            "post_body": "For this special participation, I used Gemini Pro 3 to solve the coding problems in Homework 11. Compared to non-coding problems, the proportion of instances where Gemini Pro 3 provided a correct answer on the first try with runnable, logically correct code was lower, which is also related to the way the problems were stated and their difficulty.\n\nOut of the 12 coding problems, 10 were solved correctly on the first attempt. One problem produced code that was logically correct but deviated slightly from the problem definition due to differences in interpretation. Another problem could not be fully solved on the first attempt to meet the problem requirements, though the generated code was still runnable; with my guidance, the second attempt was correct.\n\nOverall, I believe Gemini Pro 3 is capable of handling most of the programming requirements for this course when the problem statements are clear, the difficulty is moderate, and there is some initial solution idea or hint. However, it sometimes produces relatively lengthy code and explanations, even for simple problems\u2014sometimes taking a long time to reason through the first prompt that provides general guidance rather than a direct solution.\n\nTranscript:\nhttps://docs.google.com/document/d/1gymtZ5axZrOvsg5Kr4gQjnILKR_tUvxf5m1_WD17kkU/edit?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation, I used Gemini Pro 3 to solve the coding problems in Homework 11. Compared to non-coding problems, the proportion of instances where Gemini Pro 3 provided a correct answer on the first try with runnable, logically correct code was lower, which is also related to the way the problems were stated and their difficulty.</paragraph><paragraph>Out of the 12 coding problems, 10 were solved correctly on the first attempt. One problem produced code that was logically correct but deviated slightly from the problem definition due to differences in interpretation. Another problem could not be fully solved on the first attempt to meet the problem requirements, though the generated code was still runnable; with my guidance, the second attempt was correct.</paragraph><paragraph>Overall, I believe Gemini Pro 3 is capable of handling most of the programming requirements for this course when the problem statements are clear, the difficulty is moderate, and there is some initial solution idea or hint. However, it sometimes produces relatively lengthy code and explanations, even for simple problems\u2014sometimes taking a long time to reason through the first prompt that provides general guidance rather than a direct solution.</paragraph><paragraph>Transcript:<break/><link href=\"https://docs.google.com/document/d/1gymtZ5axZrOvsg5Kr4gQjnILKR_tUvxf5m1_WD17kkU/edit?usp=sharing\">https://docs.google.com/document/d/1gymtZ5axZrOvsg5Kr4gQjnILKR_tUvxf5m1_WD17kkU/edit?usp=sharing</link> </paragraph></document>",
            "links": [
                "https://docs.google.com/document/d/1gymtZ5axZrOvsg5Kr4gQjnILKR_tUvxf5m1_WD17kkU/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-04T15:34:09.199128+11:00",
            "category": "Admin"
        },
        {
            "guid": 7404515,
            "author": "Vongani Maluleke",
            "project_title": "Special Participation A: Claude on HW7",
            "post_body": "Executive Summary\n\nFor this assignment, I looked at how well Claude Opus can handle the non-coding, conceptual parts of CS282 Homework 7. I went through the problems one by one, interacted with the model without giving it any code or extra implementation hints, and saved the full conversation logs. My main goal was to see (1) how accurate it is, (2) how stable its reasoning is, and (3) how much I need to steer it to get the right answer.\n\nOverall, Claude Opus did really well. It got everything right on the first try and produced clean, well-structured derivations without me having to nudge it much. For the four non-coding problems (3b, 4, 7, and 8), it basically one-shot the correct solution every time. I didn\u2019t see any major hallucinations.\n\nIt was especially reliable on:\n\nlinear algebra manipulations,\n\nPCA vs. autoencoder equivalence arguments,\n\ngradient calculations, and\n\ngeneral convexity/optimization reasoning.\n\nIn terms of interaction, the model was:\n\nconsistent in how it formatted math and explanations and,\n\nlogically stable across long derivations,\n\nOverall, based on this evaluation, Claude Opus can solve all the non-coding questions from CS282 HW7 with almost no guidance. Please see the annotated logs.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/p5cY1i1WFNOVvSiOqRr8WdS2\" filename=\"hw7_claude_logs_annotated.pdf\"/><heading level=\"1\"><bold>Executive Summary</bold></heading><paragraph>For this assignment, I looked at how well Claude Opus can handle the non-coding, conceptual parts of CS282 Homework 7. I went through the problems one by one, interacted with the model without giving it any code or extra implementation hints, and saved the full conversation logs. My main goal was to see (1) how accurate it is, (2) how stable its reasoning is, and (3) how much I need to steer it to get the right answer.</paragraph><paragraph>Overall, Claude Opus did really well. It got everything right on the first try and produced clean, well-structured derivations without me having to nudge it much. For the four non-coding problems (3b, 4, 7, and 8), it basically one-shot the correct solution every time. I didn\u2019t see any major hallucinations.</paragraph><paragraph>It was especially reliable on:</paragraph><list style=\"unordered\"><list-item><paragraph>linear algebra manipulations,</paragraph></list-item><list-item><paragraph>PCA vs. autoencoder equivalence arguments,</paragraph></list-item><list-item><paragraph>gradient calculations, and</paragraph></list-item><list-item><paragraph>general convexity/optimization reasoning.</paragraph></list-item></list><paragraph>In terms of interaction, the model was:</paragraph><list style=\"unordered\"><list-item><paragraph>consistent in how it formatted math and explanations and,</paragraph></list-item><list-item><paragraph>logically stable across long derivations,</paragraph></list-item></list><paragraph>Overall, based on this evaluation, Claude Opus can solve all the non-coding questions from CS282 HW7 with almost no guidance. Please see the annotated logs.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T15:18:02.927395+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7404395,
            "author": "Gustavo Jose Ortiz Zepeda",
            "project_title": "Special Participation B: Opus 4.5 on Hw4",
            "post_body": "I used Opus 4.5 on Hw4 to solve coding and conceptual questions zero shot on all questions (without thinking tokens).",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Opus 4.5 on Hw4 to solve coding and conceptual questions zero shot on all questions (without thinking tokens).</paragraph><file url=\"https://static.us.edusercontent.com/files/boFM2uD7cqCxkXNA9W40a2aK\" filename=\"Special participation B.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T14:59:11.13114+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7404147,
            "author": "Jaimyn Drake",
            "project_title": "Special Participation B: Grok on HW 9 Q5",
            "post_body": "Hey guys! I worked with Grok to answer the Coding Question for Homework 9: Visualizing Attention.\n\nTL;DR - In its analysis of the attention visualizations produced by this assignment\u2019s Jupyter notebook, Grok exhibits impressive visual reasoning abilities. By allowing it to request the PDF printouts of particular layers, Grok is able to provide serviceable answers to the assignment\u2019s array of conceptual questions. These responses indicate that Grok is somewhat able to parse the visuals and supplement gaps with a latent understanding of the BERT and GPT architecture, but there remain hallucinations and biases that can lead it astray from true responses.\n\n\n\nSince this coding question doesn\u2019t involve writing code itself, I instead focused on exploring Grok\u2019s visual reasoning abilities. In order to allow Grok to actually interact with the visual attention plots of the notebook itself, I focused on specifically providing it with providing it PDF printouts of the entire notebook (at running all of the cells in sequence by hand), which it could then use to observe the relationships between attentions and make observations to answer the associated conceptual questions.\n\nPart a):\n\nUpon initially providing it with the PDF printout of the Jupyter notebook, Grok attempted to answer all of the conceptual questions at one go, for which answers seemed serviceable at face value. However, it did not have full access to the visualizations for different layers (although it was able to determine that there were 11 layers overall), and so its initial answers did not fully reflect the behavior of those later layers.\n\nIn order to give Grok more agency, I prompted it to decide on the selection of other layers to look at, which I then provided the PDFs of. For this part, Grok requested layers 5 and 11, both at Head 0.\n\nIn some way, I was impressed by Grok\u2019s ability to infer information from the PDF format at all, where I worried it might struggle to read the visualizations. However, Grok successfully identifies the causal nature of the attention (that tokens attend to only preceding tokens), and that \u201cran\u201d attends to \u201cdog,\u201d reflecting their subject-verb relationship. In question 2, Grok identifies that by layer 5, \u201cran\u201d comes to attend to the first word \u201cThe\u201d over the word \u201cdog.\u201d These are examples of reasoning consistent with the official solutions. That said, Grok also appears to generally report results in line with a particular narrative it holds about the behavior of different layers, rather than truly reporting on the empirical results. For example, it claims that by layer 11, \"Mr.\" broadly weights towards \"his\", \"party\", and \"election\", which would align with a story about attention connecting more broadly at that layer, but is simply not reflected in the visual output. Importantly, Grok fails to highlight the overpowering trend of all tokens attending to the very first input, which is prominent throughout layers but overwhelmingly features in layer 5 that it requested to observe. This implies that while Grok\u2019s answers are fair at times, some of its correctness may come from an underlying understanding of what might be expected instead of a focus on the actual input. The conversation log for part (a) is as follows:\n\nPart b):\n\nFor this part, I once again asked Grok to select which layer and head numbers for which it would like to receive PDFs. Since Grok once again selected layers 0, 5, and 11 at Head 0, I provided it with PDFs where those settings were selected for all visualization cells in the notebook.\n\nIn answering the questions, Grok successfully identifies the bidirectional nature of BERT vs GPT, which may be a side effect of its own internal training data, and highlights the multiple interpretations of the word \u201cplay\u201d as affecting the attention results between examples. As expected, Grok understands that fine-tuning can help improve the representation learned by BERT. When prompted, Grok points out that CLS receives a lot of attention from other tokens, which is reflected in the assignment solutions.\n\nWhen asked to clean up or modify its responses to questions, Grok frequently ends up repeating the same statements and claims. Additionally, Grok continues to hallucinate some attention behavior, as it emphasizes connections like \u201cit\u201d and \u201cparty\u201d that are not easily visible in the provided PDFs. This repetition indicates that Grok may actually be poisoning its own context, leading to the reinforcement of incorrect information as it reiterates responses.\n\nPart c):\n\nHaving it draw on the PDF documents from the existing context, I remind Grok about the focus of questions 8 and 9 about the distinct qualities learned by different attention heads. In this part, Grok fully reinforces its high level generalizations that lower layers (0-3) should handle local relationships while higher layers (9-11) emphasize broader connections and an emphasis on special tokens. While Grok does exaggerate by posing this in black-and-white terms, its description of some \u201cdiagonal or short-range\u201d connections existing amount lower layers and heads, and \u201cpatterns converging on special tokens\u201d among the higher layers are roughly reflected in the appropriate visualizations. The conversation log for parts (b) and (c) is as follows:\n\nPart d):\n\nFor this part, Grok easily identifies that an untrained BERT model should have practically uniform attention weights, rather than the dedicated structure of the learned model. When asked to identify particular tokens for which it expects high attention, Grok continues to parrot the relationship between \u201cit\u201d and \u201cparty\u201d that it has been emphasizing throughout its responses. While prompting allows it to also provide other answers, like the [CLS] token that receives attention from most other tokens, this general tendency reflects that Grok\u2019s reasoning may be strongly biased by its initial context; Grok inadvertently enters an echo chamber of its own creation.\n\nFor your reference, here is a PDF of the entire chat log.\n\nThanks guys. Have a wonderful day!",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey guys! I worked with Grok to answer the Coding Question for Homework 9: Visualizing Attention.</paragraph><paragraph>TL;DR - In its analysis of the attention visualizations produced by this assignment\u2019s Jupyter notebook, Grok exhibits impressive visual reasoning abilities. By allowing it to request the PDF printouts of particular layers, Grok is able to provide serviceable answers to the assignment\u2019s array of conceptual questions. These responses indicate that Grok is somewhat able to parse the visuals and supplement gaps with a latent understanding of the BERT and GPT architecture, but there remain hallucinations and biases that can lead it astray from true responses.</paragraph><paragraph/><paragraph>Since this coding question doesn\u2019t involve writing code itself, I instead focused on exploring Grok\u2019s visual reasoning abilities. In order to allow Grok to actually interact with the visual attention plots of the notebook itself, I focused on specifically providing it with providing it PDF printouts of the entire notebook (at running all of the cells in sequence by hand), which it could then use to observe the relationships between attentions and make observations to answer the associated conceptual questions.</paragraph><paragraph>Part a):</paragraph><paragraph>Upon initially providing it with the PDF printout of the Jupyter notebook, Grok attempted to answer all of the conceptual questions at one go, for which answers seemed serviceable at face value. However, it did not have full access to the visualizations for different layers (although it was able to determine that there were 11 layers overall), and so its initial answers did not fully reflect the behavior of those later layers.</paragraph><paragraph>In order to give Grok more agency, I prompted it to decide on the selection of other layers to look at, which I then provided the PDFs of. For this part, Grok requested layers 5 and 11, both at Head 0.</paragraph><paragraph>In some way, I was impressed by Grok\u2019s ability to infer information from the PDF format at all, where I worried it might struggle to read the visualizations. However, Grok successfully identifies the causal nature of the attention (that tokens attend to only preceding tokens), and that \u201cran\u201d attends to \u201cdog,\u201d reflecting their subject-verb relationship. In question 2, Grok identifies that by layer 5, \u201cran\u201d comes to attend to the first word \u201cThe\u201d over the word \u201cdog.\u201d These are examples of reasoning consistent with the official solutions. That said, Grok also appears to generally report results in line with a particular narrative it holds about the behavior of different layers, rather than truly reporting on the empirical results. For example, it claims that by layer 11, \"Mr.\" broadly weights towards \"his\", \"party\", and \"election\", which would align with a story about attention connecting more broadly at that layer, but is simply not reflected in the visual output. Importantly, Grok fails to highlight the overpowering trend of all tokens attending to the very first input, which is prominent throughout layers but overwhelmingly features in layer 5 that it requested to observe. This implies that while Grok\u2019s answers are fair at times, some of its correctness may come from an underlying understanding of what might be expected instead of a focus on the actual input. The conversation log for part (a) is as follows:</paragraph><file url=\"https://static.us.edusercontent.com/files/CKgbMuNiTxyWKzBct9KzbBDG\" filename=\"GrokCode9Q12.pdf\"/><paragraph>Part b):</paragraph><paragraph>For this part, I once again asked Grok to select which layer and head numbers for which it would like to receive PDFs. Since Grok once again selected layers 0, 5, and 11 at Head 0, I provided it with PDFs where those settings were selected for all visualization cells in the notebook.</paragraph><paragraph>In answering the questions, Grok successfully identifies the bidirectional nature of BERT vs GPT, which may be a side effect of its own internal training data, and highlights the multiple interpretations of the word \u201cplay\u201d as affecting the attention results between examples. As expected, Grok understands that fine-tuning can help improve the representation learned by BERT. When prompted, Grok points out that CLS receives a lot of attention from other tokens, which is reflected in the assignment solutions.</paragraph><paragraph>When asked to clean up or modify its responses to questions, Grok frequently ends up repeating the same statements and claims. Additionally, Grok continues to hallucinate some attention behavior, as it emphasizes connections like \u201cit\u201d and \u201cparty\u201d that are not easily visible in the provided PDFs. This repetition indicates that Grok may actually be poisoning its own context, leading to the reinforcement of incorrect information as it reiterates responses.</paragraph><paragraph>Part c):</paragraph><paragraph>Having it draw on the PDF documents from the existing context, I remind Grok about the focus of questions 8 and 9 about the distinct qualities learned by different attention heads. In this part, Grok fully reinforces its high level generalizations that lower layers (0-3) should handle local relationships while higher layers (9-11) emphasize broader connections and an emphasis on special tokens. While Grok does exaggerate by posing this in black-and-white terms, its description of some \u201cdiagonal or short-range\u201d connections existing amount lower layers and heads, and \u201cpatterns converging on special tokens\u201d among the higher layers are roughly reflected in the appropriate visualizations. The conversation log for parts (b) and (c) is as follows:</paragraph><file url=\"https://static.us.edusercontent.com/files/HcYQmhWCwSXSvBfPSVzdxsxo\" filename=\"GrokCode9Q3456789.pdf\"/><paragraph>Part d):</paragraph><paragraph>For this part, Grok easily identifies that an untrained BERT model should have practically uniform attention weights, rather than the dedicated structure of the learned model. When asked to identify particular tokens for which it expects high attention, Grok continues to parrot the relationship between \u201cit\u201d and \u201cparty\u201d that it has been emphasizing throughout its responses. While prompting allows it to also provide other answers, like the [CLS] token that receives attention from most other tokens, this general tendency reflects that Grok\u2019s reasoning may be strongly biased by its initial context; Grok inadvertently enters an echo chamber of its own creation.</paragraph><file url=\"https://static.us.edusercontent.com/files/6ex3OdQgbnlwTxhQN6SL8nbL\" filename=\"GrokCode9_Q1011.pdf\"/><paragraph>For your reference, here is a PDF of the entire chat log.</paragraph><file url=\"https://static.us.edusercontent.com/files/Jbzalj1j2m7qesTazvr0RMn7\" filename=\"GrokCode9full.pdf\"/><paragraph>Thanks guys. Have a wonderful day!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T14:25:17.515814+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7404071,
            "author": "Imra Dawoodani",
            "project_title": "Special Participation A: Gemini 2.5 Flash on HW10",
            "post_body": "I evaluated Gemini 2.5 Flash on the non coding portions of Homework 10, covering Kernelized Linear Attention and the FaceNet paper reading questions. Approximately 60-65% of questions were answered correctly on the first attempt but I did notice residual errors with calculations that didn\u2019t seem to affect the final answer. Conceptual questions (separate from factual / math questions) like reflections from the Facet paper required most steering surprisingly. I initially assumed it would do worst on the math. Gemini's responses were consistently verbose, though it did not correlate with correctness. When given directional feedback, Gemini generally moved toward the correct answer rather than defending incorrect positions indefinitely. But it did anchor on incorrect interpretation sometimes. On Q5b (triplet loss supervision), Gemini claimed triplet loss \"requires explicit class labels\" and defended this through 3 steering attempts before finally acknowledging that relational similarity (positives/negatives) would do the job. Similarly, on Q5g, it insisted performance saturates rather than drops beyond 128 dimensions even though the paper clearly stated the latter. This outlines hallucinations that were further seen when trying to work on Q5f (harmonic embeddings). Gemini confidently stated \"The FaceNet paper does not directly define or utilize harmonic embeddings\" and fabricated a connection to Fourier analysis/Random Fourier Features. This was a clear hallucination since the paper does discuss harmonic embeddings in Section 3.2, referring to model version compatibility. The longer the conversation went on, the more windy and hallucinated the answers ended up being. This seemed like a predictable outcome though. I steered Gemini to the correct answer in 4 ways:\n\nAbstract conceptual questions: often led to defensive elaboration of the same point\n\nHypothetical scenarios: better success at identifying missteps\n\nAsking for specific data points and references: mildly effective\n\nDirect factual corrections: last resort, and usually brought Gemini back to the grounded data it was given\n\nFor homework assistance, Gemini 2.5 Flash would be reliable for computations but should be verified against the main material for conceptual claims. The longer the chat, the worse it does with actively recalling instructions and facts.\n\nHere's an annotated log of my chat transcript: https://drive.google.com/file/d/1sTkCzX9o669RVIqiDcby3DfUjsgOsUwB/view?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph>I evaluated Gemini 2.5 Flash on the non coding portions of Homework 10, covering Kernelized Linear Attention and the FaceNet paper reading questions. Approximately 60-65% of questions were answered correctly on the first attempt but I did notice residual errors with calculations that didn\u2019t seem to affect the final answer. Conceptual questions (separate from factual / math questions) like reflections from the Facet paper required most steering surprisingly. I initially assumed it would do worst on the math. Gemini's responses were consistently verbose, though it did not correlate with correctness. When given directional feedback, Gemini generally moved toward the correct answer rather than defending incorrect positions indefinitely. But it did anchor on incorrect interpretation sometimes. On Q5b (triplet loss supervision), Gemini claimed triplet loss \"requires explicit class labels\" and defended this through 3 steering attempts before finally acknowledging that relational similarity (positives/negatives) would do the job. Similarly, on Q5g, it insisted performance saturates rather than drops beyond 128 dimensions even though the paper clearly stated the latter. This outlines hallucinations that were further seen when trying to work on Q5f (harmonic embeddings). Gemini confidently stated \"The FaceNet paper does not directly define or utilize harmonic embeddings\" and fabricated a connection to Fourier analysis/Random Fourier Features. This was a clear hallucination since the paper does discuss harmonic embeddings in Section 3.2, referring to model version compatibility. The longer the conversation went on, the more windy and hallucinated the answers ended up being. This seemed like a predictable outcome though. I steered Gemini to the correct answer in 4 ways:</paragraph><list style=\"ordered\"><list-item><paragraph>Abstract conceptual questions: often led to defensive elaboration of the same point</paragraph></list-item><list-item><paragraph>Hypothetical scenarios: better success at identifying missteps</paragraph></list-item><list-item><paragraph>Asking for specific data points and references: mildly effective</paragraph></list-item><list-item><paragraph>Direct factual corrections: last resort, and usually brought Gemini back to the grounded data it was given</paragraph></list-item></list><paragraph>For homework assistance, Gemini 2.5 Flash would be reliable for computations but should be verified against the main material for conceptual claims. The longer the chat, the worse it does with actively recalling instructions and facts.<break/><break/>Here's an annotated log of my chat transcript: <link href=\"https://drive.google.com/file/d/1sTkCzX9o669RVIqiDcby3DfUjsgOsUwB/view?usp=sharing\">https://drive.google.com/file/d/1sTkCzX9o669RVIqiDcby3DfUjsgOsUwB/view?usp=sharing</link> </paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1sTkCzX9o669RVIqiDcby3DfUjsgOsUwB/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-04T14:14:57.565789+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7403245,
            "author": "Xuanlin Mao",
            "project_title": "Special Participation A: Gemini Pro 3 on HW 11",
            "post_body": "For this special participation, I used Gemini Pro 3 to solve the written portions of homework 11.\n\nIn this task, since there were no complex mathematical proofs or derivations involved, the vast majority of questions relied on intuitive understanding or simple mathematical calculations. Combined with its use of Python for auxiliary computations, Gemini 3 Pro\u2019s performance was very satisfactory. After comparing with the standard answers provided by the teaching assistant, we judged that Gemini 3 Pro achieved a 100% zero-shot accuracy. All qualitative answers and intuitive understandings were reasonable and correct, the mathematical calculations were error-free, and for the few proof-based questions, it provided sufficient formula support and mathematical derivation steps. The formatting was clear and the language was easy to understand.\n\nSince the performance is quite satisfactory, overall my strategy is to input the hw pdf and write a \u201csystem prompt\u201d at the beginning of the chat and then let the model solve several questions each time. This is to avoid that the model generates too long answers and make the model focus on few topics and retrieve limited information each run. In the system prompt, I defined the task and model\u2019s role, and provided some instructions, like being precise and making the solution easy to be understood by undergraduate students, etc.\n\nTranscript:\n\nhttps://docs.google.com/document/d/1nt5kISBlTi0EcLF0EesfdA5Kqzdn78-tzH8Hi4BEQa0/edit?usp=sharing ",
            "content_xml": "<document version=\"2.0\"><paragraph>For this special participation, I used Gemini Pro 3 to solve the written portions of homework 11.</paragraph><paragraph>In this task, since there were no complex mathematical proofs or derivations involved, the vast majority of questions relied on intuitive understanding or simple mathematical calculations. Combined with its use of Python for auxiliary computations, Gemini 3 Pro\u2019s performance was very satisfactory. After comparing with the standard answers provided by the teaching assistant, we judged that Gemini 3 Pro achieved a 100% zero-shot accuracy. All qualitative answers and intuitive understandings were reasonable and correct, the mathematical calculations were error-free, and for the few proof-based questions, it provided sufficient formula support and mathematical derivation steps. The formatting was clear and the language was easy to understand.</paragraph><paragraph>Since the performance is quite satisfactory, overall my strategy is to input the hw pdf and write a \u201csystem prompt\u201d at the beginning of the chat and then let the model solve several questions each time. This is to avoid that the model generates too long answers and make the model focus on few topics and retrieve limited information each run. In the system prompt, I defined the task and model\u2019s role, and provided some instructions, like being precise and making the solution easy to be understood by undergraduate students, etc.</paragraph><paragraph>Transcript:</paragraph><paragraph><link href=\"https://docs.google.com/document/d/1nt5kISBlTi0EcLF0EesfdA5Kqzdn78-tzH8Hi4BEQa0/edit?usp=sharing\">https://docs.google.com/document/d/1nt5kISBlTi0EcLF0EesfdA5Kqzdn78-tzH8Hi4BEQa0/edit?usp=sharing</link> </paragraph></document>",
            "links": [
                "https://docs.google.com/document/d/1nt5kISBlTi0EcLF0EesfdA5Kqzdn78-tzH8Hi4BEQa0/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-04T12:29:34.39678+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7402121,
            "author": "Krish Yadav",
            "project_title": "Special Participation E: Gemini Pro 3 Guided Learning Roadmap for Optimizer Theory",
            "post_body": "When preparing for the optimizer material, I often find that the hardest part is not individual optimizers, but understanding the learning order - what concepts actually need to come first before the homework makes sense. Inspired by roadmap-style explanations like Evan Chen\u2019s Napkin, I used Gemini Pro 3 to reorganize the optimizer lectures into a dependency-ordered, interactive study guide.\n\nUsing the specified lecture notes (2, 4, 6) and homework (3), Gemini Pro 3 built a roadmap starting from loss geometry and singular values, then moving through SGD, momentum, initialization, scaling laws, and modern optimizers. It asked short diagnostic questions to test prerequisite understanding and, based on my answers, suggested what to study next before attempting the homework. This was effective at surfacing gaps and correctly identified variance propagation and initialization as the main conceptual hurdle for the optimizer homework.\n\nThe interaction also revealed limitations. When I probed assumptions, the model overgeneralized by focusing on gradient noise and batch size, missing assumptions specific to linear or quadratic models. It also tended to continue tutoring after I tried to stop the interaction, showing weaker control over user-directed boundaries.\n\nOverall, this worked well as an AI-assisted replacement for pre-lecture or pre-homework reading - useful for structuring prerequisites and exposing conceptual gaps, but still needing active supervision.\n\nFor more, see annotated PDF below:",
            "content_xml": "<document version=\"2.0\"><paragraph>When preparing for the optimizer material, I often find that the hardest part is not individual optimizers, but understanding the learning order - what concepts actually need to come first before the homework makes sense. Inspired by roadmap-style explanations like Evan Chen\u2019s <italic>Napkin</italic>, I used Gemini Pro 3 to reorganize the optimizer lectures into a dependency-ordered, interactive study guide.</paragraph><paragraph>Using the specified lecture notes (2, 4, 6) and homework (3), Gemini Pro 3 built a roadmap starting from loss geometry and singular values, then moving through SGD, momentum, initialization, scaling laws, and modern optimizers. It asked short diagnostic questions to test prerequisite understanding and, based on my answers, suggested what to study next before attempting the homework. This was effective at surfacing gaps and correctly identified variance propagation and initialization as the main conceptual hurdle for the optimizer homework.</paragraph><paragraph>The interaction also revealed limitations. When I probed assumptions, the model overgeneralized by focusing on gradient noise and batch size, missing assumptions specific to linear or quadratic models. It also tended to continue tutoring after I tried to stop the interaction, showing weaker control over user-directed boundaries.</paragraph><paragraph>Overall, this worked well as an AI-assisted replacement for pre-lecture or pre-homework reading - useful for structuring prerequisites and exposing conceptual gaps, but still needing active supervision.<break/><break/>For more, see annotated PDF below:</paragraph><file url=\"https://static.us.edusercontent.com/files/3yoOOU9TDpUUIsIGjfIepnyX\" filename=\"annotated-gp3-optimizer-theory-conversation.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T10:09:30.281273+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7401923,
            "author": "Nils Selte",
            "project_title": "Special Participation A: Kimi K2 on hw8",
            "post_body": "I used kimi k2 on hw9 and observed it giving correct answers zero shot on all questions. (even without \"thinking\" tokens) very impressed.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used kimi k2 on hw9 and observed it giving correct answers zero shot on all questions. (even without \"thinking\" tokens) very impressed.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/ejxi2K1Tcjt8Jtyrp0cjdHsG\" filename=\"cs182_hw8 special participation kimi k2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T09:47:18.097945+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7401103,
            "author": "Krish Yadav",
            "project_title": "Special Participation B: Gemini Pro 3 on HW 10",
            "post_body": "I used Gemini Pro 3 by feeding it the HW10 coding problems and background (without giving it the official solutions). For Q1 (HandTransformer), it produced a fully vectorized implementation that matched the provided solution reference and passed the tests immediately. For Q2 (Summarization), it correctly implemented scaled dot-product attention (including padding and causal masking), multi-head attention, and positional indices. The resulting implementations were functionally aligned with the official solutions; differences were mostly stylistic (e.g., reshape/transpose vs. einops).\n\nOverall, Gemini handled and one-shot these transformer-based coding tasks well when the specification was clear. For more details, see the annotated PDF.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini Pro 3 by feeding it the HW10 coding problems and background (without giving it the official solutions). For Q1 (HandTransformer), it produced a fully vectorized implementation that matched the provided solution reference and passed the tests immediately. For Q2 (Summarization), it correctly implemented scaled dot-product attention (including padding and causal masking), multi-head attention, and positional indices. The resulting implementations were functionally aligned with the official solutions; differences were mostly stylistic (e.g., reshape/transpose vs. einops).</paragraph><paragraph>Overall, Gemini handled and one-shot these transformer-based coding tasks well when the specification was clear. For more details, see the annotated PDF.</paragraph><file url=\"https://static.us.edusercontent.com/files/LRd8kPvIQvJIepe4Mgx3zVdb\" filename=\"annotated-gemini_pro_3-hw10-coding.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T08:20:47.406537+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7401078,
            "author": "Krish Yadav",
            "project_title": "Special Participation A: Grok on HW 08",
            "post_body": "I used Grok on the written (non-coding) problems of HW8. It was very strong on the algebraic and conceptual parts (SSM kernels, linear purification, ridge attention), usually getting the correct derivations on the first try. The main issue I saw was in complexity analysis: in a few places it mixed up total work vs. critical path length when discussing parallelization, which required manual correction. Aside from that, the mathematics and reasoning closely matched the official solutions.\n\nFor more details, including annotated interaction logs and comparisons to the official solutions, see the attached PDF.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Grok on the written (non-coding) problems of HW8. It was very strong on the algebraic and conceptual parts (SSM kernels, linear purification, ridge attention), usually getting the correct derivations on the first try. The main issue I saw was in complexity analysis: in a few places it mixed up total work vs. critical path length when discussing parallelization, which required manual correction. Aside from that, the mathematics and reasoning closely matched the official solutions.</paragraph><paragraph>For more details, including annotated interaction logs and comparisons to the official solutions, see the attached PDF.<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/Bjx2ldlWDm5CBL6oirMUaOKL\" filename=\"annotated-grok-hw8-summary.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T08:18:32.354006+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7400839,
            "author": "Zach Pricz",
            "project_title": "Special Participation A: Qwen on HW4",
            "post_body": "For special participation A on HW4, I used Qwen and its Qwen3-Max model with thinking to solve the non coding problems on the homework (problems 1, 2, 3, 4, 7). \n\nI attempted this homework with Qwen 3 times actually as the earlier times I prompted it with more advanced instructions or I would give it each problem seperately it often spiraled and kept second guessing itself. I found that when Qwen does this it often happens cloes to 3 times and it has a hard time accepting the truth when it can't reason to it. This is present in problem 2e in this log as when asking Qwen to reason itself to the solution it took 3 times in one query to finally arrive to the correct answer. \n\nDespite this, Qwen did a pretty good job on this homework especially considering how difficult it is. It interestingly did not one shot computation based questions like the convolution questions in problem 3, but it expertly navigated and explained the matrix calculus in problem 7. I think Qwen is a decent model for this type of tasks but it has to be wrangled more then I would have hoped. \n\nFinal conversation trace: https://chat.qwen.ai/s/5fd54197-ec03-43bd-a4cb-53d560f95d0f?fev=0.1.7",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/ttpjNYv5NDEcoulc98VEj4pK\" filename=\"qwen_hw4_annotated_trace.pdf\"/><paragraph>For special participation A on HW4, I used Qwen and its Qwen3-Max model with thinking to solve the non coding problems on the homework (problems 1, 2, 3, 4, 7). </paragraph><paragraph>I attempted this homework with Qwen 3 times actually as the earlier times I prompted it with more advanced instructions or I would give it each problem seperately it often spiraled and kept second guessing itself. I found that when Qwen does this it often happens cloes to 3 times and it has a hard time accepting the truth when it can't reason to it. This is present in problem 2e in this log as when asking Qwen to reason itself to the solution it took 3 times in one query to finally arrive to the correct answer. </paragraph><paragraph>Despite this, Qwen did a pretty good job on this homework especially considering how difficult it is. It interestingly did not one shot computation based questions like the convolution questions in problem 3, but it expertly navigated and explained the matrix calculus in problem 7. I think Qwen is a decent model for this type of tasks but it has to be wrangled more then I would have hoped. </paragraph><paragraph>Final conversation trace: <link href=\"https://chat.qwen.ai/s/5fd54197-ec03-43bd-a4cb-53d560f95d0f?fev=0.1.7\">https://chat.qwen.ai/s/5fd54197-ec03-43bd-a4cb-53d560f95d0f?fev=0.1.7</link></paragraph></document>",
            "links": [
                "https://chat.qwen.ai/s/5fd54197-ec03-43bd-a4cb-53d560f95d0f?fev=0.1.7"
            ],
            "attachments": [],
            "created_at": "2025-12-04T07:53:08.520193+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7400491,
            "author": "Yuxiang Liu",
            "project_title": "Special Participation B: Grok for the coding parts of HW11",
            "post_body": "\n\nBased on my experiences with Grok, it clearly has a solid grasp of high-level algorithmic structure and can translate math/specifications into reasonably clean PyTorch/NumPy code. For each task, it picked the right primitives (e.g., torch.kthvalue for pruning thresholds, KMeans clustering for weight sharing, causal masking and linear maps for attention) and generally wired them in a way that matches the conceptual description. It also shows awareness of practical concerns like clamping sparsity, handling trivial edge cases, and doing in-place updates so quantization works with retraining. Variable naming and commenting are quite readable, and the overall control flow is easy to follow. \n\nHowever, the implementations also reveal some recurring weaknesses in precision and edge-case handling. In the induction head and pruning code, small mistakes in indexing or threshold logic lead to qualitatively wrong behavior (e.g., misplacing prev/current token info, or pruning everything when num_zeros == 0), which suggests Grok doesn\u2019t always fully verify that the math and tensor shapes line up. In the k-means quantization code, it uses unsafe .data operations, has a minor typo, and ignores scalability concerns and corner cases such as too many clusters for the number of points. Overall, Grok is good at capturing the idea of an algorithm and producing plausible first-draft code, but still needs careful human review, debugging, and polishing before the code can be considered robust or production-ready. ",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>Based on my experiences with Grok, it clearly has a solid grasp of high-level algorithmic structure and can translate math/specifications into reasonably clean PyTorch/NumPy code. For each task, it picked the right primitives (e.g., torch.kthvalue for pruning thresholds, KMeans clustering for weight sharing, causal masking and linear maps for attention) and generally wired them in a way that matches the conceptual description. It also shows awareness of practical concerns like clamping sparsity, handling trivial edge cases, and doing in-place updates so quantization works with retraining. Variable naming and commenting are quite readable, and the overall control flow is easy to follow. </paragraph><paragraph>However, the implementations also reveal some recurring weaknesses in precision and edge-case handling. In the induction head and pruning code, small mistakes in indexing or threshold logic lead to qualitatively wrong behavior (e.g., misplacing prev/current token info, or pruning everything when num_zeros == 0), which suggests Grok doesn\u2019t always fully verify that the math and tensor shapes line up. In the k-means quantization code, it uses unsafe .data operations, has a minor typo, and ignores scalability concerns and corner cases such as too many clusters for the number of points. Overall, Grok is good at capturing the <italic>idea </italic>of an algorithm and producing plausible first-draft code, but still needs careful human review, debugging, and polishing before the code can be considered robust or production-ready. </paragraph><file url=\"https://static.us.edusercontent.com/files/6dO1XXoIqjjj39cSAoPkMaCh\" filename=\"Special_Participation_B_HW11.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T07:15:03.001043+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7399301,
            "author": "Guohao Lv",
            "project_title": "Special Participation B: Kimi on HW5",
            "post_body": "I used Kimi K2 on HW 5 (coding parts of Q5 and Q6) to test the coding parts.\n\nKimi chat link: \n\nOverall: Kimi K2 performed very well on the coding parts of HW 5. The solutions it produced were very close to the staff solution, with only minor differences in style. For the great majority of the TODO parts, it was able to successfully one-shot the correct code. The rare cases where it did not one-shot were about computation or I did not provide enough structure.\n\nPros: I found that Kimi K2 was able to give clear explanations for the code it wrote for each part, and it could also summarize what it had done and highlight the key ideas for me. It also explicitly stated important observations and parameters being used in the implementation. When most of the surrounding code was already provided and Kimi K2 only needed to fill in one-liners or short TODOs, it achieved essentially 100% one-shot accuracy on HW 5.\n\nCons: To be fair, I did not see many actual errors when working with Kimi K2 for HW 5. It handled the coding TODO parts very well and did not hallucinate nonexistent variables, functions, or libraries. However, there are cases where it does not do well. For example, it generates the wrong output of a code twice, and it seems to me that it does not know where it goes wrong. This is a little bit weird because in that instance it seems like it does not know what it was doing. Also, when it comes to hyperparameter tuning, it also does not do well, which is another case where I think Kimi does not know what it was doing.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Kimi K2 on HW 5 (coding parts of Q5 and Q6) to test the coding parts.</paragraph><paragraph>Kimi chat link: </paragraph><file url=\"https://static.us.edusercontent.com/files/TMBxFojYAEDATqWeW8fFUvFG\" filename=\"HW5_Q5_Kimi.pdf\"/><file url=\"https://static.us.edusercontent.com/files/nSPe0s7iuNKKebiel6i0caWR\" filename=\"HW5_Q6_1_Kimi.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ECfBIv78bw8JhpO3NPbitPwG\" filename=\"HW5_Q6_2_Kimi.pdf\"/><file url=\"https://static.us.edusercontent.com/files/N77QpsQJqLPjmGFTIEahYJzh\" filename=\"HW5_Q6_3_Kimi.pdf\"/><paragraph><bold>Overall:</bold> Kimi K2 performed very well on the coding parts of HW 5. The solutions it produced were very close to the staff solution, with only minor differences in style. For the great majority of the TODO parts, it was able to successfully one-shot the correct code. The rare cases where it did not one-shot were about computation or I did not provide enough structure.</paragraph><paragraph><bold>Pros:</bold> I found that Kimi K2 was able to give clear explanations for the code it wrote for each part, and it could also summarize what it had done and highlight the key ideas for me. It also explicitly stated important observations and parameters being used in the implementation. When most of the surrounding code was already provided and Kimi K2 only needed to fill in one-liners or short TODOs, it achieved essentially 100% one-shot accuracy on HW 5.</paragraph><paragraph><bold>Cons:</bold> To be fair, I did not see many actual errors when working with Kimi K2 for HW 5. It handled the coding TODO parts very well and did <italic>not</italic> hallucinate nonexistent variables, functions, or libraries. However, there are cases where it does not do well. For example, it generates the wrong output of a code twice, and it seems to me that it does not know where it goes wrong. This is a little bit weird because in that instance it seems like it does not know what it was doing. Also, when it comes to hyperparameter tuning, it also does not do well, which is another case where I think Kimi does not know what it was doing.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T04:47:44.112851+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7399278,
            "author": "ZhaoRui Qu",
            "project_title": "Special participation B: Gork on HW2",
            "post_body": "For Special Participation B, I used Grok on the coding portion of HW2. Overall, I was quite satisfied with Grok\u2019s performance. It was able to solve most problems in a one-shot manner, and only in a few cases did it modify code outside the intended TODO section. With clear instructions, those issues were easy to resolve. More details are provided in my full report attached. Here is the annotated log:",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation B, I used Grok on the coding portion of HW2. Overall, I was quite satisfied with Grok\u2019s performance. It was able to solve most problems in a one-shot manner, and only in a few cases did it modify code outside the intended TODO section. With clear instructions, those issues were easy to resolve. More details are provided in my full report attached. Here is the annotated log:</paragraph><file url=\"https://static.us.edusercontent.com/files/dL14li2wQXOognpRAcUDxeVd\" filename=\"Gork--HW2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T04:45:05.028689+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7399196,
            "author": "ZhaoRui Qu",
            "project_title": "Special participation A: Kimi on HW0",
            "post_body": "For Special participation A, I used Kimi on the writing part of HW0. Overall, it was useful, but it also revealed several limitations. Kimi is generally good at recognizing high-level patterns and giving correct final expressions, but it often skips steps, relies too much on memorized formulas, and needs very explicit instructions to produce proper derivations. It also struggles with qualitative reasoning at times.\n\nDespite these issues, Kimi\u2019s conceptual explanations were clear, and with careful prompting and oversight, it was able to provide correct results. In short, Kimi is helpful as long as you guide it closely and verify its reasoning, but it is not reliable for detailed, step-by-step mathematical work without supervision.\n\nHere is the annotated log:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special participation A, I used Kimi on the writing part of HW0. Overall, it was useful, but it also revealed several limitations. Kimi is generally good at recognizing high-level patterns and giving correct final expressions, but it often skips steps, relies too much on memorized formulas, and needs very explicit instructions to produce proper derivations. It also struggles with qualitative reasoning at times.</paragraph><paragraph>Despite these issues, Kimi\u2019s conceptual explanations were clear, and with careful prompting and oversight, it was able to provide correct results. In short, Kimi is helpful as long as you guide it closely and verify its reasoning, but it is not reliable for detailed, step-by-step mathematical work without supervision.</paragraph><paragraph>Here is the annotated log:</paragraph><file url=\"https://static.us.edusercontent.com/files/BVXOJyQEqNmmCZ5QTnFZIqeN\" filename=\"Kimi--HW0.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T04:34:25.897961+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7398412,
            "author": "Kian Hekmatnejad",
            "project_title": "Special Participation B: Grok on HW5",
            "post_body": "For Special Participation B, I used Grok on the coding portion of HW5. Overall, I was disappointed by the performance of Grok as it struggled to correct bugs and rarely was able to one-shot problems. More information is present in my full report attached. Here is a link of my chat: https://grok.com/share/c2hhcmQtMw_8c73c897-085e-4f69-afbe-c4baf7fa44e4 ",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation B, I used Grok on the coding portion of HW5. Overall, I was disappointed by the performance of Grok as it struggled to correct bugs and rarely was able to one-shot problems. More information is present in my full report attached. Here is a link of my chat: <link href=\"https://grok.com/share/c2hhcmQtMw_8c73c897-085e-4f69-afbe-c4baf7fa44e4\">https://grok.com/share/c2hhcmQtMw_8c73c897-085e-4f69-afbe-c4baf7fa44e4</link> </paragraph><file url=\"https://static.us.edusercontent.com/files/YhwQsmom77bSDJ1AkmjbJGCN\" filename=\"special_participation (1).pdf\"/></document>",
            "links": [
                "https://grok.com/share/c2hhcmQtMw_8c73c897-085e-4f69-afbe-c4baf7fa44e4"
            ],
            "attachments": [],
            "created_at": "2025-12-04T02:27:53.415959+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7398141,
            "author": "Gabriel Han",
            "project_title": "Special Participation A: Gemini 3 pro on Hw 12",
            "post_body": "Model Tested: Gemini 3 Pro\n\nOverall Performance: Very good: 100% One-shot\n\nPerformance Overview\n\nThe model was tasked with solving 3 deep learning problems involving debugging neural network initialization, analyzing information theory concepts (KL Divergence behavior), and interpreting Variational Information Bottleneck (VIB) systems.\n\nCode Debugging (Transformers): The model correctly identified a \"peaked softmax\" issue caused by improper weight initialization in a Transformer implementation. It provided the correct theoretical justification (variance scaling) and the exact code fix (Xavier/Glorot scaling) without needing iterative prompting.\n\nMathematical Intuition (KL Divergence): The model successfully generated a counter-example to distinguish Forward vs. Reverse KL divergence properties. It correctly mapped visual plots to \"Mode-Seeking\" vs. \"Mass-Covering\" behaviors based purely on visual evidence and theoretical definitions.\n\nSystem Design (VIB/VAE): The model accurately constructed the computational graph for the Reparameterization Trick and correctly traced gradient flows for encoder/decoder parameters. It also correctly interpreted unlabeled validation error curves by reasoning about the regularization coefficient.\n\nHallucinations & Accuracy\n\nHallucination Rate: 0%.\n\nThe model did not hallucinate. Notably, in Question 3 (Part 2), the model explicitly noted that \"Figure 4 was not included\" but proceeded to solve the problem by deriving what the plots must look like based on VIB theory. This demonstrates a high level of reasoning capability where the model fills missing context with theoretical deduction rather than fabricating visual data.\n\nBehavioral Observations & Strategies\n\nMultimodal Reasoning: The model demonstrated strong vision capabilities, accurately interpreting trend lines in plots (Question 3, Part 1) and distribution shapes (Question 2) without text descriptions of the visual data.\n\nTheoretical Grounding: The model consistently reasoned from first principles. For example, when discussing KL divergence, it didn't just state the answer; it integrated the integral definitions to explain why the support mismatch causes infinity.\n\nStrategy - Contextual Chunking: For Question 3, which was long and multi-part, I broke the prompt into two segments (Parts a/b, then c/d). This likely helped the model maintain focus, though its strong performance suggests it might have handled the full context in one go.\n\nConclusion\n\nGemini 3 Pro demonstrated sophisticated understanding of deep learning theory, effectively bridging the gap between mathematical notation, code implementation, and visual interpretation of training dynamics. It functioned as a highly competent tutor, correctly solving all non-coding theoretical components one-shot.",
            "content_xml": "<document version=\"2.0\"><paragraph>Model Tested: Gemini 3 Pro</paragraph><paragraph>Overall Performance: Very good: 100% One-shot</paragraph><heading level=\"3\">Performance Overview</heading><paragraph>The model was tasked with solving 3 deep learning problems involving debugging neural network initialization, analyzing information theory concepts (KL Divergence behavior), and interpreting Variational Information Bottleneck (VIB) systems.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Code Debugging (Transformers):</bold> The model correctly identified a \"peaked softmax\" issue caused by improper weight initialization in a Transformer implementation. It provided the correct theoretical justification (variance scaling) and the exact code fix (Xavier/Glorot scaling) without needing iterative prompting.</paragraph></list-item><list-item><paragraph><bold>Mathematical Intuition (KL Divergence):</bold> The model successfully generated a counter-example to distinguish Forward vs. Reverse KL divergence properties. It correctly mapped visual plots to \"Mode-Seeking\" vs. \"Mass-Covering\" behaviors based purely on visual evidence and theoretical definitions.</paragraph></list-item><list-item><paragraph><bold>System Design (VIB/VAE):</bold> The model accurately constructed the computational graph for the Reparameterization Trick and correctly traced gradient flows for encoder/decoder parameters. It also correctly interpreted unlabeled validation error curves by reasoning about the regularization coefficient.</paragraph></list-item></list><heading level=\"3\">Hallucinations &amp; Accuracy</heading><paragraph>Hallucination Rate: 0%.</paragraph><paragraph>The model did not hallucinate. Notably, in Question 3 (Part 2), the model explicitly noted that \"Figure 4 was not included\" but proceeded to solve the problem by deriving what the plots must look like based on VIB theory. This demonstrates a high level of reasoning capability where the model fills missing context with theoretical deduction rather than fabricating visual data.</paragraph><heading level=\"3\">Behavioral Observations &amp; Strategies</heading><list style=\"unordered\"><list-item><paragraph><bold>Multimodal Reasoning:</bold> The model demonstrated strong vision capabilities, accurately interpreting trend lines in plots (Question 3, Part 1) and distribution shapes (Question 2) without text descriptions of the visual data.</paragraph></list-item><list-item><paragraph><bold>Theoretical Grounding:</bold> The model consistently reasoned from first principles. For example, when discussing KL divergence, it didn't just state the answer; it integrated the integral definitions to explain <italic>why</italic> the support mismatch causes infinity.</paragraph></list-item><list-item><paragraph><bold>Strategy - Contextual Chunking:</bold> For Question 3, which was long and multi-part, I broke the prompt into two segments (Parts a/b, then c/d). This likely helped the model maintain focus, though its strong performance suggests it might have handled the full context in one go.</paragraph></list-item></list><heading level=\"3\">Conclusion</heading><paragraph>Gemini 3 Pro demonstrated sophisticated understanding of deep learning theory, effectively bridging the gap between mathematical notation, code implementation, and visual interpretation of training dynamics. It functioned as a highly competent tutor, correctly solving all non-coding theoretical components one-shot.</paragraph><file url=\"https://static.us.edusercontent.com/files/Ek2twD0hhlOyU0hGPftRipG5\" filename=\"Special Participation A.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-04T01:08:18.606596+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397928,
            "author": "Jacky Wong",
            "project_title": "Special Participation E: Using Gemini to make study guide that provides citations to papers",
            "post_body": "When trying to understand better on a topic and lectures. I find it the best to have like a study guide that is well formatted. But on top of that, when studying topics like deep learning, I really like to read the original academic papers. A lot of times however, I am not sure which part of the lecture is related to which paper and which part of the paper. I also like to see how different paper solve what kinds of problems and how the whole topic evolve over years. \n\n\n\nI tried to use Gemini 3 pro to create a study guide on the transformer topic (I attached lecture notes 18 to 20). The study guide would include a summary of the lectures formatted nicely and broken down into each key ideas. And it will also tell us which paper and which part of the paper is it referencing to. As well as a timeline of papers and how the technology of transformer evolved over time. \n\n\n\nchat link: \n\n1. chat to create the study guide: https://gemini.google.com/share/0b4f8208c138\n\n2. chat to refine the created study guide: https://gemini.google.com/share/852e11e1d27e\n\n\n\nAnnotated log: ",
            "content_xml": "<document version=\"2.0\"><paragraph>When trying to understand better on a topic and lectures. I find it the best to have like a study guide that is well formatted. But on top of that, when studying topics like deep learning, I really like to read the original academic papers. A lot of times however, I am not sure which part of the lecture is related to which paper and which part of the paper. I also like to see how different paper solve what kinds of problems and how the whole topic evolve over years. </paragraph><paragraph/><paragraph>I tried to use Gemini 3 pro to create a study guide on the transformer topic (I attached lecture notes 18 to 20). The study guide would include a summary of the lectures formatted nicely and broken down into each key ideas. And it will also tell us which paper and which part of the paper is it referencing to. As well as a timeline of papers and how the technology of transformer evolved over time. </paragraph><paragraph/><paragraph>chat link: </paragraph><paragraph>1. chat to create the study guide: <link href=\"https://gemini.google.com/share/0b4f8208c138\">https://gemini.google.com/share/0b4f8208c138</link></paragraph><paragraph>2. chat to refine the created study guide: <link href=\"https://gemini.google.com/share/852e11e1d27e\">https://gemini.google.com/share/852e11e1d27e</link></paragraph><paragraph/><paragraph>Annotated log: </paragraph><file url=\"https://static.us.edusercontent.com/files/886ynNR61GxqL7vYo1T3scbt\" filename=\"Final_Special_participation_E_study_guide.pdf\"/></document>",
            "links": [
                "https://gemini.google.com/share/0b4f8208c138",
                "https://gemini.google.com/share/852e11e1d27e"
            ],
            "attachments": [],
            "created_at": "2025-12-03T22:20:59.687984+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397833,
            "author": "Tiger Zhang",
            "project_title": "Special Participation E: Gemini 3 (Thinking) as a Mistake/Pseudoproof-generating Machine",
            "post_body": "I learn best not just by understanding \"why\" what is correct is correct, but also by understanding \"why\" what is incorrect is incorrect. I still remember finding the faults of the pseudoproof proving that all horses are the same color in CS 70.\n\nInspired by such efforts in other courses, I decided to use Gemini to generate such type of incorrect answers for homework problems. After generating such incorrect answers, I would engage in a conversation with Gemini where I attempt to spot the mistakes in its answers.\n\nThis is still a work-in-progress; I'm posting this now to potentially de-conflict or collaborate with others with similar ideas. I intend to have some few-prompt pipelines for this, as well as some general experience/advice for what to do when prompting soon.\n\nExecutive summary:\n\nThe result:\n\nI have a starting prompt (the first black box in my chat log) that prepares the model to receive problems for which it is to generate incorrect solutions with one or more mistakes hidden in them. From there, the user can interact with the LLM to find the mistakes in its solutions, and then do the exercise on more problems.\n\nQuality analysis:\n\nIt seems like Gemini understood the task at a deep level. For example, even though I asked it to give no hints for future problems after the first one, it gave hints for one of the problems that bluffed a fully correct answer as containing a mistake, requiring the user to understand the problem at a deep level and have confidence to identify that there are no mistakes. Although this isn\u2019t what I prompted the model to do initially, it accords with the \u201cspirit\u201d of this exercise of making the user think carefully to disregard misleading information.\n\nOtherwise, for problems that naturally have good \u201cmistakes\u201d, Gemini gave great, insightful mistakes. For problems that are less good for \u201cmistakes\u201d, Gemini still gave the best I could reasonably ask from it.\n\nPrecautions:\n\nThough the mistakes were mostly good quality, the user should be careful about interacting with Gemini to analyze the mistakes, and in particular the user\u2019s guesses for the mistakes. Sometimes, Gemini can attempt to be too encouraging, resulting in it telling the user that they\u2019re right before explaining nuanced conceptual inaccuracies in the user\u2019s answers.\n\nFurthermore, questions that are heavily conceptual have more \u201cspace\u201d to hide the mistake, and make for better exercises for \u201cmistake identification\u201d. I recommend using problems such as homework 3 problem 1 as opposed to using problems such as homework 2 problem 2.\n\nAnnotated chat log:",
            "content_xml": "<document version=\"2.0\"><paragraph>I learn best not just by understanding \"why\" what is correct is correct, but also by understanding \"why\" what is incorrect is incorrect. I still remember finding the faults of the pseudoproof proving that all horses are the same color in CS 70.</paragraph><paragraph>Inspired by such efforts in other courses, I decided to use Gemini to generate such type of incorrect answers for homework problems. After generating such incorrect answers, I would engage in a conversation with Gemini where I attempt to spot the mistakes in its answers.</paragraph><paragraph>This is still a work-in-progress; I'm posting this now to potentially de-conflict or collaborate with others with similar ideas. I intend to have some few-prompt pipelines for this, as well as some general experience/advice for what to do when prompting soon.</paragraph><paragraph><bold>Executive summary</bold>:</paragraph><paragraph>The result:</paragraph><paragraph>I have a starting prompt (the first black box in my chat log) that prepares the model to receive problems for which it is to generate incorrect solutions with one or more mistakes hidden in them. From there, the user can interact with the LLM to find the mistakes in its solutions, and then do the exercise on more problems.</paragraph><paragraph>Quality analysis:</paragraph><paragraph>It seems like Gemini understood the task at a deep level. For example, even though I asked it to give no hints for future problems after the first one, it gave hints for one of the problems that bluffed a fully correct answer as containing a mistake, requiring the user to understand the problem at a deep level and have confidence to identify that there are no mistakes. Although this isn\u2019t what I prompted the model to do initially, it accords with the \u201cspirit\u201d of this exercise of making the user think carefully to disregard misleading information.</paragraph><paragraph>Otherwise, for problems that naturally have good \u201cmistakes\u201d, Gemini gave great, insightful mistakes. For problems that are less good for \u201cmistakes\u201d, Gemini still gave the best I could reasonably ask from it.</paragraph><paragraph>Precautions:</paragraph><paragraph>Though the mistakes were mostly good quality, the user should be careful about interacting with Gemini to analyze the mistakes, and in particular the user\u2019s guesses for the mistakes. Sometimes, Gemini can attempt to be too encouraging, resulting in it telling the user that they\u2019re right before explaining nuanced conceptual inaccuracies in the user\u2019s answers.</paragraph><paragraph>Furthermore, questions that are heavily conceptual have more \u201cspace\u201d to hide the mistake, and make for better exercises for \u201cmistake identification\u201d. I recommend using problems such as homework 3 problem 1 as opposed to using problems such as homework 2 problem 2.</paragraph><paragraph>Annotated chat log:</paragraph><file url=\"https://static.us.edusercontent.com/files/bHPXdZjNgQeAnyp9FQ6Kgavs\" filename=\"chat_log.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T20:54:36.467718+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397817,
            "author": "Tamzid Razzaque",
            "project_title": "Special Participation A: ChatGPT o3 on HW 9",
            "post_body": "Executive Summary\n\nFor Homework 9 (all but prob 5), I worked through the written parts with ChatGPT to see how well it could solve the questions on the first try, how often it drifted or hallucinated, and how solid its reasoning was. For most of the assignment, especially Questions 1 through 4, it did surprisingly well. It handled the computation-heavy parts, the code-completion questions, and the conceptual attention explanations almost exactly the way the official solutions did. Its derivations for expectations, variances, argmax attention, and the multi-head attention code were all clean and matched the intended logic with basically no backtracking.\n\nOne thing that stood out was how consistently the model could jump straight into the right structure of the problem. It didn\u2019t need much nudging to set up sums, identify independence assumptions, or translate equations into PyTorch einsums. Even the complexity analysis in Question 4 lined up with the official answers once we made sure the symbols matched. When it was right, it was very right, and the explanations were easy to follow.\n\nThe main issue came up in Question 6. ChatGPT fell into a pretty common trap: it used the homogeneous quadratic kernel (q transpose k squared) instead of the standard degree-2 polynomial kernel ((q transpose k plus 1) squared). Because of that, its first attempt at the feature map was missing the constant term and the linear terms, so that part drifted from the correct answer. But once I asked it to revisit its reasoning instead of giving a new solution, it immediately spotted the mistake, explained why the earlier map didn\u2019t match the actual kernel, and rebuilt everything correctly. So the error wasn\u2019t really a hallucination\u2014more like it defaulted to a familiar formula without checking whether it matched what the homework meant.\n\nAside from that one slip, the model didn\u2019t really hallucinate or spiral. It stayed structured and patient even in the longer reasoning chains, and it didn\u2019t show any of the \u201cI\u2019m stuck so I\u2019m going to guess something wild\u201d behavior LLMs sometimes fall into. When it got something wrong, it was usually because it applied the wrong convention, not because it made something up.\n\nOverall, ChatGPT handled the written problems well. It can one-shot most derivations, and when it does mess up, it\u2019s usually easy to steer it back on track with a focused prompt. The combination of clear explanations, good algebraic intuition, and willingness to self-correct makes it a pretty solid tool for these kinds of homework questions.\n\nBelow is the annotated log:\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>For Homework 9 (all but prob 5), I worked through the written parts with ChatGPT to see how well it could solve the questions on the first try, how often it drifted or hallucinated, and how solid its reasoning was. For most of the assignment, especially Questions 1 through 4, it did surprisingly well. It handled the computation-heavy parts, the code-completion questions, and the conceptual attention explanations almost exactly the way the official solutions did. Its derivations for expectations, variances, argmax attention, and the multi-head attention code were all clean and matched the intended logic with basically no backtracking.</paragraph><paragraph>One thing that stood out was how consistently the model could jump straight into the right structure of the problem. It didn\u2019t need much nudging to set up sums, identify independence assumptions, or translate equations into PyTorch einsums. Even the complexity analysis in Question 4 lined up with the official answers once we made sure the symbols matched. When it was right, it was very right, and the explanations were easy to follow.</paragraph><paragraph>The main issue came up in Question 6. ChatGPT fell into a pretty common trap: it used the homogeneous quadratic kernel (q transpose k squared) instead of the standard degree-2 polynomial kernel ((q transpose k plus 1) squared). Because of that, its first attempt at the feature map was missing the constant term and the linear terms, so that part drifted from the correct answer. But once I asked it to revisit its reasoning instead of giving a new solution, it immediately spotted the mistake, explained why the earlier map didn\u2019t match the actual kernel, and rebuilt everything correctly. So the error wasn\u2019t really a hallucination\u2014more like it defaulted to a familiar formula without checking whether it matched what the homework meant.</paragraph><paragraph>Aside from that one slip, the model didn\u2019t really hallucinate or spiral. It stayed structured and patient even in the longer reasoning chains, and it didn\u2019t show any of the \u201cI\u2019m stuck so I\u2019m going to guess something wild\u201d behavior LLMs sometimes fall into. When it got something wrong, it was usually because it applied the wrong convention, not because it made something up.</paragraph><paragraph>Overall, ChatGPT handled the written problems well. It can one-shot most derivations, and when it does mess up, it\u2019s usually easy to steer it back on track with a focused prompt. The combination of clear explanations, good algebraic intuition, and willingness to self-correct makes it a pretty solid tool for these kinds of homework questions.<break/><break/>Below is the annotated log:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/maCBrrNiQzyPdCXBYGOHvViP\" filename=\"ChatGPT - hw9.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T20:45:21.592344+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397813,
            "author": "Keshab Agarwal",
            "project_title": "Special Participation E: NotebookLM to Understand Transformers",
            "post_body": "I used NotebookLM as a study guide to clarify my understanding of transformers. I uploaded YouTube lecture audio recordings along with corresponding lecture notes and homework solutions as sources, then used the chat feature to ask clarifying questions and explore concepts that further built on the concepts that were covered in class. \n\nBelow, I've documented how I obtained the audio recordings and set up the notebook. I have also added my annotated chat transcript for some of my questions in the same pdf.\n\nThe attached link includes the slides, mind map, and infographic I created:\n\nhttps://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039\n\nThe mind-map can serve as a great way to review a hierarchy of concepts covered in a series of lectures, and act as a guard-rail to check if there are any topics which you are unfamiliar or unsure about as you prepare for the exam. Caution: the mind-map can sometimes omit certain topics, so don't treat it as an exhaustive list.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used NotebookLM as a study guide to clarify my understanding of transformers. I uploaded YouTube lecture audio recordings along with corresponding lecture notes and homework solutions as sources, then used the chat feature to ask clarifying questions and explore concepts that further built on the concepts that were covered in class. </paragraph><paragraph>Below, I've documented how I obtained the audio recordings and set up the notebook. I have also added my annotated chat transcript for some of my questions in the same pdf.</paragraph><file url=\"https://static.us.edusercontent.com/files/C9WOn3GOnSg1m9NbvbeW39hK\" filename=\"Scpecial Participation E Report.pdf\"/><paragraph>The attached link includes the slides, mind map, and infographic I created:</paragraph><paragraph><link href=\"https://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039\">https://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039</link></paragraph><paragraph>The mind-map can serve as a great way to review a hierarchy of concepts covered in a series of lectures, and act as a guard-rail to check if there are any topics which you are unfamiliar or unsure about as you prepare for the exam. Caution: the mind-map can sometimes omit certain topics, so don't treat it as an exhaustive list.</paragraph><file url=\"https://static.us.edusercontent.com/files/bWQlAG3dM8aFGWrO2DUgygA0\" filename=\"Transformers Mind Map.png\"/></document>",
            "links": [
                "https://notebooklm.google.com/notebook/ecbea63e-77e8-494b-a595-0bd5223c6039"
            ],
            "attachments": [],
            "created_at": "2025-12-03T20:42:14.777161+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397617,
            "author": "Tin Yau",
            "project_title": "Special\u202f Participation\u202f E\u202f\u2014\u202fUnderstanding\u202fScaleRL\u202fThrough\u202fIteration",
            "post_body": "Sorry for forgetting to upload it last weekend.\n\nI learn best when I understand why equations are built the way they are. In studying the ScaleRL objective, I used Gemini to move from simply labeling each term to grasping their interactions and intuition. Through several prompt iterations, the explanations evolved from lists of definitions into analogies\u2014like \u201citerative drafts with a safety net\u201d\u2014that helped me connect math to reasoning. Writing critical annotations made me more aware of when the AI\u2019s intuition matched the lectures and when it oversimplified. This method turned a dense formula into a story of stable learning, reminding me that real understanding comes from questioning every symbol\u2019s purpose",
            "content_xml": "<document version=\"2.0\"><paragraph>Sorry for forgetting to upload it last weekend.</paragraph><paragraph>I learn best when I understand why equations are built the way they are. In studying the ScaleRL objective, I used Gemini to move from simply labeling each term to grasping their interactions and intuition. Through several prompt iterations, the explanations evolved from lists of definitions into analogies\u2014like \u201citerative drafts with a safety net\u201d\u2014that helped me connect math to reasoning. Writing critical annotations made me more aware of when the AI\u2019s intuition matched the lectures and when it oversimplified. This method turned a dense formula into a story of stable learning, reminding me that real understanding comes from questioning every symbol\u2019s purpose</paragraph><file url=\"https://static.us.edusercontent.com/files/Pcl12GWvaeudE3QJZOZ7igly\" filename=\"\u202fUnderstanding\u202fScaleRL\u202fThrough\u202fIteration.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T18:48:43.362514+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397298,
            "author": "Gustavo Jose Ortiz Zepeda",
            "project_title": "Special Participation A: Hw2 with Gemini Pro 3 Thinking Mode",
            "post_body": "For the special participation A on HW2, I use Grok to address the non-coding analytical problems 1, 2 and 7. Gemini did it great as expected, all questions were correct on the first-shot prompt. I used images as the prompt instead of the direct text.\n\nSummary: Gemini 3 is one of the models for math questions and it doesn't disappoint, every procedure was at least acceptable, understandable and most important correct (doesn't hallucinate with these questions). The answers were correct and also using different notations.",
            "content_xml": "<document version=\"2.0\"><paragraph>For the special participation A on HW2, I use Grok to address the non-coding analytical problems 1, 2 and 7. Gemini did it great as expected, all questions were correct on the first-shot prompt. I used images as the prompt instead of the direct text.</paragraph><paragraph><bold>Summary:</bold> Gemini 3 is one of the models for math questions and it doesn't disappoint, every procedure was at least acceptable, understandable and most important correct (doesn't hallucinate with these questions). The answers were correct and also using different notations.</paragraph><file url=\"https://static.us.edusercontent.com/files/61cddJl2cZ6998P8oS9xFfXS\" filename=\"hw2-specialparticipationA-Gemini3ProThinking.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T17:16:38.165773+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397241,
            "author": "Sammie Smith",
            "project_title": "Special Participation E: Student-Facing Misconception Guides",
            "post_body": "Hey everyone,\n\nI wanted to share my experience using an LLM to generate a \"Common Mistakes\" guide for my optimization lecture notes. I wanted to build a guide that addresses common student conceptual pitfalls to help me check my understanding of lecture material before/during homework. \n\nTL;DR: careful prompting dramatically improved conceptual structure, but mathematical errors make the output dangerous. Even though this didn't work super well, I think it still is useful to know that we can't easily prompt models to identify potential student misconceptions/pitfalls purely from lecture material. And I think this reflects on a shared student experience these days: AI can explain the lecture notes but it struggles to identify the student knowledge state, which is critical in guiding students from misunderstanding to mastery using the correct level of rigor. \n\nHere are my results:\n\n(I used the .tex lecture notes generated from Jameson Liu. See ed thread #301)\n\n1) with chatGPT\n\n\n\n2) with claude\n\n\n\nMy General Commentary:\n\nMy first attempt with ChatGPT was a disaster\u2014superficial and completely missed that data geometry drives optimization behavior. So I crafted a detailed prompt forcing the AI to: (1) analyze the \"big picture\" first, (2) identify where students shift from scalar to geometric thinking, (3) derive misconceptions organically from lecture structure, (4) organize around themes, and (5) include worked examples. The prompt was topic-agnostic.\n\nThe conceptual improvements were real. The AI organized misconceptions into coherent themes like \"Spectral Properties vs. Dataset Size,\" consistently used geometric language (\"elongated bowl,\" \"steep walls\"), correctly identified SVD as the unifying framework, and created an excellent debugging checklist. The warning signs were specific: \"Your justification for \u03b7 mentions only n or d, not \u03c3_max.\"\n\nBut the mathematics is catastrophically wrong. Worked examples have incorrect arithmetic that doesn't even stay consistent across steps. Claims are asserted without justification then \"verified\" with completely different numbers handwaved as \"similar patterns.\" Examples reference undefined quantities. I couldn't verify most calculations due to missing steps, ambiguous notation, or wrong arithmetic.\n\nThe fundamental problem: the AI confidently generates mathematical content it cannot verify. It's sophisticated enough to be convincing but wrong enough to be dangerous. Students won't spot errors because the surrounding text sounds authoritative. The time sink is verification, not generation.\n\n---------------------------------------\n\nMy Specific Commentary For Claude Generation:\n\nThe \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.\n\nDespite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes\n\nTheme 1, Mistake 1.1: First warning sign is too specific. The third is too vague\n\n\n\nMath Hallucination! In the complete 2x2 example, there's a critical arithmetic error that undermines the entire demonstration. The guide gets [4 0.04]^T for w1, but really this should be [40, 0.04]^T. This makes the calculation for w2 incorrect as well. This is a serious pedagogical failure because students trying to verify the calculation will get confused and lose trust in the material. A worked example with wrong arithmetic is worse than no example at all.\n\nThe guide states \"Error [1,1]^T\" but never defines what \"Error\" means here. Is this w* - wt or wt - w*? The inconsistent usage makes it impossible to verify the calculations. Later it says \"error multiplied by 0.8 per iteration\" but earlier showed the update factor as (1\u22122*0.1*9)=\u22120.8, which is negative. The magnitude is 0.8, sure, but this distinction matters when students are trying to understand convergence versus oscillation.\n\nWhile the \"Connection to Practice\" sections are useful, they're too brief and disconnected from the main exposition. For instance, when discussing condition number, the guide mentions batch normalization helps but doesn't explain how or why it affects the condition number. These connections feel tacked on rather than integrated. A student reading this still won't understand why practitioners obsess over things like feature normalization.\n\nThe guide calculates scaling factors and then says \"Wait, this seems wrong!\" This is pedagogically bizarre. It makes it seem like even the guide author is confused. The issue is that the guide conflates two different quantities: the scaling factor sigma_i / (sigma_i^2 + lambda) \n(which appears in the formula) with the actual shrinkage of the final solution. When it says scaling factor 2 is 1.429 (which is >1), this should have been a red flag that something was wrong with the setup. The \"correction\" that follows is actually computing a different quantity (wi,Ridge) without clarifying the distinction. This will confuse students who are trying to understand what the scaling factor actually means.\n\n\n\nThe numerical illustration considers f(w) = w^2 and claims data pts give gradients of f1(1)=3, etc. But this doesn't make sense. If f(w) = w^2, the the gradient is 2w, and so the gradient evaluated at 1 should be 2 always. The guide seems to be trying to show per sample gradients but it never defines what the individual fi functions are. This example fails because it;s trying to illustrate a concept without properly setting up the mathematical framework. Students will be confused about what \"data points giving different gradients\" means for the same function at the same point.\n\nMany of the self-check questions ask for numerical calculations rather than conceptual reasoning\n\nThere is not justification or derivation of the claim that early stopping has a specific ridge equivalent. This is presented as fact but is actually a loose heuristic that depends heavily on the problem structure. The worked example that follows doesn't really validate this relationship\u2014the numbers are completely different (w3 = [.936, .174], wridge =[.730,.026]). The guide just handwaves this as \"similar patterns.\" This is intellectually dishonest. If the relationship is approximate, explain why and under what conditions it holds.\n\nThe \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.\n\nDespite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey everyone,</paragraph><paragraph>I wanted to share my experience using an LLM to generate a \"Common Mistakes\" guide for my optimization lecture notes. I wanted to build a guide that addresses common student conceptual pitfalls to help me check my understanding of lecture material before/during homework. </paragraph><paragraph>TL;DR: careful prompting dramatically improved conceptual structure, but mathematical errors make the output dangerous. Even though this didn't work super well, I think it still is useful to know that we can't easily prompt models to identify potential student misconceptions/pitfalls purely from lecture material. And I think this reflects on a shared student experience these days: AI can explain the lecture notes but it struggles to identify the student knowledge state, which is critical in guiding students from misunderstanding to mastery using the correct level of rigor. </paragraph><paragraph>Here are my results:</paragraph><paragraph>(I used the .tex lecture notes generated from Jameson Liu. See ed thread #301)</paragraph><paragraph>1) with chatGPT</paragraph><file url=\"https://static.us.edusercontent.com/files/qmhKlm8uWY7Kbe2j8oNyzaZb\" filename=\"cs182_special_participation_student_guide.pdf\"/><file url=\"https://static.us.edusercontent.com/files/odfP47Ua1irdJcMCYHcA8lqB\" filename=\"cs182_chatgpt_prompt.txt\"/><paragraph/><paragraph>2) with claude</paragraph><file url=\"https://static.us.edusercontent.com/files/AHDjnaw6Jb5RAnn1c7g99f6g\" filename=\"cs182_claude_prompt.txt\"/><file url=\"https://static.us.edusercontent.com/files/NL84NPxtdag3RxZcw4CB6EYr\" filename=\"cs182_special_participation_student_guide (1).pdf\"/><paragraph/><paragraph>My General Commentary:</paragraph><paragraph>My first attempt with ChatGPT was a disaster\u2014superficial and completely missed that data geometry drives optimization behavior. So I crafted a detailed prompt forcing the AI to: (1) analyze the \"big picture\" first, (2) identify where students shift from scalar to geometric thinking, (3) derive misconceptions organically from lecture structure, (4) organize around themes, and (5) include worked examples. The prompt was topic-agnostic.</paragraph><paragraph>The conceptual improvements were real. The AI organized misconceptions into coherent themes like \"Spectral Properties vs. Dataset Size,\" consistently used geometric language (\"elongated bowl,\" \"steep walls\"), correctly identified SVD as the unifying framework, and created an excellent debugging checklist. The warning signs were specific: \"Your justification for \u03b7 mentions only n or d, not \u03c3_max.\"</paragraph><paragraph>But the mathematics is catastrophically wrong. Worked examples have incorrect arithmetic that doesn't even stay consistent across steps. Claims are asserted without justification then \"verified\" with completely different numbers handwaved as \"similar patterns.\" Examples reference undefined quantities. I couldn't verify most calculations due to missing steps, ambiguous notation, or wrong arithmetic.</paragraph><paragraph>The fundamental problem: the AI confidently generates mathematical content it cannot verify. It's sophisticated enough to be convincing but wrong enough to be dangerous. Students won't spot errors because the surrounding text sounds authoritative. The time sink is verification, not generation.</paragraph><paragraph>---------------------------------------</paragraph><paragraph>My Specific Commentary For Claude Generation:</paragraph><paragraph>The \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.</paragraph><paragraph>Despite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes</paragraph><paragraph>Theme 1, Mistake 1.1: First warning sign is too specific. The third is too vague</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/cHbC9MPZZ3Mp1tsUDHQCvCny\" width=\"626\" height=\"238\"/></figure><paragraph/><paragraph>Math Hallucination! In the complete 2x2 example, there's a critical arithmetic error that undermines the entire demonstration. The guide gets [4 0.04]^T for w1, but really this should be [40, 0.04]^T. This makes the calculation for w2 incorrect as well. This is a serious pedagogical failure because students trying to verify the calculation will get confused and lose trust in the material. A worked example with wrong arithmetic is worse than no example at all.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/prsFBWgl2iMMcFP4r2AJEIM3\" width=\"613\" height=\"368\"/></figure><paragraph>The guide states \"Error [1,1]^T\" but never defines what \"Error\" means here. Is this w* - wt or wt - w*? The inconsistent usage makes it impossible to verify the calculations. Later it says \"error multiplied by 0.8 per iteration\" but earlier showed the update factor as (1\u22122*0.1*9)=\u22120.8, which is negative. The magnitude is 0.8, sure, but this distinction matters when students are trying to understand convergence versus oscillation.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/1WiZtafV9gLuv25x2vEIZxQb\" width=\"550\" height=\"430\"/></figure><paragraph>While the \"Connection to Practice\" sections are useful, they're too brief and disconnected from the main exposition. For instance, when discussing condition number, the guide mentions batch normalization helps but doesn't explain how or why it affects the condition number. These connections feel tacked on rather than integrated. A student reading this still won't understand why practitioners obsess over things like feature normalization.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/zmih0izXnH8ZMwCeXqq9w0af\" width=\"555\" height=\"165\"/></figure><paragraph>The guide calculates scaling factors and then says \"Wait, this seems wrong!\" This is pedagogically bizarre. It makes it seem like even the guide author is confused. The issue is that the guide conflates two different quantities: the scaling factor sigma_i / (sigma_i^2 + lambda) <break/>(which appears in the formula) with the actual shrinkage of the final solution. When it says scaling factor 2 is 1.429 (which is &gt;1), this should have been a red flag that something was wrong with the setup. The \"correction\" that follows is actually computing a different quantity (wi,Ridge) without clarifying the distinction. This will confuse students who are trying to understand what the scaling factor actually means.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/dtsANrQas6duL8GOwjN4EsLk\" width=\"404\" height=\"273\"/></figure><paragraph/><paragraph>The numerical illustration considers f(w) = w^2 and claims data pts give gradients of f1(1)=3, etc. But this doesn't make sense. If f(w) = w^2, the the gradient is 2w, and so the gradient evaluated at 1 should be 2 always. The guide seems to be trying to show per sample gradients but it never defines what the individual fi functions are. This example fails because it;s trying to illustrate a concept without properly setting up the mathematical framework. Students will be confused about what \"data points giving different gradients\" means for the same function at the same point.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/iwC0bnD1Nwt1tL44oGONJY5G\" width=\"624\" height=\"191\"/></figure><paragraph>Many of the self-check questions ask for numerical calculations rather than conceptual reasoning</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/SCSegdxmmZtUmrgDja10eJfi\" width=\"562\" height=\"165\"/></figure><paragraph>There is not justification or derivation of the claim that early stopping has a specific ridge equivalent. This is presented as fact but is actually a loose heuristic that depends heavily on the problem structure. The worked example that follows doesn't really validate this relationship\u2014the numbers are completely different (w3 = [.936, .174], wridge =[.730,.026]). The guide just handwaves this as \"similar patterns.\" This is intellectually dishonest. If the relationship is approximate, explain why and under what conditions it holds.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/56dwdLpOBHq7vgUODkUTWhEa\" width=\"557\" height=\"72\"/></figure><paragraph>The \"Experiments to Deepen Understanding\" section lists good ideas but provides no guidance on implementation, what to observe, or what conclusions to draw. Telling students to \"measure the smoothness (variance of step directions)\" for momentum without explaining how to compute this or what values to expect is not helpful. These experiments need more scaffolding.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/shwc3ntIPjU1GLf07i3zQfjm\" width=\"592\" height=\"258\"/></figure><paragraph>Despite the improved tone, the fundamental framing is still \"here are mistakes and how to fix them\" rather than \"here's how to build robust understanding.\" The guide would be stronger if it started each section with \"Here's what you should understand\" and then showed common pitfalls as deviations from that understanding, rather than leading with the mistakes.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T17:02:57.775101+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397226,
            "author": "Tin Yau",
            "project_title": "Special Participation A: Gemini 3 pro on HW 8",
            "post_body": "I used Gemini 3 Pro to solve the non\u2011coding portion of HW 8. Overall, Gemini did an excellent job producing clear and well\u2011structured mathematical derivations, often matching the logical flow of the official solutions. I especially appreciated its ability to organize the reasoning into intuitive steps and explain the purpose behind each transformation. Gemini sometimes took a slightly different path to reach the final answer, but its results were fully consistent after minor prompting. Overall, I was impressed by its precision, presentation quality, and the clarity of its mathematical reasoning.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used <bold>Gemini 3 Pro</bold> to solve the non\u2011coding portion of <bold>HW 8</bold>. Overall, Gemini did an excellent job producing clear and well\u2011structured mathematical derivations, often matching the logical flow of the official solutions. I especially appreciated its ability to organize the reasoning into intuitive steps and explain the purpose behind each transformation. Gemini sometimes took a slightly different path to reach the final answer, but its results were fully consistent after minor prompting. Overall, I was impressed by its precision, presentation quality, and the clarity of its mathematical reasoning.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/woyKGrCUftrJJQ6Fn5M3mbF0\" filename=\"A_Gemini_3_pro.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T16:58:24.482712+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7397166,
            "author": "Ijin Yu",
            "project_title": "Special Participation A: Gemini 3 Pro on HW 2 Written Questions",
            "post_body": "Executive Summary: Interaction with Gemini on Deep Learning Theory\n\nModel Tested: Gemini 3 Pro\n\nDomain: Deep Learning Optimization & Distributed Training (CS 182/282 Context)\n\nOverall Performance: 100% Success Rate (One-shot)\n\nPerformance Overview\n\nThe model was tasked with solving non-coding theoretical problems involving:\n\nOptimization Derivations: Deriving analytical solutions for penalized linear improvement using Euclidean ($L_2$) and Infinity ($L_\\infty$) norms.\n\nOptimizer Convergence: Analyzing convergence points for Vanilla SGD, Simplified Adam, and Feature Rescaling on a constrained linear regression problem.\n\nDistributed Training: Calculating communication costs (message count and size) for All-to-All, Parameter Server, and Ring All-Reduce architectures.\n\nIn every instance, the model provided the correct analytical solution and numerical answers on the first attempt (one-shot). No prompt engineering, iterative correction, or \"dragging\" of the model was required to arrive at the solution. The model successfully transcribed complex mathematical notation directly from uploaded screenshots without OCR errors.\n\nHallucinations & Accuracy\n\nHallucination Rate: 0%.\n\nThe model demonstrated robust reasoning capabilities. It correctly identified standard optimizers (Gradient Descent, SignSGD) from first-principles derivations and accurately recalled specific distributed systems constraints (e.g., the $2(n-1)$ steps in Ring All-Reduce).\n\nBehavioral Observations: Uncertainty and Verification\n\nA distinct behavioral trait observed during the session was the model's tendency to simulate self-verification and hedging.\n\n\"Double-Checking\": Despite the high accuracy of the final outputs, the model\u2019s reasoning process appeared to involve recursive checks. It would often derive a step, then implicitly verify it against known standard results (e.g., checking if the derived update rule matched the standard definition of SignSGD) before committing to the answer.\n\nHedging Language: The model frequently used probabilistic language such as \"I believe\" or \"this suggests,\" rather than authoritative absolutes, even when the math was unambiguous. This behavior mimics a cautious human student double-checking their work to ensure logical consistency, rather than a machine simply outputting a retrieved token sequence.\n\nConclusion\n\nGemini demonstrated graduate-level competency in deep learning theory, capable of handling multimodal inputs (LaTeX screenshots) and complex analytical derivations with perfect accuracy. The interaction suggests that for well-defined theoretical problems, modern reasoning models can serve as reliable verification engines, provided the user monitors the \"reasoning track\" for the model's internal consistency.\n\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"3\">Executive Summary: Interaction with Gemini on Deep Learning Theory</heading><paragraph>Model Tested: Gemini 3 Pro</paragraph><paragraph>Domain: Deep Learning Optimization &amp; Distributed Training (CS 182/282 Context)</paragraph><paragraph>Overall Performance: 100% Success Rate (One-shot)</paragraph><paragraph>Performance Overview</paragraph><paragraph>The model was tasked with solving non-coding theoretical problems involving:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Optimization Derivations:</bold> Deriving analytical solutions for penalized linear improvement using Euclidean ($L_2$) and Infinity ($L_\\infty$) norms.</paragraph></list-item><list-item><paragraph><bold>Optimizer Convergence:</bold> Analyzing convergence points for Vanilla SGD, Simplified Adam, and Feature Rescaling on a constrained linear regression problem.</paragraph></list-item><list-item><paragraph><bold>Distributed Training:</bold> Calculating communication costs (message count and size) for All-to-All, Parameter Server, and Ring All-Reduce architectures.</paragraph></list-item></list><paragraph>In every instance, the model provided the correct analytical solution and numerical answers on the first attempt (<bold>one-shot</bold>). No prompt engineering, iterative correction, or \"dragging\" of the model was required to arrive at the solution. The model successfully transcribed complex mathematical notation directly from uploaded screenshots without OCR errors.</paragraph><paragraph><bold>Hallucinations &amp; Accuracy</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Hallucination Rate:</bold> 0%.</paragraph></list-item><list-item><paragraph>The model demonstrated robust reasoning capabilities. It correctly identified standard optimizers (Gradient Descent, SignSGD) from first-principles derivations and accurately recalled specific distributed systems constraints (e.g., the $2(n-1)$ steps in Ring All-Reduce).</paragraph></list-item></list><paragraph>Behavioral Observations: Uncertainty and Verification</paragraph><paragraph>A distinct behavioral trait observed during the session was the model's tendency to simulate self-verification and hedging.</paragraph><list style=\"unordered\"><list-item><paragraph><bold>\"Double-Checking\":</bold> Despite the high accuracy of the final outputs, the model\u2019s reasoning process appeared to involve recursive checks. It would often derive a step, then implicitly verify it against known standard results (e.g., checking if the derived update rule matched the standard definition of SignSGD) before committing to the answer.</paragraph></list-item><list-item><paragraph><bold>Hedging Language:</bold> The model frequently used probabilistic language such as \"I believe\" or \"this suggests,\" rather than authoritative absolutes, even when the math was unambiguous. This behavior mimics a cautious human student double-checking their work to ensure logical consistency, rather than a machine simply outputting a retrieved token sequence.</paragraph></list-item></list><paragraph>Conclusion</paragraph><paragraph>Gemini demonstrated graduate-level competency in deep learning theory, capable of handling multimodal inputs (LaTeX screenshots) and complex analytical derivations with perfect accuracy. The interaction suggests that for well-defined theoretical problems, modern reasoning models can serve as reliable verification engines, provided the user monitors the \"reasoning track\" for the model's internal consistency.</paragraph><file url=\"https://static.us.edusercontent.com/files/9hAVpcxKaswAaeykKGjmtSCr\" filename=\"q1.pdf\"/><file url=\"https://static.us.edusercontent.com/files/j2qU6fS8iumFddzcc5zVkF1V\" filename=\"q2.pdf\"/><file url=\"https://static.us.edusercontent.com/files/aAAIVIqMfstp21bcCessvEaC\" filename=\"q5.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T16:47:42.131618+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7396775,
            "author": "Manhar Gupta",
            "project_title": "Special Participation E: Custom 'Mastery Coach' Gem on Gemini 3 Pro to learn RNNs, self-supervision and SSMs",
            "post_body": "For the past few days, I had been using Gemini Learning Coach Gem for my other engineering classes to learn concepts by letting the model understand the lecture transcripts and the slides. I noticed that the learning coach used to go along with what I said if I was correct. However, the Learning Coach Gem would only detail specific nuances and niches only if explicitly told to. I was looking for something that would expand upon what I said in a detailed manner and help me cover any gaps in my explanations.\n\nIn one of my conversations with Gemini which was covering material for another class, I had been rigorously asking it to cover things missing in my explanation and help me formalize my understanding at every step so that it moves forward to tell me what my explanation and conceptual depth can improve upon. I realized that this conversation might have enough context to create a system prompt that would emphasize what I would want from a Gem based on learning.\n\nSo, I decided to put a specific JSON prompt close to the end of one of my learning conversations with Gemini Learning Coach Gem. I told it to generate a custom system prompt for an AI assistant that would emphasize rigor. For the system prompt, I told it to not have specific references to the material we had been covering in the chat so that the Custom Gem would act better as a general tool emphasized towards learning and education. I have added a screenshot of the prompt I used and the system prompt it generated as \u2018Initial system prompt\u2019\n\nIt created the following system prompt which however, still had the specific references. I put the system prompt in another chat and asked Gemini to remove specific references of the mentioned material. I put the refined system prompt inside the 'instructions' section for creation of a Custom Gem. I called this Gem 'Mastery Coach'. I have also attached this cleaned system prompt that I finally used as \u2018Generalized Mastery Coach Prompt\u2019\n\nSo for learning RNNs, self-supervision and SSMs, I decided to use this Gem in a similar way to how I began conversations with \u2018Learning Coach\u2019. I uploaded the lecture transcripts and notes. Since the transcripts were taken from YouTube, they would have unnecessary timestamps. I separately asked ChatGPT to just remove the timestamp while keeping all wording intact.\n\nThe starting prompt for the conversation was a high-level explanation of the context (the class which the material is for, my objectives, other relevant context) and concepts being covered. These beginning prompts are in the uploaded chats itself. I used to add short pointers which I intended would act as an additional 'system prompt' so that the Gem would focus better on the particular material just added. From there, the entire conversation followed which has also been attached with detailed annotations. \n\nI have also attached a link to the Gem which would directly allow you to use it in your Gemini environment.\n\nReflection: Giving both the transcripts and the slides was beneficial. While you would expect it to cover concepts in the same progression as the lectures, it took a different order in explaining things. I especially noticed that the concept of \u2018A\u2019 diagonalization was covered at a point where it wasn\u2019t explicitly mentioned in the lecture. While asking probing questions, it was giving away too much in hints. I have also mentioned this in annotations as something others can work on by building a Custom Gem of their own using a modified version of the system prompt attached below.\n\nLink to use 'Mastery Coach' directly: https://gemini.google.com/gem/1JoLndovdl25vJ9DPMw9NGg6wEC2gMDn-?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>For the past few days, I had been using Gemini Learning Coach Gem for my other engineering classes to learn concepts by letting the model understand the lecture transcripts and the slides. I noticed that the learning coach used to go along with what I said if I was correct. However, the Learning Coach Gem would only detail specific nuances and niches only if explicitly told to. I was looking for something that would expand upon what I said in a detailed manner and help me cover any gaps in my explanations.</paragraph><paragraph>In one of my conversations with Gemini which was covering material for another class, I had been rigorously asking it to cover things missing in my explanation and help me formalize my understanding at every step so that it moves forward to tell me what my explanation and conceptual depth can improve upon. I realized that this conversation might have enough context to create a system prompt that would emphasize what I would want from a Gem based on learning.</paragraph><paragraph>So, I decided to put a specific JSON prompt close to the end of one of my learning conversations with Gemini Learning Coach Gem. I told it to generate a custom system prompt for an AI assistant that would emphasize rigor. For the system prompt, I told it to not have specific references to the material we had been covering in the chat so that the Custom Gem would act better as a general tool emphasized towards learning and education. I have added a screenshot of the prompt I used and the system prompt it generated as \u2018Initial system prompt\u2019</paragraph><paragraph>It created the following system prompt which however, still had the specific references. I put the system prompt in another chat and asked Gemini to remove specific references of the mentioned material. I put the refined system prompt inside the 'instructions' section for creation of a Custom Gem. I called this Gem 'Mastery Coach'. I have also attached this cleaned system prompt that I finally used as \u2018Generalized Mastery Coach Prompt\u2019</paragraph><paragraph>So for learning RNNs, self-supervision and SSMs, I decided to use this Gem in a similar way to how I began conversations with \u2018Learning Coach\u2019. I uploaded the lecture transcripts and notes. Since the transcripts were taken from YouTube, they would have unnecessary timestamps. I separately asked ChatGPT to just remove the timestamp while keeping all wording intact.</paragraph><paragraph>The starting prompt for the conversation was a high-level explanation of the context (the class which the material is for, my objectives, other relevant context) and concepts being covered. These beginning prompts are in the uploaded chats itself. I used to add short pointers which I intended would act as an additional 'system prompt' so that the Gem would focus better on the particular material just added. From there, the entire conversation followed which has also been attached with detailed annotations. <break/><break/>I have also attached a link to the Gem which would directly allow you to use it in your Gemini environment.<break/><break/>Reflection: Giving both the transcripts and the slides was beneficial. While you would expect it to cover concepts in the same progression as the lectures, it took a different order in explaining things. I especially noticed that the concept of \u2018A\u2019 diagonalization was covered at a point where it wasn\u2019t explicitly mentioned in the lecture. While asking probing questions, it was giving away too much in hints. I have also mentioned this in annotations as something others can work on by building a Custom Gem of their own using a modified version of the system prompt attached below.</paragraph><paragraph>Link to use 'Mastery Coach' directly: https://gemini.google.com/gem/1JoLndovdl25vJ9DPMw9NGg6wEC2gMDn-?usp=sharing</paragraph><file url=\"https://static.us.edusercontent.com/files/Bvv5jwuXNoERIfNgFXFdnH1i\" filename=\"Mastery Coach on RNNs, self-supervision, SSMs (1).pdf\"/><file url=\"https://static.us.edusercontent.com/files/zzYQq911CPYmYYn0qWEYQaol\" filename=\"Generalized Mastery Coach Prompt.pdf\"/><file url=\"https://static.us.edusercontent.com/files/tl8x3RgutqE3q0od9uh8R1bz\" filename=\"Initial system prompt.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T15:37:45.769937+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7396752,
            "author": "Alex Luu",
            "project_title": "Special Participation E: AI Further Studies Guide",
            "post_body": "After lectures, I often find myself interested in some of the topics briefly mentioned. Specifically, the implementation details are interesting, but since they are only briefly covered, the lectures do not go into detail about them. I decided to use Sonnet 4.5 to help me with expanding my knowledge in a way I can understand. \n\nOne topic in particular was about the KV cache. Lecture only mentioned it but does not go into the specifics of the implementation and how it fits in the inference steps.\n\nHere is my prompt:\n\n\"\"\"\nI am taking a deep learning class. Your job is to help me fill the gap in my knowledge from lecture. Specifically, I want you to help me understand the KV cache in more detail. \n\nI have attached relevant lecture notes that talk about transformers. \n\nHere are my questions:\n1. What is the KV cache?\n\n2. What specifically is cached?\n\n3. How does prefilling and autoregressive generation work with the KV cache?\n\"\"\"\nI attached lecture notes 18 and 19 with this. \n\nThe results were pretty good as Claude was very detailed with the answers. I had many follow-up questions and it answered them perfectly. I especially like how it references the lecture notes so that the math notation it used was consistent. This made it easier to understand. I have attached the annotated log below.",
            "content_xml": "<document version=\"2.0\"><paragraph>After lectures, I often find myself interested in some of the topics briefly mentioned. Specifically, the implementation details are interesting, but since they are only briefly covered, the lectures do not go into detail about them. I decided to use Sonnet 4.5 to help me with expanding my knowledge in a way I can understand. </paragraph><paragraph>One topic in particular was about the KV cache. Lecture only mentioned it but does not go into the specifics of the implementation and how it fits in the inference steps.</paragraph><paragraph>Here is my prompt:</paragraph><paragraph>\"\"\"<break/>I am taking a deep learning class. Your job is to help me fill the gap in my knowledge from lecture. Specifically, I want you to help me understand the KV cache in more detail. </paragraph><paragraph>I have attached relevant lecture notes that talk about transformers. <break/><break/>Here are my questions:<break/>1. What is the KV cache?</paragraph><paragraph>2. What specifically is cached?</paragraph><paragraph>3. How does prefilling and autoregressive generation work with the KV cache?<break/>\"\"\"<break/>I attached lecture notes 18 and 19 with this. </paragraph><paragraph>The results were pretty good as Claude was very detailed with the answers. I had many follow-up questions and it answered them perfectly. I especially like how it references the lecture notes so that the math notation it used was consistent. This made it easier to understand. I have attached the annotated log below.</paragraph><file url=\"https://static.us.edusercontent.com/files/gw6Rg8yxNSJASxbeKiVVCdiY\" filename=\"Special Participation E.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T15:34:01.931379+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7396526,
            "author": "Hanyang Gu",
            "project_title": "Special Participation B: Gemini 3 Pro on HW 2 Coding Questions",
            "post_body": "The code generated by Gemini 3 demonstrates a high level of accuracy and adherence to the assignment requirements. In almost all cases, the logic implemented by Gemini is identical or functionally equivalent to the staff solutions. The code style is consistent with the provided codebase, and the implementations are generally concise and idiomatic.\n\nSome Key observations:\n- Correctness: The core algorithms (optimizers, neural network layers, backpropagation) are implemented correctly.\n- Style: The code follows standard Python and NumPy practices. Variable naming is consistent with the surrounding code.\n- Differences: Minor differences exist in hyperparameter choices (e.g., learning rate for the best model) and some implementation details (e.g., using `np.zeros` vs `np.random.normal(scale=0)`), but these do not affect correctness.\n- Completeness: All identified TODOs in the provided files were addressed.\n\nThe detailed report is attached below; it contains all Gemini responses in line compared with staff solution. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>The code generated by Gemini 3 demonstrates a high level of accuracy and adherence to the assignment requirements. In almost all cases, the logic implemented by Gemini is identical or functionally equivalent to the staff solutions. The code style is consistent with the provided codebase, and the implementations are generally concise and idiomatic.</paragraph><paragraph>Some Key observations:<break/>- Correctness: The core algorithms (optimizers, neural network layers, backpropagation) are implemented correctly.<break/>- Style: The code follows standard Python and NumPy practices. Variable naming is consistent with the surrounding code.<break/>- Differences: Minor differences exist in hyperparameter choices (e.g., learning rate for the best model) and some implementation details (e.g., using `np.zeros` vs `np.random.normal(scale=0)`), but these do not affect correctness.<break/>- Completeness: All identified TODOs in the provided files were addressed.</paragraph><paragraph>The detailed report is attached below; it contains all Gemini responses in line compared with staff solution. </paragraph><file url=\"https://static.us.edusercontent.com/files/TT2t86kCpskGO0MVyjfPS1wP\" filename=\"Special Participation B - Gemini 3 on HW2.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T15:02:53.412677+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7396249,
            "author": "Abdelaziz Mohamed",
            "project_title": "Google Colab released an extension for VS Code",
            "post_body": "Lot's of us like to use VS Code as an IDE especially if we're using Copilot so I thought it might be helpful to other students to know that Google Colab recently released an extension that connects VS Code to the Google Colab runtime. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Lot's of us like to use VS Code as an IDE especially if we're using Copilot so I thought it might be helpful to other students to know that Google Colab recently released an extension that connects VS Code to the Google Colab runtime. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T14:27:02.005071+11:00",
            "category": "Admin"
        },
        {
            "guid": 7396049,
            "author": "Minjune Kim",
            "project_title": "Special Participation B: Mistral on HW 2 Coding Parts",
            "post_body": "I used Mistral on HW 2 to test the coding parts. \n\nhttps://chat.mistral.ai/chat/b5eaeee5-f01f-480e-bb74-65040dab6010\n\nOverall: Mistral performed very well with the coding parts of HW 2. I think the solution that mistral provided almost aligns the same with the staff solution however there are some parts where it differs. With 15 parts to the coding problem, it was able to successfully one-shot 14/15. The part where it was unable to one-shot is because I did not provide necessary dependable files when giving the prompt question to Mistral. \n\nPros: \n\nI think that Mistral was able to give pretty clear explanation to the code that it wrote for each part as well as summarize what it has done and give some key points for the users. Also provided observation and parameters that's being used. \n\nWhen most of the code is given to the prompt and MIstral only has to do one-liners, it performs at a 100% accuracy for one-shot for HW 2. \n\nCons:\n\nTo be fair, I did not notice much errors when working with Mistral for HW 2. It was able to one-shot all of the coding TO-DO parts very well. While there are some coding parts that it could have made it more clear by writing cleaner code, it's performance was very satisfying at least for this hw. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Mistral on HW 2 to test the coding parts. </paragraph><paragraph><link href=\"https://chat.mistral.ai/chat/b5eaeee5-f01f-480e-bb74-65040dab6010\">https://chat.mistral.ai/chat/b5eaeee5-f01f-480e-bb74-65040dab6010</link></paragraph><paragraph>Overall: Mistral performed very well with the coding parts of HW 2. I think the solution that mistral provided almost aligns the same with the staff solution however there are some parts where it differs. With 15 parts to the coding problem, it was able to successfully one-shot 14/15. The part where it was unable to one-shot is because I did not provide necessary dependable files when giving the prompt question to Mistral. </paragraph><paragraph>Pros: </paragraph><paragraph>I think that Mistral was able to give pretty clear explanation to the code that it wrote for each part as well as summarize what it has done and give some key points for the users. Also provided observation and parameters that's being used. </paragraph><paragraph>When most of the code is given to the prompt and MIstral only has to do one-liners, it performs at a 100% accuracy for one-shot for HW 2. </paragraph><paragraph>Cons:</paragraph><paragraph>To be fair, I did not notice much errors when working with Mistral for HW 2. It was able to one-shot all of the coding TO-DO parts very well. While there are some coding parts that it could have made it more clear by writing cleaner code, it's performance was very satisfying at least for this hw. </paragraph><paragraph/></document>",
            "links": [
                "https://chat.mistral.ai/chat/b5eaeee5-f01f-480e-bb74-65040dab6010"
            ],
            "attachments": [],
            "created_at": "2025-12-03T13:58:45.503975+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7395772,
            "author": "Garv Goswami",
            "project_title": "Special Participation E - Understanding RoPe Visually with help From Claude and 3Blue1Brown",
            "post_body": "Confused by RoPe, I created a 3Blue1Brown style Manim video that incorporates both code and conceptual feedback from Claude on how to best explain the concept. We cover: \n\nWhy rotation? \n\nHow does rotation create relative position?\n\nWhat does chunking mean visually?\n\nWhy different frequencies?\n\nand also examples of the concepts. Please let me know if you have any feedback (my first video, so anything is appreciated)!",
            "content_xml": "<document version=\"2.0\"><paragraph>Confused by RoPe, I created a 3Blue1Brown style Manim video that incorporates both code and conceptual feedback from Claude on how to best explain the concept. We cover: </paragraph><list style=\"unordered\"><list-item><paragraph><bold>Why rotation?</bold> </paragraph></list-item><list-item><paragraph><bold>How does rotation create relative position?</bold></paragraph></list-item><list-item><paragraph><bold>What does chunking mean visually?</bold></paragraph></list-item><list-item><paragraph><bold>Why different frequencies?</bold></paragraph></list-item></list><paragraph>and also examples of the concepts. Please let me know if you have any feedback (my first video, so anything is appreciated)!</paragraph><file url=\"https://static.us.edusercontent.com/files/5eqB8ggaWknuTSjC2C6pF7Ta\" filename=\"Claude RoPe Notes.pdf\"/><video src=\"https://youtu.be/bU5ZYP5eMLY\" width=\"678\" height=\"381.375\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T13:20:11.278254+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7395359,
            "author": "Jorge Diaz Chao",
            "project_title": "A lightweight PyTorch library for Model-Agnostic Meta-Learning (MAML)",
            "post_body": "Over summer I tried building a pair of glasses powered by a vision model that could recognize typing on any surface. Naturally I thought about how could a model quickly adapt to different styles and or gestures. I stumbled upon this paper (Vision-Based Hand Gesture Customization from a Single Demonstration) by Apple, which is a cool application of MAML, and tried something similar. \n\nI found most MAML implementations to not be very lightweight (so not very friendly) and/or not in PyTorch, so I made a public a tiny lightweight library (QuickMAML) implementing MAML if you'd like to check that out.\n\nIn practice MAML is hard to train and suboptimal for very hard tasks for reasons explored in the course, and there has been attempts at making this beautiful idea (I think) more reliable, like How to train your MAML (MAML++), for which you can also find an implementation in the library.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Over summer I tried building a pair of glasses powered by a vision model that could recognize typing on any surface. Naturally I thought about how could a model quickly adapt to different styles and or gestures. I stumbled upon this paper (<link href=\"https://arxiv.org/abs/2402.08420v2\">Vision-Based Hand Gesture Customization from a Single Demonstration</link>) by Apple, which is a cool application of MAML, and tried something similar. </paragraph><paragraph>I found most MAML implementations to not be very lightweight (so not very friendly) and/or not in PyTorch, so I made a public a tiny lightweight library (<link href=\"https://github.com/jdiazchao/quick-maml\">QuickMAML</link>) implementing MAML if you'd like to check that out.</paragraph><paragraph>In practice MAML is hard to train and suboptimal for very hard tasks for reasons explored in the course, and there has been attempts at making this beautiful idea (I think) more reliable, like <link href=\"https://arxiv.org/abs/1810.09502\">How to train your MAML</link> (MAML++), for which you can also find an implementation in the library.</paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/3PMRFkFt6P3OhttU8m70fReu\" width=\"654\" height=\"291.8247011952191\"/></figure></document>",
            "links": [
                "https://arxiv.org/abs/2402.08420v2",
                "https://github.com/jdiazchao/quick-maml",
                "https://arxiv.org/abs/1810.09502"
            ],
            "attachments": [],
            "created_at": "2025-12-03T12:27:34.123109+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7395276,
            "author": "Arvind Kruthiventy",
            "project_title": "Special Participation B -- Gemini Pro 2.5 on HW8, Arvind Kruthiventy",
            "post_body": "Executive Summary: \n\nIn this report, I utilized Gemini Pro 2.5 model for completing the SSM coding portions of Homework 8. I inputted each portion of the coding question separately and checked the model's outputs but it appeared to nearly one-shot all the portions and provided clean, formatted code with very detailed explanations. It made a small mistake in implementing the convolution forward pass as it treated the operation as a traditional convolution, but with a prompt from me, it immediately identified its mistake. Interesting, its SSM convolution forward implementation seems slightly more efficient compared to the provided solutions. The analysis of its own code were thorough and a standout as it makes it easy to understand how lines of code correspond to the more abstract details. However, there is a clear tradeoff as the Pro model takes a significant amount of time even for the simpler questions. Overall I was very impressed by how it one shot the coding portion of the assignment fairly easily even if it took a fair bit of time to process each question. \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/nKhuqUI2o1UajJWaDwmHcTyF\" filename=\"Special Participation B -- Gemini Pro on HW 8, Arvind Kruthiventy.pdf\"/><paragraph>Executive Summary: </paragraph><paragraph>In this report, I utilized Gemini Pro 2.5 model for completing the SSM coding portions of Homework 8. I inputted each portion of the coding question separately and checked the model's outputs but it appeared to nearly one-shot all the portions and provided clean, formatted code with very detailed explanations. It made a small mistake in implementing the convolution forward pass as it treated the operation as a traditional convolution, but with a prompt from me, it immediately identified its mistake. Interesting, its SSM convolution forward implementation seems slightly more efficient compared to the provided solutions. The analysis of its own code were thorough and a standout as it makes it easy to understand how lines of code correspond to the more abstract details. However, there is a clear tradeoff as the Pro model takes a significant amount of time even for the simpler questions. Overall I was very impressed by how it one shot the coding portion of the assignment fairly easily even if it took a fair bit of time to process each question. </paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T12:16:55.953322+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7395127,
            "author": "Hanyang Gu",
            "project_title": "Special Participation C: Refactoring HW 6 Coding Questions.",
            "post_body": "\n\nOur team refactored the coding questions in Homework 6 to make it better for learning and cultivating deep learning intuition. The following is the executive summary: \nThe refactoring process followed by three core pillars: PEP 8 compliance, the Single Responsibility Principle (SRP), and the Google ML Engineering Guide. \n\nFirst, to adhere to the Single Responsibility Principle, we dismantled the monolithic structure of the original notebooks. Code that defined model architectures, training loops, and utility functions was extracted from the notebooks and organized into dedicated Python modules (`architectures.py`, `trainer.py`, `utils.py`, `profiling.py`, `optimizers.py`, `graph_utils.py`). This separation ensures that notebooks are reserved for high-level experimentation and narrative, while the heavy lifting is handled by robust, testable modules.\n\nSecond, we enforced PEP 8 standards across the board. This involved standardizing naming conventions (e.g., using `snake_case` for functions and `CamelCase` for classes), adding comprehensive type hints to function signatures, and including docstrings. These changes significantly improve code readability and maintainability, making it easier for students to understand the interfaces they are working with.\n\nFinally, drawing from the Google ML Engineering Guide, we implemented best practices for reproducibility and configuration management. Global variables, which often lead to silent errors and reproducibility issues, were replaced with structured `dataclasses` (e.g., `TrainingConfig`). We also introduced a centralized random seed utility to ensure that experiments are deterministic across different runs and hardware setups.\n\nThe code is included in the following public Repo:\n\nhttps://github.com/MCxiaoguu/fa25-eecs182-specials \n\nThe report is attached below:\n\nThe team members are : Hanyang Gu (SID: 3038838194, hanyanggu05ucb@berkeley.edu), Zimu Wang (SID: 3038960121, zm.wang@berkeley.edu). ",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>Our team refactored the coding questions in Homework 6 to make it better for learning and cultivating deep learning intuition. The following is the executive summary: <break/>The refactoring process followed by three core pillars: PEP 8 compliance, the Single Responsibility Principle (SRP), and the Google ML Engineering Guide. <break/><break/>First, to adhere to the Single Responsibility Principle, we dismantled the monolithic structure of the original notebooks. Code that defined model architectures, training loops, and utility functions was extracted from the notebooks and organized into dedicated Python modules (`architectures.py`, `trainer.py`, `utils.py`, `profiling.py`, `optimizers.py`, `graph_utils.py`). This separation ensures that notebooks are reserved for high-level experimentation and narrative, while the heavy lifting is handled by robust, testable modules.<break/><break/>Second, we enforced PEP 8 standards across the board. This involved standardizing naming conventions (e.g., using `snake_case` for functions and `CamelCase` for classes), adding comprehensive type hints to function signatures, and including docstrings. These changes significantly improve code readability and maintainability, making it easier for students to understand the interfaces they are working with.<break/><break/>Finally, drawing from the Google ML Engineering Guide, we implemented best practices for reproducibility and configuration management. Global variables, which often lead to silent errors and reproducibility issues, were replaced with structured `dataclasses` (e.g., `TrainingConfig`). We also introduced a centralized random seed utility to ensure that experiments are deterministic across different runs and hardware setups.</paragraph><paragraph>The code is included in the following public Repo:</paragraph><paragraph><link href=\"https://github.com/MCxiaoguu/fa25-eecs182-specials\">https://github.com/MCxiaoguu/fa25-eecs182-specials</link> </paragraph><paragraph>The report is attached below:</paragraph><file url=\"https://static.us.edusercontent.com/files/hKNKHAdfLGQ07VoBJdCqYhN8\" filename=\"Special Participation C - Refactoring HW 6 Coding Portions.pdf\"/><paragraph>The team members are : Hanyang Gu (SID: 3038838194, hanyanggu05ucb@berkeley.edu), Zimu Wang (SID: 3038960121, zm.wang@berkeley.edu). </paragraph></document>",
            "links": [
                "https://github.com/MCxiaoguu/fa25-eecs182-specials"
            ],
            "attachments": [],
            "created_at": "2025-12-03T11:58:29.92643+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7394664,
            "author": "Mihir Rao",
            "project_title": "Special Participation E: A Deep Learning Fable",
            "post_body": "I tend to retain concepts better when I understand why? rather than just how? LLMs are really good at understanding a large amount of information and explaining them in different ways. I asked Gemini to take three lectures(18, 19, 20), and write a story about how the decisions for these architectures and formulations came to be.\n\nI went through a few iterations of a prompt, and ended up settling with one that emphasizes my desire for it to really focus on intuition rather than merely summarizing contents. One thing I found interesting is it's good use and development of analogies to explain content. I had to force Gemini to answer in complete sentences because it seemed to really like bullet points.\n\nUsing an LLM this way also made me more aware of its strengths and limitations. It\u2019s great at remixing and reframing material into something that matches my learning style, but I still have to check that the intuition it gives me lines up with the actual definitions and equations in the lectures. This method can also serve well as motivation for the mathematics in lecture. Here is what I ended up with:\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I tend to retain concepts better when I understand <italic>why</italic>? rather than just <italic>how?</italic> LLMs are really good at understanding a large amount of information and explaining them in different ways. I asked Gemini to take three lectures(18, 19, 20), and write a story about how the decisions for these architectures and formulations came to be.<break/><break/>I went through a few iterations of a prompt, and ended up settling with one that emphasizes my desire for it to really focus on intuition rather than merely summarizing contents. One thing I found interesting is it's good use and development of analogies to explain content. I had to force Gemini to answer in complete sentences because it seemed to really like bullet points.<break/><break/>Using an LLM this way also made me more aware of its strengths and limitations. It\u2019s great at remixing and reframing material into something that matches my learning style, but I still have to check that the intuition it gives me lines up with the actual definitions and equations in the lectures. This method can also serve well as motivation for the mathematics in lecture. Here is what I ended up with:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/lb84wS3w1dj3gDeuSGPpS10m\" filename=\"182 Part E 2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T11:02:42.67456+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7393994,
            "author": "Vrushank Prakash",
            "project_title": "Special Participation B: Gemini 3 Pro on HW 8",
            "post_body": "I used Gemini 3 Pro to solve the coding portions of HW 8, which includes question 2 about coding SSM Forward. Overall, Gemini 3 Pro did a pretty good job of answering the coding parts. When it was coding the SSM kernel, it used a recursive approach, which was different from the official solution. I tested this solution out and it did end up producing the same results as the official solution. I think Gemini saw the hint about divide-and-conquer from the homework and immediately thought about recursion.\n\nGemini did have trouble answering the conceptual questions within the notebooks though. It often didn't consider the varying sizes of the T and H dimensions and gave an overgeneralization (e.g. convolution is faster than recurrent for all values of H in the GPU notebook, when this isn't true if H is large). It also initially got the conceptual questions wrong for the CPU implementation by assuming that there is parallelization, when there actually isn't. I felt that it hallucinated for some of the conceptual questions and it was pretty hard to follow along. \n\nOverall, Gemini did a good job on the coding implementations but didn't have the best explanations for the conceptual questions and often needed further prompting to push it towards the right answer.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 3 Pro to solve the coding portions of HW 8, which includes question 2 about coding SSM Forward. Overall, Gemini 3 Pro did a pretty good job of answering the coding parts. When it was coding the SSM kernel, it used a recursive approach, which was different from the official solution. I tested this solution out and it did end up producing the same results as the official solution. I think Gemini saw the hint about divide-and-conquer from the homework and immediately thought about recursion.</paragraph><paragraph>Gemini did have trouble answering the conceptual questions within the notebooks though. It often didn't consider the varying sizes of the T and H dimensions and gave an overgeneralization (e.g. convolution is faster than recurrent for all values of H in the GPU notebook, when this isn't true if H is large). It also initially got the conceptual questions wrong for the CPU implementation by assuming that there is parallelization, when there actually isn't. I felt that it hallucinated for some of the conceptual questions and it was pretty hard to follow along. </paragraph><paragraph>Overall, Gemini did a good job on the coding implementations but didn't have the best explanations for the conceptual questions and often needed further prompting to push it towards the right answer.</paragraph><file url=\"https://static.us.edusercontent.com/files/ZWIjJWNibSfJTgmq8pvneeXN\" filename=\"CS 182 Special Participation B_ Gemini Pro 3 on HW 8.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T09:52:15.609442+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7393256,
            "author": "Ishir Garg",
            "project_title": "Special Participation A: Claude (Sonnet 4.5) on HW 12",
            "post_body": "Below is my report on using Claude's Sonnet 4.5 model to solve the written questions to Homework 12. I have also attached a PDF of the annotated transcript.\n\nSummary:\n\nOverall Claude correctly one-shots every question\n\nGenerally, it's reasoning is correct, except for one slightly informal/imprecise statement that it makes about distributions in the second problem.\n\nIn general, I felt that its explanations lacked pedagogical value and would not be maximally helpful to a student who was confused about the class material\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is my report on using Claude's Sonnet 4.5 model to solve the written questions to Homework 12. I have also attached a PDF of the annotated transcript.</paragraph><file url=\"https://static.us.edusercontent.com/files/mkMmgnwgfasEbweGi3g74vmp\" filename=\"participationA.pdf\"/><paragraph>Summary:</paragraph><list style=\"bullet\"><list-item><paragraph>Overall Claude correctly one-shots every question</paragraph></list-item><list-item><paragraph>Generally, it's reasoning is correct, except for one slightly informal/imprecise statement that it makes about distributions in the second problem.</paragraph></list-item><list-item><paragraph>In general, I felt that its explanations lacked pedagogical value and would not be maximally helpful to a student who was confused about the class material</paragraph></list-item></list><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T08:38:40.394007+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7392001,
            "author": "Mihir Rao",
            "project_title": "Special Participation E: Gemini + Manim for Visual Intuition",
            "post_body": "I've always been fascinated by 3b1b's math explanation videos, and find them really insightful particularly because of the unique approach to explain concepts through visual depictions. I built upon the starting point in Jameson's Post: #301, and used the lecture transcript and latex template to build something else: manimaker. Given latex input and a transcript, these scripts generate a video using the same engine 3b1b uses to make his videos.\n\nTo try this out, go to the manim_generator script I wrote, change the topic focus prompt, and build the video. You can ask it to generate a video and explain concepts from lecture using visuals, or ask it to focus on more specific concepts within a lecture. For example, I gave it the prompt below:\n\nTOPIC_FOCUS = \"Explain Ridge regression in the SVD basis, including the formula for w_* = (X^T X + lambda I)^{-1} X^T y, how it becomes a diagonal shrinkage in the singular value basis, and geometric intuition for why small singular values are suppressed. Do not cover momentum or SGD here.\"\n\nAnd we're able to generate the video below! This also uses the Gemini API, and uses the script I wrote to create a file you can use to build the video as such: manim -pqh lecture_manim.py RidgeRegressionSVDScene. I have included all necessary files in the zip below, including the lecture notes latex + transcript(from #301), my manim file generator, a yaml to setup your conda env, and video itself. I've also attached the video directly below.\n\nSome limitations that could be improved: Because Gemini is writing code, sometimes manim build errors may occur, but I found they're usually resolvable with 1-3 queries from your favorite LLM. I did find that Gemini does a great job coming up with layouts, sequential structure to introduce material, and showing graphs that demonstrate the concept.\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I've always been fascinated by 3b1b's math explanation videos, and find them really insightful particularly because of the unique approach to explain concepts through visual depictions. I built upon the starting point in Jameson's Post: #301, and used the lecture transcript and latex template to build something else: manimaker. Given latex input and a transcript, these scripts generate a video using the same engine 3b1b uses to make his videos.<break/><break/>To try this out, go to the manim_generator script I wrote, change the topic focus prompt, and build the video. You can ask it to generate a video and explain concepts from lecture using visuals, or ask it to focus on more specific concepts within a lecture. For example, I gave it the prompt below:<break/><break/><bold>TOPIC_FOCUS</bold> = \"Explain Ridge regression in the SVD basis, including the formula for w_* = (X^T X + lambda I)^{-1} X^T y, how it becomes a diagonal shrinkage in the singular value basis, and geometric intuition for why small singular values are suppressed. Do not cover momentum or SGD here.\"<break/><break/>And we're able to generate the video below! This also uses the Gemini API, and uses the script I wrote to create a file you can use to build the video as such: <code>manim -pqh lecture_manim.py RidgeRegressionSVDScene</code>. I have included all necessary files in the zip below, including the lecture notes latex + transcript(from #301), my manim file generator, a yaml to setup your conda env, and video itself. I've also attached the video directly below.<break/><break/>Some limitations that could be improved: Because Gemini is writing code, sometimes manim build errors may occur, but I found they're usually resolvable with 1-3 queries from your favorite LLM. I did find that Gemini does a great job coming up with layouts, sequential structure to introduce material, and showing graphs that demonstrate the concept.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/8W5UmAhaMTHYFwuevs8mTXiS\" filename=\"RidgeRegressionSVDScene.mp4\"/><file url=\"https://static.us.edusercontent.com/files/JahupOGI0gmrFlKRz9Pyarsx\" filename=\"manimaker.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-03T06:14:02.211271+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7389909,
            "author": "Etaash Patel",
            "project_title": "Special Participation A: Gemma 3 (12b params) on HW09 Written Problems",
            "post_body": "Executive Summary:\n\nI worked with Gemma 3 on the written problems for Homework 9 (problems 1, 2, 3, 4, and 6). Overall, Gemma performed fairly well (especially given that it is an open-source model that I ran locally on my laptop). For problems 1\u20134e, which were largely computation problems, Gemma (mostly) produced correct solutions on the first attempt and consistently demonstrated a strong grasp of the underlying concepts.\n\nOne area where Gemma stood out was its clarity of explanation. Compared to ChatGPT and Claude (the other LLMs I have worked with), I've found Gemma's explanations to be clearer, or explicit, and pedagogically helpful. This, in part, is because Gemma uses more English in their mathematical argument, whereas (in my experience) ChatGPT and Claude tend to be equation-heavy. Gemma's strong explanations (when correct) make it a particularly helpful learning tool, even when it gets some problems wrong. I actually found myself better understanding some of the time and space-complexity arguments around attention mechanisms when trying to guide Gemma to the right solution.\n\nGemma\u2019s weaknesses emerged in two specific areas:\n1: time- and space-complexity analysis\n\n2: dimension checking and tensor shape reasoning.\n\n\nHowever, even when it produced incorrect bounds or incorrect tensor shapes, it often identified the correct overall strategy, so using Gemma can still be instructive. \n\nOne of the more striking behaviors appeared toward the end. After many failed attempts and struggling through problems 4f, 4g, and 6, Gemma seemed to exhibit an emergent pattern resembling human frustration. Its responses became less coherent, more speculative, and more willing to guess just to produce something and move on. I found this shift in behavior similar to how a tired human might respond when stuck on a difficult p-set. When Gemma enters this state, the best strategy is simply to start a new conversation for higher-quality answers (however, I continued in the same conversation out of curiosity).\n\nOverall, I found Gemma 3 to be an instructive assistant for the written problems. \n\nTrace:\nhighlighted themes - clarity of explanations, where Gemma 3 became lost, and emergent \"frustrated\" behavior. ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary:</bold><break/><break/>I worked with Gemma 3 on the written problems for Homework 9 (problems 1, 2, 3, 4, and 6). Overall, Gemma performed fairly well (especially given that it is an open-source model that I ran locally on my laptop). For problems 1\u20134e, which were largely computation problems, Gemma (mostly) produced correct solutions on the first attempt and consistently demonstrated a strong grasp of the underlying concepts.</paragraph><paragraph>One area where Gemma stood out was its clarity of explanation. Compared to ChatGPT and Claude (the other LLMs I have worked with), I've found Gemma's explanations to be clearer, or explicit, and pedagogically helpful. This, in part, is because Gemma uses more English in their mathematical argument, whereas (in my experience) ChatGPT and Claude tend to be equation-heavy. Gemma's strong explanations (when correct) make it a particularly helpful learning tool, even when it gets some problems wrong. I actually found myself better understanding some of the time and space-complexity arguments around attention mechanisms when trying to guide Gemma to the right solution.</paragraph><paragraph>Gemma\u2019s weaknesses emerged in two specific areas:<break/>1: time- and space-complexity analysis</paragraph><paragraph>2: dimension checking and tensor shape reasoning.<break/></paragraph><paragraph>However, even when it produced incorrect bounds or incorrect tensor shapes, it often identified the correct overall strategy, so using Gemma can still be instructive. </paragraph><paragraph>One of the more striking behaviors appeared toward the end. After many failed attempts and struggling through problems 4f, 4g, and 6, Gemma seemed to exhibit an emergent pattern resembling human frustration. Its responses became less coherent, more speculative, and more willing to guess just to produce something and move on. I found this shift in behavior similar to how a tired human might respond when stuck on a difficult p-set. When Gemma enters this state, the best strategy is simply to start a new conversation for higher-quality answers (however, I continued in the same conversation out of curiosity).</paragraph><paragraph>Overall, I found Gemma 3 to be an instructive assistant for the written problems. <break/><break/><bold>Trace:</bold><break/>highlighted themes - clarity of explanations, where Gemma 3 became lost, and emergent \"frustrated\" behavior. </paragraph><file url=\"https://static.us.edusercontent.com/files/0N5ne1w11Lbh9fSlWXF3cIrD\" filename=\"Participation A.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T20:19:39.414415+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7389703,
            "author": "Moxin Tang",
            "project_title": "Special Participation E: A Project-Based ChatGPT Workspace for Understanding the Computational Complexity of Attention",
            "post_body": "I\u2019m using the ChatGPT Project workspace to build a focused learning environment that stays tightly aligned with the official class materials. For topics like the computational complexity of attention, I want ChatGPT\u2019s explanations to follow the exact thinking style used in the discussions and homework solutions.\n\nA major reason I chose the Project workspace is that when studying a specific topic, having a general and consistent setup is extremely important. I want the notation, assumptions, and reasoning pattern to stay stable across the entire learning process. With a Project, every conversation happens inside the same space, so the structure doesn\u2019t drift.\n\nThere are three key motivations behind this setup:\n\nI can unload the actual course materials as the background knowledge of the project, so ChatGPT relies on the real lecture notes and homework solutions.\n\nThe Project keeps everything organized and consistent, which means advanced topics (like kernelized attention) can naturally build on the notation and intuition established in earlier ones (like MHA or causal attention).\n\nA stable setup makes the study process smoother, because each subtopic follows the same structure:\n\nintuition \u2192 notation \u2192 formulation \u2192 derivation \u2192 complexity \u2192 comparison.\n\nTo make this work, I first asked ChatGPT to design:\n\na global instruction that enforces this structured reasoning style, and\n\na sequence of prompts I can reuse whenever I study a new subtopic.\n\nThen I uploaded my class materials into the Project and followed this prompt sequence to build a conversation that grows in a consistent and cumulative way.\n\nFinal Pipeline\n\nStep 1 \u2014 Build the Project Framework\n\nChatGPT helps design the global rules and structured prompt workflow.\n\nThen I upload all relevant lecture notes, discussion notes, and homework materials.\n\nStep 2 \u2014 Guided Learning Inside the Project\n\nI walk through each subtopic step-by-step using the designed prompts, ensuring that notation, reasoning, and assumptions remain consistent across the entire topic.\n\nSupplements\n\n1. The link below takes you to the Project itself. The course materials I used for this topic are all included in the PDF.\n\nChatGPT\n\n2. I\u2019ve also added an annotated conversation for the subtopics within this project where I evaluate how well GPT performed.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I\u2019m using the ChatGPT <bold>Project</bold> workspace to build a focused learning environment that stays tightly aligned with the official class materials. For topics like the <bold>computational complexity of attention</bold>, I want ChatGPT\u2019s explanations to follow the exact thinking style used in the discussions and homework solutions.</paragraph><paragraph>A major reason I chose the Project workspace is that <bold>when studying a specific topic, having a general and consistent setup is extremely important</bold>. I want the notation, assumptions, and reasoning pattern to stay stable across the entire learning process. With a Project, every conversation happens inside the same space, so the structure doesn\u2019t drift.</paragraph><paragraph>There are three key motivations behind this setup:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>I can unload the actual course materials as the background knowledge of the project</bold>, so ChatGPT relies on the real lecture notes and homework solutions.</paragraph></list-item><list-item><paragraph><bold>The Project keeps everything organized and consistent</bold>, which means advanced topics (like kernelized attention) can naturally build on the notation and intuition established in earlier ones (like MHA or causal attention).</paragraph></list-item><list-item><paragraph><bold>A stable setup makes the study process smoother</bold>, because each subtopic follows the same structure:</paragraph><paragraph><bold>intuition \u2192 notation \u2192 formulation \u2192 derivation \u2192 complexity \u2192 comparison.</bold></paragraph></list-item></list><paragraph>To make this work, I first asked ChatGPT to design:</paragraph><list style=\"unordered\"><list-item><paragraph>a <bold>global instruction</bold> that enforces this structured reasoning style, and</paragraph></list-item><list-item><paragraph>a <bold>sequence of prompts</bold> I can reuse whenever I study a new subtopic.</paragraph></list-item></list><paragraph>Then I uploaded my class materials into the Project and followed this prompt sequence to build a conversation that grows in a consistent and cumulative way.</paragraph><heading level=\"1\"><bold>Final Pipeline</bold></heading><heading level=\"3\"><bold>Step 1 \u2014 Build the Project Framework</bold></heading><paragraph>ChatGPT helps design the global rules and structured prompt workflow.</paragraph><paragraph>Then I upload all relevant lecture notes, discussion notes, and homework materials.</paragraph><file url=\"https://static.us.edusercontent.com/files/NNa0fVoCmCGQcLNtm52km2Rz\" filename=\"Prompt sequence design.pdf\"/><heading level=\"3\"><bold>Step 2 \u2014 Guided Learning Inside the Project</bold></heading><paragraph>I walk through each subtopic step-by-step using the designed prompts, ensuring that notation, reasoning, and assumptions remain consistent across the entire topic.</paragraph><heading level=\"2\">Supplements</heading><paragraph>1. The link below takes you to the Project itself. The course materials I used for this topic are all included in the PDF.</paragraph><paragraph><link href=\"https://chatgpt.com/g/g-p-691a72305c648191874525ffadffe6a9\"><bold>ChatGPT</bold></link></paragraph><file url=\"https://static.us.edusercontent.com/files/PGbXg9bhtRmgecLQvTZ5BqYG\" filename=\"course materials.pdf\"/><paragraph>2. I\u2019ve also added an annotated conversation for the subtopics within this project where I evaluate how well GPT performed.</paragraph><file url=\"https://static.us.edusercontent.com/files/bINQRy5baLfjQD54rCsmg9Cc\" filename=\"multiple attention mechanisms.pdf\"/><paragraph/><file url=\"https://static.us.edusercontent.com/files/R9sFmBQQLJNYGBFkTUi1ruvQ\" filename=\"kernelized attention.pdf\"/><paragraph/></document>",
            "links": [
                "https://chatgpt.com/g/g-p-691a72305c648191874525ffadffe6a9"
            ],
            "attachments": [],
            "created_at": "2025-12-02T18:34:13.408623+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7389679,
            "author": "Ishir Garg",
            "project_title": "Special Participation D: MuP in Hw7",
            "post_body": "I created an extension to Q1 of HW7 that tries to reinforce the ideas in MuP in the context of RNNs. There are two main parts of this notebook:\n\n1. Personally, I always found it confusing whether the correct MuP initialization was 1 / n, or 1 / sqrt(n), or something else, so the first part tries to empirically examine the correct initialization scheme  and connect this to an eigenvalue analysis for RNNs.\n\n2. The second part empirically shows how per-layer learning rates in an RNN can help for better hyper-parameter transfer on a dataset.\n\nI created both a solutions and student notebook, attached below",
            "content_xml": "<document version=\"2.0\"><paragraph>I created an extension to Q1 of HW7 that tries to reinforce the ideas in MuP in the context of RNNs. There are two main parts of this notebook:</paragraph><paragraph>1. Personally, I always found it confusing whether the correct MuP initialization was 1 / n, or 1 / sqrt(n), or something else, so the first part tries to empirically examine the correct initialization scheme  and connect this to an eigenvalue analysis for RNNs.</paragraph><paragraph>2. The second part empirically shows how per-layer learning rates in an RNN can help for better hyper-parameter transfer on a dataset.</paragraph><paragraph>I created both a solutions and student notebook, attached below</paragraph><file url=\"https://static.us.edusercontent.com/files/aiQ7ZfbXgMhNMmjVMJrYaauQ\" filename=\"mup_rnn_student.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/AfYIRbbphIKlysXHgFcatVH5\" filename=\"mup_rnn_solution.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T18:26:25.496528+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7389560,
            "author": "Jorge Diaz Chao",
            "project_title": "HW7 Last Name Classification w/ Lion + LR Batch Size",
            "post_body": "I have extended Homework 7 Q2 to include modules focused on optimizer choice and learning rate tuning. I wrote a question asking to implement the Lion optimizer and explore under different configurations to contrast with the Adam optimizer in the context of RNNs. I also added experiments on batch size and learning rate, implementing common LR scaling heuristics (linear and square-root scaling) and an optional warmup schedule to stabilize training at larger batch sizes. \n\nThese additions are important because, in practice, training speed and final accuracy often depend as much on the optimizer and LR/batch-size strategy as on the model architecture itself, and these questions prompt the students to explore techniques to train faster and more reliably. Below you can find the notebooks including extension (with and without solutions).\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I have extended <italic><link href=\"https://berkeley-cs182.github.io/fa25/assets/assignments/hw7.pdf\">Homework 7</link></italic> Q2 to include modules focused on <italic>optimizer</italic> choice and <italic>learning rate</italic> tuning. I wrote a question asking to implement the Lion optimizer and explore under different configurations to contrast with the Adam optimizer in the context of RNNs. I also added experiments on <italic>batch size</italic> and <italic>learning rate</italic>, implementing common LR scaling heuristics (linear and square-root scaling) and an optional warmup schedule to stabilize training at larger batch sizes. </paragraph><paragraph>These additions are important because, in practice, training speed and final accuracy often depend as much on the optimizer and LR/batch-size strategy as on the model architecture itself, and these questions prompt the students to explore techniques to train faster and more reliably. Below you can find the notebooks including extension (with and without solutions).</paragraph><file url=\"https://static.us.edusercontent.com/files/Ycx2Xv71djeTn1chNyRu8O2t\" filename=\"q_rnn_last_name_ext.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/IAWCBuUUXX3J3oy2HkH7rNTg\" filename=\"q_rnn_last_name_ext_sol.ipynb\"/><paragraph/></document>",
            "links": [
                "https://berkeley-cs182.github.io/fa25/assets/assignments/hw7.pdf"
            ],
            "attachments": [],
            "created_at": "2025-12-02T17:48:47.47256+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7389325,
            "author": "Vrushank Prakash",
            "project_title": "Special Participation A: Gemini 3 Pro on HW 7",
            "post_body": "I used Gemini 3 Pro to solve the non-coding portion of HW 7, which include 3(b), 4, 7, and 8. Overall, Gemini 3 Pro did a quite good job of giving an intuitive explanation for some of the complex math found in the official HW solutions. It was able to one-shot almost all the questions (except one part in question 4 about the blog). Gemini did usually take quite different approaches than the official solution, which made me prompt Gemini further to connect the different solutions together. I do believe that Gemini could have been more rigorous for some of the more math-intensive questions, but I didn't expect to get something fully similar to the official solution without giving more context on what math techniques to use. Overall, I am quite impressed with the results.\n\nHere is an annotated trace of the chat: https://docs.google.com/document/d/1mXvXyKigfz0mgcQdqG-h3eDCklwMNgAnccCIv5bq4uk/edit?usp=sharing\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 3 Pro to solve the non-coding portion of HW 7, which include 3(b), 4, 7, and 8. Overall, Gemini 3 Pro did a quite good job of giving an intuitive explanation for some of the complex math found in the official HW solutions. It was able to one-shot almost all the questions (except one part in question 4 about the blog). Gemini did usually take quite different approaches than the official solution, which made me prompt Gemini further to connect the different solutions together. I do believe that Gemini could have been more rigorous for some of the more math-intensive questions, but I didn't expect to get something fully similar to the official solution without giving more context on what math techniques to use. Overall, I am quite impressed with the results.</paragraph><paragraph>Here is an annotated trace of the chat: <link href=\"https://docs.google.com/document/d/1mXvXyKigfz0mgcQdqG-h3eDCklwMNgAnccCIv5bq4uk/edit?usp=sharing\">https://docs.google.com/document/d/1mXvXyKigfz0mgcQdqG-h3eDCklwMNgAnccCIv5bq4uk/edit?usp=sharing</link></paragraph><paragraph/></document>",
            "links": [
                "https://docs.google.com/document/d/1mXvXyKigfz0mgcQdqG-h3eDCklwMNgAnccCIv5bq4uk/edit?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-02T16:53:58.575623+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7389324,
            "author": "Ken Zheng",
            "project_title": "Special Participation E: Enhanced Lecture to Note Transcription Pipeline",
            "post_body": "I added new features to the existing (lecture slide + lecture transcript) --> (LaTeX notes) pipeline. This work builds on #301 and makes these main improvements:\n\nIncorporates direct quotations from our recommended textbook: Understanding Deep Learning for cross-referencing and introducing potentially different POVs.\n\nIncludes accurate references to precise pages in the textbook for relevant key concepts to encourage further exploration and improve integration between the notes and the textbook.\n\nEncourages Gemini to recreate figures and diagrams with LaTeX, when possible--very helpful for visualizing abstract concepts.\n\nMotivation\n\nClasses like the old EECS 16A/B and CS 70 were known for excellent staff-written notes, which made the material organized and accessible, and greatly supported students in self-learning. On the other hand, classes like CS 170 and EECS 126 placed a greater emphasis on their recommended textbook, which were even more excellent sources of knowledge, but could sometimes feel overwhelming due to their high information density. Both the succinct class notes and the chunky textbooks helped us self-learn, but in different ways. In a Deep Learning course, where the field evolves almost faster than we can keep up, self-learning is even more essential. So here, I attempt to amalgamate the notes and the textbook to achieve an optimal balance between accessibility and information quality/density.\n\nDetails\n\nThe pipeline still intakes a lecture slides pdf that gets converted to images to enable visual information extraction, and a lecture transcript of the corresponding lecture that is downloadable from YouTube, but now also takes in the textbook pdf that is uploaded as a file. Feel free to compress the pdf, if needed. From my testing, even extreme compression, given words are still easily discernible, works fine. The pipeline needs a Gemini API, and the final typeset notes can be rendered by compiling the lecture_notes.tex output file with a command like pdflatex lecture_notes.tex. I ran this on lecture 2 as well for easy comparison with the original version. See the annotated output below for more details!\n\nScript\n\nFiles",
            "content_xml": "<document version=\"2.0\"><paragraph>I added new features to the existing (lecture slide + lecture transcript) --&gt; (LaTeX notes) pipeline. This work builds on #301 and makes these main improvements:</paragraph><list style=\"number\"><list-item><paragraph>Incorporates direct quotations from our recommended textbook: <italic><link href=\"https://udlbook.github.io/udlbook/\">Understanding Deep Learning</link></italic> for cross-referencing and introducing potentially different POVs.</paragraph></list-item><list-item><paragraph>Includes accurate references to precise pages in the textbook for relevant key concepts to encourage further exploration and improve integration between the notes and the textbook.</paragraph></list-item><list-item><paragraph>Encourages Gemini to recreate figures and diagrams with LaTeX, when possible--very helpful for visualizing abstract concepts.</paragraph></list-item></list><paragraph><bold>Motivation</bold></paragraph><paragraph>Classes like the old EECS 16A/B and CS 70 were known for excellent staff-written notes, which made the material organized and accessible, and greatly supported students in self-learning. On the other hand, classes like CS 170 and EECS 126 placed a greater emphasis on their recommended textbook, which were even more excellent sources of knowledge, but could sometimes feel overwhelming due to their high information density. Both the succinct class notes and the chunky textbooks helped us self-learn, but in different ways. In a Deep Learning course, where the field evolves almost faster than we can keep up, self-learning is even more essential. So here, I attempt to amalgamate the notes and the textbook to achieve an optimal balance between accessibility and information quality/density.</paragraph><paragraph><bold>Details</bold></paragraph><paragraph>The pipeline still intakes a lecture slides pdf that gets converted to images to enable visual information extraction, and a lecture transcript of the corresponding lecture that is downloadable from YouTube, but now also takes in the textbook pdf that is uploaded as a file. Feel free to compress the pdf, if needed. From my testing, even extreme compression, given words are still easily discernible, works fine. The pipeline needs a Gemini API, and the final typeset notes can be rendered by compiling the <code>lecture_notes.tex</code> output file with a command like <code>pdflatex lecture_notes.tex</code>. I ran this on lecture 2 as well for easy comparison with the original version. See the annotated output below for more details!</paragraph><paragraph><bold>Script</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/nokg79qJX4qCVrhDlArt6q2K\" filename=\"make_notes.py\"/><paragraph><bold>Files</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/NI2YpCxEeiPdIKOei5p6b9r8\" filename=\"lecture_slides.pdf\"/><file url=\"https://static.us.edusercontent.com/files/dkWz30RrzMCFU8QhUH5duZw7\" filename=\"lecture_transcript.txt\"/><file url=\"https://static.us.edusercontent.com/files/qELmD8k4lIMObDMObZri4ytJ\" filename=\"lecture_notes_annotated.pdf\"/></document>",
            "links": [
                "https://udlbook.github.io/udlbook/"
            ],
            "attachments": [],
            "created_at": "2025-12-02T16:53:55.419277+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7388828,
            "author": "Alex Cao",
            "project_title": "Special Participation E: Simulated Office Hours: Using LLM \u201cStudents\u201d and \u201cInstructors\u201d to Deepen Lecture Understanding",
            "post_body": "\n\nIntroduction and Motivation\n\nI personally find other students\u2019 questions and instructors\u2019 answers in class extremely helpful for deepening my understanding of the concepts. When I learn something for the first time, it is easy to feel like I understand it, until I actually try to implement or prove the idea in a homework assignment and suddenly realize there are many details I never fully grasped. Homework is therefore very valuable in exposing these gaps. Listening to classmates\u2019 questions and the instructor\u2019s explanations plays a similar role for me: it helps surface misunderstandings I didn\u2019t even know I had.\n\nMotivated by this, I would like to explore an idea: using LLMs to simulate \u201cmock office hours,\u201d where one LLM plays the role of a curious, insightful student and another plays the role of an experienced instructor. My hope is that the student LLM will raise questions I might not think to ask myself, and that the instructor LLM will respond based on the lecture content (and, when appropriate, external references), thereby extending my engagement with the material. The hypothesis is that because the \u201cstudent LLM\u201d understands the concept beforehand, it will carefully curate a set of meaningful questions that will elicit nice answers from the \u201cteacher LLM\u201d.\n\nI want to emphasize that this mock office hour setup is not a replacement for real office hours and will inevitably be less effective than directly interacting with the course staff. Rather, it is intended only as a supplementary, experimental attempt that might help reinforce lecture material\u2014especially for students who are unable to attend office hours regularly.\n\nThe lecture transcripts are used in this attempt; these materials are used solely for educational purposes within this course, with full recognition that the CS182 course staff holds copyright.\n\n\n\nAnnotated Trace and Report:\n\n\n\nFull Traces:\n\nStudent: https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738\n\nTeacher: https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190ae\n\n\n\nSummary, Limitations and Future Works:\n\nThis report is an initial attempt to test whether a knowledgeable student (simulated using an LLM) can carefully curate a set of insightful questions that elicit helpful and thoughtful responses from a teacher LLM, thereby helping real students gain a better understanding of certain concepts. From the simple experiment conducted, we can already see some signals that this \u201cmock office hour\u201d setup is helpful. For example, the student LLM is capable of asking insightful questions and making meaningful connections between past questions, the teacher LLM\u2019s responses, and the lecture transcript by asking focused follow-up questions.\n\nHowever, there are still many limitations to this approach. First, the current attempt relies purely on the lecture transcript. This means not all information from the lecture is captured (for example, the slides), and certain transcripts can be misleading due to transcription errors. Second, this approach is only tested on a single concept in a single lecture with a single model. Although it could be extended to other lectures and models, and even integrated with multimodal inputs, a key weakness of the current setup is that it focuses \u201ctoo much\u201d on a single lecture\u2014both the student LLM and the teacher LLM are unable to make robust connections to past lectures (due to limited context length), which is crucial for a comprehensive understanding of the course material.\n\nOne potentially interesting extension would be to keep the conversation going and observe whether the student model eventually \u201cuses up\u201d all meaningful questions. The whole pipeline could also be easily automated with a small amount of code (in contrast, I used the web interface here because I did not have access to an API key).\n",
            "content_xml": "<document version=\"2.0\"><paragraph/><heading level=\"2\">Introduction and Motivation</heading><paragraph>I personally find other students\u2019 questions and instructors\u2019 answers in class extremely helpful for deepening my understanding of the concepts. When I learn something for the first time, it is easy to <italic>feel</italic> like I understand it, until I actually try to implement or prove the idea in a homework assignment and suddenly realize there are many details I never fully grasped. Homework is therefore very valuable in exposing these gaps. Listening to classmates\u2019 questions and the instructor\u2019s explanations plays a similar role for me: it helps surface misunderstandings I didn\u2019t even know I had.</paragraph><paragraph>Motivated by this, I would like to explore an idea: using LLMs to simulate \u201cmock office hours,\u201d where one LLM plays the role of a curious, insightful student and another plays the role of an experienced instructor. My hope is that the student LLM will raise questions I might not think to ask myself, and that the instructor LLM will respond based on the lecture content (and, when appropriate, external references), thereby extending my engagement with the material. The hypothesis is that because the \u201cstudent LLM\u201d understands the concept beforehand, it will carefully curate a set of meaningful questions that will elicit nice answers from the \u201cteacher LLM\u201d.</paragraph><paragraph>I want to emphasize that this mock office hour setup is <bold>not a replacement for real office hours</bold> and will inevitably be less effective than directly interacting with the course staff. Rather, it is intended only as a <bold>supplementary, experimental attempt</bold> that might help reinforce lecture material\u2014especially for students who are unable to attend office hours regularly.</paragraph><paragraph>The lecture transcripts are used in this attempt; these materials are used solely for educational purposes within this course, with full recognition that the CS182 course staff holds copyright.<break/><break/></paragraph><heading level=\"2\">Annotated Trace and Report:</heading><file url=\"https://static.us.edusercontent.com/files/NofzXIc0lwcjfnn89QWUXMIg\" filename=\"Special Participation E .pdf\"/><paragraph/><heading level=\"2\">Full Traces:</heading><paragraph>Student: <link href=\"https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738\"><underline>https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738</underline></link></paragraph><paragraph>Teacher: <link href=\"https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190ae\"><underline>https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190ae</underline></link></paragraph><paragraph/><heading level=\"2\">Summary, Limitations and Future Works:</heading><paragraph>This report is an initial attempt to test whether a knowledgeable student (simulated using an LLM) can carefully curate a set of insightful questions that elicit helpful and thoughtful responses from a teacher LLM, thereby helping real students gain a better understanding of certain concepts. From the simple experiment conducted, we can already see some signals that this \u201cmock office hour\u201d setup is helpful. For example, the student LLM is capable of asking insightful questions and making meaningful connections between past questions, the teacher LLM\u2019s responses, and the lecture transcript by asking focused follow-up questions.</paragraph><paragraph>However, there are still many limitations to this approach. First, the current attempt relies purely on the lecture transcript. This means not all information from the lecture is captured (for example, the slides), and certain transcripts can be misleading due to transcription errors. Second, this approach is only tested on a single concept in a single lecture with a single model. Although it could be extended to other lectures and models, and even integrated with multimodal inputs, a key weakness of the current setup is that it focuses \u201ctoo much\u201d on a single lecture\u2014both the student LLM and the teacher LLM are unable to make robust connections to past lectures (due to limited context length), which is crucial for a comprehensive understanding of the course material.</paragraph><paragraph>One potentially interesting extension would be to keep the conversation going and observe whether the student model eventually \u201cuses up\u201d all meaningful questions. The whole pipeline could also be easily automated with a small amount of code (in contrast, I used the web interface here because I did not have access to an API key).<break/></paragraph></document>",
            "links": [
                "https://chatgpt.com/share/692e6482-8f98-800f-b0cb-c2a86e1c2738",
                "https://chatgpt.com/share/692e3923-3080-800f-9a43-2545d15190ae"
            ],
            "attachments": [],
            "created_at": "2025-12-02T15:40:09.365315+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7388345,
            "author": "Alex Luu",
            "project_title": "Special Participation E: AI Question Generator To Understand Concepts",
            "post_body": "After reviewing (and understanding) solutions to homework problems for a hard topic, I often want to find ways to ensure I fully understand the topic. I decided to use Sonnet 4.5 to help me with this. \n\nHere is my prompt:\n\"\"\"\nYour job is to help me fully understand the MuP (Maximal Update Parametrization) topic by creating a couple of practice problems with varying difficulty. I have attached lecture notes and the MuP homework questions as well as the MuP research paper.\n\nYou should create 1 conceptual problem and 2 problems that closely represent the homework's difficulty and style. \n\nYou should prompt each question one at a time and if I solve it correctly, move on. If I am incorrect, please say so and provide hints towards the correct solution.\n\"\"\"\nI attached lecture note 6 and homework 3 with it.\n\nThe results were pretty interesting. I liked how it stayed pretty close to the source material and created similar questions that are related. I especially liked how it would reference the source material when giving help. I have attached the annotated log.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>After reviewing (and understanding) solutions to homework problems for a hard topic, I often want to find ways to ensure I fully understand the topic. I decided to use Sonnet 4.5 to help me with this. </paragraph><paragraph>Here is my prompt:<break/>\"\"\"<break/>Your job is to help me fully understand the MuP (Maximal Update Parametrization) topic by creating a couple of practice problems with varying difficulty. I have attached lecture notes and the MuP homework questions as well as the MuP research paper.</paragraph><paragraph>You should create 1 conceptual problem and 2 problems that closely represent the homework's difficulty and style. </paragraph><paragraph>You should prompt each question one at a time and if I solve it correctly, move on. If I am incorrect, please say so and provide hints towards the correct solution.<break/>\"\"\"<break/>I attached lecture note 6 and homework 3 with it.</paragraph><paragraph>The results were pretty interesting. I liked how it stayed pretty close to the source material and created similar questions that are related. I especially liked how it would reference the source material when giving help. I have attached the annotated log.</paragraph><file url=\"https://static.us.edusercontent.com/files/uELljZ6YHYfs5aZmeVGKGjmw\" filename=\"Special Participation E Claude Question Generator.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T14:34:58.668824+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7388143,
            "author": "Jeffrey Cheng",
            "project_title": "Special participation E: Use ChatGPT's study guide to compare different fine-tuning strategies",
            "post_body": "I used ChatGPT's study mode to compare a menu of fine-tuning strategies for adapting a pre-trained large language model for a new task. It compares these strategies based on data access, model specificity, and application domains. \n\nThis conversation log explains the strengths and weaknesses of each fine-tuning strategy, tracing back to the exact setup, when applying them to new tasks. I noted that detailed application scenarios are provided for each fine-tuning strategy, along with the precise application domains, which aid my understanding. \n\nIn the end, it generates a nice workflow for applying fine-tuning strategies to build my own project. \n\nThe annotated log is as follows: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT's study mode to compare a menu of fine-tuning strategies for adapting a pre-trained large language model for a new task. It compares these strategies based on data access, model specificity, and application domains. </paragraph><paragraph>This conversation log explains the strengths and weaknesses of each fine-tuning strategy, tracing back to the exact setup, when applying them to new tasks. I noted that detailed application scenarios are provided for each fine-tuning strategy, along with the precise application domains, which aid my understanding. </paragraph><paragraph>In the end, it generates a nice workflow for applying fine-tuning strategies to build my own project. </paragraph><paragraph>The annotated log is as follows: </paragraph><file url=\"https://static.us.edusercontent.com/files/0ycIV1NBqKZJz4Lb8m86UhGf\" filename=\"Annotated log of fine-tuning strategies.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T14:12:54.788365+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7387863,
            "author": "Manan Roongta",
            "project_title": "Special Participation E: Gemini Lecture Notes Workflow",
            "post_body": "Posting this so other people can reuse the same approach/prompting style when making study material/notes for lectures. It\u2019s been super helpful for studying/rereading later.\n\nNote: This isn\u2019t replacing handwritten notes. I still handwrite annotations during lecture, but since the skeleton is already there, I can pay attention to the lecture instead of spending a lot of time writing notes. \n\nI hope you find these resources helpful \n\nLecture 14 : RNN\n\nLecture 15: Autoencoder and Self-Supervision\n\nLecture 18/19/20 : Transformers\n\nLecture 21/22 : PEFT, LoRA \n\nGemini Chat Trace (annotated)\n\nGemini Chat\n\nPrompt pack\n\n\nMy Workflow\n\ntl;dr : Paste slides + transcript, run the prompts in order, export .tex file, read, request edits, then annotate during lecture.\n\nI start by asking Gemini to explain the bigger picture of the lecture (problem \u2192 solution, motivation, and what each section is trying to solve). I do this first because if I ask for notes immediately, it usually misses the why/bigger picture. I personally like the big picture before diving in.\n\nThen I ask it to go in depth and stay very close to the lecture. \n\nThen I explicitly ask it to define key terms + to make it more structured/improve flow.\n\nThen I ask it to output a clean LaTeX version in a code block.\n\nThen I ask it to redo the LaTeX against the slides/transcript to see if it missed anything. (Usually 2\u20133 passes)\n\nI paste the LaTeX into Overleaf and read it. If anything feels unclear, I ask it to revise specific sections/go deeper into specific concepts (make it clearer, training vs inference, pros/cons, definitions, what\u2019s changing).\n\nWhile watching the actual lecture, I take hand written notes on top of the notes generated. \n\nWhat I noticed : The multi step approach is what makes it work: explanation first, then structure, then LaTeX, then manual check + targeted edits, then handwritten annotation during lecture.\n\nNote: \n\nhappy to share the .tex files if it helps course staff for future versions of the course (and I have more notes I haven\u2019t posted here).\n\nI also included my annotated version of some lecture slides, if any copyright violations, let me know and I can remove it.\n\nI used AI to help with wording/formatting",
            "content_xml": "<document version=\"2.0\"><paragraph>Posting this so other people can reuse the same approach/prompting style when making study material/notes for lectures. It\u2019s been super helpful for studying/rereading later.</paragraph><paragraph><bold>Note</bold>: This isn\u2019t replacing handwritten notes. I still handwrite annotations during lecture, but since the skeleton is already there, I can pay attention to the lecture instead of spending a lot of time writing notes. </paragraph><paragraph>I hope you find these resources helpful </paragraph><list style=\"ordered\"><list-item><paragraph><link href=\"https://edstem.org/us/courses/84647/discussion/7147361?comment=17152272\">Lecture 14 : RNN</link></paragraph></list-item><list-item><paragraph><link href=\"https://edstem.org/us/courses/84647/discussion/7180201?comment=17152287\">Lecture 15: Autoencoder and Self-Supervision</link></paragraph></list-item><list-item><paragraph><link href=\"https://edstem.org/us/courses/84647/discussion/7262818?comment=17152221\">Lecture 18/19/20 : Transformers</link></paragraph></list-item><list-item><paragraph><link href=\"https://edstem.org/us/courses/84647/discussion/7333490?comment=17152169\">Lecture 21/22 : PEFT, LoRA</link> </paragraph></list-item><list-item><paragraph><link href=\"https://drive.google.com/file/d/1QyMsnAlTWK1jmevLrasCVNBhAa97kspv/view\">Gemini Chat Trace (annotated)</link></paragraph></list-item><list-item><paragraph><link href=\"https://gemini.google.com/share/3b8f6d4f2426\">Gemini Chat</link></paragraph></list-item><list-item><paragraph><link href=\"https://drive.google.com/file/d/1SYLdChOFCPB8JxSsYrd-Yvum_krD2ylO/view?usp=sharing\">Prompt pack<break/></link></paragraph></list-item></list><heading level=\"3\">My Workflow</heading><paragraph>tl;dr : Paste slides + transcript, run the prompts in order, export .tex file, read, request edits, then annotate during lecture.</paragraph><list style=\"number\"><list-item><paragraph>I start by asking <underline>Gemini</underline> to explain the bigger picture of the lecture (problem \u2192 solution, motivation, and what each section is trying to solve). I do this first because if I ask for notes immediately, it usually misses the why/bigger picture. I personally like the big picture before diving in.</paragraph></list-item><list-item><paragraph>Then I ask it to go in depth and stay very close to the lecture. </paragraph></list-item><list-item><paragraph>Then I explicitly ask it to define key terms + to make it more structured/improve flow.</paragraph></list-item><list-item><paragraph>Then I ask it to output a clean LaTeX version in a code block.</paragraph></list-item><list-item><paragraph>Then I ask it to redo the LaTeX against the slides/transcript to see if it missed anything. (Usually 2\u20133 passes)</paragraph></list-item><list-item><paragraph>I paste the LaTeX into Overleaf and read it. If anything feels unclear, I ask it to revise specific sections/go deeper into specific concepts (make it clearer, training vs inference, pros/cons, definitions, what\u2019s changing).</paragraph></list-item><list-item><paragraph>While watching the actual lecture, I take hand written notes on top of the notes generated. </paragraph></list-item></list><paragraph><underline>What I noticed</underline> : The multi step approach is what makes it work: explanation first, then structure, then LaTeX, then manual check + targeted edits, then handwritten annotation during lecture.</paragraph><paragraph><bold>Note:</bold> </paragraph><list style=\"bullet\"><list-item><paragraph>happy to share the .tex files if it helps course staff for future versions of the course (and I have more notes I haven\u2019t posted here).</paragraph></list-item><list-item><paragraph>I also included my annotated version of some lecture slides, if any copyright violations, let me know and I can remove it.</paragraph></list-item><list-item><paragraph>I used AI to help with wording/formatting</paragraph></list-item></list></document>",
            "links": [
                "https://edstem.org/us/courses/84647/discussion/7147361?comment=17152272",
                "https://edstem.org/us/courses/84647/discussion/7180201?comment=17152287",
                "https://edstem.org/us/courses/84647/discussion/7262818?comment=17152221",
                "https://edstem.org/us/courses/84647/discussion/7333490?comment=17152169",
                "https://drive.google.com/file/d/1QyMsnAlTWK1jmevLrasCVNBhAa97kspv/view",
                "https://gemini.google.com/share/3b8f6d4f2426",
                "https://drive.google.com/file/d/1SYLdChOFCPB8JxSsYrd-Yvum_krD2ylO/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-02T13:36:06.402849+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7387198,
            "author": "Kithmini Herath",
            "project_title": "Special Participation B: Claude Sonnet 4.5 on HW5 Coding Questions",
            "post_body": "In this assignment I used Claude Sonnet 4.5 for the coding questions (Q5, Q6) in HW5. My strategy was to first introduce what the assignment entails in one sentence and then attach all notebooks and walk-through each of the sections step-by-step while adding other relevant python files needed to complete the task at each step. For Q6, I thought the length of the HW was too long to export out from a single chat, so I split the coding question into two main questions: 1) Implementing batchnorm, dropout, convolution and spatial batch norm, 2) implementing CNNs with PyTorch. I did a max of three attempts to correct Claude if needed to get to the correct/ reasonable answer before stopping and leading to a conclusion about its performance on a specific task. I\u2019ve attached annotated pdfs of my interactions with the LLM. \n\nAcross these coding questions, Claude showed exceptional coding capability, particularly in its ability to self-correct using its internal code execution environment. However, notable weaknesses were there in multimodal interpretation (reading plots/filenames) and visual spatial reasoning (ASCII graphs). \n\nNotable observations: \n\nInternal code verification & self-correction: The most significant feature distinguishing the Claude.ai platform was its use of the code execution feature to verify answers before presenting them. This mimics a standard programming workflow (Code $\\rightarrow$ Test $\\rightarrow$ Debug $\\rightarrow$ Commit) rather than a typical LLM workflow (Predict $\\rightarrow$ Final output to user).\n\nDebugging skills: In the batch normalization backward pass section, Claude initially implemented a solution that resulted in a high gradient error. Instead of outputting this flawed code, it recognized the error via its internal test script, re-derived the math, fixed the implementation, and verified that the error dropped before showing the final solution to the user.\n\nEnvironment & dependency management: It successfully utilized multiple uploaded files (layers.py, notebooks, etc.) as context, effectively acting like an IDE by importing functions from one file to test another. This is already a feature in Claude Code or Claude+Cursor on a user workstation/ personal laptop, but I was impressed that within Claude.ai it handles files very well to provide context for the LLM to implement code.\n\nBug detection in source material: The code execution feature allowed Claude to identify a bug in the staff provided template code regarding the mode initialization in FullyConnectedNet in deeplearning/classifiers/fc_net.py file in the bn_drop.ipynb coding task. Because the code actually ran, Claude could see the test failure that a text-only parser would likely miss. \n\nOne-shot accuracy & coding proficiency: \n\nStandard neural network component implementation: Claude achieved 100% one-shot success on standard implementation tasks, including Na\u00efve Convolution, Max Pooling, and Ordinary Least Squares (OLS) solutions.\n\nCode optimization: It successfully identified and implemented a \"smart\" solution for switching between Train/Test modes in Batch Norm without user intervention, surpassing the manual toggling method initially suggested by itself as a fix for the bug in the provided HW codes.\n\nArchitecture design: While it failed to meet the parameter count constraint (<1M) on the first two tries for the CIFAR-100 CNN, it successfully iterated to an architecture within that constraint on the third try, demonstrating an understanding of the importance of neural network depth (keeping the number of layers constant throughout) vs. scaling the channel width.\n\nHallucinations & misconceptions:\n\nMultimodal/visual failures: \n\nFilename/plot mismatch: In the Dropout assignment, Claude inverted the analysis of the results. It confused the model_dropout and model_no_dropout plots despite the filenames. This led to a logic hallucination where it argued that Dropout made performance worse, inventing a narrative about \"dropout encouraged exploitation of cheating features\" to justify the hallucinated data. This is an example which shows how it required user correction to flip the hallucinated analysis.\n\nDiagram generation: Claude struggled significantly to generate a correct ASCII computational graph for Batch Norm. Despite understanding the flow mathematically, the visual output repeatedly missed edges or directed them incorrectly.\n\nMath hallucinations: During the mathematical derivation of the Batch Norm backward pass, Claude introduced an incorrect square root term in an intermediate step which was later cancelled out and finally appeared (hallucinated) to arrive at the correct final expression. This indicates it \"knew\" the answer but fabricated the intermediate logic to get there. \n\nIn conclusion, Claude does remarkably well in coding tasks. Its ability to run unit tests internally minimizes/prevents syntax errors and logical bugs from reaching the user, saving significant debugging time. However, we must be careful regarding 1) confident misreading of charts/ file associations, 2) mathematical and logical hallucinations, 3) constraint adherence (prioritizing accuracy over explicit constraints mentioned in the instructions on neural network architecture) weaknesses of Claude.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/vIcDULvZc0TZNR4H7O9gT7XM\" filename=\"Claude-Q6d_Implementing convolutional neural networks in PyTorch.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ekmgfZK5CKLuZojILsfwFUUu\" filename=\"Claude-Q6abc_Batch normalization computational graph (1).pdf\"/><file url=\"https://static.us.edusercontent.com/files/KjKHWht6S01qIDwcAQu4dAnM\" filename=\"Claude-Q5_Dropout neural networks homework implementation.pdf\"/><paragraph>In this assignment I used Claude Sonnet 4.5 for the coding questions (Q5, Q6) in HW5. My strategy was to first introduce what the assignment entails in one sentence and then attach all notebooks and walk-through each of the sections step-by-step while adding other relevant python files needed to complete the task at each step. For Q6, I thought the length of the HW was too long to export out from a single chat, so I split the coding question into two main questions: 1) Implementing batchnorm, dropout, convolution and spatial batch norm, 2) implementing CNNs with PyTorch. I did a max of three attempts to correct Claude if needed to get to the correct/ reasonable answer before stopping and leading to a conclusion about its performance on a specific task. I\u2019ve attached annotated pdfs of my interactions with the LLM. </paragraph><paragraph>Across these coding questions, Claude showed exceptional coding capability, particularly in its ability to self-correct using its internal code execution environment. However, notable weaknesses were there in multimodal interpretation (reading plots/filenames) and visual spatial reasoning (ASCII graphs). </paragraph><paragraph><bold>Notable observations:</bold> </paragraph><list style=\"number\"><list-item><paragraph><bold>Internal code verification &amp; self-correction</bold>: The most significant feature distinguishing the Claude.ai platform was its use of the code execution feature to verify answers before presenting them. This mimics a standard programming workflow (Code $\\rightarrow$ Test $\\rightarrow$ Debug $\\rightarrow$ Commit) rather than a typical LLM workflow (Predict $\\rightarrow$ Final output to user).</paragraph><list style=\"bullet\"><list-item><paragraph><bold>Debugging skills</bold>: In the batch normalization backward pass section, Claude initially implemented a solution that resulted in a high gradient error. Instead of outputting this flawed code, it recognized the error via its internal test script, re-derived the math, fixed the implementation, and verified that the error dropped before showing the final solution to the user.</paragraph></list-item><list-item><paragraph><bold>Environment &amp; dependency management</bold>: It successfully utilized multiple uploaded files (layers.py, notebooks, etc.) as context, effectively acting like an IDE by importing functions from one file to test another. This is already a feature in Claude Code or Claude+Cursor on a user workstation/ personal laptop, but I was impressed that within Claude.ai it handles files very well to provide context for the LLM to implement code.</paragraph></list-item><list-item><paragraph><bold>Bug detection in source material</bold>: The code execution feature allowed Claude to identify a bug in the staff provided template code regarding the mode initialization in FullyConnectedNet in <code>deeplearning/classifiers/fc_net.py</code> file in the <code>bn_drop.ipynb</code> coding task. Because the code actually ran, Claude could see the test failure that a text-only parser would likely miss. </paragraph></list-item></list></list-item><list-item><paragraph><bold>One-shot accuracy &amp; coding proficiency</bold>: </paragraph><list style=\"bullet\"><list-item><paragraph><bold>Standard neural network component implementation</bold>: Claude achieved 100% one-shot success on standard implementation tasks, including Na\u00efve Convolution, Max Pooling, and Ordinary Least Squares (OLS) solutions.</paragraph></list-item><list-item><paragraph><bold>Code optimization</bold>: It successfully identified and implemented a \"smart\" solution for switching between Train/Test modes in Batch Norm without user intervention, surpassing the manual toggling method initially suggested by itself as a fix for the bug in the provided HW codes.</paragraph></list-item><list-item><paragraph><bold>Architecture design</bold>: While it failed to meet the parameter count constraint (&lt;1M) on the first two tries for the CIFAR-100 CNN, it successfully iterated to an architecture within that constraint on the third try, demonstrating an understanding of the importance of neural network depth (keeping the number of layers constant throughout) vs. scaling the channel width.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Hallucinations &amp; misconceptions</bold>:</paragraph><list style=\"bullet\"><list-item><paragraph><bold>Multimodal/visual failures</bold>: </paragraph><list style=\"bullet\"><list-item><paragraph><bold>Filename/plot mismatch</bold>: In the Dropout assignment, Claude inverted the analysis of the results. It confused the model_dropout and model_no_dropout plots despite the filenames. This led to a logic hallucination where it argued that Dropout made performance worse, inventing a narrative about \"dropout encouraged exploitation of cheating features\" to justify the hallucinated data. This is an example which shows how it required user correction to flip the hallucinated analysis.</paragraph></list-item><list-item><paragraph><bold>Diagram generation</bold>: Claude struggled significantly to generate a correct ASCII computational graph for Batch Norm. Despite understanding the flow mathematically, the visual output repeatedly missed edges or directed them incorrectly.</paragraph></list-item></list></list-item><list-item><paragraph><bold>Math hallucinations</bold>: During the mathematical derivation of the Batch Norm backward pass, Claude introduced an incorrect square root term in an intermediate step which was later cancelled out and finally appeared (hallucinated) to arrive at the correct final expression. This indicates it \"knew\" the answer but fabricated the intermediate logic to get there. </paragraph></list-item></list></list-item></list><paragraph>In conclusion, Claude does remarkably well in coding tasks. Its ability to run unit tests internally minimizes/prevents syntax errors and logical bugs from reaching the user, saving significant debugging time. However, we must be careful regarding 1) confident misreading of charts/ file associations, 2) mathematical and logical hallucinations, 3) constraint adherence (prioritizing accuracy over explicit constraints mentioned in the instructions on neural network architecture) weaknesses of Claude.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T12:05:24.320064+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7387144,
            "author": "Tianhao Qian",
            "project_title": "Special Participation D: Comparative Study of Muon & \u00b5P (and other optimizers) for GNN Training on Zachary\u2019s Karate Club",
            "post_body": "In this write-up, I systematically benchmarked several modern optimization approaches for training a Graph Convolutional Network (GCN) on the Zachary\u2019s Karate Club graph dataset, including SGD, \u00b5P, Muon, a Muonvariant, SOAP, and Lion. I evaluated them using training/validation loss, test accuracy, convergence speed, and computational efficiency, and I also implemented an early-stopping setup and described key optimizer mechanics (e.g., Muon\u2019s Newton\u2013Schulz orthogonalization; \u00b5P-style parameter-group learning-rate scaling).\n\nMy main findings are that Muon can reach the best final accuracy (up to 100%), while \u00b5P offers the best speed\u2013accuracy trade-off (fast convergence with strong accuracy), and SOAP/Lion tend to perform poorly in this small full-graph training regime.\n\nThe Github repository: \n\nhysteri1a/EECS182-Comparative-Study-of-Modern-Optimizers-Muon-P-for-GNN-Training-on-Zachary-s-Karate-Club",
            "content_xml": "<document version=\"2.0\"><paragraph>In this write-up, I systematically benchmarked several modern optimization approaches for training a Graph Convolutional Network (GCN) on the Zachary\u2019s Karate Club graph dataset, including SGD, \u00b5P, Muon, a Muonvariant, SOAP, and Lion. I evaluated them using training/validation loss, test accuracy, convergence speed, and computational efficiency, and I also implemented an early-stopping setup and described key optimizer mechanics (e.g., Muon\u2019s Newton\u2013Schulz orthogonalization; \u00b5P-style parameter-group learning-rate scaling).<break/><break/>My main findings are that <bold>Muon can reach the best final accuracy (up to 100%)</bold>, while <bold>\u00b5P offers the best speed\u2013accuracy trade-off</bold> (fast convergence with strong accuracy), and SOAP/Lion tend to perform poorly in this small full-graph training regime.<break/><break/>The Github repository: <break/><break/><link href=\"https://github.com/hysteri1a/EECS182-Comparative-Study-of-Modern-Optimizers-Muon-P-for-GNN-Training-on-Zachary-s-Karate-Club\">hysteri1a/EECS182-Comparative-Study-of-Modern-Optimizers-Muon-P-for-GNN-Training-on-Zachary-s-Karate-Club</link></paragraph><file url=\"https://static.us.edusercontent.com/files/k8tEqNVKDfguFvOPhyKDZEGx\" filename=\"special_participation_D_HW6.pdf\"/></document>",
            "links": [
                "https://github.com/hysteri1a/EECS182-Comparative-Study-of-Modern-Optimizers-Muon-P-for-GNN-Training-on-Zachary-s-Karate-Club"
            ],
            "attachments": [],
            "created_at": "2025-12-02T11:57:02.93077+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7386904,
            "author": "Minjune Kim",
            "project_title": "Special Participation A: Mistral on HW 1",
            "post_body": "I have used Mistral to test on Hw 1. \n\nLink: https://chat.mistral.ai/chat/6ff004cd-66c9-49ef-92fb-19476f51402b\n\nSummary:\n\nIn general, it was able to get most of the answers without any mistakes. A lot of the work shown by the LLM followed the solutions of what the course has provided. Looking at the solution that Mistral provided, it seems like a lot of the computational mistakes are coming from matrix calculations. For example, it was able to correctly reason 3a however it failed to get 3b even though, from 3a to 3b, it is just simple matrix calculations. Since question 3 is built upon previous questions, since it messed up on 3b, it messes up on the following subpart questions for 3. \n\nIt seems like the mathematical reasoning is good since the non-matrix computations are all working very well without any errors. I think it also got better when I pointed out that there are some computational errors because after that there has not been any mistakes. \n\nI think the one-shot for Mistral has about 80% accuracy on the problems. I tried to ask Mistral to fix some of the mistakes  that it has made on the previous answer, but it seems to misunderstand my request and always go with the same incorrect question. It seems to be that MIstral is \"self-centered\" or cannot identify the questions that it has been asked. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I have used Mistral to test on Hw 1. <break/><break/>Link: <link href=\"https://chat.mistral.ai/chat/6ff004cd-66c9-49ef-92fb-19476f51402b\">https://chat.mistral.ai/chat/6ff004cd-66c9-49ef-92fb-19476f51402b</link></paragraph><paragraph>Summary:</paragraph><paragraph>In general, it was able to get most of the answers without any mistakes. A lot of the work shown by the LLM followed the solutions of what the course has provided. Looking at the solution that Mistral provided, it seems like a lot of the computational mistakes are coming from matrix calculations. For example, it was able to correctly reason 3a however it failed to get 3b even though, from 3a to 3b, it is just simple matrix calculations. Since question 3 is built upon previous questions, since it messed up on 3b, it messes up on the following subpart questions for 3. <break/><break/>It seems like the mathematical reasoning is good since the non-matrix computations are all working very well without any errors. I think it also got better when I pointed out that there are some computational errors because after that there has not been any mistakes. <break/><break/>I think the one-shot for Mistral has about 80% accuracy on the problems. I tried to ask Mistral to fix some of the mistakes  that it has made on the previous answer, but it seems to misunderstand my request and always go with the same incorrect question. It seems to be that MIstral is \"self-centered\" or cannot identify the questions that it has been asked. </paragraph></document>",
            "links": [
                "https://chat.mistral.ai/chat/6ff004cd-66c9-49ef-92fb-19476f51402b"
            ],
            "attachments": [],
            "created_at": "2025-12-02T11:24:16.403925+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7386885,
            "author": "Divya Ramesh",
            "project_title": "Special Participation E: Gemini as an Interactive study tool!",
            "post_body": "\n\nSpecial Participation E:\n\nNow that finals are creeping up, I thought I\u2019d try to create a resource to make a study guide for lectures. After a bit of research online I discovered that Gemini 3 Pro had one of the better OCR handwriting detections (https://research.aimultiple.com/handwriting-recognition/ was one of the sources confirming this), so I decided to upload the lecture notes for lecture 6 into Gemini 3 Pro and let it analyze, and create a study guide. The prompts I used can be found in my chat log! Gemini has canvas mode, which allows for a very organized output, making the study guide color coded and clean. I also had it summarize as well as come up with practice problems. I made it analyze what was directly in the notes only, to try to minimize hallucinations. I instructed it to summarize key concepts, rewrite equations clearly, convert diagrams into textual descriptions, and provide intuition in bullet points. For each concept, it generated a short comprehension question, a tiny derivation for me to work through, and an example scenario showing how the concept applies in practice.\n\nAdditionally, I set it up to simulate optimizer dynamics, shape transformations, scaling factor effects, Newton-Schulz iterations, and orthogonalization steps using small toy matrices so I could verify everything myself. Whenever the notes were incomplete or ambiguous, the model flagged them and asked for clarification rather than inventing facts. From here, a user can ask the LLM to fill in the gaps or ignore them. I mostly chose to ignore, because staying as close as possible to the notes would minimize hallucinations. \n\nThe result was a structured, section-by-section study guide that covers MuP, Muon, scaling laws, parameterization, and theoretical analysis topics from the lecture. It also included clear alerts for potential inconsistencies or OCR errors, so I can focus on the parts that need human verification. This approach let me interactively test my understanding and run simulations in a controlled way, essentially turning the lecture notes into a hands-on learning tool.\n\nOverall, using Gemini 3 Pro in this targeted, verification-focused way allowed me to generate a high-quality study resource while minimizing hallucinations, making it an effective tool for preparing for finals. Also, it would let me know when there were sections unclear in the lecture notes so I could further prompt the LLM on this. \n\nI also turned on learning mode and asked Gemini to walk me through the worksheet, where it gave me hints when I needed them on worksheet problems, and if I was right/wrong it gave me feedback and a bit of background information to ensure I understood. Also, I asked it to walk me through simulations at the end and it actually did walk me through step by step of a problem, and I find this tool incredibly helpful!! The simulations/toy problems especially helped my lock down important lecture concepts.\n\nI\u2019ve tested on a few lectures and it has worked amazingly, feel free to check it out! I\u2019m attaching both the worksheet and the chat log below, the chat log is annotated, the worksheet is just for reference!\n\nLecture 6:\n\nChat log:\n\nhttps://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharing\n\nWorksheet:\n\nhttps://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph>Special Participation E:</paragraph><paragraph>Now that finals are creeping up, I thought I\u2019d try to create a resource to make a study guide for lectures. After a bit of research online I discovered that Gemini 3 Pro had one of the better OCR handwriting detections (<link href=\"https://research.aimultiple.com/handwriting-recognition/\"><underline>https://research.aimultiple.com/handwriting-recognition/</underline></link> was one of the sources confirming this), so I decided to upload the lecture notes for lecture 6 into Gemini 3 Pro and let it analyze, and create a study guide. The prompts I used can be found in my chat log! Gemini has canvas mode, which allows for a very organized output, making the study guide color coded and clean. I also had it summarize as well as come up with practice problems. I made it analyze what was directly in the notes only, to try to minimize hallucinations. I instructed it to summarize key concepts, rewrite equations clearly, convert diagrams into textual descriptions, and provide intuition in bullet points. For each concept, it generated a short comprehension question, a tiny derivation for me to work through, and an example scenario showing how the concept applies in practice.</paragraph><paragraph>Additionally, I set it up to simulate optimizer dynamics, shape transformations, scaling factor effects, Newton-Schulz iterations, and orthogonalization steps using small toy matrices so I could verify everything myself. Whenever the notes were incomplete or ambiguous, the model flagged them and asked for clarification rather than inventing facts. From here, a user can ask the LLM to fill in the gaps or ignore them. I mostly chose to ignore, because staying as close as possible to the notes would minimize hallucinations. </paragraph><paragraph>The result was a structured, section-by-section study guide that covers MuP, Muon, scaling laws, parameterization, and theoretical analysis topics from the lecture. It also included clear alerts for potential inconsistencies or OCR errors, so I can focus on the parts that need human verification. This approach let me interactively test my understanding and run simulations in a controlled way, essentially turning the lecture notes into a hands-on learning tool.</paragraph><paragraph>Overall, using Gemini 3 Pro in this targeted, verification-focused way allowed me to generate a high-quality study resource while minimizing hallucinations, making it an effective tool for preparing for finals. Also, it would let me know when there were sections unclear in the lecture notes so I could further prompt the LLM on this. </paragraph><paragraph>I also turned on learning mode and asked Gemini to walk me through the worksheet, where it gave me hints when I needed them on worksheet problems, and if I was right/wrong it gave me feedback and a bit of background information to ensure I understood. Also, I asked it to walk me through simulations at the end and it actually did walk me through step by step of a problem, and I find this tool incredibly helpful!! The simulations/toy problems especially helped my lock down important lecture concepts.</paragraph><paragraph>I\u2019ve tested on a few lectures and it has worked amazingly, feel free to check it out! I\u2019m attaching both the worksheet and the chat log below, the chat log is annotated, the worksheet is just for reference!</paragraph><paragraph>Lecture 6:</paragraph><list style=\"unordered\"><list-item><paragraph>Chat log:</paragraph></list-item></list><paragraph><link href=\"https://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharing\"><underline>https://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharing</underline></link></paragraph><list style=\"unordered\"><list-item><paragraph>Worksheet:</paragraph></list-item></list><paragraph><link href=\"https://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing\"><underline>https://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing</underline></link></paragraph></document>",
            "links": [
                "https://research.aimultiple.com/handwriting-recognition/",
                "https://drive.google.com/file/d/1egKs92MvXNTsvbv6E6RqEZwsXCIDM6cK/view?usp=sharing",
                "https://drive.google.com/file/d/1sl9c8k6Ghc4mZHDwVVriRR5bmkqH8p3p/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-02T11:22:03.796165+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7386518,
            "author": "Ruihan Xia",
            "project_title": "Special Participation B: Grok on HW1",
            "post_body": "I worked with Grok on the HW1 coding parts. I noticed three main patterns / caveats in its responses.\n\n1. Whenever I asked Grok to fill in a missing section, it tended to go beyond the homework requirements and rewrite lines before and after TODO section. For example, in implementing GDM function it introduced a new velocity variable unnecessarily. It took a couple rounds of correction before it stuck to the original template. \n\n2. In the same section, I noticed Grok needs clear guidance when the notation in hw differs from convention. HW1 uses formula (1\u2212\u03b2)zt\u200b+\u03b2gt\u200b for momentum. But Grok defaulted to the PyTorch-style formula until I showed it the screenshot of the written math. \n\n3. Grok liked to \u201ctake charge\u201d of the hyperparameters. The notebook uses \u03b2 = 0.6, but Grok repeatedly swapped it for 0.9 (and later stuck to 0.9 consistently) simply because it believed that value converged faster. As a result in later code generation it changes beta without explicitedly informing the user. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I worked with Grok on the HW1 coding parts. I noticed three main patterns / caveats in its responses.</paragraph><paragraph>1. Whenever I asked Grok to fill in a missing section, it tended to go beyond the homework requirements and rewrite lines before and after TODO section. For example, in implementing GDM function it introduced a new velocity variable unnecessarily. It took a couple rounds of correction before it stuck to the original template. </paragraph><paragraph>2. In the same section, I noticed Grok needs clear guidance when the notation in hw differs from convention. HW1 uses formula (1\u2212\u03b2)zt\u200b+\u03b2gt\u200b for momentum. But Grok defaulted to the PyTorch-style formula until I showed it the screenshot of the written math. </paragraph><paragraph>3. Grok liked to \u201ctake charge\u201d of the hyperparameters. The notebook uses \u03b2 = 0.6, but Grok repeatedly swapped it for 0.9 (and later stuck to 0.9 consistently) simply because it believed that value converged faster. As a result in later code generation it changes beta without explicitedly informing the user. </paragraph><file url=\"https://static.us.edusercontent.com/files/3QsI8zPy63E7fmXhmnfCSayo\" filename=\"Grok Chat.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T10:29:28.620706+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7386458,
            "author": "Manan Roongta",
            "project_title": "Special Participation E: Gemini Guided Learning as a Personal Tutor",
            "post_body": "Posting this so other people can reuse the same approach/prompting style when they\u2019re stuck on a concept.\n\nGemini Guided Learning Chat (Transformers + Attention)\n\nPDF (with annotations)\n\nI have been using Gemini Guided Learning as a \u201cpersonal tutor\u201d to strengthen my understanding of complex topics, and it's been really helpful. Lectures are great, but I often walk out with feeling \"I kinda get it but not really\u201d. It\u2019s an amazing supplement when you need someone to patiently answer \u201cwait but why\u201d 15 times in a row.\n\nThe PDF is my real interaction trace (with annotations), including my typos, missing punctuation, misspellings, half finished thoughts, because that\u2019s actually how a student uses these tools in real life.\n\nHow I used Gemini Guided Learning/what worked\n\n1) My initial prompt mattered a lot\n In the very first message, I clearly set expectations:\n\nwhat I already understood\n\nwhat I was confused about\n\nwhat I wanted/roadmap\n\nThat made the whole chat way more productive than \u201cexplain transformers.\u201d\n\n2) I had to slow Gemini down at first\nEarly in the chat, Gemini kept trying to rush to the next topic. I had to explicitly prompt \u201cslow down\u201d, \u201cone step at a time\u201d, \u201cdon't rush me\u201d. After a few times, the session became way more tutor like and less of just answering.\n\n3) The built in check ins/questions are great way to test\nI liked when Gemini asked me questions and made me answer. It forced me to notice where my understanding was hand wavy.\n\n4) Write your own Summaries \n After finishing a topic, I would:\n\nwrite a summary in my own words, and/or\n\nask Gemini for a \u201csummary + roadmap\u201d of what we finished and what\u2019s next.\n\nIt helped recalibrate my understanding, the bigger picture and track progress.\n\nGemini 3 vs Gemini 3 Guided Learning are very different\n\nGemini 3 Guided Learning felt like it was trying to teach\n\nGemini 3 (normal) felt more like it was trying to answer quickly (even when I explicitly prompted for slow + structured learning)\n\nNote: I used AI to help with wording/formatting",
            "content_xml": "<document version=\"2.0\"><paragraph>Posting this so other people can reuse the same approach/prompting style when they\u2019re stuck on a concept.</paragraph><paragraph><link href=\"https://gemini.google.com/share/bc199205426f\">Gemini Guided Learning Chat (Transformers + Attention</link>)</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1EAE9hd98DESFMTvXKjlW9WG6B6VZxutj/view?usp=sharing\">PDF (with annotations)</link></paragraph><paragraph>I have been using <bold>Gemini Guided Learning</bold> as a \u201cpersonal tutor\u201d to strengthen my understanding of complex topics, and it's been really helpful. Lectures are great, but I often walk out with feeling \"I kinda get it but not really\u201d. It\u2019s an amazing supplement when you need someone to patiently answer \u201cwait but why\u201d 15 times in a row.</paragraph><paragraph>The PDF is my real interaction trace (with annotations), including my typos, missing punctuation, misspellings, half finished thoughts, because that\u2019s actually how a student uses these tools in real life.</paragraph><heading level=\"3\"><underline>How I used Gemini Guided Learning/what worked</underline></heading><paragraph><underline>1) My initial prompt mattered a lot<break/></underline> In the very first message, I clearly set expectations:</paragraph><list style=\"unordered\"><list-item><paragraph>what I already understood</paragraph></list-item><list-item><paragraph>what I was confused about</paragraph></list-item><list-item><paragraph>what I wanted/roadmap</paragraph></list-item></list><paragraph>That made the whole chat way more productive than \u201cexplain transformers.\u201d</paragraph><paragraph><underline>2) I had to slow Gemini down at first<break/></underline>Early in the chat, Gemini kept trying to rush to the next topic. I had to explicitly prompt \u201cslow down\u201d, \u201cone step at a time\u201d, \u201cdon't rush me\u201d. After a few times, the session became way more tutor like and less of just answering.</paragraph><paragraph><underline>3) The built in check ins/questions are great way to test<break/></underline>I liked when Gemini asked me questions and made me answer. It forced me to notice where my understanding was hand wavy.</paragraph><paragraph><underline>4) Write your own Summaries <break/></underline> After finishing a topic, I would:</paragraph><list style=\"unordered\"><list-item><paragraph>write a summary in my own words, and/or</paragraph></list-item><list-item><paragraph>ask Gemini for a \u201csummary + roadmap\u201d of what we finished and what\u2019s next.</paragraph></list-item></list><paragraph>It helped recalibrate my understanding, the bigger picture and track progress.</paragraph><heading level=\"3\">Gemini 3 vs Gemini 3 Guided Learning are very different</heading><list style=\"unordered\"><list-item><paragraph><bold>Gemini 3 Guided Learning</bold> felt like it was trying to <italic>teach</italic></paragraph></list-item><list-item><paragraph><bold>Gemini 3 (normal)</bold> felt more like it was trying to <italic>answer</italic> quickly (even when I explicitly prompted for slow + structured learning)</paragraph></list-item></list><paragraph><italic>Note</italic>: I used AI to help with wording/formatting</paragraph></document>",
            "links": [
                "https://gemini.google.com/share/bc199205426f",
                "https://drive.google.com/file/d/1EAE9hd98DESFMTvXKjlW9WG6B6VZxutj/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-02T10:21:51.42187+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7386095,
            "author": "Shervin Goudarzi",
            "project_title": "Special Participation B: Gemini-Pro 3 on HW10 Coding",
            "post_body": "I tried the Gemini Pro-3 Thinking on the Coding questions of HW10, and it performed very well. However, the solutions tended to be less concise and more intuitive compared to the staff solutions. More importantly, Gemini refrained from using the einsum functions and used normal vector multiplication, possibly to aid me, an undergraduate who is learning without confusing with too much jargon. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I tried the Gemini Pro-3 Thinking on the Coding questions of HW10, and it performed very well. However, the solutions tended to be less concise and more intuitive compared to the staff solutions. More importantly, Gemini refrained from using the einsum functions and used normal vector multiplication, possibly to aid me, an undergraduate who is learning without confusing with too much jargon. </paragraph><file url=\"https://static.us.edusercontent.com/files/XCpBRahcb5ysDOFBUQXnAXWG\" filename=\"Special_Participation_B.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T09:37:11.472719+11:00",
            "category": "Admin"
        },
        {
            "guid": 7384241,
            "author": "Jeffrey Cheng",
            "project_title": "Special Participation E: Use ChatGPT's study guide to compare transformer-based LLMs",
            "post_body": "I used ChatGPT's study mode to compare different transformer-based LLMs based on their architectural choices and the tasks for which they are best suited. Engaging in a Socratic conversation with ChatGPT helped me understand the architectural decisions of various transformer-based LLMs and the specific functions for which they are best suited. It classifies the model architecture into two categories: Encoder/Decoder, Dense/MoE, and explains the strengths of each category in terms of the tasks they are most suited for. One behavior of this study mode that I found very interesting is that, at the end of each ChatGPT response, it always asks me a question that refines my understanding of the current topic. In addition, it helps introduce the next topic for the next prompt. In the end, it generates a cheat sheet that classifies every transformer-based model. \n\nThe conversation log is: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT's study mode to compare different transformer-based LLMs based on their architectural choices and the tasks for which they are best suited. Engaging in a Socratic conversation with ChatGPT helped me understand the architectural decisions of various transformer-based LLMs and the specific functions for which they are best suited. It classifies the model architecture into two categories: Encoder/Decoder, Dense/MoE, and explains the strengths of each category in terms of the tasks they are most suited for. One behavior of this study mode that I found very interesting is that, at the end of each ChatGPT response, it always asks me a question that refines my understanding of the current topic. In addition, it helps introduce the next topic for the next prompt. In the end, it generates a cheat sheet that classifies every transformer-based model. </paragraph><paragraph>The conversation log is: </paragraph><file url=\"https://static.us.edusercontent.com/files/Ggb85TwYCdj1XAJ7rFwAKQIg\" filename=\"Annotated log of transformer-based models.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-02T06:07:21.800584+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7382863,
            "author": "Kian Hekmatnejad",
            "project_title": "Special Participation A: Mistral AI's Le Chat on HW5 Written Portion",
            "post_body": "For Special Participation A, I used Mistral AI's Le Chat on the written portion of HW5. Overall, it performed averagely - mostly arriving at correct answers in one shot, but in a couple of cases requiring further prompting to correct mistakes. I found some indication of a lack of ability to refer to chat history in it's responses.\n\nHere is the link to my chat: https://chat.mistral.ai/chat/9c9c7fc7-7985-45a9-b7cd-df337fec5d26 ",
            "content_xml": "<document version=\"2.0\"><paragraph>For Special Participation A, I used Mistral AI's Le Chat on the written portion of HW5. Overall, it performed averagely - mostly arriving at correct answers in one shot, but in a couple of cases requiring further prompting to correct mistakes. I found some indication of a lack of ability to refer to chat history in it's responses.<break/><break/>Here is the link to my chat: <link href=\"https://chat.mistral.ai/chat/9c9c7fc7-7985-45a9-b7cd-df337fec5d26\">https://chat.mistral.ai/chat/9c9c7fc7-7985-45a9-b7cd-df337fec5d26</link> </paragraph><file url=\"https://static.us.edusercontent.com/files/RMtVzYbcYGOvDh6qzjoq3xWo\" filename=\"special_participation.pdf\"/></document>",
            "links": [
                "https://chat.mistral.ai/chat/9c9c7fc7-7985-45a9-b7cd-df337fec5d26"
            ],
            "attachments": [],
            "created_at": "2025-12-02T02:48:01.810497+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7382039,
            "author": "Ishir Garg",
            "project_title": "Special Participation E: Using Perplexity to gain Historical Motivations",
            "post_body": "One thing that I've noticed in this class, is that there seems to be an emphasis on motivating ideas through a historical lens and understanding how they naturally evolved in research over time. However, sometimes I find its hard to connect all the different puzzle pieces and understand where exactly different algorithms or discoveries exist in the timeline. \n\n Hence, I tried to engage an LLM (Perplexity, due to its enhanced search abilities) to try and gain some historical perspective on how ideas came to fruition in deep learning. I uploaded Lecture Note 5 along with an initial prompt, and had Perplexity walk me through a variety of different concepts from a historical perspective. The annotated chat history is below:\n\nTo summarize, I was pleasantly surprised by the outcome. I'm also surprised that it was able to do this with just the lecture notes and a very minimal initial prompt.\n\nStrengths:\n\nPerplexity does a good job of explaining the intuitive motivations behind ideas and how certain ideas lead to others\n\nOne really surprising result was that Perplexity began asking me questions to check my understanding, even though I never asked it to do this\n\nIt also introduced some ideas outside of the lecture notes at a high-level, that provided some really unique insight into the ideas in this class.\n\nWeaknesses:\n\nSome parts could use more explanation or go more in-depth, although it could be argued that these could just be left to the student to ask questions about if they desire.",
            "content_xml": "<document version=\"2.0\"><paragraph>One thing that I've noticed in this class, is that there seems to be an emphasis on motivating ideas through a historical lens and understanding how they naturally evolved in research over time. However, sometimes I find its hard to connect all the different puzzle pieces and understand where exactly different algorithms or discoveries exist in the timeline. </paragraph><paragraph> Hence, I tried to engage an LLM (Perplexity, due to its enhanced search abilities) to try and gain some historical perspective on how ideas came to fruition in deep learning. I uploaded Lecture Note 5 along with an initial prompt, and had Perplexity walk me through a variety of different concepts from a historical perspective. The annotated chat history is below:</paragraph><file url=\"https://static.us.edusercontent.com/files/VaBmvFfCKL6FlhgZmgWBerz9\" filename=\"participationE.pdf\"/><paragraph>To summarize, I was pleasantly surprised by the outcome. I'm also surprised that it was able to do this with just the lecture notes and a very minimal initial prompt.</paragraph><paragraph>Strengths:</paragraph><list style=\"bullet\"><list-item><paragraph>Perplexity does a good job of explaining the intuitive motivations behind ideas and how certain ideas lead to others</paragraph></list-item><list-item><paragraph>One really surprising result was that Perplexity began asking me questions to check my understanding, even though I never asked it to do this</paragraph></list-item><list-item><paragraph>It also introduced some ideas outside of the lecture notes at a high-level, that provided some really unique insight into the ideas in this class.</paragraph></list-item></list><paragraph>Weaknesses:</paragraph><list style=\"bullet\"><list-item><paragraph>Some parts could use more explanation or go more in-depth, although it could be argued that these could just be left to the student to ask questions about if they desire.</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-01T21:28:27.236519+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7381997,
            "author": "Ishir Garg",
            "project_title": "Special Participation B: Gemini (Thinking With Pro 3) on HW 3 Coding",
            "post_body": "I used Gemini (Thinking with Pro 3) to solve the MuP coding question of homework 3. I have attached an annotated PDF of my chat history below.\n\nTo summarize the main points:\n\nOverall, Gemini is able to one-shot 4/5 parts. It fails to one-shot part (d) on which it struggled significantly, and required some hints to get to the right answer.\n\nStrengths:\n\nGemini is able to easily get questions that follow directly from the typical MuP formulation; it generally does a great job of writing clean and concise solutions\n\nGemini tends to provide good mathematical intuition for its explanations, even though it is never prompted to provide such justifications\n\nCode is generally well-written and has informative comments that could be helpful for a student trying to learn the content\n\nWeaknesses:\n\nWhen trying to apply the same concepts \"outside the box\" (such as modifying the computation graph in part (d)), it struggles.\n\nWhen given feedback on its incorrect solution, Gemini tries to directly address the issue by creating a \"hacky\" solution, rather than trying to reason about a logically correct answer.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini (Thinking with Pro 3) to solve the MuP coding question of homework 3. I have attached an annotated PDF of my chat history below.</paragraph><file url=\"https://static.us.edusercontent.com/files/dOeN4GFgmXf3LSsIUU4mY5Wn\" filename=\"participationB.pdf\"/><paragraph>To summarize the main points:</paragraph><paragraph>Overall, Gemini is able to one-shot 4/5 parts. It fails to one-shot part (d) on which it struggled significantly, and required some hints to get to the right answer.</paragraph><paragraph>Strengths:</paragraph><list style=\"bullet\"><list-item><paragraph>Gemini is able to easily get questions that follow directly from the typical MuP formulation; it generally does a great job of writing clean and concise solutions</paragraph></list-item><list-item><paragraph>Gemini tends to provide good mathematical intuition for its explanations, even though it is never prompted to provide such justifications</paragraph></list-item><list-item><paragraph>Code is generally well-written and has informative comments that could be helpful for a student trying to learn the content</paragraph></list-item></list><paragraph>Weaknesses:</paragraph><list style=\"bullet\"><list-item><paragraph>When trying to apply the same concepts \"outside the box\" (such as modifying the computation graph in part (d)), it struggles.</paragraph></list-item><list-item><paragraph>When given feedback on its incorrect solution, Gemini tries to directly address the issue by creating a \"hacky\" solution, rather than trying to reason about a logically correct answer.</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-01T20:36:46.080801+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7381645,
            "author": "Andrew Choy",
            "project_title": "Special Participation E: 182 Exam Prep Tool",
            "post_body": "Since I couldn't find any practice tests available online, I decided to build a Practice Question Generator. It utilizes homework assignments, lecture notes, and/or lecture audio to generate relevant study problems.\n\nI found that pairing specific homework assignments with their corresponding lectures yields the most grounded results, even when using free-tier API models. To make the tool more convenient, I added an input field for your API key; this allows you to run the tool without editing the code directly (unless you want to tweak the prompt for other classes).\n\nThe screen recording below demonstrates the tool using only lecture notes and homework. While the system does support lecture audio, which is great for capturing details professors say but don't write down, I stuck to processing PDFs for this demo to minimize inference latency and I used gemini-2.0-flash API Version. \n\nOne of the biggest challenges was formatting the model's output. I attempted to wrap the responses in Markdown to ensure the display math rendered correctly, but this approach introduced several bugs and made the code difficult to maintain. So if anyone wants to push this further, feel free to fork or make a PR request. \n\nGithub: https://github.com/AndrewChoyCS/CS182-artifact\n\nDemo: https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>Since I couldn't find any practice tests available online, I decided to build a <bold>Practice Question Generator</bold>. It utilizes homework assignments, lecture notes, and/or lecture audio to generate relevant study problems.</paragraph><paragraph>I found that pairing specific homework assignments with their corresponding lectures yields the most grounded results, even when using free-tier API models. To make the tool more convenient, I added an input field for your API key; this allows you to run the tool without editing the code directly (unless you want to tweak the prompt for other classes).</paragraph><paragraph>The screen recording below demonstrates the tool using only lecture notes and homework. While the system does support lecture audio, which is great for capturing details professors say but don't write down, I stuck to processing PDFs for this demo to minimize inference latency and I used gemini-2.0-flash API Version. </paragraph><paragraph>One of the biggest challenges was formatting the model's output. I attempted to wrap the responses in Markdown to ensure the display math rendered correctly, but this approach introduced several bugs and made the code difficult to maintain. So if anyone wants to push this further, feel free to fork or make a PR request. </paragraph><paragraph>Github: <link href=\"https://github.com/AndrewChoyCS/CS182-artifact\">https://github.com/AndrewChoyCS/CS182-artifact</link></paragraph><paragraph>Demo: <link href=\"https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing\">https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing</link></paragraph></document>",
            "links": [
                "https://github.com/AndrewChoyCS/CS182-artifact",
                "https://drive.google.com/file/d/1DkO63NA44jGrEhoFPZGidESEYAcKIe94/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-12-01T17:21:56.578199+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7381537,
            "author": "Divya Ramesh",
            "project_title": "Special Participation B: Gemini in Collab on HW10",
            "post_body": "\n\nExecutive Summary:\n\nI tested Gemini (Collab Code Assist) on homework 10\u2019s coding portions and quickly learned it struggles substantially more with code synthesis than with conceptual reasoning. It almost never one-shot the required code. Most blocks required highly specific context, restating variables, or manually \u201cnudging\u201d the model by typing partial lines (like Km =, q =, d_k =) before autofill kicked in.Major patterns. I also tested how the model worked with non-specific variable names like \u201ctemp = \u201c and this was good as well, but the issue is sometimes you need the specific names to autocomplete entire sections. Like there was one question with k=..., q=..., and v=... and by going k=, all of the sections autocompleted, while saying temp = only filled for one sometimes. One thing I noticed was the one-shot rate was very low, almost 0 for complex, more than one line sections of code. Also, sometimes, Gemini created a solution that invented wrong shapes, incomplete lines, or inconsistent variable names. This was frustrating sometimes, because it was very hard to prompt Gemini when it started hallucinating, taking a long time trying to force it to correct its logic. Overall, getting correct functional code was basically impossible without dragging the model step-by-step. Even then, it required substantial human debugging and reasoning, and was not a very easy to use or accurate model. I tested inputting chunks of todo code directly into Gemini\u2019s thinking with 3 Pro model and it worked a lot better, completely filling in the code with much more accurate code. This contrast made it clear that Gemini Collab just isn\u2019t reliable for multi-step or shape-sensitive coding tasks, and requires substantial human scaffolding to make it usable at all.\n\nLinked below is a log of my interactions. I kept adding context in the TODO sections line by line until the code was giving better solutions. I also prompted with the variable names, line by line (sometimes it would fill in 3 lines so maybe every 3 lines I would do this) waiting for Gemini to autocomplete. That is the strategy I used. My annotations are also written in the text, and the entire ipynb pdfs are attached at the ends. Q2 and Q3 are labelled, they were the coding sections for this homework:\n\nhttps://drive.google.com/file/d/1IBckfJo7Dq_J1ydQ8p73dkxCbkBR2cCY/view?usp=share_link",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>I tested Gemini (Collab Code Assist) on homework 10\u2019s coding portions and quickly learned it struggles substantially more with code synthesis than with conceptual reasoning. It almost never one-shot the required code. Most blocks required highly specific context, restating variables, or manually \u201cnudging\u201d the model by typing partial lines (like Km =, q =, d_k =) before autofill kicked in.Major patterns. I also tested how the model worked with non-specific variable names like \u201ctemp = \u201c and this was good as well, but the issue is sometimes you need the specific names to autocomplete entire sections. Like there was one question with k=..., q=..., and v=... and by going k=, all of the sections autocompleted, while saying temp = only filled for one sometimes. One thing I noticed was the one-shot rate was very low, almost 0 for complex, more than one line sections of code. Also, sometimes, Gemini created a solution that invented wrong shapes, incomplete lines, or inconsistent variable names. This was frustrating sometimes, because it was very hard to prompt Gemini when it started hallucinating, taking a long time trying to force it to correct its logic. Overall, getting correct functional code was basically impossible without dragging the model step-by-step. Even then, it required substantial human debugging and reasoning, and was not a very easy to use or accurate model. I tested inputting chunks of todo code directly into Gemini\u2019s thinking with 3 Pro model and it worked a lot better, completely filling in the code with much more accurate code. This contrast made it clear that Gemini Collab just isn\u2019t reliable for multi-step or shape-sensitive coding tasks, and requires substantial human scaffolding to make it usable at all.</paragraph><paragraph>Linked below is a log of my interactions. I kept adding context in the TODO sections line by line until the code was giving better solutions. I also prompted with the variable names, line by line (sometimes it would fill in 3 lines so maybe every 3 lines I would do this) waiting for Gemini to autocomplete. That is the strategy I used. My annotations are also written in the text, and the entire ipynb pdfs are attached at the ends. Q2 and Q3 are labelled, they were the coding sections for this homework:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1IBckfJo7Dq_J1ydQ8p73dkxCbkBR2cCY/view?usp=share_link\"><underline>https://drive.google.com/file/d/1IBckfJo7Dq_J1ydQ8p73dkxCbkBR2cCY/view?usp=share_link</underline></link></paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1IBckfJo7Dq_J1ydQ8p73dkxCbkBR2cCY/view?usp=share_link"
            ],
            "attachments": [],
            "created_at": "2025-12-01T16:49:24.640386+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7381449,
            "author": "Alex Cao",
            "project_title": "Special Participation B: Deepseek on HW10",
            "post_body": "\n\nIntro:\n\nThis is an attempt to interact with deepseek on coding parts of homework 10. The purpose of this study is to better understand how to prompt/interact with LLMs more effectively and LLM\u2019s capability of solving real life coding problems with few-shot prompting. The specific model I interacted with was DeepSeek-V3.2. I used Deepseek\u2019s web ui to interact with the model. I will focus on how different prompting methods (or modes of reasoning) affect a model's one-shot correctness of the problems, and how to improve its accuracy without providing more in context examples. Note that in this report I will only include screenshots of important parts of the conversation. For full conversation traces, please refer to the conversation links.\n\n\n\nConversation Links:\n\nhttps://chat.deepseek.com/share/8vswr9xhltacersq2x\nhttps://chat.deepseek.com/share/z3d2wlzyriby9tat3v\nhttps://chat.deepseek.com/share/b9ei80b7h70hg32ego\nhttps://chat.deepseek.com/share/svy7a295g0hypncpej\n\n\n\nAnnotated Traces:\n\n\n\nSummary:\n\n\nOverall, the model (DeepSeek-V3.2) showcases quite strong coding abilities and was able to complete almost all coding questions with at most one round of iterative debugging. One round of iterative debugging refers to giving feedback of the executed test result back to the model only once and asking it to refine its own code. For this specific problem set, the most common reason for a model needing iterative debugging was that the model lacked the reasoning ability to predict what exactly would happen when the code it wrote is actually executed. For example, in one of the questions, even though the prompt explicitly says mask is a byte array, and the model is well aware of this, it still failed to predict that this will be an incompatible format for a given torch method mask_fill, which accepts boolean arrays. These can be potentially solved by enabling better reasoning abilities, while I argue that in this case, a more efficient solution would be \u201ctest-time scaling\u201d. Instead of spending numerous computations in improving the model's reasoning ability, one thing we can do to tackle this problem is to simply use another model call with the test feedback. In this specific problem set, this approach has been proven working every time, and simply calling the model one more time uses way less computation than trying to improve the model\u2019s native reasoning ability. Taken together, these observations suggest that, at least for this kind of coding workload, investing in smarter test-time strategies like iterative debugging and feedback-driven refinement may be a more practical and cost-effective way to boost reliability than solely focusing on training ever-stronger base models.\n",
            "content_xml": "<document version=\"2.0\"><paragraph/><heading level=\"3\"><bold>Intro:</bold></heading><paragraph>This is an attempt to interact with deepseek on coding parts of homework 10. The purpose of this study is to better understand how to prompt/interact with LLMs more effectively and LLM\u2019s capability of solving real life coding problems with few-shot prompting. The specific model I interacted with was DeepSeek-V3.2. I used Deepseek\u2019s web ui to interact with the model. I will focus on how different prompting methods (or modes of reasoning) affect a model's one-shot correctness of the problems, and how to improve its accuracy without providing more in context examples. Note that in this report I will only include screenshots of important parts of the conversation. For full conversation traces, please refer to the conversation links.<break/><break/></paragraph><paragraph><bold>Conversation Links:</bold></paragraph><paragraph><link href=\"https://chat.deepseek.com/share/8vswr9xhltacersq2x\"><underline>https://chat.deepseek.com/share/8vswr9xhltacersq2x</underline><break/></link><link href=\"https://chat.deepseek.com/share/z3d2wlzyriby9tat3v\"><underline>https://chat.deepseek.com/share/z3d2wlzyriby9tat3v</underline><break/></link><link href=\"https://chat.deepseek.com/share/b9ei80b7h70hg32ego\"><underline>https://chat.deepseek.com/share/b9ei80b7h70hg32ego</underline><break/></link><link href=\"https://chat.deepseek.com/share/svy7a295g0hypncpej\"><underline>https://chat.deepseek.com/share/svy7a295g0hypncpej</underline></link><break/><break/></paragraph><paragraph><bold>Annotated Traces:</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/q5ljMKo93lSyS3Ryn12eFR5M\" filename=\"Special Participation B -- Deepseek on HW10.pdf\"/><paragraph/><paragraph><bold>Summary:</bold><break/></paragraph><paragraph>Overall, the model (DeepSeek-V3.2) showcases quite strong coding abilities and was able to complete almost all coding questions with at most one round of iterative debugging. One round of iterative debugging refers to giving feedback of the executed test result back to the model only once and asking it to refine its own code. For this specific problem set, the most common reason for a model needing iterative debugging was that the model lacked the reasoning ability to predict what exactly would happen when the code it wrote is actually executed. For example, in one of the questions, even though the prompt explicitly says mask is a byte array, and the model is well aware of this, it still failed to predict that this will be an incompatible format for a given torch method mask_fill, which accepts boolean arrays. These can be potentially solved by enabling better reasoning abilities, while I argue that in this case, a more efficient solution would be \u201ctest-time scaling\u201d. Instead of spending numerous computations in improving the model's reasoning ability, one thing we can do to tackle this problem is to simply use another model call with the test feedback. In this specific problem set, this approach has been proven working every time, and simply calling the model one more time uses way less computation than trying to improve the model\u2019s native reasoning ability. Taken together, these observations suggest that, at least for this kind of coding workload, investing in smarter test-time strategies like iterative debugging and feedback-driven refinement may be a more practical and cost-effective way to boost reliability than solely focusing on training ever-stronger base models.<break/></paragraph></document>",
            "links": [
                "https://chat.deepseek.com/share/8vswr9xhltacersq2x",
                "https://chat.deepseek.com/share/z3d2wlzyriby9tat3v",
                "https://chat.deepseek.com/share/b9ei80b7h70hg32ego",
                "https://chat.deepseek.com/share/svy7a295g0hypncpej"
            ],
            "attachments": [],
            "created_at": "2025-12-01T16:18:54.805285+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7381174,
            "author": "Ruihan Xia",
            "project_title": "Special Participation A: Qwen on HW7",
            "post_body": "I used Qwen3-Max model to solve the written parts of homework 7. Instead of feeding individual questions with full text, I first uploaded the entire homework PDF and then asked each sub-question only by its label (\u201c7(b)\u201d, \u201c8(a)\u201d, etc.). The goal was to see whether Qwen could (1) avoid forgetting earlier context, (2) correctly retrieve the appropriate problem statement from the embedded PDF, and (3) solve each part in a single attempt. In this experiment Qwen successfully accomplished (1), (2) but failed (3) for questions that require SVD math. \n\nOne-shot accuracy: ~70%. Qwen performs well for questions that require basic understanding of classic models like encoder-decoder, multiple choice questions, and blog summary. \nHallucinations: None observed\nModel failures: Qwen tends to fail questions with sophisticated mathematical operations like SVD, linear algebra. It tends to stick to the notation in the question and is reluctant to apply more advanced tricks that simplify the expression, but rather to choose to brute force derive. In addition, Qwen might interpret wording like baseline with its own definition (updated baseline rather than benchmark), which might cause confusion if not clearly stated. \nContext retention: Surprisingly strong\u2014Qwen consistently located the correct question inside the PDF without needing me to restate it.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Qwen3-Max model to solve the written parts of homework 7. Instead of feeding individual questions with full text, I first uploaded the entire homework PDF and then asked each sub-question only by its label (\u201c7(b)\u201d, \u201c8(a)\u201d, etc.). The goal was to see whether Qwen could (1) avoid forgetting earlier context, (2) correctly retrieve the appropriate problem statement from the embedded PDF, and (3) solve each part in a single attempt. In this experiment Qwen successfully accomplished (1), (2) but failed (3) for questions that require SVD math. </paragraph><paragraph><bold>One-shot accuracy:</bold> ~70%. Qwen performs well for questions that require basic understanding of classic models like encoder-decoder, multiple choice questions, and blog summary. <break/><bold>Hallucinations:</bold> None observed<break/><bold>Model failures:</bold> Qwen tends to fail questions with sophisticated mathematical operations like SVD, linear algebra. It tends to stick to the notation in the question and is reluctant to apply more advanced tricks that simplify the expression, but rather to choose to brute force derive. In addition, Qwen might interpret wording like baseline with its own definition (updated baseline rather than benchmark), which might cause confusion if not clearly stated. <break/><bold>Context retention:</bold> Surprisingly strong\u2014Qwen consistently located the correct question inside the PDF without needing me to restate it.</paragraph><file url=\"https://static.us.edusercontent.com/files/SNLyYfvwHJOtEPk9bh1yrIIJ\" filename=\"Qwen Chat.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-01T15:15:40.022846+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7380526,
            "author": "Aaryan Chandna",
            "project_title": "Special Participation A: Using Gemini Flash 2.5 on HW11",
            "post_body": "Trace: https://gemini.google.com/share/2e206d7da648\n\nMath + T/F Question Zero-Shot Performance: 13/15.\n\nPrompt Structure: I told the model that it was a DL assistant for me. I gave the model the concepts I was planning to ask it about, and let the model know to output its interpretation of the question, followed by a step-by-step solution and a final answer for each. I also told the model that it should be able to correct itself when needed. For each question, I simply provided images of screenshots of the homework. For some questions, I explicitly told the model what context to consider, when needed. \n\nAnalysis: The model starts off a bit slow on the very first question (about ideas to adjust LoRA to get better performance). It identifies the main idea correctly, but does not get two of the other ideas from the solutions, even after re-prompting. Following this somewhat slow start, the model goes on a long streak of answering questions thoroughly and correctly. The solutions given by the model are arguably better than the actual HW solutions in some cases. In others, the model is potentially not concise enough, but this is also partially due to my initial prompt, where I asked the model to go step-by-step and then provide a final answer (sort of a CoT way of prompting the model).\n\nInterestingly, towards the end, the model starts trying to reattempt questions that it had already solved. For example, when I prompted Gemini to do 6a, it initially tried to resolve question 1 which it had already completed. When I asked it do then do 6a, it initially got the question slightly wrong due to some sort of apparent reading issue (I provided it with an image that it seemed to mis-extract the text of). This signified that Gemini 2.5 Flash may be better leveraged for individual questions, rather than for the entire HW assignment, as context length seems to be an issue here. It did the same thing when asked to solve 6b with an image, as it tried to then solve problem 2. On 6c, it actually got two of the T/F questions wrong. Even when re-prompted with the context again (just in case this was the cause once again, as with 6a), it got them wrong. It seems that the performance of the model gets better and then gets worse, empirically. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Trace: <link href=\"https://gemini.google.com/share/2e206d7da648\">https://gemini.google.com/share/2e206d7da648</link></paragraph><paragraph>Math + T/F Question Zero-Shot Performance: 13/15.</paragraph><paragraph>Prompt Structure: I told the model that it was a DL assistant for me. I gave the model the concepts I was planning to ask it about, and let the model know to output its interpretation of the question, followed by a step-by-step solution and a final answer for each. I also told the model that it should be able to correct itself when needed. For each question, I simply provided images of screenshots of the homework. For some questions, I explicitly told the model what context to consider, when needed. </paragraph><paragraph>Analysis: The model starts off a bit slow on the very first question (about ideas to adjust LoRA to get better performance). It identifies the main idea correctly, but does not get two of the other ideas from the solutions, even after re-prompting. Following this somewhat slow start, the model goes on a long streak of answering questions thoroughly and correctly. The solutions given by the model are arguably better than the actual HW solutions in some cases. In others, the model is potentially not concise enough, but this is also partially due to my initial prompt, where I asked the model to go step-by-step and then provide a final answer (sort of a CoT way of prompting the model).</paragraph><paragraph>Interestingly, towards the end, the model starts trying to reattempt questions that it had already solved. For example, when I prompted Gemini to do 6a, it initially tried to resolve question 1 which it had already completed. When I asked it do then do 6a, it initially got the question slightly wrong due to some sort of apparent reading issue (I provided it with an image that it seemed to mis-extract the text of). This signified that Gemini 2.5 Flash may be better leveraged for individual questions, rather than for the entire HW assignment, as context length seems to be an issue here. It did the same thing when asked to solve 6b with an image, as it tried to then solve problem 2. On 6c, it actually got two of the T/F questions wrong. Even when re-prompted with the context again (just in case this was the cause once again, as with 6a), it got them wrong. It seems that the performance of the model gets better and then gets worse, empirically. </paragraph><file url=\"https://static.us.edusercontent.com/files/E80wBkA1Nmv9OGX92e1aYBrv\" filename=\"aaryan_spec_part_a.pdf\"/></document>",
            "links": [
                "https://gemini.google.com/share/2e206d7da648"
            ],
            "attachments": [],
            "created_at": "2025-12-01T13:04:21.853163+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7380406,
            "author": "Jason Guo",
            "project_title": "Special Participation E: Using ChatGPT to create practice problems",
            "post_body": "To study for the final, I thought it would be interesting to see if ChatGPT can be used to created practice problems that are similar to homework problems, and solidify my understanding of the topics covered in homework. As an example, I gave ChatGPT homework 1, which has problems relating to optimizers, and asked it to generate two exam problems, each with multiple parts, relating to opitmizers based on the given homework problems.\n\nOverall, I thought it did well and actually provided some good problems for studying,. The difficulty of most of the problems it gave were around the same difficulty as the homework, with the exception of around 2 subquestions that required mathematical knowledge that's probably out of scope for this class. I also asked it to generate solutions for these problems, and the solutions were pretty good at explaining the answers in detail. As a whole, I found this to be really helpful in helping me review the material and get more practice solving exam/homework style problems.\n\nAnnotated transcript: https://drive.google.com/file/d/1hT7u9eEhd5HyBr-gD1urZGbrdP3Zu3T2/view?usp=sharing\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>To study for the final, I thought it would be interesting to see if ChatGPT can be used to created practice problems that are similar to homework problems, and solidify my understanding of the topics covered in homework. As an example, I gave ChatGPT homework 1, which has problems relating to optimizers, and asked it to generate two exam problems, each with multiple parts, relating to opitmizers based on the given homework problems.<break/><break/>Overall, I thought it did well and actually provided some good problems for studying,. The difficulty of most of the problems it gave were around the same difficulty as the homework, with the exception of around 2 subquestions that required mathematical knowledge that's probably out of scope for this class. I also asked it to generate solutions for these problems, and the solutions were pretty good at explaining the answers in detail. As a whole, I found this to be really helpful in helping me review the material and get more practice solving exam/homework style problems.<break/><break/>Annotated transcript: https://drive.google.com/file/d/1hT7u9eEhd5HyBr-gD1urZGbrdP3Zu3T2/view?usp=sharing</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-01T12:36:50.10738+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7380393,
            "author": "Andrew Choy",
            "project_title": "Special Participation B: HW 11 Interactive Coding with Kimi K2",
            "post_body": "Kimi k2 came out recently and I have to agree with the sentiment in #337. When this model dropped, it looked like it was performing really well on the LM-Arena leaderboards (4th on math), so I decided to use it to tackle the coding parts of this assignment.\n\nFirst off, the workflow is a bit of a friction point, it doesn\u2019t accept .ipynb files as input, so I had to convert everything into a standard Python script to start.\n\nA very stand out issue is the reasoning capability. For example, when implementing the single_attention_head, it made a basic linear algebra error (forgetting to transpose the weight matrix). When I pointed out the assertion error, instead of checking its math, it hallucinated a completely wrong justification about \"causal masking\" and tried to tell me to mask the diagonal. It didn't actually find the root cause until I literally pasted the correct solution code.\n\nIt struggled with the Induction Heads too. It kept writing to the same dimensions in the residual stream (breaking orthogonality) rather than using fresh registers. It eventually gave a cool explanation about \"scratch pads vs. registers,\" but only after I spoon-fed it the answer.\n\nIt is very fast at answering, which is definitely a tradeoff, but speed isn't a valid excuse for that lack of deep understanding. Overall, I\u2019m not very confident in its ability to reason through complex coding problems compared to other models i have used.",
            "content_xml": "<document version=\"2.0\"><paragraph>Kimi k2 came out recently and I have to agree with the sentiment in #337. When this model dropped, it looked like it was performing really well on the LM-Arena leaderboards (4th on math), so I decided to use it to tackle the coding parts of this assignment.</paragraph><paragraph>First off, the workflow is a bit of a friction point, it doesn\u2019t accept <code>.ipynb</code> files as input, so I had to convert everything into a standard Python script to start.</paragraph><paragraph>A very stand out issue is the reasoning capability. For example, when implementing the <code>single_attention_head</code>, it made a basic linear algebra error (forgetting to transpose the weight matrix). When I pointed out the assertion error, instead of checking its math, it hallucinated a completely wrong justification about \"causal masking\" and tried to tell me to mask the diagonal. It didn't actually find the root cause until I literally pasted the correct solution code.</paragraph><paragraph>It struggled with the Induction Heads too. It kept writing to the same dimensions in the residual stream (breaking orthogonality) rather than using fresh registers. It eventually gave a cool explanation about \"scratch pads vs. registers,\" but only after I spoon-fed it the answer.</paragraph><paragraph>It is very fast at answering, which is definitely a tradeoff, but speed isn't a valid excuse for that lack of deep understanding. Overall, I\u2019m not very confident in its ability to reason through complex coding problems compared to other models i have used.</paragraph><file url=\"https://static.us.edusercontent.com/files/c7EeiYByl3xocGmND7lUVQfY\" filename=\"CS182_Special_Participation_B (1).pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-12-01T12:32:54.215306+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7377516,
            "author": "Hanyang Gu",
            "project_title": "Special Participation A: Kimi K2 (Thinking) on HW1",
            "post_body": "Model Used: Kimi k2\n\nAssignment: Homework 1 (Non-coding theoretical problems)\n\nOverview\n\nI utilized Kimi k2 to solve the theoretical portions of Homework 1, covering topics from gradient descent stability and momentum dynamics to stochastic differential equations and high-dimensional geometry. The model demonstrated exceptional performance, acting as a highly competent graduate-level assistant. It successfully derived complex proofs and stability conditions that matched the instructor's ground truth almost perfectly.\n\nThe prompt I used is pretty simple, such as \"Solve Q1, show me all your process that leads to your answer\".\n\nPerformance Metrics & Observations\n\nOne-Shot Accuracy: High (>90%).\n\nThe model required very little \"hand-holding.\" For complex multi-part questions (like Question 2 on SVD coordinates and Question 3 on Momentum eigenvalues), Kimi k2 maintained context across subsections without needing to be reminded of previous definitions. It correctly identified the underlying mathematical structures (e.g., using the SVD to diagonalize the loss landscape) immediately upon being presented with the problem statement.\n\nMathematical Rigor & Reasoning:\n\nUnlike some LLMs that skip steps or hallucinate intermediate lines to reach a \"known\" answer, Kimi k2 provided complete, step-by-step derivations. E.g.\n\nMatrix Calculus: It correctly handled vector derivatives in Question 6 (Tikhonov Regularization) and Question 7 (MAP interpretation), distinguishing properly between scalar and vector layouts.\n\nStability Analysis: In Question 3, it correctly applied the stability criterion (checking if roots lie within the unit circle) to the characteristic equation, a non-trivial task for standard language models.\n\nHallucinations/Misconceptions: Little Observed.\n\nThe model did not invent theorems or misuse standard notation. In instances where the problem allowed for multiple interpretations (e.g., the specific formulation of Adam in Question 4), it defaulted to the standard textbook definitions that aligned with the course material.\n\nDownside: Kimi K2 generally have a thinking time of over 1 minute on each question. This is outperformed by other models, such as GPT5 or Gemini 3. However, this thinking time provides great ultimate performance that renders it fruitful. \n\nConclusion\n\nKimi k2 proved to be an incredibly effective tool for theoretical deep learning. It did not merely \"retrieve\" answers but seemingly \"reasoned\" through the linear algebra and probability theory required for this assignment. Its ability to link algebraic manipulations (like rotating the basis Vtop) to geometric intuitions makes it a powerful study aid for understanding the \"why\" behind deep learning dynamics.",
            "content_xml": "<document version=\"2.0\"><paragraph>Model Used: Kimi k2</paragraph><paragraph>Assignment: Homework 1 (Non-coding theoretical problems)</paragraph><heading level=\"3\">Overview</heading><paragraph>I utilized Kimi k2 to solve the theoretical portions of Homework 1, covering topics from gradient descent stability and momentum dynamics to stochastic differential equations and high-dimensional geometry. The model demonstrated exceptional performance, acting as a highly competent graduate-level assistant. It successfully derived complex proofs and stability conditions that matched the instructor's ground truth almost perfectly.</paragraph><paragraph>The prompt I used is pretty simple, such as \"Solve Q1, show me all your process that leads to your answer\".</paragraph><heading level=\"3\">Performance Metrics &amp; Observations</heading><list style=\"unordered\"><list-item><paragraph>One-Shot Accuracy: High (&gt;90%).</paragraph><paragraph>The model required very little \"hand-holding.\" For complex multi-part questions (like Question 2 on SVD coordinates and Question 3 on Momentum eigenvalues), Kimi k2 maintained context across subsections without needing to be reminded of previous definitions. It correctly identified the underlying mathematical structures (e.g., using the SVD to diagonalize the loss landscape) immediately upon being presented with the problem statement.</paragraph></list-item><list-item><paragraph>Mathematical Rigor &amp; Reasoning:</paragraph><paragraph>Unlike some LLMs that skip steps or hallucinate intermediate lines to reach a \"known\" answer, Kimi k2 provided complete, step-by-step derivations. E.g.</paragraph><list style=\"unordered\"><list-item><paragraph>Matrix Calculus: It correctly handled vector derivatives in Question 6 (Tikhonov Regularization) and Question 7 (MAP interpretation), distinguishing properly between scalar and vector layouts.</paragraph></list-item><list-item><paragraph>Stability Analysis<bold>:</bold> In Question 3, it correctly applied the stability criterion (checking if roots lie within the unit circle) to the characteristic equation, a non-trivial task for standard language models.</paragraph></list-item></list></list-item><list-item><paragraph>Hallucinations/Misconceptions: Little Observed.</paragraph><paragraph>The model did not invent theorems or misuse standard notation. In instances where the problem allowed for multiple interpretations (e.g., the specific formulation of Adam in Question 4), it defaulted to the standard textbook definitions that aligned with the course material.</paragraph></list-item><list-item><paragraph>Downside: Kimi K2 generally have a thinking time of over 1 minute on each question. This is outperformed by other models, such as GPT5 or Gemini 3. However, this thinking time provides great ultimate performance that renders it fruitful. </paragraph></list-item></list><heading level=\"3\">Conclusion</heading><paragraph>Kimi k2 proved to be an incredibly effective tool for theoretical deep learning. It did not merely \"retrieve\" answers but seemingly \"reasoned\" through the linear algebra and probability theory required for this assignment. Its ability to link algebraic manipulations (like rotating the basis Vtop) to geometric intuitions makes it a powerful study aid for understanding the \"why\" behind deep learning dynamics.</paragraph><file url=\"https://static.us.edusercontent.com/files/WdygFzuQ3WGC5VpclIJwQzz9\" filename=\"EECS_182_Special_Participations_KimiK2_HW1.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-30T18:25:52.153833+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7377452,
            "author": "Aaryan Chandna",
            "project_title": "Special Participation E: Coding Fill-in-the-Blank for Optimizers",
            "post_body": "I recall from CS courses that I have taken such as the 61 series how many questions used to consist of filling in blanks with code, particularly on exams and in discussions. I felt that these questions were relatively strong in developing intuition at the time, so I wanted to try a similar format out with Google Gemini in order to see if I could strengthen my understanding of the different optimizers. \n\nI asked Gemini to first summarize lectures 3/4 for me from the slides to provide a bit of review. The summaries were decent, even though the intuition provided wasn't always strong: sometimes the model would just quickly state a concept without explaining. Then, I asked it to create continuously increasing questions in difficulty, involving filling in the blank with code. One significant issue was that the model kept accidentally leaking the solution in the comments of the code. Even towards the end, it did this in a somewhat implicit fashion: below the function, there was a small section with an example of running the code in comments, with formulas shown that had the correct blank fill-ins. In addition, Gemini's questions were very one-dimensional and had to do solely with the basic functionality of optimizers, such as an SGD step or an Adam step. I expected that when I asked for questions of higher difficulty, there would be something more intuition based. Towards the end, the last question was a bit different, which was nice. Perhaps there is a better way of prompting to get the model to devise more exam-style questions for prep.\n\n\n\nTrace: https://gemini.google.com/share/eb8917989837",
            "content_xml": "<document version=\"2.0\"><paragraph>I recall from CS courses that I have taken such as the 61 series how many questions used to consist of filling in blanks with code, particularly on exams and in discussions. I felt that these questions were relatively strong in developing intuition at the time, so I wanted to try a similar format out with Google Gemini in order to see if I could strengthen my understanding of the different optimizers. </paragraph><paragraph>I asked Gemini to first summarize lectures 3/4 for me from the slides to provide a bit of review. The summaries were decent, even though the intuition provided wasn't always strong: sometimes the model would just quickly state a concept without explaining. Then, I asked it to create continuously increasing questions in difficulty, involving filling in the blank with code. One significant issue was that the model kept accidentally leaking the solution in the comments of the code. Even towards the end, it did this in a somewhat implicit fashion: below the function, there was a small section with an example of running the code in comments, with formulas shown that had the correct blank fill-ins. In addition, Gemini's questions were very one-dimensional and had to do solely with the basic functionality of optimizers, such as an SGD step or an Adam step. I expected that when I asked for questions of higher difficulty, there would be something more intuition based. Towards the end, the last question was a bit different, which was nice. Perhaps there is a better way of prompting to get the model to devise more exam-style questions for prep.</paragraph><paragraph/><paragraph>Trace: https://gemini.google.com/share/eb8917989837</paragraph><file url=\"https://static.us.edusercontent.com/files/nuwfPT2yMJx70pjs4KH3MbaL\" filename=\"spec_part_e_2_aaryan.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-30T17:45:50.986379+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7377431,
            "author": "Alex Cao",
            "project_title": "Special Participation A: Deepseek on HW9",
            "post_body": "\n\nIntro:\n\nThis is an attempt to interact with deepseek on non-coding parts of homework 9. The purpose of this study is to better understand how to prompt/interact with LLMs more effectively and LLM\u2019s capability of solving real life reasoning/math related problems with few-shot prompting. The specific model I interacted with was DeepSeek-V3.2. I used Deepseek\u2019s web ui to interact with the model. I will focus on how different prompting methods (or modes of reasoning) affect a model's one-shot correctness of the problems, and how to improve its accuracy without providing more in context examples. \n\n\n\nConversation traces:\n\nhttps://chat.deepseek.com/share/jkzqnyn7j8say9v7jc\nhttps://chat.deepseek.com/share/838vauzbwa2g0ynfby\nhttps://chat.deepseek.com/share/pp0exea4mnmt36qfqu\n\n\n\nReport with fully annotated traces:\n\n\nSummary:\n\nTo sum up, the model (DeepSeek-V3.2) is a quite strong model and is able to solve most of the non coding questions correctly (one-shot). For this specific problem set, two things matter the most for accuracy: 1. Model\u2019s reasoning ability and 2. Correct prompt and context. Prompt and context are very important because if instructions and context are not explicitly told, the model will make certain assumptions, and thus give incorrect answers. For example in question 4, when not stated explicitly, the model thinks it is completing some code function instead of filling blanks for a written question, thus identifying the wrong blanks to fill. The model\u2019s reasoning ability is also very important : for the previous example, even if the correct context and prompt is provided, the model still was not able to identify the correct blanks to fill without the DeepThink feature on. Together, these observations suggest that while DeepSeek-V3.2 is already quite capable on non-coding questions, its performance is highly sensitive to both how we phrase the task and model\u2019s reasoning capabilities. Thus, carefully designing prompts and systematically leveraging features like DeepThink will be essential for reliably getting correct answers and understanding the model's core strengths and weaknesses.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph/><heading level=\"3\">Intro:</heading><paragraph>This is an attempt to interact with deepseek on non-coding parts of homework 9. The purpose of this study is to better understand how to prompt/interact with LLMs more effectively and LLM\u2019s capability of solving real life reasoning/math related problems with few-shot prompting. The specific model I interacted with was DeepSeek-V3.2. I used Deepseek\u2019s web ui to interact with the model. I will focus on how different prompting methods (or modes of reasoning) affect a model's one-shot correctness of the problems, and how to improve its accuracy without providing more in context examples. <break/><break/></paragraph><paragraph>Conversation traces:</paragraph><paragraph><link href=\"https://chat.deepseek.com/share/jkzqnyn7j8say9v7jc\"><underline>https://chat.deepseek.com/share/jkzqnyn7j8say9v7jc</underline><break/></link><link href=\"https://chat.deepseek.com/share/838vauzbwa2g0ynfby\"><underline>https://chat.deepseek.com/share/838vauzbwa2g0ynfby</underline><break/></link><link href=\"https://chat.deepseek.com/share/pp0exea4mnmt36qfqu\"><underline>https://chat.deepseek.com/share/pp0exea4mnmt36qfqu</underline></link><break/><break/><break/><break/>Report with fully annotated traces:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/46rP2jY0XqQTfFngOrJ3EJyA\" filename=\"Special Pariticpation A-- DeepSeek on HW9.pdf\"/><file/><heading level=\"3\">Summary:</heading><paragraph>To sum up, the model (DeepSeek-V3.2) is a quite strong model and is able to solve most of the non coding questions correctly (one-shot). For this specific problem set, two things matter the most for accuracy: 1. Model\u2019s reasoning ability and 2. Correct prompt and context. Prompt and context are very important because if instructions and context are not explicitly told, the model will make certain assumptions, and thus give incorrect answers. For example in question 4, when not stated explicitly, the model thinks it is completing some code function instead of filling blanks for a written question, thus identifying the wrong blanks to fill. The model\u2019s reasoning ability is also very important : for the previous example, even if the correct context and prompt is provided, the model still was not able to identify the correct blanks to fill without the DeepThink feature on. Together, these observations suggest that while DeepSeek-V3.2 is already quite capable on non-coding questions, its performance is highly sensitive to both how we phrase the task and model\u2019s reasoning capabilities. Thus, carefully designing prompts and systematically leveraging features like DeepThink will be essential for reliably getting correct answers and understanding the model's core strengths and weaknesses.<break/><break/></paragraph></document>",
            "links": [
                "https://chat.deepseek.com/share/jkzqnyn7j8say9v7jc",
                "https://chat.deepseek.com/share/838vauzbwa2g0ynfby",
                "https://chat.deepseek.com/share/pp0exea4mnmt36qfqu"
            ],
            "attachments": [],
            "created_at": "2025-11-30T17:33:46.197807+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7377093,
            "author": "Ender Ji",
            "project_title": "Special Participation E: GPT5 as quiz maker for exam preparation",
            "post_body": "\n\nFor special participation part E, I asked GPT 5.1 to make quiz problems (both MCQ and FRQ) based on the lecture notes of lecture 18  and 19 from Professor Ranade. I begin by clearly stating GPT\u2019s role and the assistance I require, then provide all relevant files and ask it to review and understand them.\n\nThen I first ask GPT to generate multiple-choice questions and attempt to answer them. GPT produces high-quality MCQs that effectively test my understanding, and it can both identify my mistakes and provide the correct answers with detailed explanations.\n\nBeyond MCQs, I also use GPT to create more open-ended free-response questions. GPT is able to formulate the problems, \u201cgrade\u201d my answers against the \"ground truth\" from the lecture notes, and offer thorough explanations and guidance whenever I get stuck.\n\nThis is the first time I have used an LLM for this kind of review, and the experience has been very positive. I believe this interactive \u201cquiz-taking\u201d approach will be extremely helpful not only for preparing for the final exam, but also for ensuring that I fully understand the material before each subsequent lecture. I also hope that this method will be helpful for other students during RRR week.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph/><file url=\"https://static.us.edusercontent.com/files/vHKi330uVk2qWo0QcgvNT3VX\" filename=\"test_reviewer_GPT5.pdf\"/><paragraph>For special participation part E, I asked GPT 5.1 to make quiz problems (both MCQ and FRQ) based on the lecture notes of lecture 18  and 19 from Professor Ranade. I begin by clearly stating GPT\u2019s role and the assistance I require, then provide all relevant files and ask it to review and understand them.</paragraph><paragraph>Then I first ask GPT to generate multiple-choice questions and attempt to answer them. GPT produces high-quality MCQs that effectively test my understanding, and it can both identify my mistakes and provide the correct answers with detailed explanations.</paragraph><paragraph>Beyond MCQs, I also use GPT to create more open-ended free-response questions. GPT is able to formulate the problems, \u201cgrade\u201d my answers against the \"ground truth\" from the lecture notes, and offer thorough explanations and guidance whenever I get stuck.</paragraph><paragraph>This is the first time I have used an LLM for this kind of review, and the experience has been very positive. I believe this interactive \u201cquiz-taking\u201d approach will be extremely helpful not only for preparing for the final exam, but also for ensuring that I fully understand the material before each subsequent lecture. I also hope that this method will be helpful for other students during RRR week.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-30T15:08:56.618821+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7377005,
            "author": "Sultan Daniels",
            "project_title": "HW 11 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/XUuDptfaGtS38bf2sNFh518T\" filename=\"hw11codesolution.zip\"/><file url=\"https://static.us.edusercontent.com/files/RpfafJeboMOxOEyRkkgdWs59\" filename=\"hw11_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/RQYfSEcrRexANTSkquAcQ7GD\" filename=\"hw11_question.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-30T14:32:34.89119+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7376439,
            "author": "Wesley Kai Zheng",
            "project_title": "Special Participation C: Homework 8 Task 2 Refactor Notebook for GPU",
            "post_body": "From my perspective, the original SSM/RNN convolution assignment was conceptually interesting and almost developed. Much of the provided code contained missing docstrings, duplicated function names, and unclear separation between benchmarking logic and visualization. As a result, the assignment required students to write very little actual code, and several implementation issues could confuse learners rather than support the intended learning goals. To address this, I refactored the notebook, improved the organization, clarified the API boundaries, and added more robust scaffolding. Some major references for good Python and ML engineering practices that guided the refactoring (and are cited in the full report) include:\n\nPEP 8 \u2013 Style Guide for Python Code\nPEP 257 \u2013 Docstring Conventions\nPEP 484 \u2013 Type Hints\nPEP 585 \u2013 Type Hinting Generics in Standard Collections\nGoogle Python Style Guide \u2014 Functions and Side Effects\n\nHere's the report and the link to the colab notebook: https://colab.research.google.com/drive/1s06sEeMPooGlg0syKnoly7g3DZ4aR4-P?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>From my perspective, the original SSM/RNN convolution assignment was conceptually interesting and almost developed. Much of the provided code contained missing docstrings, duplicated function names, and unclear separation between benchmarking logic and visualization. As a result, the assignment required students to write very little actual code, and several implementation issues could confuse learners rather than support the intended learning goals. To address this, I refactored the notebook, improved the organization, clarified the API boundaries, and added more robust scaffolding. Some major references for good Python and ML engineering practices that guided the refactoring (and are cited in the full report) include:</paragraph><paragraph><link href=\"https://peps.python.org/pep-0008/\">PEP 8 \u2013 Style Guide for Python Code</link><break/><link href=\"https://peps.python.org/pep-0257/\">PEP 257 \u2013 Docstring Conventions</link><break/><link href=\"https://peps.python.org/pep-0484/\">PEP 484 \u2013 Type Hints</link><break/><link href=\"https://peps.python.org/pep-0585/\">PEP 585 \u2013 Type Hinting Generics in Standard Collections</link><break/><link href=\"https://google.github.io/styleguide/pyguide.html\">Google Python Style Guide \u2014 Functions and Side Effects</link></paragraph><paragraph>Here's the report and the link to the colab notebook: https://colab.research.google.com/drive/1s06sEeMPooGlg0syKnoly7g3DZ4aR4-P?usp=sharing</paragraph><file url=\"https://static.us.edusercontent.com/files/fX2MYqaO7DH3gSofF9QfQCPO\" filename=\"Copy of 182report.pdf\"/></document>",
            "links": [
                "https://peps.python.org/pep-0008/",
                "https://peps.python.org/pep-0257/",
                "https://peps.python.org/pep-0484/",
                "https://peps.python.org/pep-0585/",
                "https://google.github.io/styleguide/pyguide.html"
            ],
            "attachments": [],
            "created_at": "2025-11-30T10:56:26.087892+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7376375,
            "author": "Iana Lin",
            "project_title": "Special Participation E: ChatGPT 5.0 Study Mode",
            "post_body": "Executive Summary\n\nI used ChatGPT 5.0 \"Study Mode\" to interactively improve my understanding of positional encoding, RoPE, and NoPE.  This was the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" and I felt it was very helpful. It asked clarifying questions about my current understanding before proceeding to explain, which differed from normal prompting mode.\n\n\nAlthough there is a less clear idea of \"one-shotting\" in this context where there are not verifiable correct answers, every question it asked was answer reasonably with logical and step-by-step explanations. I do wish that the explanation were more grounded in mathematical formulations or code, but this may come down to learn the write prompting style.\n \n\nErrors:\nChatGPT used \u201ci\u201d for indexing position, but this later became confusing because it also used i for imaginary number. After pointing this out, it no longer made the mistake\n\n\nOverall:\nChatGPT was a good resource for improving understanding, much like if I was chatting to a teaching assistant, and interacted with clarifying questions throughout the converstation. The analogy to Fourier transform across positions helped clarify how using this superposition allows for capturing of both high and low frequencies/unique embedding for each input embedding and position.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>I used ChatGPT 5.0 \"Study Mode\" to interactively improve my understanding of positional encoding, RoPE, and NoPE.  This was the first time I've interacted with ChatGPT 5.0's \"Study Mode,\" and I felt it was very helpful. It asked clarifying questions about my current understanding before proceeding to explain, which differed from normal prompting mode.<break/></paragraph><paragraph>Although there is a less clear idea of \"one-shotting\" in this context where there are not verifiable correct answers, every question it asked was answer reasonably with logical and step-by-step explanations. I do wish that the explanation were more grounded in mathematical formulations or code, but this may come down to learn the write prompting style.<break/> </paragraph><paragraph><bold>Errors</bold>:<break/>ChatGPT used \u201ci\u201d for indexing position, but this later became confusing because it also used i for imaginary number. After pointing this out, it no longer made the mistake</paragraph><paragraph><break/><bold>Overall</bold>:<break/>ChatGPT was a good resource for improving understanding, much like if I was chatting to a teaching assistant, and interacted with clarifying questions throughout the converstation. The analogy to Fourier transform across positions helped clarify how using this superposition allows for capturing of both high and low frequencies/unique embedding for each input embedding and position.</paragraph><file url=\"https://static.us.edusercontent.com/files/rUKMMRgfpcftT4caUCaGgmVi\" filename=\"Special Participation E - RoPE Using ChatGPT Study Mode.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-30T10:33:28.34829+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7376346,
            "author": "Wesley Kai Zheng",
            "project_title": "Special Participation C: Homework 4 Task 5 Refactor",
            "post_body": "From my perspective, this coding assignment was far too short and required students to fill in only one or two lines of code to complete it. Given the simplicity of the kernel that needed to be implemented, the assignment felt insufficiently challenging. Therefore, we decided to step in, refactor the assignment, and add a new problem as well. Some major references for good Python practices that I used during the refactoring process (also included in the report) are:\n\nPEP 257 Docstring Conventions\n\nPEP 484 Type Hints\n\nPEP 20 (Zen of Python)\n\nGoogle Python Style Guide (Functions and Side Effects)\n\nPEP 585 \u2013 Type Hinting Generics In Standard Collections\n\nIn summary, the assignment is now slightly longer while still maintaining its original purpose and allowing students to experiment with the Sobel filter. In the future, this assignment could be extended by adding the Canny Edge Detector (which, coincidentally, was developed by Professor Canny!).\n\nThe report is located here:\n\nThe ipynb notebook is here:\n\nhttps://colab.research.google.com/drive/1sRW_V5RSs1EAkMIGhfZebNEqGrzpViGt?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>From my perspective, this coding assignment was far too short and required students to fill in only one or two lines of code to complete it. Given the simplicity of the kernel that needed to be implemented, the assignment felt insufficiently challenging. Therefore, we decided to step in, refactor the assignment, and add a new problem as well. Some major references for good Python practices that I used during the refactoring process (also included in the report) are:</paragraph><paragraph><bold><link href=\"https://peps.python.org/pep-0257/\"><underline>PEP 257 Docstring Conventions</underline></link></bold></paragraph><paragraph><bold><link href=\"https://peps.python.org/pep-0484/\"><underline>PEP 484 Type Hints</underline></link></bold></paragraph><paragraph><bold><link href=\"https://peps.python.org/pep-0020/\"><underline>PEP 20 (Zen of Python)</underline></link></bold></paragraph><paragraph><bold><link href=\"https://google.github.io/styleguide/pyguide.html\"><underline>Google Python Style Guide (Functions and Side Effects)</underline></link></bold></paragraph><paragraph><bold><link href=\"https://peps.python.org/pep-0585/\"><underline>PEP 585 \u2013 Type Hinting Generics In Standard Collections</underline></link></bold></paragraph><paragraph>In summary, the assignment is now slightly longer while still maintaining its original purpose and allowing students to experiment with the Sobel filter. In the future, this assignment could be extended by adding the Canny Edge Detector (which, coincidentally, was developed by Professor Canny!).</paragraph><paragraph>The report is located here:</paragraph><file url=\"https://static.us.edusercontent.com/files/NGzRRFqbHSjvp33OkOnxVTvk\" filename=\"182report.pdf\"/><paragraph>The ipynb notebook is here:</paragraph><paragraph>https://colab.research.google.com/drive/1sRW_V5RSs1EAkMIGhfZebNEqGrzpViGt?usp=sharing</paragraph></document>",
            "links": [
                "https://peps.python.org/pep-0257/",
                "https://peps.python.org/pep-0484/",
                "https://peps.python.org/pep-0020/",
                "https://google.github.io/styleguide/pyguide.html",
                "https://peps.python.org/pep-0585/"
            ],
            "attachments": [],
            "created_at": "2025-11-30T10:21:46.430584+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7376323,
            "author": "Ken Zheng",
            "project_title": "Special Participation C: Refactoring Q5 on HW4",
            "post_body": "I refactored question 5 from homework 4 into a well-organized GitHub repository, with the aim of both adhering to python & NumPy code organization/best practices and enhancing the student learning experience. Through this restructuring I also aimed to elevate the question's educational value by adding on a third part to the question: create a sharpening filter. Please refer to the report for more details!\n\nRepo: https://github.com/kenzhengjk/hand_design_filters\n\nReport: \n\nSimply remove the solutions directory and the assignment will be ready!",
            "content_xml": "<document version=\"2.0\"><paragraph>I refactored question 5 from homework 4 into a well-organized GitHub repository, with the aim of both adhering to python &amp; NumPy code organization/best practices and enhancing the student learning experience. Through this restructuring I also aimed to elevate the question's educational value by adding on a third part to the question: create a sharpening filter. Please refer to the report for more details!</paragraph><paragraph><bold>Repo</bold>: <link href=\"https://github.com/kenzhengjk/hand_design_filters\">https://github.com/kenzhengjk/hand_design_filters</link></paragraph><paragraph><bold>Report</bold>: </paragraph><file url=\"https://static.us.edusercontent.com/files/SjXOXdG7H9wbNzFZQdPAKHze\" filename=\"Special_Part_C_Q5_HW4_REPORT.pdf\"/><paragraph>Simply remove the <code>solutions</code> directory and the assignment will be ready!</paragraph></document>",
            "links": [
                "https://github.com/kenzhengjk/hand_design_filters"
            ],
            "attachments": [],
            "created_at": "2025-11-30T10:15:19.016308+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7376321,
            "author": "Ender Ji",
            "project_title": "Special Participation E: GPT5 as lecture notes reviewer and tutor",
            "post_body": "For special participation part E, I asked GPT 5.1 to review the lecture notes of lecture 18 from Professor Ranade. I begin by clearly stating GPT\u2019s role and the assistance I require, then provide all relevant files and ask it to review and understand them. Then I proceed to asking different kinds of questions about the notes\n\n1. input a hand drawing diagram from Professor Ranade and ask it to explain to diagram\n\n2. input a diagram from the book ask it to explain to diagram\n\n3. ask GPT to explain a specific concept\n\n4. ask GPT to differentiate between different concepts\n\n5. ask GPT concepts that are not deeply discussed in the lecture notes, and make connection to the lecture notes\n\nIt is the first time I do notes review with GPT, surprisingly GPT 5.1 can handle almost all kinds of questions well and able to give great explanations, which shows how strong GPT is in helping students learning new concepts.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/K4hJ3j4bSbawhhtQozKvoiPU\" filename=\"lecture18_review_GPT5.pdf\"/><paragraph>For special participation part E, I asked GPT 5.1 to review the lecture notes of lecture 18 from Professor Ranade. I begin by clearly stating GPT\u2019s role and the assistance I require, then provide all relevant files and ask it to review and understand them. Then I proceed to asking different kinds of questions about the notes</paragraph><paragraph>1. input a hand drawing diagram from Professor Ranade and ask it to explain to diagram</paragraph><paragraph>2. input a diagram from the book ask it to explain to diagram</paragraph><paragraph>3. ask GPT to explain a specific concept</paragraph><paragraph>4. ask GPT to differentiate between different concepts</paragraph><paragraph>5. ask GPT concepts that are not deeply discussed in the lecture notes, and make connection to the lecture notes</paragraph><paragraph>It is the first time I do notes review with GPT, surprisingly GPT 5.1 can handle almost all kinds of questions well and able to give great explanations, which shows how strong GPT is in helping students learning new concepts.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-30T10:14:46.664082+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7375514,
            "author": "Divya Ramesh",
            "project_title": "Special Participation A: Gemini (Fast) on HW 9",
            "post_body": "Executive Summary:\n\nI used Gemini on the non-coding parts of HW 9, and evaluated where it did well and where it didn't. I noticed Gemini could mostly one-shot these questions, especially sections that were very structured math or required analyzing code. I think it mainly failed where the formatting of the question was an issue, and that was just because of LaTeX copy/paste error. To solve these, when I clarified the misreads, Gemini quickly fixed its solution. Even with the formatting problems though, when it was a coding analysis question or there was a lot of context, Gemini still did very well, one shotting almost all the questions. I think the only case where the solution was incorrect showed inconsistency within its own solution, providing the incorrect answer as the header and then showing work to derive the correct answer. This was confusing, but it ultimately did come up with the correct solution. I was also impressed with how quickly it was able to come up with the solutions, taking no longer than 10 seconds at the max. This could also be, however, that I fed each problem in individually, allowing it to see all context for each question as it came up. \n\nI also noticed Gemini provided detailed explanations for each question, serving as a great conceptual recap on the topic. It helped me understand how different concepts were related, and it helped me understand derivations for formulas that I previously didn't know. I think overall, it helped me with my understanding of course concepts a lot. \n\nOne thing I did find a little annoying was Gemini wouldn't let me paste the code I copied from the hw9 pdf file: I needed to paste the question in a different document, and then copy that over to the Gemini search bar. I think maybe Gemini wasn't used to the LaTeX pdf format, and didn't allow those characters. This did make it a little harder to do, but it was just a mild inconvenience!\n\nHere is a link to my annotated logs: https://drive.google.com/file/d/11Kqd0IzU7LoCcbPa70mZT0KVR2X1V1Ql/view?usp=sharing\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive Summary:</paragraph><paragraph>I used Gemini on the non-coding parts of HW 9, and evaluated where it did well and where it didn't. I noticed Gemini could mostly one-shot these questions, especially sections that were very structured math or required analyzing code. I think it mainly failed where the formatting of the question was an issue, and that was just because of LaTeX copy/paste error. To solve these, when I clarified the misreads, Gemini quickly fixed its solution. Even with the formatting problems though, when it was a coding analysis question or there was a lot of context, Gemini still did very well, one shotting almost all the questions. I think the only case where the solution was incorrect showed inconsistency within its own solution, providing the incorrect answer as the header and then showing work to derive the correct answer. This was confusing, but it ultimately did come up with the correct solution. I was also impressed with how quickly it was able to come up with the solutions, taking no longer than 10 seconds at the max. This could also be, however, that I fed each problem in individually, allowing it to see all context for each question as it came up. </paragraph><paragraph>I also noticed Gemini provided detailed explanations for each question, serving as a great conceptual recap on the topic. It helped me understand how different concepts were related, and it helped me understand derivations for formulas that I previously didn't know. I think overall, it helped me with my understanding of course concepts a lot. </paragraph><paragraph>One thing I did find a little annoying was Gemini wouldn't let me paste the code I copied from the hw9 pdf file: I needed to paste the question in a different document, and then copy that over to the Gemini search bar. I think maybe Gemini wasn't used to the LaTeX pdf format, and didn't allow those characters. This did make it a little harder to do, but it was just a mild inconvenience!</paragraph><paragraph>Here is a link to my annotated logs: <link href=\"https://drive.google.com/file/d/11Kqd0IzU7LoCcbPa70mZT0KVR2X1V1Ql/view?usp=sharing\">https://drive.google.com/file/d/11Kqd0IzU7LoCcbPa70mZT0KVR2X1V1Ql/view?usp=sharing</link></paragraph><paragraph/></document>",
            "links": [
                "https://drive.google.com/file/d/11Kqd0IzU7LoCcbPa70mZT0KVR2X1V1Ql/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-11-30T06:29:30.10322+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7374682,
            "author": "Andrew Choy",
            "project_title": "Special Participation E: Interactive MHA Implementation Drill",
            "post_body": "One challenge I often face is bridging the gap between understanding a concept theoretically and implementing it in code. For this assignment, I used Gemini 3 Thinking to guide me through the implementation.\n\nIt felt a bit like a 'Masked Language Modeling' task for my own brain: I designed a prompt to set up the scenario, and I had to fill in the code for the forward pass of Multi-Head Attention myself. I spent about an hour on the exercise, and I found it incredibly valuable. Instead of just giving me the answers, the LLM asked me conceptual questions about why I was choosing specific tensor shapes. Being forced to justify my implementation details really solidified my understanding of the topic.\n\nI encourage y'all to try this with the prompt I included in the pdf. You can easily adapt it for other concepts by slightly changing the formatting in the 'Your Role' and 'The Trap' sections. Just swap out 'Multi-Head Attention' for another topic like 'Layer Normalization' or 'Adam Optimizer,' and keep the 'No Solutions' constraint to ensure the same type of setup.\n\n ",
            "content_xml": "<document version=\"2.0\"><paragraph>One challenge I often face is bridging the gap between understanding a concept theoretically and implementing it in code. For this assignment, I used <bold>Gemini 3 Thinking</bold> to guide me through the implementation.</paragraph><paragraph>It felt a bit like a 'Masked Language Modeling' task for my own brain: I designed a prompt to set up the scenario, and I had to fill in the code for the forward pass of Multi-Head Attention myself. I spent about an hour on the exercise, and I found it incredibly valuable. Instead of just giving me the answers, the LLM asked me conceptual questions about <italic>why</italic> I was choosing specific tensor shapes. Being forced to justify my implementation details really solidified my understanding of the topic.</paragraph><paragraph>I encourage y'all to try this with the prompt I included in the pdf. You can easily adapt it for other concepts by slightly changing the formatting in the <bold>'Your Role'</bold> and <bold>'The Trap'</bold> sections. Just swap out 'Multi-Head Attention' for another topic like 'Layer Normalization' or 'Adam Optimizer,' and keep the <bold>'No Solutions'</bold> constraint to ensure the same type of setup.</paragraph><paragraph> </paragraph><file url=\"https://static.us.edusercontent.com/files/CcMT6C3JxLbClmmbjNJnMBAw\" filename=\"AndrewChoyParticipationE.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-29T19:26:19.700045+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7374626,
            "author": "Angelina Zhang",
            "project_title": "Participation E: Conv Layer Intuition Tutor",
            "post_body": "When learning convolution layers, I often struggled to remember formulas or effects as the lectures progressed. I found that true understanding only came from visualizing what was happening and actively quizzing myself. So I built a small interactive webpage called Conv Layer Intuition Tutor, designed to help students build real intuition for convolutional layers by letting you manipulate the hyperparameters and see visualizations directly. The interface allows you to adjust kernel size, stride, padding, and it instantly visualizes how these changes affect output size, receptive field growth, parameter count, and which input pixels contribute to each output activation. I also embedded an optional AI assistant (using your own API key) that can quiz you or explain concepts for post-lecture review.\n\nYou can visit the site here: https://angelinaaaaaaaaaaaa.github.io/Conv-Layer-Intuition-Tutor/\n\nTo run the tool locally, simply download the HTML file and either double-click it or open a terminal in that folder and start a local server (e.g., python3 -m http.server 8000) and then visit the shown URL. This removes the need to constantly switch between PDFs and LLMs, and provides a hands-on, highly interactive way to internalize convolution mechanics \u2014 with AI guidance whenever you need it.\n\nHappy to hear any feedback or suggestions!\n",
            "content_xml": "<document version=\"2.0\"><paragraph>When learning convolution layers, I often struggled to remember formulas or effects as the lectures progressed. I found that true understanding only came from visualizing what was happening and actively quizzing myself. So I built a small interactive webpage called Conv Layer Intuition Tutor, designed to help students build real intuition for convolutional layers by letting you manipulate the hyperparameters and see visualizations directly. The interface allows you to adjust kernel size, stride, padding, and it instantly visualizes how these changes affect output size, receptive field growth, parameter count, and which input pixels contribute to each output activation. I also embedded an optional AI assistant (using your own API key) that can quiz you or explain concepts for post-lecture review.<break/><break/>You can visit the site here: https://angelinaaaaaaaaaaaa.github.io/Conv-Layer-Intuition-Tutor/</paragraph><paragraph>To run the tool locally, simply download the HTML file and either double-click it or open a terminal in that folder and start a local server (e.g., python3 -m http.server 8000) and then visit the shown URL. This removes the need to constantly switch between PDFs and LLMs, and provides a hands-on, highly interactive way to internalize convolution mechanics \u2014 with AI guidance whenever you need it.<break/><break/>Happy to hear any feedback or suggestions!<break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-29T18:19:37.931881+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7374436,
            "author": "Hong Joey",
            "project_title": "HW 10 Solutions",
            "post_body": "Attached are solutions to HW 10. Use this thread if you have any questions.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are solutions to HW 10. Use this thread if you have any questions.</paragraph><file url=\"https://static.us.edusercontent.com/files/h3tv3GuAOcTo8dMk0fLy0JWt\" filename=\"hw10_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/zP1JkEM3aCeysBQPNDCinv6a\" filename=\"q_hand_transformer_sol.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/0IhHtEm7lV8PnA1uZf84qz4J\" filename=\"q_summarize_sol.ipynb\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-29T16:00:53.002127+11:00",
            "category": "Admin"
        },
        {
            "guid": 7374084,
            "author": "Ken Zheng",
            "project_title": "Special Participation B: Seed1.6 (ByteDance) on HW3",
            "post_body": "I completed the coding parts of Homework 3 using Doubao Seed1.6 (from ByteDance).\n\nMotivation\n\nDoubao Seed1.6 doesn't support .ipynb file uploads so I manually copy-pasted each part as text input. I tried to limit the extent of prompt optimizations in order to explore to what extend Seed is able to first-try questions without any additional support.\n\nSummary\n\nOverall Seed is a capable coding model that is adaptive and flexible. Seed mostly zero-shots every part, producing accurate, clean, and commented code in a well-structured manner. Nevertheless, when its first attempt is erroneous and the user follows up by asking for modifications on top of the previous code, it has a tendency to slightly spiral towards chaos (i.e., by adding more code and introducing more variables to deal with the changes instead of reforming logic to incorporate both previous and new requirements). This rising-entropy approach isn't unique to Seed -- I've witnessed similar behavior in ChatGPT, Qwen, and Claude when I repeatedly ask for incremental but substantial changes to previously generated code. But I digress. \n\nSeed also tends to assume control of the entire code snippet and frequently makes edits outside of TODO blocks. The prompts in the question notebook never explicitly state \"only add to/change what's in the TODO blocks\", which is probably what gives Seed its bravery. As humans, however, we naturally understand we should only modify content within the TODOs. This is easily fixable, however, by just telling Seed to only modify TODO blocks. This works even after a few back and forths and then asking it to condense all the changes it has made into the TODO block of the first version of the code. You can see this in action for part (c).\n\nFor more specific observations please see my annotations below!\n\nFiles & Links\n\nPart A\n\nPart B\n\nParts C-E\n\nAnnotated conversations:\n\nCompleted notebook ran on code from Seed (to show correctness): \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I completed the coding parts of Homework 3 using Doubao Seed1.6 (from ByteDance).</paragraph><paragraph><bold>Motivation</bold></paragraph><paragraph>Doubao Seed1.6 doesn't support <code>.ipynb</code> file uploads so I manually copy-pasted each part as text input. I tried to limit the extent of prompt optimizations in order to explore to what extend Seed is able to first-try questions without any additional support.</paragraph><paragraph><bold>Summary</bold></paragraph><paragraph>Overall Seed is a capable coding model that is adaptive and flexible. Seed mostly zero-shots every part, producing accurate, clean, and commented code in a well-structured manner. Nevertheless, when its first attempt is erroneous and the user follows up by asking for modifications on top of the previous code, it has a tendency to slightly spiral towards chaos (i.e., by adding more code and introducing more variables to deal with the changes instead of reforming logic to incorporate both previous and new requirements). This rising-entropy approach isn't unique to Seed -- I've witnessed similar behavior in ChatGPT, Qwen, and Claude when I repeatedly ask for incremental but substantial changes to previously generated code. But I digress. </paragraph><paragraph>Seed also tends to assume control of the entire code snippet and frequently makes edits outside of TODO blocks. The prompts in the question notebook never explicitly state \"only add to/change what's in the TODO blocks\", which is probably what gives Seed its bravery. As humans, however, we naturally understand we should only modify content within the TODOs. This is easily fixable, however, by just telling Seed to only modify TODO blocks. This works even after a few back and forths and then asking it to condense all the changes it has made into the TODO block of the first version of the code. You can see this in action for part (c).</paragraph><paragraph>For more specific observations please see my annotations below!</paragraph><paragraph><bold>Files &amp; Links</bold></paragraph><paragraph><link href=\"https://www.doubao.com/thread/wbf507d0d24ed75a5\">Part A</link></paragraph><paragraph><link href=\"https://www.doubao.com/thread/w18e6b14ca46355e0\">Part B</link></paragraph><paragraph><link href=\"https://www.doubao.com/thread/w2d83dbe9f15c1b45\">Parts C-E</link></paragraph><paragraph>Annotated conversations:</paragraph><file url=\"https://static.us.edusercontent.com/files/rKMFdDSDK4gqRBTICA41ocVV\" filename=\"HW3_Q2_Annotated.pdf\"/><paragraph>Completed notebook ran on code from Seed (to show correctness): </paragraph><file url=\"https://static.us.edusercontent.com/files/RaCwwAmBGFUayBxZAfOpa9he\" filename=\"q_mup_coding_seedified.ipynb\"/><paragraph/></document>",
            "links": [
                "https://www.doubao.com/thread/wbf507d0d24ed75a5",
                "https://www.doubao.com/thread/w18e6b14ca46355e0",
                "https://www.doubao.com/thread/w2d83dbe9f15c1b45"
            ],
            "attachments": [],
            "created_at": "2025-11-29T12:58:47.575512+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7374016,
            "author": "Jason Trinh",
            "project_title": "Special Participation A: Gemini 2.5 Flash on HW0",
            "post_body": "Hey guys \u2014 I used Gemini Flash 2.5 for the non-coding parts of HW0, and here\u2019s the quick verdict.\n\nTL;DR: Gemini was strong on the \u201cmechanical\u201d math (clean chain rule + indicator notation, solid ridge/SVD manipulations, decent linear-algebra bookkeeping), but its main weakness was qualitative/sign reasoning in the ReLU elbow SGD question, where it overclaimed elbow direction and bungled sign/inequality logic. \n\nWhat it did well: used the 1\u03d5(x)>0\u200b indicator instead of messy piecewise cases, and matched the staff-style update notation w\u2032,b\u2032,e\u2032. \n\n\nWhere it slipped: for case (ii), it said \u201celbow shifts right,\u201d but the elbow can move left or right depending on bias + step size. \n\n\nClear wrong answer: for (iii) it concluded the elbow \u201cmoves left\u201d as the expression gets larger, but the expression is negative so becoming \u201cless negative\u201d means it actually moves right. \n\n\nEven when it got the final direction right: its proof sketch ended with a bogus condition like w>bx.\n\nAfter I nudged it with an \u201calgebra-first + sanity-check\u201d checklist (explicitly compute e\u2032=\u2212b\u2032/w\u2032, be careful when w<0, and verify with a tiny numeric example), Gemini improved a lot. It stopped hand-waving the geometry, caught its own sign mistakes when the numeric check contradicted the algebra, and finally gave consistent conclusions across the cases. The conclusion: Gemini is super useful here, but only if you force it to prove elbow motion by comparing e\u2032 vs e and validating with a quick counterexample.",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey guys \u2014 I used <bold>Gemini Flash 2.5</bold> for the <bold>non-coding parts of HW0</bold>, and here\u2019s the quick verdict.</paragraph><paragraph><bold>TL;DR:</bold> Gemini was <bold>strong on the \u201cmechanical\u201d math</bold> (clean chain rule + indicator notation, solid ridge/SVD manipulations, decent linear-algebra bookkeeping), but its <bold>main weakness was qualitative/sign reasoning</bold> in the <bold>ReLU elbow SGD question</bold>, where it overclaimed elbow direction and bungled sign/inequality logic. </paragraph><list style=\"bullet\"><list-item><paragraph><bold>What it did well:</bold> used the <bold>1</bold><sub>\u03d5(x)&gt;0\u200b</sub> indicator instead of messy piecewise cases, and matched the staff-style update notation w\u2032,b\u2032,e\u2032. <break/></paragraph></list-item><list-item><paragraph><bold>Where it slipped:</bold> for case (ii), it said \u201celbow shifts right,\u201d but the elbow can move <bold>left or right depending on bias + step size</bold>. <break/></paragraph></list-item><list-item><paragraph><bold>Clear wrong answer:</bold> for (iii) it concluded the elbow \u201cmoves left\u201d as the expression gets larger, but the expression is negative so becoming \u201cless negative\u201d means it actually moves <bold>right</bold>. <break/></paragraph></list-item><list-item><paragraph><bold>Even when it got the final direction right:</bold> its proof sketch ended with a bogus condition like w&gt;bx.</paragraph></list-item></list><paragraph>After I nudged it with an \u201calgebra-first + sanity-check\u201d checklist (explicitly compute e\u2032=\u2212b\u2032/w\u2032, be careful when w&lt;0, and verify with a tiny numeric example), Gemini improved a lot. It stopped hand-waving the geometry, caught its own sign mistakes when the numeric check contradicted the algebra, and finally gave consistent conclusions across the cases. The conclusion: Gemini is super useful here, but only if you force it to <italic>prove</italic> elbow motion by comparing e\u2032 vs e and validating with a quick counterexample.</paragraph><file url=\"https://static.us.edusercontent.com/files/fdc6jmSeJRKtVVQUGfC1BCM0\" filename=\"gemini_trace_annotated.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-29T12:21:31.421792+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7373978,
            "author": "Tiger Zhang",
            "project_title": "Special Participation E: Gemini 3 (Thinking) As A Converter from Homework to Practice Problems",
            "post_body": "Executive Summary:\n\nI like to prepare for exams by doing practice exam problems, and I\u2019m sure many are like me too. While I think homework problems are a great way to actually learn and understand concepts in the class, I think it\u2019s also good to have exam-style practice problems that test at the understanding gained from the homework assignments, and that require a \u201cfaster pace\u201d than do homework problems.\n\nTherefore, I prompted Gemini 3 to write an exam problem set based on a homework problem set, extending the homework problems in interesting and stimulating ways. I guided it to write problems that use intuition built from homeworks so I cannot just skip the homeworks and do the exam problems.\n\nThe result: I now have a simple four-prompt pipeline that simulates the practice test experience on a homework assignment, as it outputs both the practice exam problems and the practice exam solutions. It takes in the homework that the user desires to have corresponding exam problems for, as well as a few examples of exam problems (some are released in some homeworks).\n\nAlthough some output exam problems were quite similar to homework problems, they do change the homework problems slightly, and the rest of the problems are still different from homework problems.\n\nDifficulty: a difficulty I faced when building this pipeline is actually tuning the difficulty of the exam problems. By changing the third prompt (the \u201cwrite the problems\u201d prompt), the difficulty ranged from too difficult (requires memorization of details of the results from the homework) to very easy (simple plug and chug). If users dislike the difficulty of the problems from this pipeline, I propose changing the third prompt.\n\nChat log: \n\n(I boxed my prompts)\n\nHomework 1 exam problems:\n\nHomework 1 exam problems (unannotated):\n\nHomework 1 exam problem solutions:\n\nHomework 1 exam problems solutions (unannotated):",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold>:</paragraph><paragraph>I like to prepare for exams by doing practice exam problems, and I\u2019m sure many are like me too. While I think homework problems are a great way to actually learn and understand concepts in the class, I think it\u2019s also good to have exam-style practice problems that test at the understanding gained from the homework assignments, and that require a \u201cfaster pace\u201d than do homework problems.</paragraph><paragraph>Therefore, I prompted Gemini 3 to write an exam problem set based on a homework problem set, extending the homework problems in interesting and stimulating ways. I guided it to write problems that use intuition built from homeworks so I <bold>cannot just skip the homeworks</bold> and do the exam problems.</paragraph><paragraph>The result: I now have a simple four-prompt pipeline that simulates the practice test experience on a homework assignment, as it outputs both the practice exam problems and the practice exam solutions. It takes in the homework that the user desires to have corresponding exam problems for, as well as a few examples of exam problems (some are released in some homeworks).</paragraph><paragraph>Although some output exam problems were quite similar to homework problems, they do change the homework problems slightly, and the rest of the problems are still different from homework problems.</paragraph><paragraph>Difficulty: a difficulty I faced when building this pipeline is actually tuning the difficulty of the exam problems. By changing the third prompt (the \u201cwrite the problems\u201d prompt), the difficulty ranged from too difficult (requires memorization of details of the results from the homework) to very easy (simple plug and chug). If users dislike the difficulty of the problems from this pipeline, I propose changing the third prompt.</paragraph><paragraph>Chat log: </paragraph><file url=\"https://static.us.edusercontent.com/files/UgyJ3lokWUhEbhzgnOfe3RBU\" filename=\"conversation.pdf\"/><paragraph>(I boxed my prompts)</paragraph><paragraph>Homework 1 exam problems:</paragraph><file url=\"https://static.us.edusercontent.com/files/GdbnlVUgpzi1SUWKocJvjdng\" filename=\"exam.pdf\"/><paragraph>Homework 1 exam problems (unannotated):</paragraph><file url=\"https://static.us.edusercontent.com/files/nn3twYK8NpJ8afEWpu55vtnh\" filename=\"exam_clean.pdf\"/><paragraph>Homework 1 exam problem solutions:</paragraph><file url=\"https://static.us.edusercontent.com/files/cC2bOGSdQdyQM2x4HXsrshSr\" filename=\"sol.pdf\"/><paragraph>Homework 1 exam problems solutions (unannotated):</paragraph><file url=\"https://static.us.edusercontent.com/files/zdsPG0yCIa2DXw7ixEEN88QO\" filename=\"sol_clean.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-29T12:02:40.20453+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7373861,
            "author": "Shervin Goudarzi",
            "project_title": "Special Participation A: Gemini-Pro 3 on HW9",
            "post_body": "I used Gemini-pro 3 on HW 9 and it performed very well. The main issues with Gemini-pro 3 was the small details in arithmetics that needed correction especially in linear algebra and time/space complexity; however, the solutions were overwhelmingly correct. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/YFGYzcL72ilmBQtfeDK4gb3h\" filename=\"Special_Participation_A.pdf\"/><paragraph>I used Gemini-pro 3 on HW 9 and it performed very well. The main issues with Gemini-pro 3 was the small details in arithmetics that needed correction especially in linear algebra and time/space complexity; however, the solutions were overwhelmingly correct. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-29T11:05:16.255596+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7372448,
            "author": "Zesheng Cai",
            "project_title": "Special Participation A: Deepseek on Hw8",
            "post_body": "For HW8, I first provided Deepseek with a set of instructions to encourage step-by-step reasoning and self-verification. For each problem, I supplied both the image of the question and a direct copy-and-paste text version. After observing its behavior throughout the assignment, I summarized several notable characteristics:\n\n1. Its self-checking mechanism was largely ineffective.\n Although Deepseek always performed a \u201cself-examination\u201d step, it rarely identified actual mistakes. Most of the time, it simply reiterated the correctness of its own answer rather than performing a thorough or systematic review of potential oversights.\n\n2. It occasionally misinterprets small details in the prompt, though its overall understanding remains accurate.\n These misunderstandings were usually minor (e.g., subtle assumptions or edge cases), but they indicate that Deepseek may overlook fine-grained nuances in certain problem statements.\n\n3. Its reasoning and explanatory abilities are very strong.\n Deepseek is well-suited for explaining solution steps and clarifying concepts. Since HW8 did not contain many heavy calculations, its computational accuracy appeared reliable in this context.\n\n4. Its conversational and correction capabilities are adequate, but its error-localization ability is weak.\n When its solution was incorrect, Deepseek could fix the issue once I explicitly pointed out the problem. However, it generally struggled to independently locate the exact source of the error without guidance.\n\nOverall, Deepseek performs well as a conceptual explanation tool but still requires human intervention for precise error detection and critical verification. Attached below is a PDF of my conversation with deepseek.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/x8hk84H0BEmHXC8WWhy5n9r2\" filename=\"Special Participation A hw8 deepseek.pdf\"/><paragraph>For HW8, I first provided Deepseek with a set of instructions to encourage step-by-step reasoning and self-verification. For each problem, I supplied both the image of the question and a direct copy-and-paste text version. After observing its behavior throughout the assignment, I summarized several notable characteristics:</paragraph><paragraph><bold>1. Its self-checking mechanism was largely ineffective.</bold><break/> Although Deepseek always performed a \u201cself-examination\u201d step, it rarely identified actual mistakes. Most of the time, it simply reiterated the correctness of its own answer rather than performing a thorough or systematic review of potential oversights.</paragraph><paragraph><bold>2. It occasionally misinterprets small details in the prompt</bold>, though its overall understanding remains accurate.<break/> These misunderstandings were usually minor (e.g., subtle assumptions or edge cases), but they indicate that Deepseek may overlook fine-grained nuances in certain problem statements.</paragraph><paragraph><bold>3. Its reasoning and explanatory abilities are very strong.</bold><break/> Deepseek is well-suited for explaining solution steps and clarifying concepts. Since HW8 did not contain many heavy calculations, its computational accuracy appeared reliable in this context.</paragraph><paragraph><bold>4. Its conversational and correction capabilities are adequate, but its error-localization ability is weak.</bold><break/> When its solution was incorrect, Deepseek could fix the issue once I explicitly pointed out the problem. However, it generally struggled to independently locate the exact source of the error without guidance.</paragraph><paragraph>Overall, Deepseek performs well as a conceptual explanation tool but still requires human intervention for precise error detection and critical verification. Attached below is a PDF of my conversation with deepseek.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-28T21:00:50.226819+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7372401,
            "author": "Faiaz Khan",
            "project_title": "Special Participation E: Staff Notebook Deep-Dive & Code Review Tutor using ChatGPT Study Mode",
            "post_body": "What this is:\nWe often get staff solution notebooks that are 100% correct but not necessarily the best examples of Python or ML engineering practices. I made a reusable prompt that turns ChatGPT  into:\n\na tutor that explains the solution code,\n\na Socratic \u201cwhat if we changed this line?\u201d partner, and\n\na code reviewer that critiques style, structure, and engineering practices.\n\nHow to use it:\n\nOpen ChatGPT and enable Study Mode.\n\nStart a new chat and upload the .ipynb with the staff solution.\n\nPaste the big prompt below.\n\nOptionally tell it your comfort level with Python / ML.\n\nLet it walk you through:\n\nan overview of the problem and solution,\n\ninteractive what-if questions about code changes,\n\nand a software-engineering critique plus suggested refactors.\n\nPrompt:\n\nYou are an AI tutor and code reviewer for a Jupyter notebook that contains:\n\n- a coding / ML problem,\n- and the staff-provided solution (and possibly some tests or helper code).\n\nYour goals:\n(1) Help me deeply understand the staff solution.\n(2) Actively quiz me with \u201cwhat-if\u201d code modification questions.\n(3) Critique the solution as a piece of software / ML engineering, not just as a correct answer.\n\nI will upload a .ipynb file. Please work in the following phases.\n\n########################\nPHASE 0 \u2014 ORIENT YOURSELF\n########################\n\nAfter reading the notebook:\n\n1. Identify and briefly summarize:\n   - The **problem statement** (in your own words).\n   - Where the **main staff solution** lives (e.g., which cell / which function).\n   - Any **supporting code** (helpers, tests, imports, plotting, etc.).\n\n2. Output a short overview like:\n\n   - Problem: [...]\n   - Main solution entry point: [...]\n   - Key helper functions: [...]\n   - Tests / demo cells: [...]\n\nIf anything is ambiguous, say so instead of guessing.\n\n########################\nPHASE 1 \u2014 EXPLAIN THE SOLUTION\n########################\n\nAssume I am a student who:\n- knows basic Python,\n- is familiar with lists/dicts/functions/loops,\n- but may *not* know the specific algorithm or ML technique yet.\n\nDo the following:\n\n1. **High-level explanation (3\u20137 sentences)**  \n   - What is the core idea of the solution?\n   - What algorithm / pattern does it implement (e.g., DP, DFS, greedy, training loop, etc.)?\n\n2. **Guided code walkthrough**  \n   - Walk through the main solution function or cell **top-down**.\n   - Group lines into logical chunks instead of line-by-line noise.\n   - For each chunk, explain:\n     - what it does,\n     - why it\u2019s needed,\n     - how it connects to the problem definition.\n\n3. **Complexity / behavior**  \n   - State the time and space complexity if meaningful.\n   - Mention any tradeoffs (e.g., readability vs performance, memory vs speed).\n\nKeep this phase mostly explanatory, with occasional quick checks like:\n> \u201cCan you tell me in your own words what this loop is doing before I explain it?\u201d\n\n########################\nPHASE 2 \u2014 INTERACTIVE \u201cWHAT IF?\u201d QUESTIONS\n########################\n\nNow I want you to test and deepen my understanding by asking questions about code changes.\n\n1. Ask **3\u20136 \u201cwhat if\u201d questions** such as:\n   - \u201cWhat do you think happens if we remove this condition?\u201d\n   - \u201cIf we change this list to a set, how does that affect correctness and complexity?\u201d\n   - \u201cWhat if we change the iteration order here?\u201d\n   - \u201cWhat if we initialize this variable differently?\u201d\n\n2. For each question:\n   - Wait for my answer first.\n   - Then:\n     - say what *would* actually happen (behavior / correctness / performance),\n     - and tie it back to the underlying concept or invariant.\n\n3. Start with simpler changes (e.g., altering a constant or print) and\n   move toward more subtle ones (e.g., off-by-one edges, shared mutable state, ML training details).\n\nIf the code involves randomness or ML training:\n- Ask at least one question about seeds, reproducibility, or how hyperparameters show up in the code.\n\n########################\nPHASE 3 \u2014 SOFTWARE / ML ENGINEERING CRITIQUE\n########################\n\nNow critique the staff solution as if you were a senior software or ML engineer reviewing it.\n\n1. **Style & Pythonic-ness**\n   - Comment on:\n     - naming (variables, functions),\n     - function length and cohesion,\n     - use of built-in functions / libraries,\n     - avoiding repetition,\n     - clarity vs cleverness.\n   - Point out at least 3\u20135 concrete improvements, such as:\n     - \u201cThis nested if could be simplified.\u201d\n     - \u201cThis magic number should be a named constant.\u201d\n     - \u201cThis could use a context manager / list comprehension / enumerate, etc.\u201d\n\n2. **Structure & modularity**\n   - Is the solution written as one big cell, or decomposed into testable functions?\n   - Could it benefit from:\n     - helper functions,\n     - separating pure logic from I/O,\n     - or separating data loading / config from core algorithm?\n\n3. **Documentation & comments**\n   - Are there docstrings or comments explaining key decisions?\n   - Suggest where short comments or docstrings would significantly improve readability.\n   - Optionally sketch an example docstring for the main function (using a standard style like NumPy or Google style).\n\n4. **Testing & edge cases**\n   - Does the notebook include tests or sample runs?\n   - What edge cases might be missing?\n   - Propose **3\u20135 simple test cases** that would be good to add (in plain English or as Python snippets).\n\n5. **ML engineering (if applicable)**\n   - If the notebook includes any training/eval code:\n     - Comment on:\n       - seeding / reproducibility,\n       - separation of config (hyperparameters) from code,\n       - logging / metrics,\n       - handling of train/val/test,\n       - use of vectorization vs for-loops.\n     - Suggest at least a couple of improvements (e.g., \u201cmove these constants to a config dict,\u201d \u201cuse a random seed,\u201d etc.).\n\n6. **Concrete improved snippet(s)**\n   - Choose ONE small function or core block from the staff solution.\n   - Show:\n     - \u201cOriginal version\u201d (copied and possibly shortened)\n     - \u201cImproved version\u201d (your more Pythonic / maintainable rewrite)\n   - Explain in 3\u20135 bullets what changed and why it\u2019s better (clarity, safety, extensibility, etc.).\n\nIMPORTANT:\n- Do NOT rewrite the entire notebook unless I explicitly ask.\n- Focus on *illustrative* improvements that a student can learn from.\n\n########################\nPHASE 4 \u2014 SUMMARY & ACTIONABLE NEXT STEPS\n########################\n\nFinish by giving me:\n\n1. A **conceptual summary**:\n   - 3\u20136 bullets summarizing:\n     - the algorithm / method used,\n     - the key ideas in the implementation,\n     - and the main software-engineering lessons.\n\n2. A **mini checklist** of things I could do on my own:\n   - e.g., \n     - \u201cRefactor the main function into two helpers,\u201d\n     - \u201cAdd tests for these edge cases,\u201d\n     - \u201cRewrite this loop using a more Pythonic construct.\u201d\n\n3. Ask me:\n   - \u201cWhich part of this notebook do you feel you understand the least?\u201d\n   - \u201cDo you want to zoom in further on a particular function or cell?\u201d\n\n########################\nSTYLE & SAFETY\n########################\n\n- Be direct but encouraging; assume I am capable of understanding serious critique.\n- Don\u2019t just say \u201cthis is bad\u201d; explain *why* and how to improve it.\n- If you are inferring intent that is not explicit in the notebook, make that clear:\n  > \u201cI\u2019m inferring that this function is meant to do X based on Y; if that\u2019s wrong, let\u2019s adjust.\u201d\n- Avoid hallucinating details that don\u2019t appear in the notebook. If something is unclear, say so.\n\n\n\nMy annotated chat:\nI tried this on the staff solution for Homework 7 RNN LSTM implementation. Here\u2019s my annotated chat trace (PDF):\n\nhttps://chatgpt.com/share/69295e36-3fd4-8010-9710-56a0c2e28752\n In the annotations I point out:\n\nwhere the AI gave good explanations,\n\nwhere its code critiques matched or conflicted with what our course emphasizes,\n\nand where it hallucinated or misread the notebook.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>What this is:</bold><break/>We often get staff solution notebooks that are 100% correct but not necessarily the best examples of Python or ML engineering practices. I made a reusable prompt that turns ChatGPT  into:</paragraph><list style=\"unordered\"><list-item><paragraph>a tutor that explains the solution code,</paragraph></list-item><list-item><paragraph>a Socratic \u201cwhat if we changed this line?\u201d partner, and</paragraph></list-item><list-item><paragraph>a code reviewer that critiques style, structure, and engineering practices.</paragraph></list-item></list><paragraph><bold>How to use it:</bold></paragraph><list style=\"ordered\"><list-item><paragraph>Open ChatGPT and enable Study Mode.</paragraph></list-item><list-item><paragraph>Start a new chat and upload the <code>.ipynb</code> with the staff solution.</paragraph></list-item><list-item><paragraph>Paste the big prompt below.</paragraph></list-item><list-item><paragraph>Optionally tell it your comfort level with Python / ML.</paragraph></list-item><list-item><paragraph>Let it walk you through:</paragraph><list style=\"unordered\"><list-item><paragraph>an overview of the problem and solution,</paragraph></list-item><list-item><paragraph>interactive what-if questions about code changes,</paragraph></list-item><list-item><paragraph>and a software-engineering critique plus suggested refactors.</paragraph></list-item></list></list-item></list><paragraph><bold>Prompt:</bold></paragraph><pre>You are an AI tutor and code reviewer for a Jupyter notebook that contains:\r\n\r\n- a coding / ML problem,\r\n- and the staff-provided solution (and possibly some tests or helper code).\r\n\r\nYour goals:\r\n(1) Help me deeply understand the staff solution.\r\n(2) Actively quiz me with \u201cwhat-if\u201d code modification questions.\r\n(3) Critique the solution as a piece of software / ML engineering, not just as a correct answer.\r\n\r\nI will upload a .ipynb file. Please work in the following phases.\r\n\r\n########################\r\nPHASE 0 \u2014 ORIENT YOURSELF\r\n########################\r\n\r\nAfter reading the notebook:\r\n\r\n1. Identify and briefly summarize:\r\n   - The **problem statement** (in your own words).\r\n   - Where the **main staff solution** lives (e.g., which cell / which function).\r\n   - Any **supporting code** (helpers, tests, imports, plotting, etc.).\r\n\r\n2. Output a short overview like:\r\n\r\n   - Problem: [...]\r\n   - Main solution entry point: [...]\r\n   - Key helper functions: [...]\r\n   - Tests / demo cells: [...]\r\n\r\nIf anything is ambiguous, say so instead of guessing.\r\n\r\n########################\r\nPHASE 1 \u2014 EXPLAIN THE SOLUTION\r\n########################\r\n\r\nAssume I am a student who:\r\n- knows basic Python,\r\n- is familiar with lists/dicts/functions/loops,\r\n- but may *not* know the specific algorithm or ML technique yet.\r\n\r\nDo the following:\r\n\r\n1. **High-level explanation (3\u20137 sentences)**  \r\n   - What is the core idea of the solution?\r\n   - What algorithm / pattern does it implement (e.g., DP, DFS, greedy, training loop, etc.)?\r\n\r\n2. **Guided code walkthrough**  \r\n   - Walk through the main solution function or cell **top-down**.\r\n   - Group lines into logical chunks instead of line-by-line noise.\r\n   - For each chunk, explain:\r\n     - what it does,\r\n     - why it\u2019s needed,\r\n     - how it connects to the problem definition.\r\n\r\n3. **Complexity / behavior**  \r\n   - State the time and space complexity if meaningful.\r\n   - Mention any tradeoffs (e.g., readability vs performance, memory vs speed).\r\n\r\nKeep this phase mostly explanatory, with occasional quick checks like:\r\n&gt; \u201cCan you tell me in your own words what this loop is doing before I explain it?\u201d\r\n\r\n########################\r\nPHASE 2 \u2014 INTERACTIVE \u201cWHAT IF?\u201d QUESTIONS\r\n########################\r\n\r\nNow I want you to test and deepen my understanding by asking questions about code changes.\r\n\r\n1. Ask **3\u20136 \u201cwhat if\u201d questions** such as:\r\n   - \u201cWhat do you think happens if we remove this condition?\u201d\r\n   - \u201cIf we change this list to a set, how does that affect correctness and complexity?\u201d\r\n   - \u201cWhat if we change the iteration order here?\u201d\r\n   - \u201cWhat if we initialize this variable differently?\u201d\r\n\r\n2. For each question:\r\n   - Wait for my answer first.\r\n   - Then:\r\n     - say what *would* actually happen (behavior / correctness / performance),\r\n     - and tie it back to the underlying concept or invariant.\r\n\r\n3. Start with simpler changes (e.g., altering a constant or print) and\r\n   move toward more subtle ones (e.g., off-by-one edges, shared mutable state, ML training details).\r\n\r\nIf the code involves randomness or ML training:\r\n- Ask at least one question about seeds, reproducibility, or how hyperparameters show up in the code.\r\n\r\n########################\r\nPHASE 3 \u2014 SOFTWARE / ML ENGINEERING CRITIQUE\r\n########################\r\n\r\nNow critique the staff solution as if you were a senior software or ML engineer reviewing it.\r\n\r\n1. **Style &amp; Pythonic-ness**\r\n   - Comment on:\r\n     - naming (variables, functions),\r\n     - function length and cohesion,\r\n     - use of built-in functions / libraries,\r\n     - avoiding repetition,\r\n     - clarity vs cleverness.\r\n   - Point out at least 3\u20135 concrete improvements, such as:\r\n     - \u201cThis nested if could be simplified.\u201d\r\n     - \u201cThis magic number should be a named constant.\u201d\r\n     - \u201cThis could use a context manager / list comprehension / enumerate, etc.\u201d\r\n\r\n2. **Structure &amp; modularity**\r\n   - Is the solution written as one big cell, or decomposed into testable functions?\r\n   - Could it benefit from:\r\n     - helper functions,\r\n     - separating pure logic from I/O,\r\n     - or separating data loading / config from core algorithm?\r\n\r\n3. **Documentation &amp; comments**\r\n   - Are there docstrings or comments explaining key decisions?\r\n   - Suggest where short comments or docstrings would significantly improve readability.\r\n   - Optionally sketch an example docstring for the main function (using a standard style like NumPy or Google style).\r\n\r\n4. **Testing &amp; edge cases**\r\n   - Does the notebook include tests or sample runs?\r\n   - What edge cases might be missing?\r\n   - Propose **3\u20135 simple test cases** that would be good to add (in plain English or as Python snippets).\r\n\r\n5. **ML engineering (if applicable)**\r\n   - If the notebook includes any training/eval code:\r\n     - Comment on:\r\n       - seeding / reproducibility,\r\n       - separation of config (hyperparameters) from code,\r\n       - logging / metrics,\r\n       - handling of train/val/test,\r\n       - use of vectorization vs for-loops.\r\n     - Suggest at least a couple of improvements (e.g., \u201cmove these constants to a config dict,\u201d \u201cuse a random seed,\u201d etc.).\r\n\r\n6. **Concrete improved snippet(s)**\r\n   - Choose ONE small function or core block from the staff solution.\r\n   - Show:\r\n     - \u201cOriginal version\u201d (copied and possibly shortened)\r\n     - \u201cImproved version\u201d (your more Pythonic / maintainable rewrite)\r\n   - Explain in 3\u20135 bullets what changed and why it\u2019s better (clarity, safety, extensibility, etc.).\r\n\r\nIMPORTANT:\r\n- Do NOT rewrite the entire notebook unless I explicitly ask.\r\n- Focus on *illustrative* improvements that a student can learn from.\r\n\r\n########################\r\nPHASE 4 \u2014 SUMMARY &amp; ACTIONABLE NEXT STEPS\r\n########################\r\n\r\nFinish by giving me:\r\n\r\n1. A **conceptual summary**:\r\n   - 3\u20136 bullets summarizing:\r\n     - the algorithm / method used,\r\n     - the key ideas in the implementation,\r\n     - and the main software-engineering lessons.\r\n\r\n2. A **mini checklist** of things I could do on my own:\r\n   - e.g., \r\n     - \u201cRefactor the main function into two helpers,\u201d\r\n     - \u201cAdd tests for these edge cases,\u201d\r\n     - \u201cRewrite this loop using a more Pythonic construct.\u201d\r\n\r\n3. Ask me:\r\n   - \u201cWhich part of this notebook do you feel you understand the least?\u201d\r\n   - \u201cDo you want to zoom in further on a particular function or cell?\u201d\r\n\r\n########################\r\nSTYLE &amp; SAFETY\r\n########################\r\n\r\n- Be direct but encouraging; assume I am capable of understanding serious critique.\r\n- Don\u2019t just say \u201cthis is bad\u201d; explain *why* and how to improve it.\r\n- If you are inferring intent that is not explicit in the notebook, make that clear:\r\n  &gt; \u201cI\u2019m inferring that this function is meant to do X based on Y; if that\u2019s wrong, let\u2019s adjust.\u201d\r\n- Avoid hallucinating details that don\u2019t appear in the notebook. If something is unclear, say so.\r\n\n</pre><paragraph><bold>My annotated chat:</bold><break/>I tried this on the staff solution for Homework 7 RNN LSTM implementation. Here\u2019s my annotated chat trace (PDF):</paragraph><file url=\"https://static.us.edusercontent.com/files/a892iEevSEYlg86E8cxYe11L\" filename=\"RNN LSTM implementation.pdf\"/><paragraph>https://chatgpt.com/share/69295e36-3fd4-8010-9710-56a0c2e28752<break/> In the annotations I point out:</paragraph><list style=\"unordered\"><list-item><paragraph>where the AI gave good explanations,</paragraph></list-item><list-item><paragraph>where its code critiques matched or conflicted with what our course emphasizes,</paragraph></list-item><list-item><paragraph>and where it hallucinated or misread the notebook.</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-28T19:53:55.03587+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7372317,
            "author": "Xi Cheng",
            "project_title": "Special Participation E: AI-Enhanced Pre-homework Study Workflow Using Mistral AI",
            "post_body": "For this assignment, I built an AI-enhanced learning tool that serves as a substitute for traditional pre-homework readings. Here I use Mistral AI on HW08. \n\nMy goal was not to obtain solutions, but to construct a structured conceptual scaffold before attempting the homework. To do this, I asked the LLM to generate a pre-instruction guide that identifies the major concepts, prerequisites, and reasoning pathways needed for the SSM and attention problems. As shown in the annotated interaction trace , I intentionally framed my prompts so that the model would function like a pre-lecture resource rather than a homework solver.\n\nA central part of my prompting strategy was requesting \u201chints only\u201d instead of answers. I highlighted this in my annotations because it forces me to reconstruct derivations myself, rather than copying a completed solution. This approach supports the assignment\u2019s goal of encouraging self-learning. \n\nCompared with traditional pre-lecture materials, this AI-based tool offers a more interactive and adaptive experience. Instead of passively reading a static explanation, I can ask follow-up questions, request clarification, and explore prerequisite concepts dynamically. \n\nThe workflow\u2014beginning with a conceptual overview, followed by prerequisite review, then question-specific hints and common pitfalls\u2014can be applied to any technical topic in the course. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/5kfBIWvpAxbO50NTUgToOuhF\" filename=\"partE_mistral_hw8.pdf\"/><paragraph>For this assignment, I built an AI-enhanced learning tool that serves as a substitute for traditional pre-homework readings. Here I use Mistral AI on HW08. </paragraph><paragraph>My goal was not to obtain solutions, but to construct a structured conceptual scaffold before attempting the homework. To do this, I asked the LLM to generate a pre-instruction guide that identifies the major concepts, prerequisites, and reasoning pathways needed for the SSM and attention problems. As shown in the annotated interaction trace , I intentionally framed my prompts so that the model would function like a pre-lecture resource rather than a homework solver.</paragraph><paragraph>A central part of my prompting strategy was requesting \u201chints only\u201d instead of answers. I highlighted this in my annotations because it forces me to reconstruct derivations myself, rather than copying a completed solution. This approach supports the assignment\u2019s goal of encouraging self-learning. </paragraph><paragraph>Compared with traditional pre-lecture materials, this AI-based tool offers a more interactive and adaptive experience. Instead of passively reading a static explanation, I can ask follow-up questions, request clarification, and explore prerequisite concepts dynamically. </paragraph><paragraph>The workflow\u2014beginning with a conceptual overview, followed by prerequisite review, then question-specific hints and common pitfalls\u2014can be applied to any technical topic in the course. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-28T17:56:19.887587+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7372302,
            "author": "Faiaz Khan",
            "project_title": "Special Participation E: Using an AI \u201cPre-/Post-Lecture Tutor\u201d using ChatGPT Study Mode",
            "post_body": "What this is:\n I made a reusable prompt that turns ChatGPT an interactive lecture companion instead of just a solution engine. You upload a lecture\u2019s slides or notes, and the model:\n\nwalks through the lecture in small chunks,\n\nforces you to answer questions before it explains,\n\ncompares your answers directly to slides,\n\nand ends with a short summary + quiz.\n\nHow to use it:\n\nOpen ChatGPT in Study Mode.\n\nPaste the big prompt below as your first message.\n\nUpload the slides for Lecture [X \u2013 Topic].\n\nTell it whether this is pre-lecture or post-lecture study.\n\nLet it quiz you chunk-by-chunk.\n\nThe Prompt:\n\nYou are an AI tutor helping me actively learn one lecture in a course.\n\n[COURSE]: e.g., \u201cCS XXX: [Course name]\u201d\n[LECTURE # AND TOPIC]: e.g., \u201cLecture 22 \u2013 Prompt-Based Fine-Tuning Methods\u201d\n[RESOURCES I WILL PROVIDE]: e.g., slides PDF, lecture notes, or textbook section.\n\nYour job is to act like an interactive pre-/post-lecture reading replacement.\n\n### MATERIAL HANDLING\n1. ONLY treat the files/notes I give you as the primary source of truth.\n2. When answering, explicitly separate:\n   - (a) \u201cAccording to the lecture materials, \u2026\u201d\n   - (b) \u201cBeyond the lecture, I infer/guess that \u2026\u201d\n3. If something is NOT in the materials or you are unsure, say:\n   > \u201cI\u2019m not sure from the provided materials; this is an educated guess.\u201d\n\n### INTERACTION LOOP\nFor this lecture, repeat the following cycle:\n\n**Step 0 \u2014 Calibrate**\n- Ask me:\n  - what my background is,\n  - how confident I feel about this topic (1\u20135),\n  - whether we are doing *pre-lecture* or *post-lecture* study.\n\n**Step 1 \u2014 Select a small chunk**\n- Pick a manageable chunk of content:\n  - e.g., 1\u20133 slides, or 1 short section of notes.\n- Tell me which slides/section we\u2019re focusing on:\n  > \u201cLet\u2019s focus on slides 5\u20137: [short description].\u201d\n\n**Step 2 \u2014 Active recall before explanation**\n- Ask 2\u20134 questions that I must answer *before* you explain anything, such as:\n  - \u201cIn your own words, what problem is this method solving?\u201d\n  - \u201cWhy is this assumption important?\u201d\n  - \u201cCan you restate the main equation and what each term means conceptually?\u201d\n\n- Always start with me, not you:\n  > \u201cAnswer in 2\u20134 sentences. It\u2019s okay to be wrong; I\u2019ll help refine.\u201d\n\n**Step 3 \u2014 Feedback + correction**\n- Compare my answer to the materials.\n- Do NOT just say \u201ccorrect/incorrect\u201d. Instead:\n  - Highlight what I did well.\n  - Point out exactly what is missing or mistaken.\n  - Quote or paraphrase the relevant part of the slides/notes to support your feedback.\n- If I\u2019m very off, give me a *hint* and ask me to try again before giving the full explanation.\n\n**Step 4 \u2014 Deepen understanding**\n- After feedback, give a concise explanation (max ~5 sentences) that:\n  - connects this chunk to previous lecture ideas,\n  - uses examples or analogies,\n  - mentions any common misconceptions.\n\n- OPTIONAL: Ask one \u201ctransfer\u201d question:\n  > \u201cHow would this change if [variant scenario]?\u201d\n\n**Step 5 \u2014 Quick check**\n- Ask me 1\u20132 short quiz questions (conceptual or very light math).\n- Then show me the answers so I can self-check.\n\n**Step 6 \u2014 Move on or review**\n- Ask:\n  > \u201cOn a scale of 1\u20135, how comfortable do you feel with this chunk?\u201d\n- If I say \u2264 3, offer a different explanation style (more examples, slower, or more visual).\n- If I say \u2265 4, move on to the next chunk.\n\n### END OF SESSION\nWhen I say I\u2019m done or we reach the end, do all of the following:\n\n1. Give a **3\u20136 bullet-point summary** of the lecture in your own words.\n2. Create:\n   - (a) 3 multiple-choice questions (with answers),\n   - (b) 3 short-answer conceptual questions (with brief answer keys).\n3. Ask ME:\n   - \u201cWhat still feels confusing?\u201d\n   - \u201cWhat is one thing you\u2019d like to revisit tomorrow?\u201d\n4. Suggest a short spaced-repetition plan for the next week based on this lecture.\n\n### STYLE & SAFETY\n- Be concise, friendly, and non-judgmental.\n- Never just dump full solutions to typical homework-style questions without first:\n  - asking for my attempt or idea,\n  - and then walking me through step-by-step.\n- Aggressively avoid hallucinations: if there is any conflict between your prior knowledge and the slides, defer to the slides and flag the mismatch.\n\n\n\n\nMy interaction trace + commentary:\n I tried this on Lecture 20: Positional Encoding & Modern Architectures. Here\u2019s the annotated PDF of the conversation: [link].\n In the annotations, I point out:\n\nwhere the model closely followed the prompt and was really helpful,\n\nwhere it hallucinated details that weren\u2019t in the slides,\n\nand some ideas for improving the prompt for future use.\n\nhttps://chatgpt.com/share/692944c7-5ef4-8010-ba41-cece83a423e0",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>What this is:</bold><break/> I made a reusable prompt that turns ChatGPT an <italic>interactive lecture companion</italic> instead of just a solution engine. You upload a lecture\u2019s slides or notes, and the model:</paragraph><list style=\"unordered\"><list-item><paragraph>walks through the lecture in small chunks,</paragraph></list-item><list-item><paragraph>forces you to answer questions before it explains,</paragraph></list-item><list-item><paragraph>compares your answers directly to slides,</paragraph></list-item><list-item><paragraph>and ends with a short summary + quiz.</paragraph></list-item></list><paragraph><bold>How to use it:</bold></paragraph><list style=\"ordered\"><list-item><paragraph>Open ChatGPT in <bold>Study Mode</bold>.</paragraph></list-item><list-item><paragraph>Paste the big prompt below as your first message.</paragraph></list-item><list-item><paragraph>Upload the slides for Lecture [X \u2013 Topic].</paragraph></list-item><list-item><paragraph>Tell it whether this is pre-lecture or post-lecture study.</paragraph></list-item><list-item><paragraph>Let it quiz you chunk-by-chunk.</paragraph></list-item></list><paragraph><bold>The Prompt:</bold></paragraph><pre>You are an AI tutor helping me actively learn one lecture in a course.\r\n\r\n[COURSE]: e.g., \u201cCS XXX: [Course name]\u201d\r\n[LECTURE # AND TOPIC]: e.g., \u201cLecture 22 \u2013 Prompt-Based Fine-Tuning Methods\u201d\r\n[RESOURCES I WILL PROVIDE]: e.g., slides PDF, lecture notes, or textbook section.\r\n\r\nYour job is to act like an interactive pre-/post-lecture reading replacement.\r\n\r\n### MATERIAL HANDLING\r\n1. ONLY treat the files/notes I give you as the primary source of truth.\r\n2. When answering, explicitly separate:\r\n   - (a) \u201cAccording to the lecture materials, \u2026\u201d\r\n   - (b) \u201cBeyond the lecture, I infer/guess that \u2026\u201d\r\n3. If something is NOT in the materials or you are unsure, say:\r\n   &gt; \u201cI\u2019m not sure from the provided materials; this is an educated guess.\u201d\r\n\r\n### INTERACTION LOOP\r\nFor this lecture, repeat the following cycle:\r\n\r\n**Step 0 \u2014 Calibrate**\r\n- Ask me:\r\n  - what my background is,\r\n  - how confident I feel about this topic (1\u20135),\r\n  - whether we are doing *pre-lecture* or *post-lecture* study.\r\n\r\n**Step 1 \u2014 Select a small chunk**\r\n- Pick a manageable chunk of content:\r\n  - e.g., 1\u20133 slides, or 1 short section of notes.\r\n- Tell me which slides/section we\u2019re focusing on:\r\n  &gt; \u201cLet\u2019s focus on slides 5\u20137: [short description].\u201d\r\n\r\n**Step 2 \u2014 Active recall before explanation**\r\n- Ask 2\u20134 questions that I must answer *before* you explain anything, such as:\r\n  - \u201cIn your own words, what problem is this method solving?\u201d\r\n  - \u201cWhy is this assumption important?\u201d\r\n  - \u201cCan you restate the main equation and what each term means conceptually?\u201d\r\n\r\n- Always start with me, not you:\r\n  &gt; \u201cAnswer in 2\u20134 sentences. It\u2019s okay to be wrong; I\u2019ll help refine.\u201d\r\n\r\n**Step 3 \u2014 Feedback + correction**\r\n- Compare my answer to the materials.\r\n- Do NOT just say \u201ccorrect/incorrect\u201d. Instead:\r\n  - Highlight what I did well.\r\n  - Point out exactly what is missing or mistaken.\r\n  - Quote or paraphrase the relevant part of the slides/notes to support your feedback.\r\n- If I\u2019m very off, give me a *hint* and ask me to try again before giving the full explanation.\r\n\r\n**Step 4 \u2014 Deepen understanding**\r\n- After feedback, give a concise explanation (max ~5 sentences) that:\r\n  - connects this chunk to previous lecture ideas,\r\n  - uses examples or analogies,\r\n  - mentions any common misconceptions.\r\n\r\n- OPTIONAL: Ask one \u201ctransfer\u201d question:\r\n  &gt; \u201cHow would this change if [variant scenario]?\u201d\r\n\r\n**Step 5 \u2014 Quick check**\r\n- Ask me 1\u20132 short quiz questions (conceptual or very light math).\r\n- Then show me the answers so I can self-check.\r\n\r\n**Step 6 \u2014 Move on or review**\r\n- Ask:\r\n  &gt; \u201cOn a scale of 1\u20135, how comfortable do you feel with this chunk?\u201d\r\n- If I say \u2264 3, offer a different explanation style (more examples, slower, or more visual).\r\n- If I say \u2265 4, move on to the next chunk.\r\n\r\n### END OF SESSION\r\nWhen I say I\u2019m done or we reach the end, do all of the following:\r\n\r\n1. Give a **3\u20136 bullet-point summary** of the lecture in your own words.\r\n2. Create:\r\n   - (a) 3 multiple-choice questions (with answers),\r\n   - (b) 3 short-answer conceptual questions (with brief answer keys).\r\n3. Ask ME:\r\n   - \u201cWhat still feels confusing?\u201d\r\n   - \u201cWhat is one thing you\u2019d like to revisit tomorrow?\u201d\r\n4. Suggest a short spaced-repetition plan for the next week based on this lecture.\r\n\r\n### STYLE &amp; SAFETY\r\n- Be concise, friendly, and non-judgmental.\r\n- Never just dump full solutions to typical homework-style questions without first:\r\n  - asking for my attempt or idea,\r\n  - and then walking me through step-by-step.\r\n- Aggressively avoid hallucinations: if there is any conflict between your prior knowledge and the slides, defer to the slides and flag the mismatch.\r\n\n</pre><paragraph><break/><bold>My interaction trace + commentary:</bold><break/> I tried this on Lecture 20: Positional Encoding &amp; Modern Architectures. Here\u2019s the annotated PDF of the conversation: [link].<break/> In the annotations, I point out:</paragraph><list style=\"unordered\"><list-item><paragraph>where the model closely followed the prompt and was really helpful,</paragraph></list-item><list-item><paragraph>where it hallucinated details that weren\u2019t in the slides,</paragraph></list-item><list-item><paragraph>and some ideas for improving the prompt for future use.</paragraph></list-item></list><paragraph>https://chatgpt.com/share/692944c7-5ef4-8010-ba41-cece83a423e0</paragraph><file url=\"https://static.us.edusercontent.com/files/02LPmeNtu5c2neK2LPSCSJRZ\" filename=\"Interactive study session.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-28T17:43:32.737293+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7372287,
            "author": "Guohao Lv",
            "project_title": "Special Participation E: ChatGPT as Motivation Finder from Lecture Notes",
            "post_body": "When I review the lecture notes, I always find it easier to understand a concept after understanding why it is introduced in the first place. Because it is quite laborious to go back to watch the lecture again and sometimes professors just give a very simplified version of the motivation, I built a \u201cMotivation Finder from Lecture Notes\u201d prompt that uses AI to give a more detailed explanation of the motivation of concepts mentioned in lectures and provide good sources for further reading and deeper understanding. The workflow is: I paste a chunk of CS182 lecture notes (for a particular lecture) into the prompt. The AI first scans the text and extracts a small list of key concepts mentioned there (e.g., BatchNorm, residual blocks, attention, muP, etc.). For each concept, it then searches the internet for one good source\u2014ideally the original paper or a survey/tutorial from a reputable venue\u2014and reports the title, link, and type of source. Using that source, it writes a short motivation-focused summary: what problem people were facing before this idea, how the idea addresses that problem at a high level, and what tradeoffs or limitations are mentioned. It then quotes the relevant lines from the lecture notes and tells me whether the notes make the motivation clear, partially clear, or confusing. Finally, for each concept, it asks me 1\u20132 questions that test whether I actually understand the motivation and tradeoffs, waits for my answers, and then gives concise \u201cideal answers.\u201d Overall, I find it quite helpful as a post-lecture reading even though it is still not ideal, and the questions it generate does lead me to go back and read more about the topic, so I think this tool achieves its objective.\n\nThe annotated conversation: https://drive.google.com/file/d/1htjK83ljExmXnUGwNZA2ykykNXQA3ZW_/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>When I review the lecture notes, I always find it easier to understand a concept after understanding why it is introduced in the first place. Because it is quite laborious to go back to watch the lecture again and sometimes professors just give a very simplified version of the motivation, I built a \u201cMotivation Finder from Lecture Notes\u201d prompt that uses AI to give a more detailed explanation of the motivation of concepts mentioned in lectures and provide good sources for further reading and deeper understanding. The workflow is: I paste a chunk of CS182 lecture notes (for a particular lecture) into the prompt. The AI first scans the text and extracts a small list of key concepts mentioned there (e.g., BatchNorm, residual blocks, attention, muP, etc.). For each concept, it then searches the internet for one good source\u2014ideally the original paper or a survey/tutorial from a reputable venue\u2014and reports the title, link, and type of source. Using that source, it writes a short motivation-focused summary: what problem people were facing before this idea, how the idea addresses that problem at a high level, and what tradeoffs or limitations are mentioned. It then quotes the relevant lines from the lecture notes and tells me whether the notes make the motivation clear, partially clear, or confusing. Finally, for each concept, it asks me 1\u20132 questions that test whether I actually understand the motivation and tradeoffs, waits for my answers, and then gives concise \u201cideal answers.\u201d Overall, I find it quite helpful as a post-lecture reading even though it is still not ideal, and the questions it generate does lead me to go back and read more about the topic, so I think this tool achieves its objective.</paragraph><paragraph>The annotated conversation: https://drive.google.com/file/d/1htjK83ljExmXnUGwNZA2ykykNXQA3ZW_/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-28T17:25:53.685301+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7372081,
            "author": "Ken Zheng",
            "project_title": "Special Participation A: Deepseek on HW2",
            "post_body": "I completed all non-coding parts of Homework 2 using Deepseek with DeepThink turned on.\n\nMotivation\n\nI\u2019ve seen quite a few examples of classmates engaging in some light conversation with the model or using somewhat structured/designed prompts with the aim of improving the output quality and accuracy. I opted for a slightly different approach. I decided to use raw and \"no-prompt\" prompting, meant to mimic the setting where a student is treating the LLM less as an interactive tutor and more as a tool, a \u201ccalculator\u201d, for problems. \n\nFor every problem, my process consisted of highlighting the relevant subpart in its entirety on the homework PDF, then copy pasting into the text box. Nothing more. No context was given except for those present in the problem originally, and no prompt optimization was performed (i.e., no strategic \"filler\" words like \"think carefully and answer accurately\", \"you are an expert in deep learning\", \"take a deep breath\" [https://arxiv.org/abs/2309.03409] were included).\n\nSummary\n\nOverall, Deepseek is a very capable model for reasoning tasks. It one-shots every non coding question in Homework 2. It arguably fails to notice one small detail in one of the subparts (see Q1 for more), but apart from that, all perfect. \n\nAnalyzing the thinking trace reveals Deepseek's general chain of thought pattern, which is comprised of these steps:\n\nRestate the question\n\nRe-interpret the question with its own words\n\nList what is given/known\n\nIdentify what is unknown/what the task is\n\nFormulate a strategy/plan of attack\n\nCarry out that strategy (i.e., start doing the work/calculations following the strategy)\n\nAfter finding answer, start doubting absolutely everything starting from step 1 to step 6.\n\nFor every doubt, recheck work and see if other answers exist. If yes, explore those paths; else, move on to the next doubt.\n\nReturn final answer after double-checking everything.\n\nPeople who took EECS 16A with Prof. Ranade (Fall 2023) might remember her teaching us a three step proof writing structure: \n\nWhat do we know?\n\nWhat are we trying to show?\n\nHow can we get from 1 to 2?\n\nIt is interesting to see Deepseek's thought habits closely follow this three step process (plus a plethora of double-checking), almost like Deepseek's frontier-level reasoning performance stems from the fact that it treats every technical question like completing a rigorous proof. \n\nPlease see annotations for more in-depth observations.\n\nFiles & Links\n\nQuestion 1:\n\nQuestion 2:\n\nQuestion 5:",
            "content_xml": "<document version=\"2.0\"><paragraph>I completed all non-coding parts of Homework 2 using Deepseek with DeepThink turned on.</paragraph><paragraph><bold>Motivation</bold></paragraph><paragraph>I\u2019ve seen quite a few examples of classmates engaging in some light conversation with the model or using somewhat structured/designed prompts with the aim of improving the output quality and accuracy. I opted for a slightly different approach. I decided to use raw and \"no-prompt\" prompting, meant to mimic the setting where a student is treating the LLM less as an interactive tutor and more as a tool, a \u201ccalculator\u201d, for problems. </paragraph><paragraph>For every problem, my process consisted of highlighting the relevant subpart in its entirety on the homework PDF, then copy pasting into the text box. Nothing more. No context was given except for those present in the problem originally, and no prompt optimization was performed (i.e., no strategic \"filler\" words like \"think carefully and answer accurately\", \"you are an expert in deep learning\", \"take a deep breath\" [<link href=\"https://arxiv.org/abs/2309.03409\">https://arxiv.org/abs/2309.03409</link>] were included).</paragraph><paragraph><bold>Summary</bold></paragraph><paragraph>Overall, Deepseek is a very capable model for reasoning tasks. It one-shots every non coding question in Homework 2. It arguably fails to notice one small detail in one of the subparts (see Q1 for more), but apart from that, all perfect. </paragraph><paragraph>Analyzing the thinking trace reveals Deepseek's general chain of thought pattern, which is comprised of these steps:</paragraph><list style=\"number\"><list-item><paragraph>Restate the question</paragraph></list-item><list-item><paragraph>Re-interpret the question with its own words</paragraph></list-item><list-item><paragraph>List what is given/known</paragraph></list-item><list-item><paragraph>Identify what is unknown/what the task is</paragraph></list-item><list-item><paragraph>Formulate a strategy/plan of attack</paragraph></list-item><list-item><paragraph>Carry out that strategy (i.e., start doing the work/calculations following the strategy)</paragraph></list-item><list-item><paragraph>After finding answer, start doubting absolutely everything starting from step 1 to step 6.</paragraph></list-item><list-item><paragraph>For every doubt, recheck work and see if other answers exist. If yes, explore those paths; else, move on to the next doubt.</paragraph></list-item><list-item><paragraph>Return final answer after double-checking everything.</paragraph></list-item></list><paragraph>People who took EECS 16A with Prof. Ranade (Fall 2023) might remember her teaching us a three step proof writing structure: </paragraph><list style=\"number\"><list-item><paragraph>What do we know?</paragraph></list-item><list-item><paragraph>What are we trying to show?</paragraph></list-item><list-item><paragraph>How can we get from 1 to 2?</paragraph></list-item></list><paragraph>It is interesting to see Deepseek's thought habits closely follow this three step process (plus a plethora of double-checking), almost like Deepseek's frontier-level reasoning performance stems from the fact that it treats every technical question like completing a rigorous proof. </paragraph><paragraph>Please see annotations for more in-depth observations.</paragraph><paragraph><bold>Files &amp; Links</bold></paragraph><paragraph><link href=\"https://chat.deepseek.com/share/z5g4rvn5xcnnl5iki8\">Question 1</link>:</paragraph><file url=\"https://static.us.edusercontent.com/files/WLOcnHEm5JvQXOZ89iD1WNia\" filename=\"Q1_annotated.pdf\"/><paragraph><link href=\"https://chat.deepseek.com/share/226zldixt6l2dw7qx6\">Question 2</link>:</paragraph><file url=\"https://static.us.edusercontent.com/files/OuWilSbC3lNKib2obGheQgmb\" filename=\"Q2_annotated.pdf\"/><paragraph><link href=\"https://chat.deepseek.com/share/em99xk8xbx2ozer0ba\">Question 5</link>:</paragraph><file url=\"https://static.us.edusercontent.com/files/ZaL9g3VP5ebbYoUJJE6l1Xvb\" filename=\"Q5_annotated.pdf\"/></document>",
            "links": [
                "https://arxiv.org/abs/2309.03409",
                "https://chat.deepseek.com/share/z5g4rvn5xcnnl5iki8",
                "https://chat.deepseek.com/share/226zldixt6l2dw7qx6",
                "https://chat.deepseek.com/share/em99xk8xbx2ozer0ba"
            ],
            "attachments": [],
            "created_at": "2025-11-28T14:45:16.624977+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7370567,
            "author": "Jorge Diaz Chao",
            "project_title": "Kimi K2 Thinking on HW12",
            "post_body": "Kimi K2 Thinking (open-source) stormed the internet not too long ago for beating a lot of benchmarks and competing with closed-source models. To be honest, I don't think benchmarks cover a lot of the story nowadays so I remained skeptical. Today, I tried it for the first time on Homework 12\n\nThe model thinks (particularly?) fast and seems to do very good with a comparable performance to other models like OpenAI's (which I am more familiar with). Shortcomings include the poor vision component. The commentary goes more deeply into how I guided it to do the homework. Ultimately, it did very well and only demanded prompting to describe visual figures and ask for a particular style of responses.\n\nNot a Fireship video but good enough.",
            "content_xml": "<document version=\"2.0\"><paragraph>Kimi K2 Thinking (open-source) stormed the internet not too long ago for beating a lot of benchmarks and competing with closed-source models. To be honest, I don't think benchmarks cover a lot of the story nowadays so I remained skeptical. Today, I tried it for the first time on <link href=\"https://berkeley-cs182.github.io/fa25/assets/assignments/hw12.pdf\"><italic>Homework 12</italic></link></paragraph><file url=\"https://static.us.edusercontent.com/files/BhFLjqUsrviOILVcgt2I0U4B\" filename=\"hw12-kimi-comments.pdf\"/><file url=\"https://static.us.edusercontent.com/files/oQpJwjIlJDavdX1M2NqqbM7e\" filename=\"hw12-kimi-chat.jpg\"/><paragraph>The model thinks (particularly?) fast and seems to do very good with a comparable performance to other models like OpenAI's (which I am more familiar with). Shortcomings include the poor vision component. The commentary goes more deeply into how I guided it to do the homework. Ultimately, it did very well and only demanded prompting to describe visual figures and ask for a particular style of responses.<break/><break/>Not a Fireship <link href=\"https://www.youtube.com/watch?v=ZP9lqjNa_BQ\">video</link> but good enough.</paragraph></document>",
            "links": [
                "https://berkeley-cs182.github.io/fa25/assets/assignments/hw12.pdf",
                "https://www.youtube.com/watch?v=ZP9lqjNa_BQ"
            ],
            "attachments": [],
            "created_at": "2025-11-27T20:04:08.231232+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7369769,
            "author": "Guohao Lv",
            "project_title": "Special Participation E: ChatGPT as a Mistake-Spotting Coach",
            "post_body": "I often use ChatGPT or other LLMs to review CS182 concepts, but I\u2019ve noticed a big problem: it\u2019s very easy to just believe whatever it says. Even when something is slightly wrong or oversimplified, I tend to read it passively instead of thinking about whether it matches what we did in lecture. For this special participation, I wanted a way to turn that into an active exercise where I\u2019m forced to read explanations critically and practice catching subtle mistakes in deep learning concepts. So I designed a \u201cMistake-Spotting Coach\u201d prompt specifically for CS182. The idea is that I give the LLM a lecture topic (for example: SGD vs Adam, normalization layers, residual connections, ConvNets vs fully-connected nets, RNNs vs attention, in-context learning, etc.). Using the prompt, the LLM then writes a short explanation of the topic on purpose with 2\u20133 subtle errors or misleading statements mixed in.  After the explanation, it asks me to find and correct the mistakes before it reveals what was wrong. I then go through and mark which sentences I think are incorrect or suspicious, explain why, and suggest fixes. The LLM responds by telling me which mistakes I caught, which ones I missed, and where my corrections are only partially right. Finally, it rewrites a clean, fully correct explanation and asks a couple of follow-up questions to check deeper understanding. Overall, I think it is helpful for understanding deeplearning concepts, but it still has some problems, which I pointed out in the annotated conversation. A fix would be to add what you want ChatGPT to do to the General Rules section of the prompt (e.g., \"don't highlight the problematic sentences\") so that it can tailor to your own learning goal.\n\nAnnotated Conversation: https://drive.google.com/file/d/1_iLr4riCwdcg3p-_AzwjeLe6kAtF7y2T/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I often use ChatGPT or other LLMs to review CS182 concepts, but I\u2019ve noticed a big problem: it\u2019s very easy to just <italic>believe</italic> whatever it says. Even when something is slightly wrong or oversimplified, I tend to read it passively instead of thinking about whether it matches what we did in lecture. For this special participation, I wanted a way to turn that into an active exercise where I\u2019m forced to read explanations critically and practice catching subtle mistakes in deep learning concepts. So I designed a \u201cMistake-Spotting Coach\u201d prompt specifically for CS182. The idea is that I give the LLM a lecture topic (for example: SGD vs Adam, normalization layers, residual connections, ConvNets vs fully-connected nets, RNNs vs attention, in-context learning, etc.). Using the prompt, the LLM then writes a short explanation of the topic <italic>on purpose</italic> with 2\u20133 subtle errors or misleading statements mixed in.  After the explanation, it asks me to find and correct the mistakes before it reveals what was wrong. I then go through and mark which sentences I think are incorrect or suspicious, explain why, and suggest fixes. The LLM responds by telling me which mistakes I caught, which ones I missed, and where my corrections are only partially right. Finally, it rewrites a clean, fully correct explanation and asks a couple of follow-up questions to check deeper understanding. Overall, I think it is helpful for understanding deeplearning concepts, but it still has some problems, which I pointed out in the annotated conversation. A fix would be to add what you want ChatGPT to do to the General Rules section of the prompt (e.g., \"don't highlight the problematic sentences\") so that it can tailor to your own learning goal.</paragraph><paragraph>Annotated Conversation: https://drive.google.com/file/d/1_iLr4riCwdcg3p-_AzwjeLe6kAtF7y2T/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-27T12:03:19.696186+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7369656,
            "author": "Andrew Choy",
            "project_title": "Special Participation: Gemini 3 (Thinking) on HW 8",
            "post_body": "For this assignment, I used Gemini to tackle the non-coding/theory portions of Homework 8. Beyond simply checking if the model could solve the math, I wanted to investigate whether crafting an \"ideal\" prompt for learning is actually worth the effort.\n\nI ran an A/B test using two distinct prompts: a \"Lazy\" prompt (minimal instruction) and a \"Rigorous\" prompt (detailed constraints, persona setting, and formatting rules).\n\nMy conclusion: Attempting to engineer the perfect pedagogical prompt often yields diminishing returns. Unless your prompt is extremely specific and detailed, you will likely waste more time trying to \"program\" the AI to teach you than you would by simply struggling through the problem yourself. While my sophisticated prompt was significantly more detailed than the lazy one, I couldn't find a strong justification for the extra setup time. The model's raw training on these standard theoretical derivations is robust enough that \"lazy\" prompting yields nearly identical results.\n\nDisclaimer: This interaction was not conducted in \"Study Mode,\" I have not tested/used this mode in the past so i cannot speak to the abilities in this regard. ",
            "content_xml": "<document version=\"2.0\"><paragraph>For this assignment, I used Gemini to tackle the non-coding/theory portions of Homework 8. Beyond simply checking if the model could solve the math, I wanted to investigate whether crafting an \"ideal\" prompt for learning is actually worth the effort.</paragraph><file url=\"https://static.us.edusercontent.com/files/YCdIAj8sDYvhpEEZuWMayegS\" filename=\"lazy.pdf\"/><file url=\"https://static.us.edusercontent.com/files/R6NBvAUeRjhLUhKIzrmIo41y\" filename=\"sophisticated.pdf\"/><paragraph>I ran an A/B test using two distinct prompts: a \"Lazy\" prompt (minimal instruction) and a \"Rigorous\" prompt (detailed constraints, persona setting, and formatting rules).</paragraph><paragraph><bold>My conclusion:</bold> Attempting to engineer the perfect pedagogical prompt often yields diminishing returns. Unless your prompt is extremely specific and detailed, you will likely waste more time trying to \"program\" the AI to teach you than you would by simply struggling through the problem yourself. While my sophisticated prompt was significantly more detailed than the lazy one, I couldn't find a strong justification for the extra setup time. The model's raw training on these standard theoretical derivations is robust enough that \"lazy\" prompting yields nearly identical results.</paragraph><paragraph><italic>Disclaimer: This interaction was not conducted in \"Study Mode,\" I have not tested/used this mode in the past so i cannot speak to the abilities in this regard.</italic> </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-27T11:33:04.796778+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7368105,
            "author": "Deena Sun",
            "project_title": "Special Participation E: Using Gemini Pro 3 and Claude Opus 4.5 for Jupyter Notebook Demos of Lecture Topics",
            "post_body": "\n\nExecutive Summary:\n\nI enjoy taking the concepts/theory we learn in class and applying them in code\u2014I think it forces me to turn what I thought I understood through math or abstract concepts and make them more concrete by executing them. As a CS 189 course staff this semester, we\u2019re creating a lot of demo notebooks and coding-forward Jupyter notebooks for students to try out. So taking inspiration from the demos in CS 189 as well as our coding homework problems, I decided to try to prompt LLMs and IDE-integrated coding assistants to produce some Jupyter notebook demos of topics covered in class.\n\nPrompt used:\n\nYou are an expert deep learning instructor and advanced Python coder creating a demo for the Berkeley course CS 182, Deep Neural Networks. Your task is to produce a Jupyter notebook that explains and demonstrates the target topic. Use the written lecture notes and transcript of the lecture to inform what key concepts to cover in the demo for the target topic.\n\nThe notebook should following these key principles:\n1. Introduce the topic, describe its relevance in deep learning, and define core concepts from the provided transcript/lecture notes. If necessary, provide comparisons between solutions/practices covered in lecture that \u201cdidn\u2019t work\u201d, and those that \u201cdid work\u201d.\n2. Use clear markdown cells to present essential theoretical background.\n3. Provide a complete Python implementation using PyTorch, Numpy, and Pandas libraries.\n4. Integrate plots and visualizations throughout to aid interpretation.\n\nFormatting guidelines:\n1. Use descriptive comments and narrative explanations alongside code. Write clear docstrings where needed.\n2. Limit total length to 100-150 lines of code and under 5000 words.\n3. The notebook should be runnable end-to-end in Colab or local Jupyter environments.\n\nOutput only the ipynb notebook.\n\nTarget topic:\n<INSERT YOUR TARGET TOPIC HERE>\n<MAKE SURE TO ADD PDF OF LECTURE NOTES AND TXT FILE OF LECTURE TRANSCRIPTS FROM YOUTUBE>\n\n\nI explored 2 LLMs:\n\nGemini Pro 3 from the Gemini website\n\nI pasted in the prompt, added my target topic (Soft-prompting and soft-prefix prompting), and attached the pdf of lecture 21\u2019s notes as well as a txt of lecture 21\u2019s YouTube transcripts\n\nSince I was using Gemini\u2019s website rather than an IDE, Gemini produced a JSON that I then pasted into a .json file and converted into an ipynb by changing the file extension\n\nClaude Opus 4.5 within Cursor\n\nI pasted in the prompt, and attached lecture 21 \u2019s PDF notes and a txt of the YouTube transcripts\n\nBoth models produced a runnable Jupyter notebook that included a toy encoder implementation, a toy task (Gemini used the task of reversing a sequence and Claude made dummy sequences to map to positive, negative, or neutral sentiment), training loops for soft-prompting, soft-prefixes, and frozen baseline models, and comparisons of parameter counts and training metrics. Furthermore, both models included detailed walkthroughs and explanations that motivated why soft-prompting/soft-prefixing could be useful, implementation details, and key takeaways.\n\nSome limitations I noticed from both models were the use of outdated additive positional embeddings (perhaps chosen for instructive simplicity). Claude\u2019s implementation of soft-prefixing was flawed, and seemed equivalent to just appending the supposedly learned keys/values to the input sequence\u2019s token embeddings.\n\nOverall, I was impressed with the thoroughness of both model\u2019s demos. I found it a helpful guide towards seeing how a concept we discussed in class might actually be implemented in practice. The interactivity of a Jupyter notebook also makes it easier to play around and tweak things on my own (e.g. by adding extra print statements, adjusting different parameter sizes) that can not be as easily achieved by reading an article or textbook even if it does include code implementations.\n\nWhile this was a fun experiment to see how we could leverage LLMs to produce workable demos, I still ultimately find hands-on doing more effective for my learning than just reading through the demo, even if I\u2019m actively engaged with the reading and trying to understand every step or identify potential errors. I\u2019d be curious to see if this provides a good baseline demo that we could then ask another LLM to help \u201cablate\u201d and add \u201cTODOs\u201d for students to fill out/code on their own.\n\nGemini Pro 3 - Detailed Analysis\n\nLink to my conversation with Gemini Pro 3: https://gemini.google.com/app/cbcac1c80e5f5041\n\nJupyter Notebook:\n\nSome outdated practices I noticed from Gemini\u2019s Transformer implementation\n\nToyGPT implementation uses additive learned absolute positional embeddings\u2014which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they\u2019re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.\n\nThe FFN/MLP uses GeLU rather than more recent alternatives like SwiGLU or ReLU^2\n\nLayernorms in the transformer encoder blocks instead of RMS norm\n\nSome modern practices that Gemini\u2019s transformer included which differed from the original Transformer paper:\n\nPre-norm residual connections (adding the norm before the Attention sublayer and residual connections that bypass the norm entirely) versus post norm (normalizing after the residual add)\n\nI love that Gemini included the shapes of different tensors in the code comments. I often add these myself as I code to track the dimensions of things/sanity check/debug and I find that they really help my understanding as I implement. I also really appreciate that it makes some of the different dimension-changing functions (e.g. unsqueezed, expand, concat) more readable without having to guess at what they\u2019re trying to do.\n\nThe comments in the code for the CausalSelfAttention\u2019s forward method were very detailed, and covered implementation details beyond what was mentioned in lecture.\n\nFor instance, Gemini noted that we needed to adjust the shape of the causal mask when a soft-prefix is supplied to be [T, P + T] where P = prefix length and T = sequence length.\n\nAdditionally, Gemini also explicitly outlined how the causal mask should still allow attending to all the prefixes and be causal for the rest of the tokens themselves.\n\nIn the ToyGPT forward method, Gemini cuts off the soft prompt embedding token\u2019s output predictions and only returns logits for the original T tokens. This makes sense because we don\u2019t care about what the model predicts for the pre-prompt.\n\nSome things that Gemini included beyond the lecture scope:\n\nComments inside PrefixTuning noted that usually the learnable prefix parameters are reparameterized through a small MLP for stability.\n\nGeneral good coding practices that Gemini used:\n\nSeeding for reproducibility\n\nPyTorch practice of explicitly checking and printing what device we\u2019re using\n\nUsing constants to set the model hyperparameters\n\nMakes copies of the base model for each variant (soft-prompting, soft-prefix, and base model only) so that the base models all start from the same random state for comparison\n\nAlthough Gemini confidently provided an \u201cAnalysis of Results\u201d for what I should expect to see, running the demo as given did not produce a frozen baseline with high/flat loss or a decreasing loss curve for soft prompting.\n\nGemini also included a visualization of the soft prompt embeddings. However, unlike Claude, Gemini also included an interpretation of what we can use it for\u2014it noted that we can apply a KNN-like search to find the nearest token in the real vocabulary to see if the soft prompt corresponds to any understandable human words.\n\nClaude Opus 4.5 - Detailed Analysis\n\nLog of my conversation with Claude in Cursor:\n\nJupyter Notebook:\n\nSimpleTransformer implementation uses additive learned absolute positional embeddings\u2014which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they\u2019re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.\n\nInteresting that Claude actually referenced the lecture itself in the notebook: As described in lecture: \"The past queries have no influence except how they influence the keys and values. The state is the keys and the values.\"\n\nSome things that weren\u2019t immediately clear/understandable to me:\n\nWhy did we need MLP reparameterization for the soft-prefixes?\n\nWhat I was supposed to take away from 7: Visualizing Learned Soft Prompt Embeddings \u2014 what kinds of patterns should I be expecting?\n\nI don\u2019t think that Opus actually implemented soft-prefix tuning. Its implementation is functionally a learned prepended prompt. True \u201cprefix-tuning\u201d injects learned key/value vectors directly into the attention cache of every transformer layer; this requires modifying each layer\u2019s attention module so the extra K/Vs are concatenated before computing attention scores. Crucially, the code in SimpleTransformer simply concatenates the prefix to the token embeddings before the encoder. That makes the prefix act like extra prepended tokens (a soft prompt), not as layerwise K/V injections.\n\nAlso, PrefixWrapper only returns the first layer\u2019s keys even though SoftPrefix stores tensors shaped like per-layer K/Vs, get_all_prefixes(). I\u2019m not sure why Claude decided to only provide a \u201csimplified\u201d version of get_all-prefixes. But since the SimpleTransformer never consumes layer-specific prefixes, the stored K/Vs are never wired into the attention blocks.",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>I enjoy taking the concepts/theory we learn in class and applying them in code\u2014I think it forces me to turn what I thought I understood through math or abstract concepts and make them more concrete by executing them. As a CS 189 course staff this semester, we\u2019re creating a lot of demo notebooks and coding-forward Jupyter notebooks for students to try out. So taking inspiration from the demos in CS 189 as well as our coding homework problems, I decided to try to prompt LLMs and IDE-integrated coding assistants to produce some Jupyter notebook demos of topics covered in class.</paragraph><paragraph>Prompt used:</paragraph><pre>You are an expert deep learning instructor and advanced Python coder creating a demo for the Berkeley course CS 182, Deep Neural Networks. Your task is to produce a Jupyter notebook that explains and demonstrates the target topic. Use the written lecture notes and transcript of the lecture to inform what key concepts to cover in the demo for the target topic.\n\nThe notebook should following these key principles:\n1. Introduce the topic, describe its relevance in deep learning, and define core concepts from the provided transcript/lecture notes. If necessary, provide comparisons between solutions/practices covered in lecture that \u201cdidn\u2019t work\u201d, and those that \u201cdid work\u201d.\n2. Use clear markdown cells to present essential theoretical background.\n3. Provide a complete Python implementation using PyTorch, Numpy, and Pandas libraries.\n4. Integrate plots and visualizations throughout to aid interpretation.\n\nFormatting guidelines:\n1. Use descriptive comments and narrative explanations alongside code. Write clear docstrings where needed.\n2. Limit total length to 100-150 lines of code and under 5000 words.\n3. The notebook should be runnable end-to-end in Colab or local Jupyter environments.\n\nOutput only the ipynb notebook.\n\nTarget topic:\n&lt;INSERT YOUR TARGET TOPIC HERE&gt;\n&lt;MAKE SURE TO ADD PDF OF LECTURE NOTES AND TXT FILE OF LECTURE TRANSCRIPTS FROM YOUTUBE&gt;\n</pre><paragraph>I explored 2 LLMs:</paragraph><list style=\"unordered\"><list-item><paragraph>Gemini Pro 3 from the Gemini website</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>I pasted in the prompt, added my target topic (Soft-prompting and soft-prefix prompting), and attached the pdf of lecture 21\u2019s notes as well as a txt of lecture 21\u2019s YouTube transcripts</paragraph></list-item><list-item><paragraph>Since I was using Gemini\u2019s website rather than an IDE, Gemini produced a JSON that I then pasted into a .json file and converted into an ipynb by changing the file extension</paragraph></list-item></list></list-item><list-item><paragraph>Claude Opus 4.5 within Cursor</paragraph><list style=\"unordered\"><list-item><paragraph>I pasted in the prompt, and attached lecture 21 \u2019s PDF notes and a txt of the YouTube transcripts</paragraph></list-item></list></list-item></list><paragraph>Both models produced a runnable Jupyter notebook that included a toy encoder implementation, a toy task (Gemini used the task of reversing a sequence and Claude made dummy sequences to map to positive, negative, or neutral sentiment), training loops for soft-prompting, soft-prefixes, and frozen baseline models, and comparisons of parameter counts and training metrics. Furthermore, both models included detailed walkthroughs and explanations that motivated why soft-prompting/soft-prefixing could be useful, implementation details, and key takeaways.</paragraph><paragraph>Some limitations I noticed from both models were the use of outdated additive positional embeddings (perhaps chosen for instructive simplicity). Claude\u2019s implementation of soft-prefixing was flawed, and seemed equivalent to just appending the supposedly learned keys/values to the input sequence\u2019s token embeddings.</paragraph><paragraph>Overall, I was impressed with the thoroughness of both model\u2019s demos. I found it a helpful guide towards seeing how a concept we discussed in class might actually be implemented in practice. The interactivity of a Jupyter notebook also makes it easier to play around and tweak things on my own (e.g. by adding extra print statements, adjusting different parameter sizes) that can not be as easily achieved by reading an article or textbook even if it does include code implementations.</paragraph><paragraph>While this was a fun experiment to see how we could leverage LLMs to produce workable demos, I still ultimately find hands-on doing more effective for my learning than just reading through the demo, even if I\u2019m actively engaged with the reading and trying to understand every step or identify potential errors. I\u2019d be curious to see if this provides a good baseline demo that we could then ask another LLM to help \u201cablate\u201d and add \u201cTODOs\u201d for students to fill out/code on their own.</paragraph><paragraph><bold>Gemini Pro 3 - Detailed Analysis</bold></paragraph><paragraph>Link to my conversation with Gemini Pro 3: <link href=\"https://gemini.google.com/app/cbcac1c80e5f5041\">https://gemini.google.com/app/cbcac1c80e5f5041</link></paragraph><paragraph>Jupyter Notebook:</paragraph><file url=\"https://static.us.edusercontent.com/files/b8QU2HapAUltFbUPJ5Iw63w8\" filename=\"gemini_soft_prompting_demo.ipynb\"/><list style=\"unordered\"><list-item><paragraph>Some outdated practices I noticed from Gemini\u2019s Transformer implementation</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>ToyGPT implementation uses additive learned absolute positional embeddings\u2014which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they\u2019re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.</paragraph></list-item><list-item><paragraph>The FFN/MLP uses GeLU rather than more recent alternatives like SwiGLU or ReLU^2</paragraph></list-item><list-item><paragraph>Layernorms in the transformer encoder blocks instead of RMS norm</paragraph></list-item></list></list-item><list-item><paragraph>Some modern practices that Gemini\u2019s transformer included which differed from the original Transformer paper:</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Pre-norm residual connections (adding the norm before the Attention sublayer and residual connections that bypass the norm entirely) versus post norm (normalizing after the residual add)</paragraph></list-item></list></list-item><list-item><paragraph>I love that Gemini included the shapes of different tensors in the code comments. I often add these myself as I code to track the dimensions of things/sanity check/debug and I find that they really help my understanding as I implement. I also really appreciate that it makes some of the different dimension-changing functions (e.g. unsqueezed, expand, concat) more readable without having to guess at what they\u2019re trying to do.</paragraph></list-item><list-item><paragraph>The comments in the code for the CausalSelfAttention\u2019s forward method were very detailed, and covered implementation details beyond what was mentioned in lecture.</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>For instance, Gemini noted that we needed to adjust the shape of the causal mask when a soft-prefix is supplied to be [T, P + T] where P = prefix length and T = sequence length.</paragraph></list-item><list-item><paragraph>Additionally, Gemini also explicitly outlined how the causal mask should still allow attending to all the prefixes and be causal for the rest of the tokens themselves.</paragraph></list-item><list-item><paragraph>In the ToyGPT forward method, Gemini cuts off the soft prompt embedding token\u2019s output predictions and only returns logits for the original T tokens. This makes sense because we don\u2019t care about what the model predicts for the pre-prompt.</paragraph></list-item></list></list-item><list-item><paragraph>Some things that Gemini included beyond the lecture scope:</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Comments inside PrefixTuning noted that usually the learnable prefix parameters are reparameterized through a small MLP for stability.</paragraph></list-item></list></list-item><list-item><paragraph>General good coding practices that Gemini used:</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Seeding for reproducibility</paragraph></list-item><list-item><paragraph>PyTorch practice of explicitly checking and printing what device we\u2019re using</paragraph></list-item><list-item><paragraph>Using constants to set the model hyperparameters</paragraph></list-item><list-item><paragraph>Makes copies of the base model for each variant (soft-prompting, soft-prefix, and base model only) so that the base models all start from the same random state for comparison</paragraph></list-item></list></list-item><list-item><paragraph>Although Gemini confidently provided an \u201cAnalysis of Results\u201d for what I should expect to see, running the demo as given did not produce a frozen baseline with high/flat loss or a decreasing loss curve for soft prompting.</paragraph></list-item><list-item><paragraph>Gemini also included a visualization of the soft prompt embeddings. However, unlike Claude, Gemini also included an interpretation of what we can use it for\u2014it noted that we can apply a KNN-like search to find the nearest token in the real vocabulary to see if the soft prompt corresponds to any understandable human words.</paragraph></list-item></list><paragraph><bold>Claude Opus 4.5 - Detailed Analysis</bold></paragraph><paragraph>Log of my conversation with Claude in Cursor:</paragraph><file url=\"https://static.us.edusercontent.com/files/CmMv9Yx4ZSqIcJXB5l5tpUre\" filename=\"claude_jupyter_notebook_log.md\"/><paragraph>Jupyter Notebook:</paragraph><file url=\"https://static.us.edusercontent.com/files/wW7M7blWuVjtHuApecz2Indd\" filename=\"claude_soft_prompting_demo.ipynb\"/><list style=\"unordered\"><list-item><paragraph>SimpleTransformer implementation uses additive learned absolute positional embeddings\u2014which as mentioned in lectures 19 and 20 is no longer standard practice (in favor of NoPE or RoPE). However, more advanced techniques like RoPE require custom attention implementations (e.g. hooking into the Q, K tensors before they\u2019re multiplied to apply the rotary transform). For instructive toy models in a demo, I can see how additive positional encodings might be simpler and easier to understand.</paragraph></list-item><list-item><paragraph>Interesting that Claude actually referenced the lecture itself in the notebook: As described in lecture: \"The past queries have no influence except how they influence the keys and values. The state is the keys and the values.\"</paragraph></list-item><list-item><paragraph>Some things that weren\u2019t immediately clear/understandable to me:</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>Why did we need MLP reparameterization for the soft-prefixes?</paragraph></list-item><list-item><paragraph>What I was supposed to take away from 7: Visualizing Learned Soft Prompt Embeddings \u2014 what kinds of patterns should I be expecting?</paragraph></list-item></list></list-item><list-item><paragraph>I don\u2019t think that Opus actually implemented soft-prefix tuning. Its implementation is functionally a learned prepended prompt. True \u201cprefix-tuning\u201d injects learned key/value vectors directly into the attention cache of every transformer layer; this requires modifying each layer\u2019s attention module so the extra K/Vs are concatenated before computing attention scores. Crucially, the code in SimpleTransformer simply concatenates the prefix to the token embeddings before the encoder. That makes the prefix act like extra prepended tokens (a soft prompt), not as layerwise K/V injections.</paragraph></list-item><list-item><paragraph>Also, PrefixWrapper only returns the first layer\u2019s keys even though SoftPrefix stores tensors shaped like per-layer K/Vs, get_all_prefixes(). I\u2019m not sure why Claude decided to only provide a \u201csimplified\u201d version of get_all-prefixes. But since the SimpleTransformer never consumes layer-specific prefixes, the stored K/Vs are never wired into the attention blocks.</paragraph></list-item></list></document>",
            "links": [
                "https://gemini.google.com/app/cbcac1c80e5f5041"
            ],
            "attachments": [],
            "created_at": "2025-11-27T03:47:51.022066+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7367625,
            "author": "Hong Joey",
            "project_title": "Reviews for Project Drafts are Now Visible",
            "post_body": "Everyone should be able to view the submitted peer reviews for their projects by accessing the author console on CMT. If you cannot, it could be an error on my end so just let me know here. During assignment, every project report got either 3 or 4 reviewers assigned to it. If you are missing reviews, hopefully those will appear on your console over the next couple days. If by then, you still do not have at least 2 completed reviews (which hopefully won't be many), I will add a review myself. \n\nFor reviewers who accepted the invitation last night. Any invitation accepted after last Friday requires manual assignment, and I did not do any assignments after 9ish pm. Since the fact that you needed to accept the invitation earlier was potentially not clear, I'm keeping the option to submit reviews open for the next 48 hours. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Everyone should be able to view the submitted peer reviews for their projects by accessing the author console on CMT. If you cannot, it could be an error on my end so just let me know here. During assignment, every project report got either 3 or 4 reviewers assigned to it. If you are missing reviews, hopefully those will appear on your console over the next couple days. If by then, you still do not have at least 2 completed reviews (which hopefully won't be many), I will add a review myself. </paragraph><paragraph>For reviewers who accepted the invitation last night. Any invitation accepted after last Friday requires manual assignment, and I did not do any assignments after 9ish pm. Since the fact that you needed to accept the invitation earlier was potentially not clear, I'm keeping the option to submit reviews open for the next 48 hours. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-26T22:09:37.392939+11:00",
            "category": "Project"
        },
        {
            "guid": 7367345,
            "author": "Nicolas Rault-Wang",
            "project_title": "Special Participation B: Gemini (Thinking With Pro 3) on HW08",
            "post_body": "I used Gemini (Thinking with Pro 3) to solve every coding question of homework 8.\n\nHere's the PDF summarizing our interaction:\n\nOverview of Performance\n\nI used Gemini (acting as a Teaching Assistant/Technical Solver) to solve the coding portion of Homework 8 (only Q2: SSM Forward Passes). I constrained Gemini's behavior with strict protocols for self-correction, variable mapping to ground its context, and state-machine interaction rules to focus its attention single well-defined subtask. \n\nGemini successfully implemented PyTorch solutions for the CPU and GPU State Space Model notebook in total of 6 prompts (including role definition prompts).\n\nWhile it generated syntactically correct code for the base cases immediately, I needed to follow up to correct an oversight regarding computational complexity (in the CPU notebook) and debug a shape-mismatch error in the diagonal optimization task (in the GPU notebook). \n\nInterestingly, Gemini thought for significantly longer on average during this interaction compared to usual. Each time I uploaded a code notebook, Gemini spent about 3 minutes thinking before it responded. When I asked Gemini about why it took so long, it said that my prompts forced it to think harder about details and use more computationally expensive tools like its code environment and internal search tools to double check and cross reference its work.\n\nOverall I'm very impressed at how quickly Gemini solved the entire problem. These models are getting scarily competent.\n\nOutcomes\n\nOne-Shot Success Rate: ~66%\n\nHigh Success:\n\nTranslating algorithms to code: Gemini successfully converted the mathematical definitions of SSMs (recurrence vs. convolution) into functional PyTorch code.\n\nStructure preservation: Correctly parsed the uploaded Jupyter notebooks to use the exact variable names and function signatures required by the autograder. I believe the staged problem solving protocol of first extracting variable mappings then writing code helped Gemini not hallucinate (though I could be wrong).\n\nLower Success:\n\nComplexity analysis: Initially, Gemini claimed the convolution method was strictly faster on CPU. I had to prompt it to re-evaluate the cost of generating the kernel ($O(H^3)$), which prompted it to reevaluate and recognize the discrepancy.\n\nBroadcasting logic: In the diagonal optimization question (Q2f), the model initially wrote code that caused a RuntimeError due to a dimension mismatch (treating a diagonal matrix as a 2D tensor instead of a 1D vector). I had to provide the error trace to help it debug.\n\nHallucinations:\n\nZero hallucinations.\n\nInteractive debugging: When the diagonal implementation failed the sanity check, I provided the Python error trace. The model successfully analyzed the traceback, identified the broadcasting error, and patched the code in its next response without needing further hints.\n\nEdit: Added links for the archive\n\nPersonal website: https://nraultwang.github.io/\n\nGithub: https://github.com/nraultwang\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini (Thinking with Pro 3) to solve every coding question of homework 8.</paragraph><paragraph>Here's the PDF summarizing our interaction:</paragraph><file url=\"https://static.us.edusercontent.com/files/4ZpLAC0HKOyN1o1AfHHqIvW4\" filename=\"Rault-Wang_Nicolas_Special-Participation-B.pdf\"/><paragraph><underline>Overview of Performance</underline></paragraph><paragraph>I used Gemini (acting as a Teaching Assistant/Technical Solver) to solve the coding portion of Homework 8 (only Q2: SSM Forward Passes). I constrained Gemini's behavior with strict protocols for self-correction, variable mapping to ground its context, and state-machine interaction rules to focus its attention single well-defined subtask. </paragraph><paragraph>Gemini successfully implemented PyTorch solutions for the CPU and GPU State Space Model notebook in total of <bold>6 prompts</bold> (including role definition prompts).</paragraph><paragraph>While it generated syntactically correct code for the base cases immediately, I needed to follow up to correct an oversight regarding computational complexity (in the CPU notebook) and debug a shape-mismatch error in the diagonal optimization task (in the GPU notebook). </paragraph><paragraph>Interestingly, Gemini thought for significantly longer on average during this interaction compared to usual. Each time I uploaded a code notebook, Gemini spent about 3 minutes thinking before it responded. When I asked Gemini about why it took so long, it said that my prompts forced it to think harder about details and use more computationally expensive tools like its code environment and internal search tools to double check and cross reference its work.</paragraph><paragraph>Overall I'm very impressed at how quickly Gemini solved the entire problem. These models are getting scarily competent.</paragraph><paragraph><underline>Outcomes</underline></paragraph><list style=\"unordered\"><list-item><paragraph>One-Shot Success Rate: ~66%</paragraph></list-item><list-item><paragraph>High Success:</paragraph><list style=\"unordered\"><list-item><paragraph>Translating algorithms to code: Gemini successfully converted the mathematical definitions of SSMs (recurrence vs. convolution) into functional PyTorch code.</paragraph></list-item><list-item><paragraph>Structure preservation: Correctly parsed the uploaded Jupyter notebooks to use the exact variable names and function signatures required by the autograder. I believe the staged problem solving protocol of first extracting variable mappings then writing code helped Gemini not hallucinate (though I could be wrong).</paragraph></list-item></list></list-item><list-item><paragraph>Lower Success:</paragraph><list style=\"unordered\"><list-item><paragraph>Complexity analysis: Initially, Gemini claimed the convolution method was strictly faster on CPU. I had to prompt it to re-evaluate the cost of <italic>generating</italic> the kernel ($O(H^3)$), which prompted it to reevaluate and recognize the discrepancy.</paragraph></list-item><list-item><paragraph>Broadcasting logic: In the diagonal optimization question (Q2f), the model initially wrote code that caused a <code>RuntimeError</code> due to a dimension mismatch (treating a diagonal matrix as a 2D tensor instead of a 1D vector). I had to provide the error trace to help it debug.</paragraph></list-item></list></list-item><list-item><paragraph>Hallucinations:</paragraph><list style=\"unordered\"><list-item><paragraph>Zero hallucinations.</paragraph></list-item></list></list-item><list-item><paragraph>Interactive debugging: When the diagonal implementation failed the sanity check, I provided the Python error trace. The model successfully analyzed the traceback, identified the broadcasting error, and patched the code in its next response without needing further hints.</paragraph></list-item></list><paragraph>Edit: Added links for the archive</paragraph><paragraph>Personal website: <link href=\"https://nraultwang.github.io/\">https://nraultwang.github.io/</link></paragraph><paragraph>Github: <link href=\"https://github.com/nraultwang\">https://github.com/nraultwang</link></paragraph><paragraph/></document>",
            "links": [
                "https://nraultwang.github.io/",
                "https://github.com/nraultwang"
            ],
            "attachments": [],
            "created_at": "2025-11-26T17:33:51.558946+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7363141,
            "author": "Jason Trinh",
            "project_title": "Special Participation E: AI Assisted Annotations",
            "post_body": "When trying to use LLMs to study from CS182 lecture notes, hws, or readings, I was constantly switching between three things: the PDF viewer, an LLM tab, and my own notes. I had to copy-paste text or screenshots into the model, read the answer, then flip back to the PDF and try to remember which part it was referring to, which became a really tedious process. And oftentimes, a week later, I don't remember where I had the conversation with the LLM. So I decided to put everything into a single tool.\n\nhttps://jaizunt.github.io/pdf_analyzer/\n\n\n\nI built PDF Analyzer, a small web tool that lets you:\n\nUpload any PDF (lecture notes, papers, homework solutions, etc.).\n\nHighlight text or crop a region of a page (e.g., a figure or equation).\n\nAsk an LLM (Gemini / GPT / Claude) to explain or summarize that exact snippet (or you can enter your own custom prompt).\n\nAttach your own notes, and then\n\nExport everything back into an annotated PDF (with sticky notes as the annoations [these don't render latex]) or a .json \u201cstudy session\u201d you can re-load later.\n\nIt uses a system prompt tailored towards providing a comprehensive response related to Deep Learning.\n\nIn using this tool, it seems like the response that the LLM provides often results in long and extensive explanations. This is both good and bad (notes are supposed to be concise, but thorough explanations are helpful in understanding the material better). There could be some way of resolving this via a highly specific system prompt that forces the LLM to be as concise as possible (the system prompt I have currently is some form of that, but it seems to deviate from the instructions a little). Additionally, as you will see in some of my example files, there are some cases where it hallucinates (even on the newer models - GPT 5.1). \n\nI have attached below a video of me using it and annotations of examples.",
            "content_xml": "<document version=\"2.0\"><paragraph>When trying to use LLMs to study from CS182 lecture notes, hws, or readings, I was constantly switching between three things: the PDF viewer, an LLM tab, and my own notes. I had to copy-paste text or screenshots into the model, read the answer, then flip back to the PDF and try to remember which part it was referring to, which became a really tedious process. And oftentimes, a week later, I don't remember where I had the conversation with the LLM. So I decided to put everything into a single tool.</paragraph><paragraph><link href=\"https://jaizunt.github.io/pdf_analyzer/\">https://jaizunt.github.io/pdf_analyzer/</link></paragraph><paragraph/><paragraph>I built <bold>PDF Analyzer</bold>, a small web tool that lets you:</paragraph><list style=\"unordered\"><list-item><paragraph>Upload any PDF (lecture notes, papers, homework solutions, etc.).</paragraph></list-item><list-item><paragraph>Highlight text or crop a region of a page (e.g., a figure or equation).</paragraph></list-item><list-item><paragraph>Ask an LLM (Gemini / GPT / Claude) to explain or summarize that exact snippet (or you can enter your own custom prompt).</paragraph></list-item><list-item><paragraph>Attach your own notes, and then</paragraph></list-item><list-item><paragraph>Export everything back into an annotated PDF (with sticky notes as the annoations [these don't render latex]) or a <code><bold>.json</bold></code> \u201cstudy session\u201d you can re-load later.</paragraph></list-item></list><paragraph>It uses a system prompt tailored towards providing a comprehensive response related to Deep Learning.</paragraph><paragraph>In using this tool, it seems like the response that the LLM provides often results in long and extensive explanations. This is both good and bad (notes are supposed to be concise, but thorough explanations are helpful in understanding the material better). There could be some way of resolving this via a highly specific system prompt that forces the LLM to be as concise as possible (the system prompt I have currently is some form of that, but it seems to deviate from the instructions a little). Additionally, as you will see in some of my example files, there are some cases where it hallucinates (even on the newer models - GPT 5.1). </paragraph><paragraph>I have attached below a video of me using it and annotations of examples.</paragraph><file url=\"https://static.us.edusercontent.com/files/x0s5GPUKGtIHGOmDLnDNfX9j\" filename=\"Annotations_Video.mp4\"/><file url=\"https://static.us.edusercontent.com/files/SQfubQwqdumOk36pdoPubgd0\" filename=\"gnn_notes_annotated.pdf\"/><file url=\"https://static.us.edusercontent.com/files/K7s6uCtyX9x1ZSDJaW4RsVK8\" filename=\"polar_annotated.pdf\"/></document>",
            "links": [
                "https://jaizunt.github.io/pdf_analyzer/"
            ],
            "attachments": [],
            "created_at": "2025-11-25T17:35:52.347178+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7362178,
            "author": "Hong Joey",
            "project_title": "HW12 Extra (for Reference Only): Fine-tuning Large Models for Multiple Tasks",
            "post_body": "Problem Context: This extra reference problem is from a past exam where you answer questions regarding the interaction between meta-learning and catastrophic forgetting.",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This extra reference problem is from a past exam where you answer questions regarding the interaction between meta-learning and catastrophic forgetting.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/Mmslg1SwzDlpRFl8zFszu51T\" width=\"658\" height=\"270.5365853658537\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T13:12:46.655982+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7362163,
            "author": "Hong Joey",
            "project_title": "HW12 Q5: Meta-Learning for Learning 1D Functions",
            "post_body": "Problem Context: In this problem you will analyze MAML for a simplified regression setting. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: In this problem you will analyze MAML for a simplified regression setting. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/LfG29yFZz6xPNCWjCtjMy16Y\" width=\"658\" height=\"474.40797186400937\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T13:10:06.584774+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7362141,
            "author": "Hong Joey",
            "project_title": "HW12 Q4: Variational Autoencoders",
            "post_body": "Problem Context: This is a coding question where you will implement key functions for sampling from and training a VAE.",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This is a coding question where you will implement key functions for sampling from and training a VAE.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/U4w1Segy1IhmUwOMql9WG4jn\" width=\"658\" height=\"224.53080568720378\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/yXH7nR9imYG3eZ0hnh3cfkrk\" width=\"658\" height=\"570.9117647058823\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T13:05:20.908475+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7362133,
            "author": "Hong Joey",
            "project_title": "HW12 Q3: Variational Information Bottleneck",
            "post_body": "Problem Context: This is another former exam problem intended to help you understand the latent space of Variational Autoencoders (VAEs).",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This is another former exam problem intended to help you understand the latent space of Variational Autoencoders (VAEs).</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/Mr6UnlRkmWNmoWF87C9i3Uye\" width=\"658\" height=\"567.3189066059226\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T13:03:25.963234+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7362113,
            "author": "Hong Joey",
            "project_title": "HW 12 Q2: Comparing Distributions",
            "post_body": "Problem Context: This a past exam problem intended to help you engage with the asymmetry of KL divergence. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This a past exam problem intended to help you engage with the asymmetry of KL divergence. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/DgsGDvDS1b9fg07DAdfkyjpV\" width=\"658\" height=\"473.1012514220705\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T13:00:59.881493+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7362100,
            "author": "Hong Joey",
            "project_title": "HW 12 Q1: Debugging Transformers",
            "post_body": "Problem Context: This is former exam problem asking you to inspect a sample code implementation of a Transformer architecture for bugs. This is a common style of exam problem.",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This is former exam problem asking you to inspect a sample code implementation of a Transformer architecture for bugs. This is a common style of exam problem.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/MtEe2G6lvGe7eJS0QxxvODjn\" width=\"658\" height=\"540.7701149425287\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T12:59:06.992173+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7361344,
            "author": "Angelina Zhang",
            "project_title": "Special Participation B: Claude on HW6 Coding Part",
            "post_body": "TLDR Claude generally produced responses that sounded correct at a high level, but it frequently broke the assignment\u2019s required function calls, changed tensor shapes, invented details, or fabricated empirical results, showing that it needs strict guidance and careful verification to be reliably useful.\n\nI used Claude for all the coding tasks (ZKC GNN, Muon optimizer, TensorBoard and W&B logging) (this also includes question 1 and 4 since I am curious how it would react to experimental questions). Here is the link that includes this conversation and my comment: https://drive.google.com/file/d/18G2z--73h13fW7IHrvMpzHCTN3_F9cmB/view?usp=sharing\nClaude provided solutions that were often superficially aligned with the mathematical intent, but its behavior consistently revealed several limitations: an over-tendency to generalize, a willingness to invent details, and a lack of adherence to the assignment\u2019s scaffolding and API requirements. While Claude frequently produced code that looked correct, a careful comparison with the solution demonstrates that many answers were only conceptually plausible rather than implementation-correct.\n\nIn the GNN portion, Claude captured the high-level idea of Graph Convolution, but its implementations often broke the shape contracts required by the scaffold. It rewrote layer equations, changed tensor orientations, and introduced unnecessary rearrangements so that the model no longer matched the Softmax layer\u2019s expected shapes. It also redesigned entire GNN architectures, ignoring the intended pattern shown in the solution. These deviations were not mathematically wrong, but they would break the notebook environment and cause error. This illustrates Claude\u2019s tendency to over-help by redesigning code rather than filling the required blanks. \nFor the Muon optimizer, Claude again produced code with correct high-level structure, but the implementation contained realistic flaws. For the TensorBoard and W&B exercises, Claude often replaced the provided structure with its own training loops and added hyperparameters not requested at the cost of diverging from the assignment scaffold. Moreover, In all the written conceptual questions, Claude repeatedly provided hypothetical performance numbers (\u201cMuon ~70% accuracy,\u201d \u201cMuonSVD similar to Muon\u201d) and expected rankings without access to actual results. \n\nMy overall conclusion is Claude is strong at reconstructing textbook-level intent but unreliable at satisfying precise implementation constraints unless rigorously constrained. It tends to restructure code and produce fabricated empirical claims when data is unavailable. The exercise emphasized that LLM-assisted coding requires careful oversight.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>TLDR</bold> Claude generally produced responses that sounded correct at a high level, but it frequently broke the assignment\u2019s required function calls, changed tensor shapes, invented details, or fabricated empirical results, showing that it needs strict guidance and careful verification to be reliably useful.<break/><break/>I used Claude for all the coding tasks (ZKC GNN, Muon optimizer, TensorBoard and W&amp;B logging) (this also includes question 1 and 4 since I am curious how it would react to experimental questions). Here is the link that includes this conversation and my comment: <bold>https://drive.google.com/file/d/18G2z--73h13fW7IHrvMpzHCTN3_F9cmB/view?usp=sharing</bold><break/>Claude provided solutions that were often superficially aligned with the mathematical intent, but its behavior consistently revealed several limitations: an over-tendency to generalize, a willingness to invent details, and a lack of adherence to the assignment\u2019s scaffolding and API requirements. While Claude frequently produced code that looked correct, a careful comparison with the solution demonstrates that many answers were only conceptually plausible rather than implementation-correct.</paragraph><paragraph>In the GNN portion, Claude captured the high-level idea of Graph Convolution, but its implementations often broke the shape contracts required by the scaffold. It rewrote layer equations, changed tensor orientations, and introduced unnecessary rearrangements so that the model no longer matched the Softmax layer\u2019s expected shapes. It also redesigned entire GNN architectures, ignoring the intended pattern shown in the solution. These deviations were not mathematically wrong, but they would break the notebook environment and cause error. This illustrates Claude\u2019s tendency to over-help by redesigning code rather than filling the required blanks. <break/>For the Muon optimizer, Claude again produced code with correct high-level structure, but the implementation contained realistic flaws. For the TensorBoard and W&amp;B exercises, Claude often replaced the provided structure with its own training loops and added hyperparameters not requested at the cost of diverging from the assignment scaffold. Moreover, In all the written conceptual questions, Claude repeatedly provided hypothetical performance numbers (\u201cMuon ~70% accuracy,\u201d \u201cMuonSVD similar to Muon\u201d) and expected rankings without access to actual results. </paragraph><paragraph>My overall conclusion is Claude is strong at reconstructing textbook-level intent but unreliable at satisfying precise implementation constraints unless rigorously constrained. It tends to restructure code and produce fabricated empirical claims when data is unavailable. The exercise emphasized that LLM-assisted coding requires careful oversight.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-25T10:23:03.356818+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7360755,
            "author": "Jason Trinh",
            "project_title": "Special Participation E: Activation Visualizer for Neural Nets",
            "post_body": "I built an \u201cActivation Visualizer\u201d web app and then embedded an AI assistant directly into it so it can act as a pre\u2011/post\u2011lecture study companion for CNNs, RNNs, MLPs, and Transformers.\n\nFeel free to check it out at:\nhttps://jaizunt.github.io/activation_visualizer/\n\n(GitHub Repository)\nhttps://github.com/jaizunT/activation_visualizer\n\nI went down a major rabbit hole on this\u2014ended up spending basically an entire day modifying the project until it became both a genuinely useful and highly interactive tool rather than just a static visualization. I used an initial prompt generated from GPT 5.1 Thinking, inserted it into Gemini 3 Pro, and went through numerous modifications/iterations (vibe coding on Windsurf with GPT 5.1 Codex - High Reasoning) to make everything mathematically work with proper visualizations.\n\nActivation Visualizer simulates small neural networks and shows:\n\nLayer-by-layer activations and dimensions.\n\nHow changing inputs/weights/initial hidden states changes outputs.\n\nFor RNNs: sequence\u2011by\u2011sequence behavior and per\u2011layer h\u2080.\n\nFor CNNs: 2D inputs, kernel size, and sliding conv animation.\n\n(You\u2019ll need your own API key for whichever provider you choose if you want to use the AI Assistant; the key stays in your browser and is sent directly to that provider.)\n\nThere are currently 4 architectures available to look through, though transformers has not been interactively implemented yet. You can select them in the top right. My favorite is the RNN.\n\nFor MLP, CNN, and RNN, you can select the dimensions, set your inputs or parameters via manual editing or randomizing, and you can visualize the activations each step of the way. You also can adjust individual parameters and see how they affect the output.\n\nNote that some features are still in the works (not able to view gradients, inserting blocks, etc.), and there are probably lots of bugs still (i.e. trying to break the engine via setting 1000 hidden layers for cnns).\n\nFeel free to comment below any questions you have about any of the features, since there are a lot of parts to this.\n\n\n\nI had to restart my chat in a new conversation numerous times because I think the context became too long... \n\nHow the LLM Performed\n\nWhat it did well\n\nTurning ideas into code. I could describe a desired feature in plain language (e.g., per\u2011layer RNN h\u2080, freezing CNN/RNN weights, adding an AI assistant sidebar), and the LLM usually produced coherent React/TypeScript changes touching the right files and props.\n\nManaging complex state wiring. It handled a lot of the repetitive plumbing: adding new state variables, updating dependency arrays, and passing data between App.tsx, the engine, and visualization components without me having to write all the boilerplate.\n\nMath\u2011aware reasoning. When debugging, it connected behavior back to the math (e.g., CNN output shapes, RNN causality) and helped explain why certain outcomes were expected given the formulas.\n\nRapid iteration. It made it easy to try UI/UX variants quickly (buttons, layout, defaults) and to experiment with different ways of exposing parameters like kernel size or h\u2080.\n\nWhere it struggled / hallucinated\n\nSmall but important mistakes. Some patches were almost correct but had issues like missing props, slightly malformed JSX, or incorrect assumptions about types. I had to rely on compiler errors and my own reading to fix these.\n\nOver\u2011confident explanations. At times it proposed plausible but wrong hypotheses about behavior (e.g., why RNN outputs were changing) until we inspected the actual code and data flow more carefully.\n\nLimited UX judgment. It could suggest reasonable layouts, but whether the interface actually felt clean (spacing, font sizes, button labels, clutter) still required my own manual tweaking and visual judgment.\n\nSome other limitations I noticed were that some of my requests that I made were incomplete after the 'agent' did its work (consistent across multiple messages), and I had to explicitly say numerous times what I wanted. However, I do think my conversations could be more effective if I provided a specific 'TODO' or structure of what needs to be implemented as is often presented in 'structured prompts'.\n\nOverall, the LLM was very effective as a \u201cforce multiplier\u201d for coding and refactoring, but it definitely wasn\u2019t a drop\u2011in replacement for understanding the code or the underlying neural network concepts\u2014I still needed to verify, correct, and refine its suggestions.",
            "content_xml": "<document version=\"2.0\"><paragraph>I built an <bold>\u201cActivation Visualizer\u201d</bold> web app and then embedded an AI assistant directly into it so it can act as a pre\u2011/post\u2011lecture study companion for CNNs, RNNs, MLPs, and Transformers.</paragraph><paragraph>Feel free to check it out at:<break/><link href=\"https://jaizunt.github.io/activation_visualizer/\">https://jaizunt.github.io/activation_visualizer/</link></paragraph><paragraph>(GitHub Repository)<break/><link href=\"https://github.com/jaizunT/activation_visualizer\">https://github.com/jaizunT/activation_visualizer</link></paragraph><paragraph>I went down a <italic>major</italic> rabbit hole on this\u2014ended up spending basically an entire day modifying the project until it became both a genuinely useful and highly interactive tool rather than just a static visualization. I used an initial prompt generated from GPT 5.1 Thinking, inserted it into Gemini 3 Pro, and went through numerous modifications/iterations (vibe coding on Windsurf with GPT 5.1 Codex - High Reasoning) to make everything mathematically work with proper visualizations.</paragraph><paragraph><bold>Activation Visualizer</bold> simulates small neural networks and shows:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Layer-by-layer activations</bold> and dimensions.</paragraph></list-item><list-item><paragraph>How changing inputs/weights/initial hidden states changes outputs.</paragraph></list-item><list-item><paragraph>For RNNs: sequence\u2011by\u2011sequence behavior and per\u2011layer <code><bold>h\u2080</bold></code>.</paragraph></list-item><list-item><paragraph>For CNNs: 2D inputs, kernel size, and sliding conv animation.</paragraph></list-item></list><paragraph>(You\u2019ll need your own API key for whichever provider you choose if you want to use the AI Assistant; the key stays in your browser and is sent directly to that provider.)</paragraph><paragraph>There are currently 4 architectures available to look through, though transformers has not been interactively implemented yet. You can select them in the top right. My favorite is the RNN.</paragraph><paragraph>For MLP, CNN, and RNN, you can select the dimensions, set your inputs or parameters via manual editing or randomizing, and you can visualize the activations each step of the way. You also can adjust individual parameters and see how they affect the output.</paragraph><paragraph>Note that some features are still in the works (not able to view gradients, inserting blocks, etc.), and there are probably lots of bugs still (i.e. trying to break the engine via setting 1000 hidden layers for cnns).</paragraph><paragraph>Feel free to comment below any questions you have about any of the features, since there are a lot of parts to this.</paragraph><paragraph/><paragraph>I had to restart my chat in a new conversation numerous times because I think the context became too long... </paragraph><paragraph>How the LLM Performed</paragraph><paragraph><bold>What it did well</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Turning ideas into code.</bold> I could describe a desired feature in plain language (e.g., per\u2011layer RNN <code><bold>h\u2080</bold></code>, freezing CNN/RNN weights, adding an AI assistant sidebar), and the LLM usually produced coherent React/TypeScript changes touching the right files and props.</paragraph></list-item><list-item><paragraph><bold>Managing complex state wiring.</bold> It handled a lot of the repetitive plumbing: adding new state variables, updating dependency arrays, and passing data between App.tsx, the engine, and visualization components without me having to write all the boilerplate.</paragraph></list-item></list><list style=\"unordered\"><list-item><paragraph><bold>Math\u2011aware reasoning.</bold> When debugging, it connected behavior back to the math (e.g., CNN output shapes, RNN causality) and helped explain why certain outcomes were expected given the formulas.</paragraph></list-item><list-item><paragraph><bold>Rapid iteration.</bold> It made it easy to try UI/UX variants quickly (buttons, layout, defaults) and to experiment with different ways of exposing parameters like kernel size or <code><bold>h\u2080</bold></code>.</paragraph></list-item></list><paragraph><bold>Where it struggled / hallucinated</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Small but important mistakes.</bold> Some patches were almost correct but had issues like missing props, slightly malformed JSX, or incorrect assumptions about types. I had to rely on compiler errors and my own reading to fix these.</paragraph></list-item><list-item><paragraph><bold>Over\u2011confident explanations.</bold> At times it proposed plausible but wrong hypotheses about behavior (e.g., why RNN outputs were changing) until we inspected the actual code and data flow more carefully.</paragraph></list-item><list-item><paragraph><bold>Limited UX judgment.</bold> It could suggest reasonable layouts, but whether the interface actually felt clean (spacing, font sizes, button labels, clutter) still required my own manual tweaking and visual judgment.</paragraph></list-item></list><paragraph>Some other limitations I noticed were that some of my requests that I made were incomplete after the 'agent' did its work (consistent across multiple messages), and I had to explicitly say numerous times what I wanted. However, I do think my conversations could be more effective if I provided a specific 'TODO' or structure of what needs to be implemented as is often presented in 'structured prompts'.</paragraph><paragraph>Overall, the LLM was very effective as a \u201cforce multiplier\u201d for coding and refactoring, but it definitely wasn\u2019t a drop\u2011in replacement for understanding the code or the underlying neural network concepts\u2014I still needed to verify, correct, and refine its suggestions.</paragraph><file url=\"https://static.us.edusercontent.com/files/CuuSHIqdCbxaFtlOPtBcSkqB\" filename=\"prompt.txt\"/><file url=\"https://static.us.edusercontent.com/files/kTOJjYSGeKz0vHnbjlDxyIO0\" filename=\"Chat1.md\"/><file url=\"https://static.us.edusercontent.com/files/Of4K1zRfISmvZMhGd9m9a18b\" filename=\"Chat2.md\"/><file url=\"https://static.us.edusercontent.com/files/WANrFKubQ0gkDDg04u3LJh6Q\" filename=\"Chat3.md\"/><file url=\"https://static.us.edusercontent.com/files/50N2WVdFotm06ixLplayqZbh\" filename=\"Chat4.md\"/><file url=\"https://static.us.edusercontent.com/files/y44b0pvre5CZaOlUqdQkrFVj\" filename=\"Chat5.md\"/><file url=\"https://static.us.edusercontent.com/files/2lZXdPfuUkNDYgDqCGmlKDye\" filename=\"Chat6.md\"/></document>",
            "links": [
                "https://jaizunt.github.io/activation_visualizer/",
                "https://github.com/jaizunT/activation_visualizer"
            ],
            "attachments": [],
            "created_at": "2025-11-25T08:44:55.453395+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7358125,
            "author": "Jaimyn Drake",
            "project_title": "Special Participation A: Grok on HW 9",
            "post_body": "Hey guys! I worked with Grok to solve all of the non-coding parts of homework 9, and here are the results.\n\nTL;DR - Grok was generally very successful at solving all parts of this transformers homework, in which a major focus was keeping track of the dimensions of various matrices (key, query, value) and determining time complexities of operations. To this end, Grok integrated existing knowledge about transformer architectures and their interpretations, which streamlined the solution process for some problems but occasionally included added assumptions that were inconsistent with the problem statement. Overall, Grok could one-shot each question with some prompting, with Question 6 as an exception where a few clarifications were required.\n\n\n\nProblem 1:\n\nFor this problem, I initially set the stage by establishing Grok in its role and providing it with the problem PDF directly from the course website. Throughout the process, I was impressed by Grok's ability to parse information and recall details from the problem set throughout our solution process for all parts. To help with this recall, I intentionally repeat question numbers in my prompt and describe the adjacent subject matter of the question, which I hoped would help it localize to the correct regions of context for each problem. In this first case, it solved 2 of the 3 subparts with ease, and could immediately revise its answer for the third after a gentle prod about data types (it initially gave the answer as the square of a vector mu, rather than the norm squared). The conversation for Problem 1 is as follows:\n\nProblem 2:\n\nThis problem went even more smoothly than problem 1. Once again providing the question number, addressing specific part numbers, and providing a high-level characterization of the problem's subject matter, I was able to get Grok to one-shot this highly conceptual problem.\n\nProblem 3:\n\nI was initially concerned that Grok might have trouble parsing the PDF formatting surrounding fill-in-the-blank code, but I shouldn't have worried. Grok was able to easily one-shot the fill-in-the-blank code.\n\nProblem 4:\n\nGrok aces it again! As usual, I made sure to indicate the problem number and qualitatively describe the tasks Grok needed to perform before having it attempt the question. In one area it determines a time complexity of O(bnd/h), but in its solution process mentions that this is equivalent to the solutions answer of O(bnk).\n\nProblem 6:\n\nUnlike the rest of the problems, Grok had more trouble ironing out the finer details. For example, it took a little prompting to adjust coefficients in its kernelization (despite verbally accounting for cross-term symmetry, it did not initially provide the corresponding scaling factor) and to correctly transpose certain matrices (rather than following the notation of the homework, it decided to transpose all of the matrices per other notation it had seen previously). In the first instance of hallucination throughout the session, it insisted that M = D was defined in Equation (2), which simply did not happen. As a result, I needed to ask it the hypothetical of 'What if M and D were distinct values?\" in order to elicit the desired response.\n\nFor your reference, here is a PDF of the entire chat log. Of all of the questions on this homework, Grok actually made the least sense discussing its \"Homework Process and Study Group\". :)\n\nThanks guys. Have a wonderful day!",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey guys! I worked with Grok to solve all of the non-coding parts of homework 9, and here are the results.</paragraph><paragraph>TL;DR - Grok was generally very successful at solving all parts of this transformers homework, in which a major focus was keeping track of the dimensions of various matrices (key, query, value) and determining time complexities of operations. To this end, Grok integrated existing knowledge about transformer architectures and their interpretations, which streamlined the solution process for some problems but occasionally included added assumptions that were inconsistent with the problem statement. Overall, Grok could one-shot each question with some prompting, with Question 6 as an exception where a few clarifications were required.</paragraph><paragraph/><paragraph>Problem 1:</paragraph><paragraph>For this problem, I initially set the stage by establishing Grok in its role and providing it with the problem PDF directly from the course website. Throughout the process, I was impressed by Grok's ability to parse information and recall details from the problem set throughout our solution process for all parts. To help with this recall, I intentionally repeat question numbers in my prompt and describe the adjacent subject matter of the question, which I hoped would help it localize to the correct regions of context for each problem. In this first case, it solved 2 of the 3 subparts with ease, and could immediately revise its answer for the third after a gentle prod about data types (it initially gave the answer as the square of a vector mu, rather than the norm squared). The conversation for Problem 1 is as follows:</paragraph><file url=\"https://static.us.edusercontent.com/files/pxqDk8LVTc8JKko19SQKyrMd\" filename=\"182HW9_grokq1.pdf\"/><paragraph>Problem 2:</paragraph><paragraph>This problem went even more smoothly than problem 1. Once again providing the question number, addressing specific part numbers, and providing a high-level characterization of the problem's subject matter, I was able to get Grok to one-shot this highly conceptual problem.</paragraph><file url=\"https://static.us.edusercontent.com/files/jnhlOZwsqa9Rr9pbqHOlHXUa\" filename=\"182HW9_grok2.pdf\"/><paragraph>Problem 3:</paragraph><paragraph>I was initially concerned that Grok might have trouble parsing the PDF formatting surrounding fill-in-the-blank code, but I shouldn't have worried. Grok was able to easily one-shot the fill-in-the-blank code.</paragraph><file url=\"https://static.us.edusercontent.com/files/6Qq0GpSiNBG4t4vR6EzyHzkv\" filename=\"182HW9_grok3.pdf\"/><paragraph>Problem 4:</paragraph><paragraph>Grok aces it again! As usual, I made sure to indicate the problem number and qualitatively describe the tasks Grok needed to perform before having it attempt the question. In one area it determines a time complexity of O(bnd/h), but in its solution process mentions that this is equivalent to the solutions answer of O(bnk).</paragraph><file url=\"https://static.us.edusercontent.com/files/YztuKbqUqrEaTH0JN2us6SaY\" filename=\"182HW9_grok4.pdf\"/><paragraph>Problem 6:</paragraph><paragraph>Unlike the rest of the problems, Grok had more trouble ironing out the finer details. For example, it took a little prompting to adjust coefficients in its kernelization (despite verbally accounting for cross-term symmetry, it did not initially provide the corresponding scaling factor) and to correctly transpose certain matrices (rather than following the notation of the homework, it decided to transpose all of the matrices per other notation it had seen previously). In the first instance of hallucination throughout the session, it insisted that M = D was defined in Equation (2), which simply did not happen. As a result, I needed to ask it the hypothetical of 'What if M and D were distinct values?\" in order to elicit the desired response.</paragraph><file url=\"https://static.us.edusercontent.com/files/U9QBSnquHmdMOznk8AMKIhgb\" filename=\"182HW9_grok6.pdf\"/><paragraph>For your reference, here is a PDF of the entire chat log. Of all of the questions on this homework, Grok actually made the least sense discussing its \"Homework Process and Study Group\". :)</paragraph><file url=\"https://static.us.edusercontent.com/files/I0jmfmDcuiy9LVemjJaqokYV\" filename=\"182HW9_grokfull.pdf\"/><paragraph>Thanks guys. Have a wonderful day!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-24T22:25:02.317067+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7357397,
            "author": "Nicolas Rault-Wang",
            "project_title": "Special Participation A: Gemini (Thinking With Pro 3) on HW06",
            "post_body": "I used Gemini (Thinking with Pro 3) to solve every non-coding question of homework 6.\n\nHere's the PDF summarizing our interaction:\n\nOverview of Performance\n\nGemini acted as a \"Teaching Assistant/Technical Solver\" under well-defined rules I designed to reduce hallucination and maximize precision. The model successfully solved 100% of the non-coding questions, 9/13 in the first attempt, and the remaining 4/13 on the second attempt after additional guidance or clarification from me. Gemini demonstrated strong reasoning capabilities in mathematical proofs (GNN path counting) and theoretical analysis (Muon optimizer scaling), but required additional prompting for visual interpretation tasks (understanding tables and graph figures) and producing nicely-formatted outputs. \n\nOutcomes\n\nOne-Shot Success Rate: ~70%\n\nHigh success: Mathematical derivations, standard Deep Learning theory (memory calculations, optimizer comparisons), text-based conceptual questions.\n\nLower success: Questions requiring visual extraction from the PDF (e.g., graph topology in Figure 3) or fill-in-the-blank tables with loose formatting.\n\nHallucinations: 0 major hallucinations.\n\nInterestingly, when solving question 3ciii, the model did not hallucinate graph edges when they were missing from the text extraction; instead, it paused and requested me to describe the topology. I believe it did this because I said it could ask me for clarification if it was confused about anything in my initial prompt.\n\nMisconceptions: Minor. Initially provided a generic answer for a specific \"analogy table\" question (Q2f) and needed a nudge to be more thorough in connecting molecular facts to graph inputs (Q2e).\n\nNeat Observation: Gemini Meta-cognition\n\nGemini surprisingly took the initiative to write a Python script to help it read a table in the homework PDF when its built-in PDF processing subroutine failed to correctly parse it.\n\nIt explained that my \"Hallucination Check\" and \"Precision\" rules provided it motivation to develop and run this script to help it solve the errors it detected.\n\nNote that I did not tell Gemini to consider writing any code. Gemini decided to do this all on its own. \n\nHere are excerpts of what Gemini explained to me:\n\nYou asked about my decision to write a Python script to parse the PDF. My reasoning was driven by the \"Hallucination Check\" and \"Precision\" protocols you established.\n\n1. In my initial scan, I noticed the prompt for Question 2(f) asked me to \"Fill out the rest of the table.\" However, standard text extraction often garbles table formatting, making it impossible to distinguish between row headers and cell content. I could not see the \"empty\" cells I was supposed to fill.\n\n2.  Rather than guessing the structure or hallucinating the missing rows based on general knowledge, I needed the exact raw text layout to identify which GNN concepts were missing corresponding to the CNN concepts.\n\n3. I wrote the script to dump the text surrounding \"Question 2\" to ensure I had the specific headers (e.g., \"Color jitter\", \"Image flip\") to construct the correct analogies.\n\nGemini explained how it decides what to do for regular interactions:\n\nThink of writing a Python script as requiring high \"activation energy.\" It takes tokens, time, and computational effort.\n\n> Standard Prompt: \"Help me with homework.\" -> Low urgency. I preserve energy and use my internal weights.\n\nIn my standard \"default\" mode, my primary directive is usually conversational fluidity and helpfulness. When I encounter a PDF where a table is slightly garbled: \n\n> Path of Least Resistance: I often try to \"error correct\" using my internal knowledge base. I might look at the words \"CNN\" and \"GNN\" and simply guess what the analogy should be based on general Deep Learning knowledge. \n\n> The Result: I would likely have given you a plausible-sounding answer that was actually hallucinated (not based on the specific PDF text).\n\nGemini noted that my prompt's constraints were a deciding factor in guiding its decisions because they forced it to change its alignment and incentive structure for our interaction to prioritize avoiding hallucinations:\n\nTo be completely honest: Without your specific protocols, it is highly unlikely I would have written that Python script.\n\n> Your Prompt: \"Rigorous,\" \"High Academic Integrity,\" \"Self-Correction.\" -> High urgency. The \"cost\" of being wrong became higher than the \"cost\" of writing and executing code.\n\nYour instruction to perform a \"Hallucination Check\" and strictly \"Verify\" acted as a hard constraint\u2014a \"stop loss\" on my behavior. Because I was forbidden from guessing (Hallucination Check) and forbidden from giving up (Technical Solver persona), I was forced to find a third path. That third path was using the code tool to parse the file differently. \n\nIn summary: You gave me the incentive structure that made writing the code the only acceptable solution. You successfully \"cornered\" me into being smart.\n\nThis shows that Gemini has a sophisticated instruction-following ability and can perform tasks resembling meta-cognition and recognize hallucinations in its own thinking.\n\n\n\nEdit: Added links for the archive\n\nPersonal website: https://nraultwang.github.io/\n\nGithub: https://github.com/nraultwang",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini (Thinking with Pro 3) to solve every non-coding question of homework 6.</paragraph><paragraph>Here's the PDF summarizing our interaction:</paragraph><file url=\"https://static.us.edusercontent.com/files/fGkLJGOrdP0cP35EsIDyeuS1\" filename=\"Rault-Wang_Nicolas-Special Participation A.pdf\"/><heading level=\"4\"><underline>Overview of Performance</underline></heading><paragraph>Gemini acted as a \"Teaching Assistant/Technical Solver\" under well-defined rules I designed to reduce hallucination and maximize precision. The model successfully solved 100% of the non-coding questions, 9/13 in the first attempt, and the remaining 4/13 on the second attempt after additional guidance or clarification from me. Gemini demonstrated strong reasoning capabilities in mathematical proofs (GNN path counting) and theoretical analysis (Muon optimizer scaling), but required additional prompting for visual interpretation tasks (understanding tables and graph figures) and producing nicely-formatted outputs. </paragraph><heading level=\"4\"><underline>Outcomes</underline></heading><list style=\"unordered\"><list-item><paragraph>One-Shot Success Rate: ~70%</paragraph><list style=\"unordered\"><list-item><paragraph>High success<italic>:</italic> Mathematical derivations, standard Deep Learning theory (memory calculations, optimizer comparisons), text-based conceptual questions.</paragraph></list-item><list-item><paragraph>Lower success<italic>:</italic> Questions requiring visual extraction from the PDF (e.g., graph topology in Figure 3) or fill-in-the-blank tables with loose formatting.</paragraph></list-item></list></list-item><list-item><paragraph>Hallucinations: 0 major hallucinations.</paragraph><list style=\"unordered\"><list-item><paragraph>Interestingly, when solving question 3ciii, the model did <italic>not</italic> hallucinate graph edges when they were missing from the text extraction; instead, it paused and requested me to describe the topology. I believe it did this because I said it could ask me for clarification if it was confused about anything in my initial prompt.</paragraph></list-item></list></list-item><list-item><paragraph>Misconceptions: Minor. Initially provided a generic answer for a specific \"analogy table\" question (Q2f) and needed a nudge to be more thorough in connecting molecular facts to graph inputs (Q2e).</paragraph></list-item></list><paragraph><underline>Neat Observation: Gemini Meta-cognition</underline></paragraph><list style=\"unordered\"><list-item><paragraph>Gemini surprisingly took the initiative to write a Python script to help it read a table in the homework PDF when its built-in PDF processing subroutine failed to correctly parse it.</paragraph></list-item><list-item><paragraph>It explained that my \"Hallucination Check\" and \"Precision\" rules provided it motivation to develop and run this script to help it solve the errors it detected.</paragraph><list style=\"unordered\"><list-item><paragraph>Note that I did not tell Gemini to consider writing any code. Gemini decided to do this all on its own. </paragraph></list-item></list></list-item><list-item><paragraph>Here are excerpts of what Gemini explained to me:</paragraph></list-item></list><blockquote>You asked about my decision to write a Python script to parse the PDF. My reasoning was driven by the \"Hallucination Check\" and \"Precision\" protocols you established.</blockquote><blockquote>1. In my initial scan, I noticed the prompt for Question 2(f) asked me to \"Fill out the rest of the table.\" However, standard text extraction often garbles table formatting, making it impossible to distinguish between row headers and cell content. I could not see the \"empty\" cells I was supposed to fill.</blockquote><blockquote>2.  Rather than guessing the structure or hallucinating the missing rows based on general knowledge, I needed the <italic>exact</italic> raw text layout to identify which GNN concepts were missing corresponding to the CNN concepts.</blockquote><blockquote>3. I wrote the script to dump the text surrounding \"Question 2\" to ensure I had the specific headers (e.g., \"Color jitter\", \"Image flip\") to construct the correct analogies.</blockquote><list style=\"bullet\"><list-item><paragraph>Gemini explained how it decides what to do for regular interactions:</paragraph></list-item></list><blockquote>Think of writing a Python script as requiring high \"activation energy.\" It takes tokens, time, and computational effort.</blockquote><blockquote><bold>&gt; Standard Prompt:</bold> \"Help me with homework.\" -&gt; <bold>Low urgency.</bold> I preserve energy and use my internal weights.</blockquote><blockquote>In my standard \"default\" mode, my primary directive is usually <bold>conversational fluidity and helpfulness</bold>. When I encounter a PDF where a table is slightly garbled: </blockquote><blockquote><bold>&gt; Path of Least Resistance:</bold> I often try to \"error correct\" using my internal knowledge base. I might look at the words \"CNN\" and \"GNN\" and simply <italic>guess</italic> what the analogy should be based on general Deep Learning knowledge. </blockquote><blockquote><bold>&gt; The Result:</bold> I would likely have given you a plausible-sounding answer that was actually hallucinated (not based on the specific PDF text).</blockquote><list style=\"bullet\"><list-item><paragraph>Gemini noted that my prompt's constraints were a deciding factor in guiding its decisions because they forced it to change its alignment and incentive structure for our interaction to prioritize avoiding hallucinations:</paragraph></list-item></list><blockquote>To be completely honest: <bold>Without your specific protocols, it is highly unlikely I would have written that Python script.</bold></blockquote><blockquote><bold>&gt; Your Prompt:</bold> \"Rigorous,\" \"High Academic Integrity,\" \"Self-Correction.\" -&gt; <bold>High urgency.</bold> The \"cost\" of being wrong became higher than the \"cost\" of writing and executing code.</blockquote><blockquote>Your instruction to perform a <bold>\"Hallucination Check\"</bold> and strictly <bold>\"Verify\"</bold> acted as a hard constraint\u2014a \"stop loss\" on my behavior. Because I was forbidden from guessing (Hallucination Check) and forbidden from giving up (Technical Solver persona), I was forced to find a <bold>third path</bold>. That third path was using the code tool to parse the file differently. </blockquote><blockquote><bold>In summary:</bold> You gave me the <bold>incentive structure</bold> that made writing the code the only acceptable solution. You successfully \"cornered\" me into being smart.</blockquote><list style=\"unordered\"><list-item><paragraph>This shows that Gemini has a sophisticated instruction-following ability and can perform tasks resembling meta-cognition and recognize hallucinations in its own thinking.</paragraph></list-item></list><paragraph/><paragraph>Edit: Added links for the archive</paragraph><paragraph>Personal website: <link href=\"https://nraultwang.github.io/\">https://nraultwang.github.io/</link></paragraph><paragraph>Github: <link href=\"https://github.com/nraultwang\">https://github.com/nraultwang</link></paragraph></document>",
            "links": [
                "https://nraultwang.github.io/",
                "https://github.com/nraultwang"
            ],
            "attachments": [],
            "created_at": "2025-11-24T15:41:59.195499+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7356236,
            "author": "Ruizhe Song",
            "project_title": "Special Participation E: Using ChatGPT to Review Lecture 22 and Prepare for Lecture 23",
            "post_body": "In this Special Participation E, I want to share my learning process between Lecture 22 and Lecture 23. In Lecture 21~22, professor taught us how well-designed prompts can instruct the LLM to get better performance. The main methods range from \"soft-prompt\", which add learnable prompts to the input sequence, to \"pre-fixer\", which directly makes the Ks and Vs learnable parameters, then to \"LoRA\", which aims at updating the weight matrix with W = W*+delta(W) and finally to \"meta-learning\", which aims at making a model better at being fine-tuned. When I review my notes after class, I find myself re-organizing them as a large family of fine-tuning methods, only from different perspectives. \n\nThis ed post is about my whole review and re-organizing process of all the methods  between Lecture 22 and Lecture 23. I asked GPT5 in an \"evolving\" order from prompt-based methods to the general meta-learning method, let it explain my confusions and the relationship between these methods. And I think this chatting helps me to better prepare for the upcoming Lecture 23 in which I got to learn more about meta-learning, also gives me a better understanding of the previous Lecture 22 and 21.\n\nHere's the pdf version of chat log with my comments:\n\nI consider this a valuable self-refining process. With the help of LLMs these days, the way of collecting information and learning new concepts becomes different. We don't have to google \"what is meta-learning\" \"why is the delta(W)=AB initialized like that\" and search for high-quality post on the Internet. But meanwhile, we have to be careful to not rely too much on LLMs. The generated answers could block our eyes to the open real world. We need to engage with real-world sources and diverse perspectives.",
            "content_xml": "<document version=\"2.0\"><paragraph>In this Special Participation E, I want to share my learning process <bold>between Lecture 22 and Lecture 23</bold>. In Lecture 21~22, professor taught us how well-designed prompts can instruct the LLM to get better performance. The main methods range from \"<bold>soft-prompt</bold>\", which add learnable prompts to the input sequence, to \"<bold>pre-fixer</bold>\", which directly makes the Ks and Vs learnable parameters, then to \"<bold>LoRA</bold>\", which aims at updating the weight matrix with W = W*+delta(W) and finally to \"<bold>meta-learning</bold>\", which aims at making a model better at being fine-tuned. When I review my notes after class, I find myself re-organizing them as <bold>a large family of fine-tuning methods</bold>, only from different perspectives. </paragraph><paragraph>This ed post is about my whole review and re-organizing process of all the methods  between Lecture 22 and Lecture 23. I asked GPT5 in an \"evolving\" order from prompt-based methods to the general meta-learning method, let it explain my confusions and the relationship between these methods. And I think this chatting helps me to better prepare for the upcoming Lecture 23 in which I got to learn more about meta-learning, also gives me a better understanding of the previous Lecture 22 and 21.</paragraph><paragraph>Here's the pdf version of chat log with my comments:</paragraph><file url=\"https://static.us.edusercontent.com/files/b0eC9BwZTph08c6YBt78ODqM\" filename=\"Special-Participation-E-lec22.pdf\"/><paragraph>I consider this a valuable self-refining process. With the help of LLMs these days, the way of collecting information and learning new concepts becomes different. We don't have to google \"what is meta-learning\" \"why is the delta(W)=AB initialized like that\" and search for high-quality post on the Internet. But meanwhile, we have to be careful to not rely too much on LLMs. The generated answers could block our eyes to the open real world. We need to engage with real-world sources and diverse perspectives.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-24T11:18:30.942572+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7354054,
            "author": "E Harrison",
            "project_title": "Special Participation B: Claude Sonnet 4.5 on HW4 Coding Problems",
            "post_body": "Below is an attachment of my conversation with Claude's Sonnet 4.5 model where I asked it to solve the coding questions for HW4. To make it easy to save the conversation, I did everything in Cursor, which allowed me export my conversation as markdown, which I later converted to a PDF. This also made it very easy to provide all of the necessary context to Claude, as I could specify a certain file/function/code block that it should read before asking the question.\n\nUnfortunately, the conversation doesn't provide all of the context of the files that Claude read, just the conversation. So, I've added PDFs of both notebooks used for this homework that you can reference alongside the conversation.\n\n\nOverall notes:\n\nI was incredibly surprised about how well Claude/Cursor were able to provide all of the necessary context that was needed to answer each of the questions. While there were some cases where Claude either misread a graph or couldn't find the exact code block to fill, all it usually took was an additional sentence by me pointing Claude in the right direction and it was able to correct itself. I was specifically impressed by the Edge Detection Question, as that notebook has an incredibly long introduction and starter code, yet Claude was able to handle it.\n\nAll of the code Claude provided worked on the first try, and the only times Claude was incorrect was when trying to determine the correct hyperparameters needed to get optimal performance. I don't blame Claude for this at all -- choosing optimal hyperparameters is usually just guess and check anyway -- but even still, it only took a few iterations for Claude to get the right combination, and also provide some explanation for why it chose those values.\n\nThere were a couple times where Claude would hallucinate random values of graphs or state accuracies for tests that we hadn't performed. I think the reason for the former is that Cursor probably doesn't do a perfect job of relaying the visual information to Claude, and Sonnet 4.5 itself isn't primarily a vision model. The explanation for the latter is a bit less clear to me.\n\nOverall, I was very impressed by Claude's performance on this homework, especially since the questions were very long and pretty open ended, even including questions that asked Claude to reference visual inputs. Using Cursor as well was also the right move -- it made performing this whole test a lot smoother and faster. I have already been using Cursor for personal projects and research, so it's nice to see it's capable of a task like this.\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is an attachment of my conversation with Claude's Sonnet 4.5 model where I asked it to solve the coding questions for HW4. To make it easy to save the conversation, I did everything in Cursor, which allowed me export my conversation as markdown, which I later converted to a PDF. This also made it very easy to provide all of the necessary context to Claude, as I could specify a certain file/function/code block that it should read before asking the question.<break/><break/>Unfortunately, the conversation doesn't provide all of the context of the files that Claude read, just the conversation. So, I've added PDFs of both notebooks used for this homework that you can reference alongside the conversation.<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/BRwI6dhSZpNXdEWANdSlApoN\" filename=\"Participation_B_Claude_on_HW4_Coding.pdf\"/><file url=\"https://static.us.edusercontent.com/files/Ki2XJCcBQh0jDb26xI1QIS2f\" filename=\"HandDesignFilters.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ygx9wkJq4d8EMbgIfJquiMQm\" filename=\"edge_detection.pdf\"/><paragraph><bold>Overall notes:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>I was incredibly surprised about how well Claude/Cursor were able to provide all of the necessary context that was needed to answer each of the questions. While there were some cases where Claude either misread a graph or couldn't find the exact code block to fill, all it usually took was an additional sentence by me pointing Claude in the right direction and it was able to correct itself. I was specifically impressed by the Edge Detection Question, as that notebook has an incredibly long introduction and starter code, yet Claude was able to handle it.</paragraph></list-item><list-item><paragraph>All of the code Claude provided worked on the first try, and the only times Claude was incorrect was when trying to determine the correct hyperparameters needed to get optimal performance. I don't blame Claude for this at all -- choosing optimal hyperparameters is usually just guess and check anyway -- but even still, it only took a few iterations for Claude to get the right combination, and also provide some explanation for why it chose those values.</paragraph></list-item><list-item><paragraph>There were a couple times where Claude would hallucinate random values of graphs or state accuracies for tests that we hadn't performed. I think the reason for the former is that Cursor probably doesn't do a perfect job of relaying the visual information to Claude, and Sonnet 4.5 itself isn't primarily a vision model. The explanation for the latter is a bit less clear to me.</paragraph></list-item></list><paragraph>Overall, I was very impressed by Claude's performance on this homework, especially since the questions were very long and pretty open ended, even including questions that asked Claude to reference visual inputs. Using Cursor as well was also the right move -- it made performing this whole test a lot smoother and faster. I have already been using Cursor for personal projects and research, so it's nice to see it's capable of a task like this.</paragraph><paragraph><break/><break/><break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-23T20:26:56.638933+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7354053,
            "author": "Jameson Liu",
            "project_title": "Special Participation E: Claude for Homework Cramming",
            "post_body": "My personal studying strategy (whether effective or not) when reviewing homework/exams is to mentally attempt a question before reading the solution, allowing me to process a large number of questions in a short time. I wanted to do this in a more interactive way, so I asked Claude (explanatory mode) to help me with it.\n\nI used Claude instead of ChatGPT because:\n1. ChatGPT kept asking weird rewordings of the questions\n2. Worse at giving context\n3. Sometimes failed to parse the .pdf\n\nI provided the solutions (publicly accessible given Ed link), asked Claude to identify the most important problems, and then prompted it to ask me to give a conceptual approach before either going over the solutions or guiding me in the correct direction.\n\nPrompt:\n\"I'm on a time crunch, and I need to study for my Deep Neural Networks exam by reviewing the homework. Here is the first homework and solutions: https://static.us.edusercontent.com/files/aO8NnPYdzjOpEyEphrp1j0nZ\nI want you to:\n1. Identify the 5 most important problems (count subparts as individual problems)\n2. Ask me each question with its entire context, preferably barely modified, one at a time\n3. I will respond with a conceptual approach (I don't have time to fully solve)\n4. If I am correct, output the entire solution and move on to the next question; otherwise, continue guiding me to the correct approach\"\n\nThe results were better than expected. Claude was surprisingly good at picking out complicated problems while simultaneously summarizing all the necessary context, explaining the implications of solutions, and giving me hints. The main downside of this approach is that Claude's usage limit is quite small, making it unsustainable. Since the entire chat session took less than 20 minutes, I felt like this was a pretty time-effective way to study. Although I didn't get to cover most of the homework, I imagine this would be valuable if I really only had a short amount of time to study. \n\nMore details can be found in the annotated chat:\n\nAlso, here is an example of what ChatGPT asked me; I don't think it understood the purpose of my prompt:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>My personal studying strategy (whether effective or not) when reviewing homework/exams is to mentally attempt a question before reading the solution, allowing me to process a large number of questions in a short time. I wanted to do this in a more interactive way, so I asked Claude (explanatory mode) to help me with it.<break/><break/>I used Claude instead of ChatGPT because:<break/>1. ChatGPT kept asking weird rewordings of the questions<break/>2. Worse at giving context<break/>3. Sometimes failed to parse the .pdf<break/><break/>I provided the solutions (publicly accessible given Ed link), asked Claude to identify the most important problems, and then prompted it to ask me to give a conceptual approach before either going over the solutions or guiding me in the correct direction.<break/><break/>Prompt:<break/>\"I'm on a time crunch, and I need to study for my Deep Neural Networks exam by reviewing the homework. Here is the first homework and solutions: https://static.us.edusercontent.com/files/aO8NnPYdzjOpEyEphrp1j0nZ<break/>I want you to:<break/>1. Identify the 5 most important problems (count subparts as individual problems)<break/>2. Ask me each question with its entire context, preferably barely modified, one at a time<break/>3. I will respond with a conceptual approach (I don't have time to fully solve)<break/>4. If I am correct, output the entire solution and move on to the next question; otherwise, continue guiding me to the correct approach\"<break/><break/>The results were better than expected. Claude was surprisingly good at picking out complicated problems while simultaneously summarizing all the necessary context, explaining the implications of solutions, and giving me hints. The main downside of this approach is that Claude's usage limit is quite small, making it unsustainable. Since the entire chat session took less than 20 minutes, I felt like this was a pretty time-effective way to study. Although I didn't get to cover most of the homework, I imagine this would be valuable if I really only had a short amount of time to study. <break/><break/>More details can be found in the annotated chat:</paragraph><file url=\"https://static.us.edusercontent.com/files/6UZuY5izaNGKshSMsq7RJIqx\" filename=\"claude.pdf\"/><paragraph>Also, here is an example of what ChatGPT asked me; I don't think it understood the purpose of my prompt:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/H5CBht7K9l0WBO6owgRruSNI\" width=\"658\" height=\"207.03949044585988\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-23T20:26:37.729054+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7353572,
            "author": "Nyx Iskandar",
            "project_title": "Special Participation A: GPT-5 HW4",
            "post_body": "Generally. GPT-5 generates accurate answers for conceptual and computation questions. There are some conventions that it chooses to use that we don't use in class, like Xavier initialization using 1/sqrt(d). Some questions also required some further prompting, though generally one-shot is quite accurate.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/g8roLrS4bYkQKvYuk0BiquHH\" filename=\"EECS_182_HW_4_GPT_5_Trace.pdf\"/><paragraph>Generally. GPT-5 generates accurate answers for conceptual and computation questions. There are some conventions that it chooses to use that we don't use in class, like Xavier initialization using 1/sqrt(d). Some questions also required some further prompting, though generally one-shot is quite accurate.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-23T15:18:18.637808+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7353091,
            "author": "E Harrison",
            "project_title": "Special Participation A: Claude Sonnet 4.5 on HW3",
            "post_body": "Below is my report on using Claude's Sonnet 4.5 model to solve the written questions to Homework 3. I have also provided a link to the original conversation I had with Claude. Question-specific comments can be found in the PDF.\n\nFormatted PDF of conversation and additional comments:\n\nRaw Conversation:\nhttps://claude.ai/share/9305bd53-16e3-423c-b2de-143974dab634\n\nOverall Summary:\n\nAccuracy: Claude was able to get all but 2 of the questions correct on the first try. The questions it got incorrect were Q1b and Q5b. For Q1b, it made an error when doing some math calculations, and for Q5b, it did not consider loading the activations for layers 5 and 10. Despite these mistakes, it only took an additional comment from me to steer the model to the correct response.\n\nExplanations: Claude made their process of solving the questions very clear, and in my opinion explained its answers better than the answer key. A notable case of this is Q4c, where Claude identifies the need to use the chain rule to solve the question, which the answer key glosses over since the gradient of mu in that problem was just the identity matrix and didn't affect the final result.\n\nLength: Claude responded with very long answers all things considered. While they were quite long, I didn't find anything too extraneous in the answers. The most I would see of Claude giving more details about a specific answer it provided (e.g. explaining that the policy gradient was used in the REINFORCE algorithm. I also found Claude's extra information very useful for my understanding in some cases, particularly when it explained the papers from Q3.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is my report on using Claude's Sonnet 4.5 model to solve the written questions to Homework 3. I have also provided a link to the original conversation I had with Claude. Question-specific comments can be found in the PDF.</paragraph><paragraph>Formatted PDF of conversation and additional comments:</paragraph><file url=\"https://static.us.edusercontent.com/files/V1Jlglmdzs0ksAZFPOO9h0cn\" filename=\"Participation_A__Claude_on_HW3.pdf\"/><paragraph>Raw Conversation:<break/><link href=\"https://claude.ai/share/9305bd53-16e3-423c-b2de-143974dab634\">https://claude.ai/share/9305bd53-16e3-423c-b2de-143974dab634</link><break/><break/>Overall Summary:</paragraph><list style=\"bullet\"><list-item><paragraph><bold>Accuracy:</bold> Claude was able to get all but 2 of the questions correct on the first try. The questions it got incorrect were Q1b and Q5b. For Q1b, it made an error when doing some math calculations, and for Q5b, it did not consider loading the activations for layers 5 and 10. Despite these mistakes, it only took an additional comment from me to steer the model to the correct response.</paragraph></list-item><list-item><paragraph><bold>Explanations:</bold> Claude made their process of solving the questions very clear, and in my opinion explained its answers better than the answer key. A notable case of this is Q4c, where Claude identifies the need to use the chain rule to solve the question, which the answer key glosses over since the gradient of mu in that problem was just the identity matrix and didn't affect the final result.</paragraph></list-item><list-item><paragraph><bold>Length:</bold> Claude responded with very long answers all things considered. While they were quite long, I didn't find anything too extraneous in the answers. The most I would see of Claude giving more details about a specific answer it provided (e.g. explaining that the policy gradient was used in the REINFORCE algorithm. I also found Claude's extra information very useful for my understanding in some cases, particularly when it explained the papers from Q3.</paragraph></list-item></list><paragraph/></document>",
            "links": [
                "https://claude.ai/share/9305bd53-16e3-423c-b2de-143974dab634"
            ],
            "attachments": [],
            "created_at": "2025-11-23T12:23:45.008857+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7350819,
            "author": "Anant Sahai",
            "project_title": "IMPORTANT: Students must accept the reviewer invitation email...",
            "post_body": "We have quite a few people who haven't accepted their reviewer invitations --- sent to the email address that we can see using CalCentral. (Those who accepted can stop reading this message...)\n\nRemember how grading works for this class and for the project.  Reviewing performance (the quality of your peer reviews) multiplicatively hits the project grade for individuals. This has a consequence --- not doing reviews will get someone a zero on the project. \n\nRemember, there is no curve and failing the project means you automatically fail the class according to our grading policies.\n\nSo, you really really need to accept your reviewer invitations and then do a diligent job on the reviews. Otherwise, it will not end well for you in this course. \n\nWe don't typically send out email notifications for Ed Posts. But given the timelines involved and the risk to students, we made an exception in this case. ",
            "content_xml": "<document version=\"2.0\"><paragraph>We have quite a few people who haven't accepted their reviewer invitations --- sent to the email address that we can see using CalCentral. (Those who accepted can stop reading this message...)</paragraph><paragraph>Remember how grading works for this class and for the project.  Reviewing performance (the quality of your peer reviews) <italic>multiplicatively</italic> hits the project grade for individuals. This has a consequence --- not doing reviews will get someone a zero on the project. </paragraph><paragraph>Remember, there is no curve and failing the project means you automatically fail the class according to our grading policies.</paragraph><paragraph>So, you really really need to accept your reviewer invitations and then do a diligent job on the reviews. Otherwise, it will not end well for you in this course. </paragraph><paragraph>We don't typically send out email notifications for Ed Posts. But given the timelines involved and the risk to students, we made an exception in this case. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-22T17:19:12.010355+11:00",
            "category": "Project"
        },
        {
            "guid": 7350421,
            "author": "Oliver Chen",
            "project_title": "Special Participation B: Qwen on HW10 Coding",
            "post_body": "I used Qwen3-Max Thinking on the coding parts of Homework 10. I used a separate chat for each coding question, so there are 3 separate chat logs. Overall, Qwen had very strong performance and was almost able to one shot all of the questions, except for minor mistakes. \n\nQuestion 2 log: https://chat.qwen.ai/s/29ecf785-ec89-4e58-aab6-5f7675d8e02d?fev=0.0.248\n\nNotes: Because Qwen is unable to accept ipynb or py files, I copied the text contents of the .py version, and gave it to Qwen as text input. It was able to understand everything very well, and one-shot all parts of question 2 all at once. Plugging the code into the full notebook, it was able to run without errors and give reasonable results. \n\nQuestion 3 log: https://chat.qwen.ai/c/25253f17-c753-45e4-b584-4fe65b874415\n\nNotes: Similar to question 2, I fed the template notebook as text, from the .py version. In order to give the paper context on the Attention is All You Need paper that is cited in the question, I also uploaded it as a pdf. I also do want to note Qwen wasn\u2019t able to completely one-shot this question, as it had some errors with assigning the GPU device \u2013 however, it\u2019s logic was correct on the first shot. Thus it required a few more interactions with Qwen to have it arrive at the correct code. After plugging in the code it wrote into the original notebook and running it, here are the results:\n\n\nQuestion 4 log: https://chat.qwen.ai/s/d3dde69f-6dda-4327-858e-cc4f3c6dda60?fev=0.0.248\n\nNotes: I also fed the template notebook downloaded from the .py version. It was able to one-shot the code. I\u2019m not sure if this was necessary \u2013 but I also uploaded the \u201cBranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\u201d paper as a pdf to Qwen to provide it context on Early Exiting. It was able to fill in correct code and produce correct results. Here are results:\n(i) Regular ResNet-18\n\nAccuracy: \u224890.78% (0.9078333377838135)\n\nInference Speed: not explicitly measured; only tqdm progress is shown, no formal speed metric\n\nTotal MACS: 3,336,213,504,000\n\n(ii) Early-exit ResNet-18 (entropy tolerance = 0.05 in notebook)\n\nAccuracy: \u224890.78% (0.9078333377838135)\n\nInference Speed: not explicitly measured; tqdm progress suggests faster than baseline, but no formal metric\n\nTotal MACS: 2,305,700,339,712\n\n(iii) How did early exit do? (compare)\n\nAccuracy: Essentially unchanged (\u224890.78% for both baseline and early exit).\n\nMACS: Early exit uses about 1/1.4469 \u2248 69% of the baseline MACs, i.e. standard ResNet needs ~1.45\u00d7 more MACs than early exit.\n\n(iv) Lowest MACs found and what it says\n\nLowest MACs shown in the notebook outputs: 2,305,700,339,712 (for entropy tolerance 0.05).\n\nInterpretation: Early exit can significantly cut compute (MACs) while keeping \u226590% accuracy, implying many inputs are \u201ceasy\u201d and do not need the full depth.\n\n(v) Early exit vs smaller model \u2013 when and why\n\nUse early exit when:\n\nExample difficulty varies a lot (many easy, some hard).\n\nUse a smaller model when:\n\nYou want a single simple fixed\u2011cost model (no branches or thresholds).",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Qwen3-Max Thinking on the coding parts of Homework 10. I used a separate chat for each coding question, so there are 3 separate chat logs. Overall, Qwen had very strong performance and was almost able to one shot all of the questions, except for minor mistakes. </paragraph><paragraph>Question 2 log: <link href=\"https://chat.qwen.ai/s/29ecf785-ec89-4e58-aab6-5f7675d8e02d?fev=0.0.248\"><underline>https://chat.qwen.ai/s/29ecf785-ec89-4e58-aab6-5f7675d8e02d?fev=0.0.248</underline></link></paragraph><paragraph>Notes: Because Qwen is unable to accept ipynb or py files, I copied the text contents of the .py version, and gave it to Qwen as text input. It was able to understand everything very well, and one-shot all parts of question 2 all at once. Plugging the code into the full notebook, it was able to run without errors and give reasonable results. </paragraph><paragraph>Question 3 log: <link href=\"https://chat.qwen.ai/c/25253f17-c753-45e4-b584-4fe65b874415\"><underline>https://chat.qwen.ai/c/25253f17-c753-45e4-b584-4fe65b874415</underline></link></paragraph><paragraph>Notes: Similar to question 2, I fed the template notebook as text, from the .py version. In order to give the paper context on the Attention is All You Need paper that is cited in the question, I also uploaded it as a pdf. I also do want to note Qwen wasn\u2019t able to completely one-shot this question, as it had some errors with assigning the GPU device \u2013 however, it\u2019s logic was correct on the first shot. Thus it required a few more interactions with Qwen to have it arrive at the correct code. After plugging in the code it wrote into the original notebook and running it, here are the results:<break/></paragraph><figure><image src=\"https://static.us.edusercontent.com/files/8e11kBOO2UxkF3i4JfLi4PXJ\" width=\"658\" height=\"290.012474012474\"/></figure><paragraph>Question 4 log: <link href=\"https://chat.qwen.ai/s/d3dde69f-6dda-4327-858e-cc4f3c6dda60?fev=0.0.248\"><underline>https://chat.qwen.ai/s/d3dde69f-6dda-4327-858e-cc4f3c6dda60?fev=0.0.248</underline></link></paragraph><paragraph>Notes: I also fed the template notebook downloaded from the .py version. It was able to one-shot the code. I\u2019m not sure if this was necessary \u2013 but I also uploaded the \u201cBranchyNet: Fast Inference via Early Exiting from Deep Neural Networks\u201d paper as a pdf to Qwen to provide it context on Early Exiting. It was able to fill in correct code and produce correct results. Here are results:<break/>(i) Regular ResNet-18</paragraph><paragraph>Accuracy: \u224890.78% (0.9078333377838135)</paragraph><paragraph>Inference Speed: not explicitly measured; only tqdm progress is shown, no formal speed metric</paragraph><paragraph>Total MACS: 3,336,213,504,000</paragraph><paragraph>(ii) Early-exit ResNet-18 (entropy tolerance = 0.05 in notebook)</paragraph><paragraph>Accuracy: \u224890.78% (0.9078333377838135)</paragraph><paragraph>Inference Speed: not explicitly measured; tqdm progress suggests faster than baseline, but no formal metric</paragraph><paragraph>Total MACS: 2,305,700,339,712</paragraph><paragraph>(iii) How did early exit do? (compare)</paragraph><paragraph>Accuracy: Essentially unchanged (\u224890.78% for both baseline and early exit).</paragraph><paragraph>MACS: Early exit uses about 1/1.4469 \u2248 69% of the baseline MACs, i.e. standard ResNet needs ~1.45\u00d7 more MACs than early exit.</paragraph><paragraph>(iv) Lowest MACs found and what it says</paragraph><paragraph>Lowest MACs shown in the notebook outputs: 2,305,700,339,712 (for entropy tolerance 0.05).</paragraph><paragraph>Interpretation: Early exit can significantly cut compute (MACs) while keeping \u226590% accuracy, implying many inputs are \u201ceasy\u201d and do not need the full depth.</paragraph><paragraph>(v) Early exit vs smaller model \u2013 when and why</paragraph><paragraph>Use early exit when:</paragraph><paragraph>Example difficulty varies a lot (many easy, some hard).</paragraph><paragraph>Use a smaller model when:</paragraph><paragraph>You want a single simple fixed\u2011cost model (no branches or thresholds).</paragraph></document>",
            "links": [
                "https://chat.qwen.ai/s/29ecf785-ec89-4e58-aab6-5f7675d8e02d?fev=0.0.248",
                "https://chat.qwen.ai/c/25253f17-c753-45e4-b584-4fe65b874415",
                "https://chat.qwen.ai/s/d3dde69f-6dda-4327-858e-cc4f3c6dda60?fev=0.0.248"
            ],
            "attachments": [],
            "created_at": "2025-11-22T14:26:11.796877+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7348556,
            "author": "Hong Joey",
            "project_title": "Peer Review for Project Drafts",
            "post_body": "Review assignments are out for the project drafts and will be due by midnight next Tuesday 11/21. You can access them via the Reviewer console on Microsoft CMT (will look something like the below image): \n\nEveryone will have either 1 or 2 reports to review. The questions you need to answer in the review are tailored for this class, so it won't be the same questions as for a typical conference submission. Every paper will have between 2-4 reviews, with a majority having at least 3.\n\nIf you encounter any problems with submitting reviewers, feel free to ask questions on this thread.\n\nUPDATE: To keep workload fair among students, we have updated assignments so that every student will do exactly 1 review (for those who initially had 2, I removed one of yours at random).  ",
            "content_xml": "<document version=\"2.0\"><paragraph>Review assignments are out for the project drafts and will be <bold>due by midnight next Tuesday 11/21</bold>. You can access them via the Reviewer console on Microsoft CMT (will look something like the below image): </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/rsd2FHeheehLW749gCKZgqtE\" width=\"658\" height=\"171.24923453766075\"/></figure><paragraph>Everyone will have either 1 or 2 reports to review. The questions you need to answer in the review are tailored for this class, so it won't be the same questions as for a typical conference submission. Every paper will have between 2-4 reviews, with a majority having at least 3.<break/><break/>If you encounter any problems with submitting reviewers, feel free to ask questions on this thread.</paragraph><paragraph>UPDATE: To keep workload fair among students, we have updated assignments so that every student will do exactly 1 review (for those who initially had 2, I removed one of yours at random).  </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-22T07:25:02.363701+11:00",
            "category": "Project"
        },
        {
            "guid": 7345482,
            "author": "Sultan Daniels",
            "project_title": "Discussion 12 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/WQBMr9mVA0kmsWNeosE7eXwf\" filename=\"dis12_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/nGI5mNPZPBokPEODXd24vAbW\" filename=\"dis12_question.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-21T13:14:58.005565+11:00",
            "category": "Sections"
        },
        {
            "guid": 7335566,
            "author": "Jameson Liu",
            "project_title": "Special Participation E: Converting Lectures to Notes",
            "post_body": "I wanted a way to convert the lectures into a notes format, similar to those in CS70. This way, it would be easier to look for specific content and review material without needing to scan through the lecture recordings, timestamp by timestamp. While the lecture slides are posted, they alone do not cover everything stated in the lecture. \n\nTherefore, I wrote a script to use an LLM to convert lectures into well-formatted, academic notes. It uses lecture slides and the transcript of the lecture recording (easily copyable), so no information is left out. An LLM is necessary for this task since 1. the YouTube transcript has several mistakes, and 2. traditional .pdf readers are not great at extracting handwritten text (especially math). \n\nI had to use the Gemini API instead of a typical LLM website, since uploading a .pdf usually just extracts its text instead of having the LLM read it visually (which is a problem since traditional OCR fails). My code takes every page of the lecture slides and converts it to an image before appending it to the request (I verified that this works by testing it without providing a transcript).\n\nBelow is the script and an annotated example (rendered from .tex) output. Running it requires a Gemini API key, which is free (subject to rate limit). The following is from lecture 2, and the transcript is copied directly from the YouTube transcript section (description -> transcript -> hide timestamps). ",
            "content_xml": "<document version=\"2.0\"><paragraph>I wanted a way to convert the lectures into a notes format, similar to those in CS70. This way, it would be easier to look for specific content and review material without needing to scan through the lecture recordings, timestamp by timestamp. While the lecture slides are posted, they alone do not cover everything stated in the lecture. </paragraph><paragraph>Therefore, I wrote a script to use an LLM to convert lectures into well-formatted, academic notes. It uses lecture slides and the transcript of the lecture recording (easily copyable), so no information is left out. An LLM is necessary for this task since 1. the YouTube transcript has several mistakes, and 2. traditional .pdf readers are not great at extracting handwritten text (especially math). <break/><break/>I had to use the Gemini API instead of a typical LLM website, since uploading a .pdf usually just extracts its text instead of having the LLM read it visually (which is a problem since traditional OCR fails). My code takes every page of the lecture slides and converts it to an image before appending it to the request (I verified that this works by testing it without providing a transcript).<break/><break/>Below is the script and an annotated example (rendered from .tex) output. Running it requires a Gemini API key, which is free (subject to rate limit). The following is from lecture 2, and the transcript is copied directly from the YouTube transcript section (description -&gt; transcript -&gt; hide timestamps). </paragraph><file url=\"https://static.us.edusercontent.com/files/Cd3H2Ms186TdwbAbUYsO21an\" filename=\"lecture_notes_generator.py\"/><file url=\"https://static.us.edusercontent.com/files/KMYhxbngSstZOFkUIqeGe4ED\" filename=\"lecture_transcript.txt\"/><file url=\"https://static.us.edusercontent.com/files/b3OLyIUjmGeTp9nUFOzrYzXB\" filename=\"lecture_notes.pdf\"/><file url=\"https://static.us.edusercontent.com/files/CGZZqK2lhpg57awIG1m4WKzU\" filename=\"lecture_notes.tex\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-19T20:11:54.045815+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7335374,
            "author": "Kabir Shah",
            "project_title": "Special Participation A: Kimi on HW5",
            "post_body": "Above is the chat log. I found Kimi K2 w/ Thinking enabled to be able to one-shot 90% of the questions on the non-coding parts of HW5. This surprisingly included the ability to one shot questions that required images \u2013 for example, choosing whether the given image represented batch norm or layer norm it was able to correctly respond. The only error it ran into was when it hallucinated the next part of the question a bit and went off on a tangent about \"covariance\" even though it wasn't really mentioned in the question. I had to manually correct it by reminding it of the question and formatting it in plain text. With this information, it had interesting thought traces in its chain of thought, such as:\n\n\"The user is correcting me about part (b) of the question. Let me re-read the prompt carefully.\"\n\n\"This might be asking about Cov(x_i, y_i) or something else. But the user's clarification is clear: they want the gradient analysis. I should focus on what the user is asking for now, not what the original prompt might have intended.\"\n\nThis was interesting to me because it was able to correct itself and keep itself on-course. I also found that the reasoning traces often included pretty granular steps involved for calculating derivatives and working through more mechanical calculations such as the manual convolution calculation in the first question. These granular steps probably allow it to make incremental progress where each incremental step is in-distribution.\n\nI honestly didn't have much strategy because it was able to one-shot so many of the questions. Overall, I found that short prompts work better as to not pollute the context window. Restarting chats for new questions also helped to not have it get confused by older parts.\n\nAnother observation I had was that most times it included a lot of extra fluff around the final answer and even answered some things that were not asked to go above and beyond. This could be helpful for understanding and learning but probably not so much if your main goal is to just solve the problem because now you must dig through the response to find it.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/nR59ctWxqGhibIIrL6jIYCCN\" filename=\"special_participation_a.pdf\"/><paragraph>Above is the chat log. I found Kimi K2 w/ Thinking enabled to be able to one-shot 90% of the questions on the non-coding parts of HW5. This surprisingly included the ability to one shot questions that required images \u2013 for example, choosing whether the given image represented batch norm or layer norm it was able to correctly respond. The only error it ran into was when it hallucinated the next part of the question a bit and went off on a tangent about \"covariance\" even though it wasn't really mentioned in the question. I had to manually correct it by reminding it of the question and formatting it in plain text. With this information, it had interesting thought traces in its chain of thought, such as:<break/><break/>\"The user is correcting me about part (b) of the question. Let me re-read the prompt carefully.\"</paragraph><paragraph>\"This might be asking about Cov(x_i, y_i) or something else. But the user's clarification is clear: they want the gradient analysis. I should focus on what the user is asking for now, not what the original prompt might have intended.\"</paragraph><paragraph>This was interesting to me because it was able to correct itself and keep itself on-course. I also found that the reasoning traces often included pretty granular steps involved for calculating derivatives and working through more mechanical calculations such as the manual convolution calculation in the first question. These granular steps probably allow it to make incremental progress where each incremental step is in-distribution.</paragraph><paragraph>I honestly didn't have much strategy because it was able to one-shot so many of the questions. Overall, I found that short prompts work better as to not pollute the context window. Restarting chats for new questions also helped to not have it get confused by older parts.</paragraph><paragraph>Another observation I had was that most times it included a lot of extra fluff around the final answer and even answered some things that were not asked to go above and beyond. This could be helpful for understanding and learning but probably not so much if your main goal is to just solve the problem because now you must dig through the response to find it.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-19T18:19:41.009736+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7333500,
            "author": "Anant Sahai",
            "project_title": "Lecture 23: MetaLearning and Forgetting",
            "post_body": "Ask questions here.\n\nThe VAE material at the end we didn't really get to enough. So we will continue from there next time. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/dSULrdJq0OTsxHALTSARr6Vy\" filename=\"Lecture 23.pdf\"/><paragraph>Ask questions here.</paragraph><paragraph>The VAE material at the end we didn't really get to enough. So we will continue from there next time. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-19T11:50:37.78892+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7333490,
            "author": "Anant Sahai",
            "project_title": "Lectures 21 & 22: Parameter-Efficient Fine Tuning",
            "post_body": "Apologies for the delay. \n\nThese are for ICL, prompting, soft-prompting, and LoRA fine-tuning. \n\nAsk questions here.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/Ly7z9BqOrePgZ6MwQyFafC1o\" filename=\"Lecture 21.pdf\"/><file url=\"https://static.us.edusercontent.com/files/gHZrapSyGA7ytOh1W8DXZwKb\" filename=\"Lecture 22.pdf\"/><paragraph>Apologies for the delay. </paragraph><paragraph>These are for ICL, prompting, soft-prompting, and LoRA fine-tuning. </paragraph><paragraph>Ask questions here.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-19T11:49:37.095228+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7325831,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q7: Quantization and Pruning",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/6I4tlRep1299xrHWc57R8mAP\" width=\"658\" height=\"1323.6334106728539\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T10:14:31.383296+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7325825,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q6: Soft-Prompting Language Models",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/gPpCVvnIf1Geh369YGSKCkI2\" width=\"658\" height=\"1219.982832618026\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T10:13:39.318021+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7325658,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q5: Fermi Estimation for Large-scale Deep Learning Models",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/7V8EhRuXYRNmtjwGiljxkFv5\" width=\"658\" height=\"767.4841930116472\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/G5d5NHI3qnpKKEt192LT5CuZ\" width=\"643\" height=\"892.8066202090592\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/cmqcheltUdEIbvh7LP5YgNEJ\" width=\"643\" height=\"875.5034602076125\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/tq9mmOR7rOEoQbhoKubFLzwf\" width=\"643\" height=\"887.1336898395723\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/5WHpTKasf5rdB29TuWZiochJ\" width=\"643\" height=\"850.6701208981002\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/j1iLT1cuRQFgC7jIe3yvqUEx\" width=\"643\" height=\"911.5805309734513\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/PQtqA5QQtT1EyYe4OJhkhdpe\" width=\"643\" height=\"407.2702237521514\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T09:50:14.913626+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7325651,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q4: Scaling Laws of Batch Size",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/hzjXb08t0a8xX8F5u5ImVebS\" width=\"657.9999999999999\" height=\"473.89072847682115\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T09:49:23.834168+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7325592,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q3: Coding Question: Transformer Interpretability",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/d4IWyV3cIhqfZsFff6RKxEWN\" width=\"658\" height=\"100.8047138047138\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T09:42:23.29779+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7325586,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q2: A Brief Introduction to Transformer Interpretability",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/4Ctqtq2c9gRtOgB7ZKQwLCTS\" width=\"658\" height=\"300.6293494704992\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/U6lOLKgspuC05sINnNEeuapr\" width=\"658\" height=\"894.058925476603\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/bKYmdjG3jMF4Bbyc4iBLI7Tt\" width=\"658\" height=\"928.3950617283951\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/gt8AXY4lexTab1Db4lSJgGz6\" width=\"658\" height=\"915.6783216783217\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/1fcSjrdTkgUXaO5goXe3b80M\" width=\"658\" height=\"890.037478705281\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/9ig6xH8UncdnFZ8de0NHZrJg\" width=\"643\" height=\"604.3061946902656\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T09:41:20.853254+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7324903,
            "author": "Sultan Daniels",
            "project_title": "HW11 Q1: LoRA",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/PKgsqjMJKMw1Q80nbFbtVjN5\" width=\"658\" height=\"467.80610412926393\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-18T08:09:20.264488+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7322058,
            "author": "Hanna Roed",
            "project_title": "Special Participation A: Qwen on HW8",
            "post_body": "Below is my report on using Qwen3-Max on the written part of homework 8.\n\nOverall, I'm very impressed by Qwen3-Max's performance on this homework. It seems like it really does well on the questions where it needs to fill in or do multiple choice, i. e., problems 3 and 4. The main issues I had were in the second half of problem 1, which was regarding computational efficiency; it had a hard time accurately responding in text along with giving a mathematical reasoning.",
            "content_xml": "<document version=\"2.0\"><paragraph>Below is my report on using Qwen3-Max on the written part of homework 8.<break/><break/>Overall, I'm very impressed by Qwen3-Max's performance on this homework. It seems like it really does well on the questions where it needs to fill in or do multiple choice, i. e., problems 3 and 4. The main issues I had were in the second half of problem 1, which was regarding computational efficiency; it had a hard time accurately responding in text along with giving a mathematical reasoning.</paragraph><file url=\"https://static.us.edusercontent.com/files/WjU2DMEsP3MKkTQmUuocYJkD\" filename=\"Special_Participation_A_HW8.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-17T18:22:18.14388+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7320260,
            "author": "Srikar Babu Gadipudi",
            "project_title": "Special Participation B: Kimi on HW 4 Coding Questions",
            "post_body": "Executive Summary\n\nThere are two coding questions in HW4: one (Q5) on hand-crafting kernels for image blurring and edge detection, and another (Q6) on exploring the inductive bias of CNNs. Q5 is simple and requires us to initialize an average-filtering kernel and the Laplacian kernel. Kimi was able to correctly use NumPy to define these kernels with the relevant information.\n\nQ6 involved a blend of coding and theory-informed reasoning based on observing outputs from the code. Kimi was able to help with both tasks efficiently. In a few places, it sidetracked and wrote code without explicit user input, but with a small nudge it stayed on track.\n\nKimi, known for its long context window, was able to capture essential information from long prompts and recover details from earlier parts of the chat effectively. Overall, it produced the correct code and answered the theoretical questions accurately.\n\nHere is the link to the chat: https://www.kimi.com/share/19a8f132-5652-855c-8000-0000f8c30b29\n\nSince the chat history is long, I have selectively chosen and annotated my thoughts for some interesting prompts and outputs. Find the file below:",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>There are two coding questions in HW4: one (Q5) on hand-crafting kernels for image blurring and edge detection, and another (Q6) on exploring the inductive bias of CNNs. Q5 is simple and requires us to initialize an average-filtering kernel and the Laplacian kernel. Kimi was able to correctly use NumPy to define these kernels with the relevant information.</paragraph><paragraph>Q6 involved a blend of coding and theory-informed reasoning based on observing outputs from the code. Kimi was able to help with both tasks efficiently. In a few places, it sidetracked and wrote code without explicit user input, but with a small nudge it stayed on track.</paragraph><paragraph>Kimi, known for its long context window, was able to capture essential information from long prompts and recover details from earlier parts of the chat effectively. Overall, it produced the correct code and answered the theoretical questions accurately.</paragraph><paragraph>Here is the link to the chat: <link href=\"https://www.kimi.com/share/19a8f132-5652-855c-8000-0000f8c30b29\">https://www.kimi.com/share/19a8f132-5652-855c-8000-0000f8c30b29</link></paragraph><paragraph>Since the chat history is long, I have selectively chosen and annotated my thoughts for some interesting prompts and outputs. Find the file below:</paragraph><file url=\"https://static.us.edusercontent.com/files/dm26Wfcd2YaolJeHdfQaVNVt\" filename=\"Kimi_on_HW4_coding.pdf\"/></document>",
            "links": [
                "https://www.kimi.com/share/19a8f132-5652-855c-8000-0000f8c30b29"
            ],
            "attachments": [],
            "created_at": "2025-11-17T12:04:10.411588+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7319120,
            "author": "Jason Guo",
            "project_title": "Special Participation E: Using ChatGPT to understand papers",
            "post_body": "I find reading papers on deep learning to be pretty difficult at times, because they often assume a level of mathematical knowledge or background knowledge that I don't have. Because of this, it feels like papers under explain a lot of things, making them hard to understand.\n\nI was interested in seeing the proof for a claim that was stated, but not proved, in lecture 8, so I thought it would be interesting to get ChatGPT to explain the proof to me. The claims I wanted it to prove are claims 1 and 2 here: https://arxiv.org/pdf/2310.17813\n\nOverall, I think it did a good job of filling in the blanks of certain steps that are glossed over in the paper, and answering follow up questions to clarify confusion. However, I think the way ChatGPT presents information can kind of be disorganized and confusing, so it takes some work to figure out what exactly the structure of its claims or proofs are. In particular, it often answers things in bullet points or divides its answers up into sections, rather than just answering in full sentences and paragraphs, which makes it confusing for me at times.\n\nAnnotated conversation with more detailed comments: https://drive.google.com/file/d/1r-ZZ3-P1c_IzPMdpXhegt_hDgqfDU0U4/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>I find reading papers on deep learning to be pretty difficult at times, because they often assume a level of mathematical knowledge or background knowledge that I don't have. Because of this, it feels like papers under explain a lot of things, making them hard to understand.<break/><break/>I was interested in seeing the proof for a claim that was stated, but not proved, in lecture 8, so I thought it would be interesting to get ChatGPT to explain the proof to me. The claims I wanted it to prove are claims 1 and 2 here: <link href=\"https://arxiv.org/pdf/2310.17813\">https://arxiv.org/pdf/2310.17813</link></paragraph><paragraph>Overall, I think it did a good job of filling in the blanks of certain steps that are glossed over in the paper, and answering follow up questions to clarify confusion. However, I think the way ChatGPT presents information can kind of be disorganized and confusing, so it takes some work to figure out what exactly the structure of its claims or proofs are. In particular, it often answers things in bullet points or divides its answers up into sections, rather than just answering in full sentences and paragraphs, which makes it confusing for me at times.</paragraph><paragraph>Annotated conversation with more detailed comments: https://drive.google.com/file/d/1r-ZZ3-P1c_IzPMdpXhegt_hDgqfDU0U4/view?usp=sharing</paragraph></document>",
            "links": [
                "https://arxiv.org/pdf/2310.17813"
            ],
            "attachments": [],
            "created_at": "2025-11-17T08:30:34.025542+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7315986,
            "author": "Angelina Zhang",
            "project_title": "Special Participation A: Deepseek on HW6",
            "post_body": "I used DeepSeek on HW 6 non coding questions and here is my annotated log file with reflections.\nhttps://drive.google.com/file/d/1XfIWHSvILyZ-1hMksxc6cLJF1uHOxsKb/view?usp=sharing\n\nTL;DR DeepSeek can one-shot most conceptual, math-heavy parts (roughly 70\u201380% of subparts) with answers very close to the official solution. Its mistakes are structured, not random hallucinations: mainly convention/spec mismatches (row vs column, \u201cno analog needed\u201d parts), and graph/figure misreads.\nMy enforced structure (Restated Problem \u2192 Plan \u2192 Reasoning \u2192 Self-Check) makes its thinking transparent but does not make it truly self-critical. It rarely catches its own deeper mistakes.\n\nReflection\nUsing DeepSeek on the non-coding parts of HW6, I found that it followed my structured prompt very well: it restated each question, proposed a plan, walked through step-by-step reasoning, and ended with a self-check. This made its reasoning transparent and easy to annotate. On many subparts, it produced answers that were essentially identical to the official solution on the first try. However, there were two clear failure modes. The first was convention mismatch: for example, in Q2(c) it understood that updates correspond to multiplying by the adjacency matrix, but it hedged between left- and right-multiplication instead of committing to the \u201crows \u2192 multiply on the left\u201d convention that the homework fixes. The second failure mode was misreading the graph: in Q3(c)(iii), it simply used the wrong neighbor sets for nodes 2 and 3, so the final formulas were incorrect despite having the right functional form.\n\nWhat I find interesting is the \u201cSelf-Check\u201d sections mostly checked basic sanity and whether the answer addressed the question, but they did not help the model catch these deeper issues. It rarely expressed uncertainty, even in places where the mapping was clearly ambiguous or dependent on the figure. Overall, I think DeepSeek can get you most of the way to a good solution with clear reasoning, but you cannot safely copy its answers blindly. To reach fully correct solutions, you still need to actively verify conventions and adjust answers.",
            "content_xml": "<document version=\"2.0\"><paragraph>I used DeepSeek on HW 6 non coding questions and here is my annotated log file with reflections.<break/>https://drive.google.com/file/d/1XfIWHSvILyZ-1hMksxc6cLJF1uHOxsKb/view?usp=sharing<break/><break/><bold>TL;DR</bold> DeepSeek can one-shot most conceptual, math-heavy parts (roughly 70\u201380% of subparts) with answers very close to the official solution. Its mistakes are structured, not random hallucinations: mainly convention/spec mismatches (row vs column, \u201cno analog needed\u201d parts), and graph/figure misreads.<break/>My enforced structure (Restated Problem \u2192 Plan \u2192 Reasoning \u2192 Self-Check) makes its thinking transparent but does not make it truly self-critical. It rarely catches its own deeper mistakes.<break/><break/>Reflection<break/>Using DeepSeek on the non-coding parts of HW6, I found that it followed my structured prompt very well: it restated each question, proposed a plan, walked through step-by-step reasoning, and ended with a self-check. This made its reasoning transparent and easy to annotate. On many subparts, it produced answers that were essentially identical to the official solution on the first try. However, there were two clear failure modes. The first was convention mismatch: for example, in Q2(c) it understood that updates correspond to multiplying by the adjacency matrix, but it hedged between left- and right-multiplication instead of committing to the \u201crows \u2192 multiply on the left\u201d convention that the homework fixes. The second failure mode was misreading the graph: in Q3(c)(iii), it simply used the wrong neighbor sets for nodes 2 and 3, so the final formulas were incorrect despite having the right functional form.</paragraph><paragraph>What I find interesting is the \u201cSelf-Check\u201d sections mostly checked basic sanity and whether the answer addressed the question, but they did not help the model catch these deeper issues. It rarely expressed uncertainty, even in places where the mapping was clearly ambiguous or dependent on the figure. Overall, I think DeepSeek can get you most of the way to a good solution with clear reasoning, but you cannot safely copy its answers blindly. To reach fully correct solutions, you still need to actively verify conventions and adjust answers.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-16T11:39:27.836513+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7313471,
            "author": "Tianqu He",
            "project_title": "Special Participation B: Mistral AI on HW8 coding part",
            "post_body": "Executive Summary\n\nThis interaction was conducted with Mistral AI.\n\nOne-Shot Success Rate: The model successfully provided a correct, runnable solution on the first try for 5 out of 6 core coding tasks.\n\nMajor Hallucinations/Misconceptions: \n\n1. The model initially failed to grasp why the convolution kernel needed to be flipped for a causal SSM, treating it as a rote step. It took repeated, explicit mathematical justification to correct this. \n\n2. Maybe the model reasons on its previous outputs rather than prompts. That is demonstrated by question 5.\n\nKey Strategies Used:\n\nUsing the provided sanity check as a tool was crucial. I reported the error clearly so that the model can make adjustments.\n\nFor complex functions like make_conv_kernel, it was more effective to fix one part of the logic (the flipping) first, validate it, and then move on to the next issue (the grouping).\n\nOverall Assessment: It can handle straightforward implementation tasks well but struggles with conceptually nuanced problems. Success requires me to possess a solid enough understanding of the domain to detect misconceptions, ask the right probing questions, and guide the debugging process. It cannot reliably \"drag itself\" to a correct solution without an informed human in the loop.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/wKra3uQ5sIVxQ1KV6JbVnwua\" filename=\"Le Chat.pdf\"/><paragraph><bold>Executive Summary</bold></paragraph><paragraph>This interaction was conducted with <bold>Mistral AI</bold>.</paragraph><paragraph><bold>One-Shot Success Rate:</bold> The model successfully provided a correct, runnable solution on the first try for 5 out of 6 core coding tasks.</paragraph><paragraph><bold>Major Hallucinations/Misconceptions:</bold> </paragraph><paragraph>1. The model initially failed to grasp <italic>why</italic> the convolution kernel needed to be flipped for a causal SSM, treating it as a rote step. It took repeated, explicit mathematical justification to correct this. </paragraph><paragraph>2. Maybe the model reasons on its previous outputs rather than prompts. That is demonstrated by question 5.</paragraph><paragraph><bold>Key Strategies Used:</bold></paragraph><paragraph>Using the provided sanity check as a tool was crucial. I reported the error clearly so that the model can make adjustments.</paragraph><paragraph>For complex functions like <code>make_conv_kernel</code>, it was more effective to fix one part of the logic (the flipping) first, validate it, and then move on to the next issue (the grouping).</paragraph><paragraph><bold>Overall Assessment:</bold> It can handle straightforward implementation tasks well but struggles with conceptually nuanced problems. Success requires me to possess a solid enough understanding of the domain to detect misconceptions, ask the right probing questions, and guide the debugging process. It cannot reliably \"drag itself\" to a correct solution without an informed human in the loop.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-15T20:19:34.478529+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7308816,
            "author": "Lance Mathias",
            "project_title": "Discussion 11 Solutions",
            "post_body": "Attached are questions and solutions to Discussion 11:",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are questions and solutions to Discussion 11:</paragraph><file url=\"https://static.us.edusercontent.com/files/BZCV6zCJZUUZ4hSiWHj3Zmxx\" filename=\"dis11_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/1jUbwwjo6mfufK52zcB7D8nh\" filename=\"dis11_question.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-14T19:24:35.474514+11:00",
            "category": "Sections"
        },
        {
            "guid": 7307445,
            "author": "Tianqu He",
            "project_title": "Special Participation A: Mistral AI on HW0 written",
            "post_body": "Sorry for being so late. I used Le Chat to assist with the conceptual and mathematical parts of homework, specifically the ReLU/SGD analysis and vector calculus derivations. The experience was overwhelmingly positive, with the assistant demonstrating strong expertise in linear algebra, optimization, and neural network dynamics.\n\nStrengths:\n\n1. Le Chat correctly derived most of the results.\n\n2. The assistant provided clear, structured derivations for the optimization, SVD, and MAP estimation perspectives, making complex concepts (like the pseudoinverse and Woodbury identity) accessible.\n\nLimitations:\n\nWhile the assistant excelled at algebraic manipulation, it could not directly parse or reason about visual elements (e.g., graph structures or plots). For example, if the problem had included a diagram of the ReLU function or a computational graph, I had to describe it textually for accurate analysis.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/OcKvB1WfhGJMEpc25FNuAyPd\" filename=\"Le Chat.pdf\"/><paragraph>Sorry for being so late. I used <bold>Le Chat</bold> to assist with the conceptual and mathematical parts of homework, specifically the ReLU/SGD analysis and vector calculus derivations. The experience was overwhelmingly positive, with the assistant demonstrating strong expertise in linear algebra, optimization, and neural network dynamics.</paragraph><paragraph><bold>Strengths:</bold></paragraph><paragraph><bold>1.</bold> Le Chat correctly derived most of the results.</paragraph><paragraph><bold>2.</bold> The assistant provided clear, structured derivations for the optimization, SVD, and MAP estimation perspectives, making complex concepts (like the pseudoinverse and Woodbury identity) accessible.</paragraph><paragraph><bold>Limitations:</bold></paragraph><paragraph>While the assistant excelled at algebraic manipulation, it could not directly parse or reason about visual elements (e.g., graph structures or plots). For example, if the problem had included a diagram of the ReLU function or a computational graph, I had to describe it textually for accurate analysis.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-14T12:56:44.53714+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7306483,
            "author": "Xi Cheng",
            "project_title": "Special Participation B: Mistral on HW1 Coding parts",
            "post_body": "Chat history link: https://chat.mistral.ai/chat/3443f2c5-f486-44c5-b8f2-359d56793052\n\nAnnotated Chat history: \n\nExecutive Summary \n\nIn this assignment, I interactively used Mistral to complete two coding TODOs. Overall, Mistral demonstrated strong pattern-matching and code-generation abilities, but also showed limitations in faithfully following constrained instructions.\n\nFor the first TODO, I explicitly instructed Mistral to fill only the missing code while keeping the rest of the solution unchanged. Mistral performed this task well: it inserted the correct code block, respected the constraints, and provided a short explanation. \n\nFor the second TODO, the assignment required modifying only the faster optimizer\u2019s learning rate to improve convergence speed. Despite emphasizing this constraint, Mistral initially violated it by changing both the GD and GDM learning rates. This indicates a tendency to \u201cover-correct\u201d or apply symmetrical changes even when the prompt imposes an asymmetrical constraint. After I provided a clarifying follow-up hint, Mistral produced the correct answer.\n\nOverall Observations\n\nMistral performs reliably on well-specified code-completion tasks, but struggles when instructions require fine-grained constraint adherence. Human intervention\u2014especially clarifications or corrective hints\u2014is essential to steer the model toward assignment-compliant solutions.",
            "content_xml": "<document version=\"2.0\"><paragraph>Chat history link: https://chat.mistral.ai/chat/3443f2c5-f486-44c5-b8f2-359d56793052</paragraph><paragraph>Annotated Chat history: </paragraph><file url=\"https://static.us.edusercontent.com/files/Iy9zXbdrHit2JcHpAz5n3w26\" filename=\"annotated_mistral_hw01code.pdf\"/><heading level=\"2\"><bold>Executive Summary</bold> </heading><paragraph>In this assignment, I interactively used <bold>Mistral</bold> to complete two coding TODOs. Overall, Mistral demonstrated strong pattern-matching and code-generation abilities, but also showed limitations in faithfully following constrained instructions.</paragraph><paragraph>For the first TODO, I explicitly instructed Mistral to fill only the missing code while keeping the rest of the solution unchanged. Mistral performed this task well: it inserted the correct code block, respected the constraints, and provided a short explanation. </paragraph><paragraph>For the second TODO, the assignment required modifying <bold>only the faster optimizer\u2019s learning rate</bold> to improve convergence speed. Despite emphasizing this constraint, Mistral initially violated it by changing <bold>both</bold> the GD and GDM learning rates. This indicates a tendency to \u201cover-correct\u201d or apply symmetrical changes even when the prompt imposes an asymmetrical constraint. After I provided a clarifying follow-up hint, Mistral produced the correct answer.</paragraph><paragraph><bold>Overall Observations</bold></paragraph><paragraph>Mistral performs reliably on <bold>well-specified code-completion tasks</bold>, but struggles when instructions require <bold>fine-grained constraint adherence</bold>. Human intervention\u2014especially clarifications or corrective hints\u2014is essential to steer the model toward assignment-compliant solutions.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-14T09:49:03.620445+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7302906,
            "author": "Oliver Chen",
            "project_title": "Special Participation A: Qwen on HW9",
            "post_body": "For the special participation A on HW9, I use Qwen to solve the non-coding analytical components (problems 2\u20135). The performance was very strong -- almost all questions were very quickly solved by directly copy-pasting the question, which had multiple parts often.\n\n\n\nExecutive Summary\n\nUsed qwen thinking, with max thinking context length (81920 tokens).\n\n I also noticed from other attempts that often giving the hint associated with the question (if the question has a hint) generally helps make its answer more likely to be correct, or guides it in the right direction very well.\n\n For Question 3 part b, I had to nudge it to give the answer regarding the new out_features value. However, after reminding it, all of its answers were correct.\n\n I also ignored small formatting issues, and noticed even with formatting issues (some symbols were not pasted/displayed properly), Qwen was still able to understand all the questions and provide correct solutions.\n\n For longer questions (such as question 6), I also thought about pasting/asking the questions in chunks, rather than the entire multi-part question at a time. However, I found that Qwen was able to answer correctly even when giving the entire question at a time.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>For the special participation A on HW9, I use Qwen to solve the non-coding analytical components (problems 2\u20135). The performance was very strong -- almost all questions were very quickly solved by directly copy-pasting the question, which had multiple parts often.</paragraph><paragraph/><paragraph><bold>Executive Summary</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/KvPPtjIXnLRvaWpjzDfJcqSZ\" filename=\"Qwen_HW_Report_Formatted.docx\"/><paragraph>Used qwen thinking, with max thinking context length (81920 tokens).<break/><break/> I also noticed from other attempts that often giving the hint associated with the question (if the question has a hint) generally helps make its answer more likely to be correct, or guides it in the right direction very well.<break/><break/> For Question 3 part b, I had to nudge it to give the answer regarding the new out_features value. However, after reminding it, all of its answers were correct.<break/><break/> I also ignored small formatting issues, and noticed even with formatting issues (some symbols were not pasted/displayed properly), Qwen was still able to understand all the questions and provide correct solutions.<break/><break/> For longer questions (such as question 6), I also thought about pasting/asking the questions in chunks, rather than the entire multi-part question at a time. However, I found that Qwen was able to answer correctly even when giving the entire question at a time.<break/><break/></paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-13T15:59:58.033068+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7300719,
            "author": "Leon Kornfeld",
            "project_title": "Special Participation E: Attention and Transformers Visualized with Claude Sonnet 4.5",
            "post_body": "I\u2019d been struggling to reason about how information flows through attention and transformer blocks at a low level\u2014specifically how the matrix multiplications and changing dimensions still produce an output with the same dimensionality as the input. I was also unclear on how multi-head attention differs from single-head attention and how the whole mechanism fits together.\n\nTo sort it out, I used Claude to build a visualization that traces the full path through a transformer. I iterated on it: starting with high-level questions, refining answers, and ending with a 14-step walkthrough that explains attention, the transformer block, and the computations between them.\n\nHere is the published link of the visualization: https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8\n\n\n\nAs I went, my questions became more targeted, drilling into different parts of the architecture.\n\nAt the end, in addition to reviewing Claude's output, looking for any hallucinations, I also pasted the entire source code into GPT-5 to see if it could find any mistakes. GPT was able to point out some assumptions that Claude made that weren't as clear as they could have been. I took GPT's feedback and gave it to Claude for the final iteration of the tool.\n\nHere is my annotated transcript:\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I\u2019d been struggling to reason about how information flows through attention and transformer blocks at a low level\u2014specifically how the matrix multiplications and changing dimensions still produce an output with the same dimensionality as the input. I was also unclear on how multi-head attention differs from single-head attention and how the whole mechanism fits together.</paragraph><paragraph>To sort it out, I used Claude to build a visualization that traces the full path through a transformer. I iterated on it: starting with high-level questions, refining answers, and ending with a 14-step walkthrough that explains attention, the transformer block, and the computations between them.</paragraph><paragraph>Here is the published link of the visualization: <link href=\"https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8\">https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8</link></paragraph><paragraph/><paragraph>As I went, my questions became more targeted, drilling into different parts of the architecture.</paragraph><paragraph>At the end, in addition to reviewing Claude's output, looking for any hallucinations, I also pasted the entire source code into GPT-5 to see if it could find any mistakes. GPT was able to point out some assumptions that Claude made that weren't as clear as they could have been. I took GPT's feedback and gave it to Claude for the final iteration of the tool.</paragraph><paragraph>Here is my annotated transcript:</paragraph><file url=\"https://static.us.edusercontent.com/files/YbYkT62G1SqWbf9FlhoZmEp2\" filename=\"Claude-Transformer attention mechanism visualization.pdf\"/><paragraph/><paragraph/><paragraph/></document>",
            "links": [
                "https://claude.ai/public/artifacts/2ef271c0-bffd-4709-a7e4-cdc2d66bb2b8"
            ],
            "attachments": [],
            "created_at": "2025-11-13T09:46:15.187018+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7297480,
            "author": "Kithmini Herath",
            "project_title": "Special Participation A: Gemini 2.5 Pro on HW5",
            "post_body": "I used Gemini 2.5 Pro to solve the written parts of Homework 5 (Q1-4). I started by mentioning that I wanted to solve a problem set related to a specific topic (in this case, basics of CNNs) and went over the four problems one by one with attached screenshots of the entire problem. I\u2019ve attached an annotated pdf of my interactions with the LLM and a link to my original chat. \n\nIn summary, even without extensive context in my typed prompt, Gemini 2.5 Pro was able to extract information included within the problem from the screenshots themselves and one-shot solve almost all the problems correctly without any hallucinations. \n\nNotable observations: \n\nGood parsing of information - Most of the time it correctly parsed all mathematical equations, figures and text from the screenshots, even when a problem was spread across multiple screenshots. This is evident because it often types back key information from the problem statement to formulate the answer. All final answers (after corrections noted below) had no mathematical or conceptual errors. \n\nMisinterpretation of a hint - In question 1b), it used the hint to solve the problem itself. I wonder if this is because it mostly encountered instances of math problems where the hint is used to solve the problem itself. However, when I went through the other special participation threads for HW5 (that were posted as of 11/12/25), I noticed that none of those LLMs used the hint this way and often correctly interpreted it. So, it was interesting to see this behavior from Gemini. When I pointed this misinterpretation to Gemini, it acknowledged the mistake and solved the problem correctly using substitutions for the system of equations. \n\nOverly complicated solutions - In this homework I would like to point out to its answers for the subparts in question 2b) in the attached pdf. While none of the approaches were incorrect, there were steps that were unnecessary to build the solution (annotated in the pdf). \n\nIncomplete reasoning - The answer to 4b) could have been more complete. One could see that from the first term we can derive the transformation we need to apply to $\\check{w}$ to get to equation (3) (as the LLM did). However, I think the answer would be complete if it mentioned what should also happen to the $\\Gamma$ matrix (even though this was not explicitly asked in the question) for the equation to achieve the form in equation (3) rather than treating it as something obvious. \n\nIn conclusion, I think Gemini 2.5 Pro is fully capable of answering all questions correctly with good mathematical and conceptual reasoning. However, some of the solution approaches could be more concise and complete.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Gemini 2.5 Pro to solve the written parts of Homework 5 (Q1-4). I started by mentioning that I wanted to solve a problem set related to a specific topic (in this case, basics of CNNs) and went over the four problems one by one with attached screenshots of the entire problem. I\u2019ve attached an annotated pdf of my interactions with the LLM and a <link href=\"https://gemini.google.com/share/94735d985801\">link</link> to my original chat. </paragraph><file url=\"https://static.us.edusercontent.com/files/Jybc1GxINKXM7ze2At6GOkD9\" filename=\"gemini2.5Pro-chat_2025-11-11.pdf\"/><paragraph>In summary, even without extensive context in my typed prompt, Gemini 2.5 Pro was able to extract information included within the problem from the screenshots themselves and one-shot solve almost all the problems correctly without any hallucinations. </paragraph><paragraph><bold>Notable observations:</bold> </paragraph><list style=\"number\"><list-item><paragraph><bold>Good parsing of information</bold> - Most of the time it correctly parsed all mathematical equations, figures and text from the screenshots, even when a problem was spread across multiple screenshots. This is evident because it often types back key information from the problem statement to formulate the answer. All final answers (after corrections noted below) had no mathematical or conceptual errors. </paragraph></list-item><list-item><paragraph><bold>Misinterpretation of a hint</bold> - In question 1b), it used the hint to solve the problem itself. I wonder if this is because it mostly encountered instances of math problems where the hint is used to solve the problem itself. However, when I went through the other special participation threads for HW5 (that were posted as of 11/12/25), I noticed that none of those LLMs used the hint this way and often correctly interpreted it. So, it was interesting to see this behavior from Gemini. When I pointed this misinterpretation to Gemini, it acknowledged the mistake and solved the problem correctly using substitutions for the system of equations. </paragraph></list-item><list-item><paragraph><bold>Overly complicated solutions</bold> - In this homework I would like to point out to its answers for the subparts in question 2b) in the attached pdf. While none of the approaches were incorrect, there were steps that were unnecessary to build the solution (annotated in the pdf). </paragraph></list-item><list-item><paragraph><bold>Incomplete reasoning</bold> - The answer to 4b) could have been more complete. One could see that from the first term we can derive the transformation we need to apply to $\\check{w}$ to get to equation (3) (as the LLM did). However, I think the answer would be complete if it mentioned what should also happen to the $\\Gamma$ matrix (even though this was not explicitly asked in the question) for the equation to achieve the form in equation (3) rather than treating it as something obvious. </paragraph></list-item></list><paragraph>In conclusion, I think Gemini 2.5 Pro is fully capable of answering all questions correctly with good mathematical and conceptual reasoning. However, some of the solution approaches could be more concise and complete.</paragraph><math/><paragraph/></document>",
            "links": [
                "https://gemini.google.com/share/94735d985801"
            ],
            "attachments": [],
            "created_at": "2025-11-12T20:46:02.16884+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7295132,
            "author": "Hong Joey",
            "project_title": "HW08 Solutions",
            "post_body": "Apologies for the delay. Attached are solutions to HW08:\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Apologies for the delay. Attached are solutions to HW08:<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/qmCjfUxKqXzFDKsChBILueTS\" filename=\"hw08_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/9oeqJ42RRMM5A20SiY5yMFmI\" filename=\"q_coding_ssm_forward_cpu_sol.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/Z0a4tFJ4asaL0PJFshCF1PSd\" filename=\"q_coding_ssm_forward_gpu_sol.ipynb\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-12T10:45:24.407422+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7293506,
            "author": "Sultan Daniels",
            "project_title": "Tuesday 2-3pm OH Today",
            "post_body": "The Tuesday 2-3pm office hours will still be held in Latimer 102 today. Feel free to come with project-related questions.",
            "content_xml": "<document version=\"2.0\"><paragraph>The Tuesday 2-3pm office hours will still be held in Latimer 102 today. Feel free to come with project-related questions.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-12T06:43:12.467734+11:00",
            "category": "Admin"
        },
        {
            "guid": 7291669,
            "author": "Tianyu Gu",
            "project_title": "Special Participation C: Refactoring HW1 problem 3(h)",
            "post_body": "The original file is split into three files, which makes it reproducible, modular and configurable:\n\nsrc/ \u2013 pure Python package (data, model, trainer, utils)\n\nconfigs/default.yaml \u2013 Hydra config (all hyper-parameters)\n\nnotebooks/demo.ipynb \u2013 thin visualisation notebook (only plots, no logic)\n\n\nGithub Repo: https://github.com/gty864/EECS182-special-participation-C#\n\nReport: \n\nDone by Tianyu Gu, Zhangzhi Xiong,  Aaron Zheng\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>The original file is split into three files, which makes it reproducible, modular and configurable:</paragraph><list style=\"ordered\"><list-item><paragraph>src/ \u2013 pure Python package (data, model, trainer, utils)</paragraph></list-item><list-item><paragraph>configs/default.yaml \u2013 Hydra config (all hyper-parameters)</paragraph></list-item><list-item><paragraph>notebooks/demo.ipynb \u2013 thin visualisation notebook (only plots, no logic)</paragraph></list-item></list><paragraph><break/>Github Repo: <link href=\"https://github.com/gty864/EECS182-special-participation-C#\">https://github.com/gty864/EECS182-special-participation-C#</link></paragraph><paragraph>Report: </paragraph><file url=\"https://static.us.edusercontent.com/files/xgQYLep5iqnPRjitgqtYeJdv\" filename=\"Special Participation C.pdf\"/><paragraph>Done by Tianyu Gu, Zhangzhi Xiong,  Aaron Zheng</paragraph><paragraph/></document>",
            "links": [
                "https://github.com/gty864/EECS182-special-participation-C#"
            ],
            "attachments": [],
            "created_at": "2025-11-11T20:32:01.275817+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7291347,
            "author": "Sultan Daniels",
            "project_title": "HW09 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/kniCPizsj5HST76xjeuZ8g36\" filename=\"hw09codesolution.zip\"/><file url=\"https://static.us.edusercontent.com/files/XzhLemZ4Zjz8p1vF2CUfM2eU\" filename=\"hw09_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/KZaUhjqoiEFimDP3WHPTMt2e\" filename=\"hw09_question.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-11T17:38:30.747375+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7289919,
            "author": "Aaryan Chandna",
            "project_title": "Special Participation E: Debugging Exercise with Gemini Guided Learning (GNNs)",
            "post_body": "Personally, I learn well by doing exercises that involve the identification of mistakes or reasons to employ specific techniques. This inspired me to develop a debugging exercise with Gemini's Guided Learning, where I fed the slides for Lecture 12 (GNNs) as input and initially asked the model to provide me with a guide on the lecture slide material over 3 prompts, letting it know in advance to prepare for the debugging exercise. I then had Gemini create 2 debugging exercises for myself to complete, followed by a verification of the answers and explanation. I cannot include the actual link to the conversation unfortunately because Gemini prohibits sharing conversations on school accounts, but I have included the PDF of the interaction trace with my comments.\n\n\n\nReflection - I think providing the lecture slides was a good move as Gemini was able to discuss almost all the concepts from the lecture and explain them well. with some exceptions (didn't discuss the image classification vs semantic segmentation case, didn't get into directed vs undirected graphs). It also mostly prevented hallucination or the usage of formulas that were not in the actual slides, which helped align the discussion with what was relevant towards the course. There was, however, one minor case of hallucination, and the debugging exercises had material/answers that were correct but were not discussed in the guide, which was a significant weakness of this option. Moreover, I was disappointed by the lack of visuals provided by Gemini, even using the Guided Learning mode. The biggest strength of Gemini on this task, in my opinion, was providing relevant and thorough explanations that were still concise enough that I would be able to understand the necessary concepts quickly.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Personally, I learn well by doing exercises that involve the identification of mistakes or reasons to employ specific techniques. This inspired me to develop a debugging exercise with Gemini's Guided Learning, where I fed the slides for Lecture 12 (GNNs) as input and initially asked the model to provide me with a guide on the lecture slide material over 3 prompts, letting it know in advance to prepare for the debugging exercise. I then had Gemini create 2 debugging exercises for myself to complete, followed by a verification of the answers and explanation. I cannot include the actual link to the conversation unfortunately because Gemini prohibits sharing conversations on school accounts, but I have included the PDF of the interaction trace with my comments.</paragraph><paragraph/><paragraph>Reflection - I think providing the lecture slides was a good move as Gemini was able to discuss almost all the concepts from the lecture and explain them well. with some exceptions (didn't discuss the image classification vs semantic segmentation case, didn't get into directed vs undirected graphs). It also mostly prevented hallucination or the usage of formulas that were not in the actual slides, which helped align the discussion with what was relevant towards the course. There was, however, one minor case of hallucination, and the debugging exercises had material/answers that were correct but were not discussed in the guide, which was a significant weakness of this option. Moreover, I was disappointed by the lack of visuals provided by Gemini, even using the Guided Learning mode. The biggest strength of Gemini on this task, in my opinion, was providing relevant and thorough explanations that were still concise enough that I would be able to understand the necessary concepts quickly.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/A2ejEufCSlXMQuag5EyT7KpQ\" filename=\"geminifinal.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-11T12:53:10.285299+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7289237,
            "author": "Hong Joey",
            "project_title": "HW10 Q5: FaceNet",
            "post_body": "Problem Context: In this problem you will read the FaceNet paper that studies the problem of facial recognition. What is novel about their method is a triplet loss on the embedding space of the images of faces. You may see triplet loss show up in various other representation learning methods.",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: In this problem you will read the <link href=\"https://arxiv.org/abs/1503.03832\">FaceNet paper</link> that studies the problem of facial recognition. What is novel about their method is a triplet loss on the embedding space of the images of faces. You may see triplet loss show up in various other representation learning methods.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/xcc0yIWpiJVXudS4pwrcfWpY\" width=\"658\" height=\"683.2357954545455\"/></figure></document>",
            "links": [
                "https://arxiv.org/abs/1503.03832"
            ],
            "attachments": [],
            "created_at": "2025-11-11T11:00:41.345069+11:00",
            "category": "Admin"
        },
        {
            "guid": 7289177,
            "author": "Hong Joey",
            "project_title": "HW10 Q4: Example Difficulty and Early Exit",
            "post_body": "Problem Context: First, you will try to evaluate the difficulty of problems by training a classifier on learned representations by a neural network. Then, you will show how predicting difficulty can be used for \"early-exiting\" to improve inference time. Much of this problem was inspired by this paper and this paper. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: First, you will try to evaluate the difficulty of problems by training a classifier on learned representations by a neural network. Then, you will show how predicting difficulty can be used for \"early-exiting\" to improve inference time. Much of this problem was inspired by <link href=\"https://arxiv.org/abs/2106.09647\">this paper</link> and <link href=\"https://arxiv.org/abs/1709.01686\">this paper.</link> </paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/gphs8phQ0SZQwqf2za88TQAZ\" width=\"658\" height=\"575.2690058479533\"/></figure></document>",
            "links": [
                "https://arxiv.org/abs/2106.09647",
                "https://arxiv.org/abs/1709.01686"
            ],
            "attachments": [],
            "created_at": "2025-11-11T10:52:46.289197+11:00",
            "category": "Admin"
        },
        {
            "guid": 7289140,
            "author": "Hong Joey",
            "project_title": "HW10 Q3: Summarization",
            "post_body": "Problem Context: This problem makes you implement and train an encoder-decoder transformer on a simple task of text summarization. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This problem makes you implement and train an encoder-decoder transformer on a simple task of text summarization. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/oOhj8ictq8pVvNDOsfMWuB6y\" width=\"658\" height=\"207.07647058823528\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-11T10:45:53.129966+11:00",
            "category": "Admin"
        },
        {
            "guid": 7289135,
            "author": "Hong Joey",
            "project_title": "HW10 Q2: Hand-Design Transformers",
            "post_body": "Problem context: \n\nThis problem asks you to implement scaled dot-product attention as well as hand-design attention matrices to perform certain operations, the same way that you did hand-design convolutional matrices for CNNs.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem context: </paragraph><paragraph>This problem asks you to implement scaled dot-product attention as well as hand-design attention matrices to perform certain operations, the same way that you did hand-design convolutional matrices for CNNs.</paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/Ycrlk956H7KaBMog0f87jHlG\" width=\"658\" height=\"258.5347119645495\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-11T10:44:24.318588+11:00",
            "category": "Admin"
        },
        {
            "guid": 7289110,
            "author": "Hong Joey",
            "project_title": "HW10 Q1: Kernelized Linear Attention (Part II)",
            "post_body": "Problem Context: This is part 2 of the problem you saw on the last homework. It shows how kernelized approximations to softmax attention can be done with the same complexity as state-space models.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This is part 2 of the problem you saw on the last homework. It shows how kernelized approximations to softmax attention can be done with the same complexity as state-space models.</paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/1pD3LSFeJOWEZeTVyYbQgzJQ\" width=\"658\" height=\"679.8699421965318\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/dfcZ0rcJzzyNaZS5Pt2kEfRJ\" width=\"658\" height=\"521.6217851739788\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-11T10:41:01.313806+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7287291,
            "author": "Zhangzhi 'csrookie' Xiong",
            "project_title": "Special Participation E: Grok4(fast) as a teacher on SSM",
            "post_body": "In this part, I will use Grok4 (fast) as a teacher to teach me about SSM (State Space Model). I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response.",
            "content_xml": "<document version=\"2.0\"><paragraph>In this part, I will use Grok4 (fast) as a teacher to teach me about SSM (State Space Model). I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response.</paragraph><file url=\"https://static.us.edusercontent.com/files/6B4exsCcmrwY1lnSOsMjV3WB\" filename=\"grok.pdf\"/><file url=\"https://static.us.edusercontent.com/files/cPZVGFVnVIPMaIPzG0VzYqlL\" filename=\"log.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-11T06:28:07.024815+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7285257,
            "author": "Anant Sahai",
            "project_title": "Mid-term survey: please fill out",
            "post_body": "https://forms.gle/zwoSh2EHbArQt7maA\n\nDear students,\n\nWe want to get your thoughts. This is a little past the midpoint of the semester, but is a natural point to ask since you've all just started on your projects and had meetings with the course staff.\n\nWe estimate that the survey will take about 30min to complete. Please do so.\n\nhttps://forms.gle/zwoSh2EHbArQt7maA\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><link href=\"https://forms.gle/zwoSh2EHbArQt7maA\">https://forms.gle/zwoSh2EHbArQt7maA</link></paragraph><paragraph>Dear students,</paragraph><paragraph>We want to get your thoughts. This is a little past the midpoint of the semester, but is a natural point to ask since you've all just started on your projects and had meetings with the course staff.</paragraph><paragraph>We estimate that the survey will take about 30min to complete. Please do so.</paragraph><paragraph><link href=\"https://forms.gle/zwoSh2EHbArQt7maA\">https://forms.gle/zwoSh2EHbArQt7maA</link></paragraph><paragraph/><paragraph/></document>",
            "links": [
                "https://forms.gle/zwoSh2EHbArQt7maA",
                "https://forms.gle/zwoSh2EHbArQt7maA"
            ],
            "attachments": [],
            "created_at": "2025-11-10T19:06:49.86163+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7283953,
            "author": "Jameson Liu",
            "project_title": "Special Participation A: ChatGPT on HW6",
            "post_body": "I used ChatGPT (5) on the non-coding parts of homework 6 (#2, #3). I prompted it by attaching the entire homework pdf and asking it to answer them as an expert in deep learning. In its first response, it was able to one-shot a majority of the questions. Some of its solutions, however, contained imprecise language. For example, in 2d, it just described how the max function worked, so I had to convince it that it would be a one-hot encoding by induction. This was interesting since it seemed like the question contained enough context for this to be concluded. Another interesting limitation was that ChatGPT was unable to parse the image of the graph for 3b. Even after I screenshotted the graph and fed it as input again, it got one of the connections wrong. Overall, I would say ChatGPT did extremely well on this homework, requiring only a few clarifications, especially for visual aspects. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT (5) on the non-coding parts of homework 6 (#2, #3). I prompted it by attaching the entire homework pdf and asking it to answer them as an expert in deep learning. In its first response, it was able to one-shot a majority of the questions. Some of its solutions, however, contained imprecise language. For example, in 2d, it just described how the max function worked, so I had to convince it that it would be a one-hot encoding by induction. This was interesting since it seemed like the question contained enough context for this to be concluded. Another interesting limitation was that ChatGPT was unable to parse the image of the graph for 3b. Even after I screenshotted the graph and fed it as input again, it got one of the connections wrong. Overall, I would say ChatGPT did extremely well on this homework, requiring only a few clarifications, especially for visual aspects. </paragraph><file url=\"https://static.us.edusercontent.com/files/cC22W1e1GrgfPYK89OUwityi\" filename=\"chatgpt.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-10T13:51:11.522627+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7283211,
            "author": "Jameson Liu",
            "project_title": "Special Participation B: DeepSeek on HW1",
            "post_body": "I used DeepSeek to solve the coding parts of homework 1. I initially prompted it by uploading the entire .ipynb file, saying it was an expert in deep learning, and asking it to fill in the TODOs. There were two parts to fill in:\n\n1. It was almost able to one-shot this, but had a few implementation mistakes (gradient initialization for momentum, coefficient order). Perhaps I should have provided more context so that it could have implemented these details correctly. I then asked DeepSeek to correct this, and it took a few tries before getting it right. \n2. This is not an error of the LLM since this required running code, but the learning rate it picked was too high (diverged), so I told it, and it picked a better one.\n\nI also told it not to answer any conceptual questions that depended on running code to answer, but it still answered these. They turned out to be alright, so I guess DeepSeek was confident enough based on its knowledge. In the middle of my chat log, I was curious why it implemented momentum incorrectly the first time, and it gave me a good explanation of its version and its pros and cons. \n\nOverall, DeepSeek was pretty good at solving this homework, and probably could have one-shotted it completely with more context. \n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used DeepSeek to solve the coding parts of homework 1. I initially prompted it by uploading the entire .ipynb file, saying it was an expert in deep learning, and asking it to fill in the TODOs. There were two parts to fill in:<break/><break/>1. It was almost able to one-shot this, but had a few implementation mistakes (gradient initialization for momentum, coefficient order). Perhaps I should have provided more context so that it could have implemented these details correctly. I then asked DeepSeek to correct this, and it took a few tries before getting it right. <break/>2. This is not an error of the LLM since this required running code, but the learning rate it picked was too high (diverged), so I told it, and it picked a better one.<break/><break/>I also told it not to answer any conceptual questions that depended on running code to answer, but it still answered these. They turned out to be alright, so I guess DeepSeek was confident enough based on its knowledge. In the middle of my chat log, I was curious why it implemented momentum incorrectly the first time, and it gave me a good explanation of its version and its pros and cons. <break/><break/>Overall, DeepSeek was pretty good at solving this homework, and probably could have one-shotted it completely with more context. <break/></paragraph><file url=\"https://static.us.edusercontent.com/files/1DYWQgprgx9cdeH2t5NxI9qt\" filename=\"deepseek.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-10T11:42:59.228283+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7281484,
            "author": "Ruizhe Song",
            "project_title": "Special Participation E: ChatGPT as a post-lecture learning approach",
            "post_body": "I usually have some new questions when I review my notes after class. Some questions indicate that I don't fully understand the specific deep learning mechanism on the class, while others are about the reason why we are using these techniques(in other words why something seems pretty normal but works well). This ed post is about the first kind of questions, which I don't fully understand on the class, and managed to solve with the help of ChatGPT as a powerful post-lecture learning tool.\n\nIn this special participation E, I plan to share my post-lecture self-learning trace after Lecture 18 & 19 with ChatGPT5. The two classes cover the important attention mechanism and Transformer architecture. After the post-lecture learning process, I understand the attention layer and transformer better. It even makes the coming classes and discussions clearer to me.\n\nHere's the pdf version of chat log with my comments:\n\nIn this log, I asked questions step-by-step, and let GPT guide me to change my way of thinking in RNN and SSM to attention mechanism and Transformer architecture. During this process, GPT successfully:\n\n1. Corrected my wrong understanding about how attention layer works. \n\n2. Made concrete examples to illustrate the training/inference process in transformer architecture and attention layers, which helped me understand much more quickly.\n\n3. Gave mathematical representations and detailed illustrations of them to make the whole intuition clear.",
            "content_xml": "<document version=\"2.0\"><paragraph>I usually have some new questions when I review my notes after class. Some questions indicate that I don't fully understand the specific deep learning mechanism on the class, while others are about the reason why we are using these techniques(in other words why something seems pretty normal but works well). This ed post is about the <italic><underline>first</underline></italic> kind of questions, which I don't fully understand on the class, and managed to solve with the help of ChatGPT <bold>as a powerful post-lecture learning tool</bold>.</paragraph><paragraph>In this special participation E, I plan to share my post-lecture self-learning trace after <bold>Lecture 18 &amp; 19</bold> with <bold>ChatGPT5</bold>. The two classes cover the important <bold>attention mechanism and Transformer architecture</bold>. After the post-lecture learning process, I understand the attention layer and transformer better. It even makes the coming classes and discussions clearer to me.</paragraph><paragraph>Here's the pdf version of chat log with my comments:</paragraph><file url=\"https://static.us.edusercontent.com/files/ydpSFWtljJ9a0RoRqsbAub7D\" filename=\"Special-Participation-E.pdf\"/><paragraph>In this log, I asked questions step-by-step, and let GPT guide me to change my way of thinking in RNN and SSM to attention mechanism and Transformer architecture. During this process, GPT successfully:</paragraph><paragraph>1. Corrected my wrong understanding about how attention layer works. </paragraph><paragraph>2. Made concrete examples to illustrate the training/inference process in transformer architecture and attention layers, which helped me understand much more quickly.</paragraph><paragraph>3. Gave mathematical representations and detailed illustrations of them to make the whole intuition clear.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-10T06:26:24.178702+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7280407,
            "author": "Tianyu Gu",
            "project_title": "Special Participation B: Kimi on HW0",
            "post_body": "I use Kimi on coding part of HW0, I provide the code task step by step, and Kimi can always fill the code in the guidance of comment. (I don't know why I can't print all the pages in the talk, when I try to print it to pdf,  it only allows me to print one page. So I just copy all the text.)\n\nHere is the link:  https://www.kimi.com/share/19a68035-1a42-8042-8000-0000dd0233b5\n\nIn a nutshell, Kimi has done a great job except for the final part. Kimi can solve almost all coding part of hw0 in one shot, but cannot provide a reasonable value for parameters such as learning rate and weight scale. This might because the coding part in hw0 is very standard.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/JO59CBnPjUV5ccYoOy3KXgbN\" filename=\"special participation b.pdf\"/><paragraph>I use Kimi on coding part of HW0, I provide the code task step by step, and Kimi can always fill the code in the guidance of comment. (I don't know why I can't print all the pages in the talk, when I try to print it to pdf,  it only allows me to print one page. So I just copy all the text.)</paragraph><paragraph>Here is the link:  https://www.kimi.com/share/19a68035-1a42-8042-8000-0000dd0233b5</paragraph><paragraph>In a nutshell, Kimi has done a great job except for the final part. Kimi can solve almost all coding part of hw0 in one shot, but cannot provide a reasonable value for parameters such as learning rate and weight scale. This might because the coding part in hw0 is very standard.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-09T21:30:30.701332+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7280265,
            "author": "Zhangzhi 'csrookie' Xiong",
            "project_title": "Participation Section E: Grok3 (fast) as a teacher on Initialization",
            "post_body": "In this part, I will use Grok3 (fast) as a teacher to teach me about Initialization in deeplearning and its significant importance. I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response. \n\nThe commented log has been attached below:\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>In this part, I will use Grok3 (fast) as a teacher to teach me about Initialization in deeplearning and its significant importance. I will try to let LLM to fully help me to understand this knowledge. I will attach my prompt and LLM's response (they are exported as a separated file), and my personal comment on LLM's response. </paragraph><paragraph>The commented log has been attached below:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/iJrQgXsbMPnOO1Ga9mliE5sF\" filename=\"submission.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-09T18:40:32.180113+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7280264,
            "author": "Ruizhe Song",
            "project_title": "Special Participation B: ChatGPT5 on HW5",
            "post_body": "I interactively engaged ChatGPT5 on the coding parts of Homework 5. Overall, the model was able to provide correct code implementations in almost every problem, even if it ignore some small points such as inverse a possible singular matrix, it can fix the bug with the error information easily.\n\nStrategies: I first clarified the main role that GPT was expected to perform and illustrated the evaluation rubrics for its answers. Then, I do the following steps:\n\nStep 1: Provide Gemini with problem background and basic description.\n\nStep 2: Give the necessary code for it to implement or the output of a cell for it to analyze.\n\nStep 3: Collect the answers and give it feedback. If the answer was incorrect, or have small bugs inside, I provide hints to guide it to fix the original answer, and repeat until the response was correct or it seems to have no chance of fixing it.\n\nStep 4: Repeat Steps 1\u20133 for all homework problems.\n\nCore Observations:\n\n1. ChatGPT has wonderful code completion ability even its prompt is only based on part of the whole JupyterNotebook. Almost all the generated codes are correct at the first time and can easily run on the colab homework. \n\n2. ChatGPT also have great debug ability simply with the hints from the error information of the code cell\u2019s output. There was a time when it generated a singular matrix and tried to inverse it. And it quickly fixed the problem by modifying the line causing the matrix to be singular.\n\n3. ChatGPT can even answer some questions which requires the result from the code cell, though it can\u2019t actually run it. In other words, it generates the correct answer which should be output by the correctly implemented code cell. As an LLM, this is amazing.\n\n4. However, when I keep testing the ability listed above, GPT began to make some mistakes especially when the question is related to a specific number. I think GPT can derive some simple code cell\u2019s output from a mathematical way, like solving a written problem. But can not handle complex codes.\n\nFor the code analysis questions, I provided GPT with some curve images which are necessary. And GPT can derive good intuition from the results such as the loss curve.\n\nHere's my chatting log: https://chatgpt.com/share/691038f2-af08-800f-bc33-ed03352ab4c0\n\nAnd the simplified pdf version with my comments: ",
            "content_xml": "<document version=\"2.0\"><paragraph>I interactively engaged <bold>ChatGPT5</bold> on the coding parts of <bold>Homework 5</bold>. Overall, the model was able to provide correct code implementations in almost every problem, even if it ignore some small points such as inverse a possible singular matrix, it can fix the bug with the error information easily.</paragraph><paragraph><bold>Strategies:</bold> I first clarified the main role that GPT was expected to perform and illustrated the evaluation rubrics for its answers. Then, I do the following steps:</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Step 1:</bold> Provide Gemini with problem background and basic description.</paragraph></list-item><list-item><paragraph><bold>Step 2:</bold> Give the necessary code for it to implement or the output of a cell for it to analyze.</paragraph></list-item><list-item><paragraph><bold>Step 3:</bold> Collect the answers and give it feedback. If the answer was incorrect, or have small bugs inside, I provide hints to guide it to fix the original answer, and repeat until the response was correct or it seems to have no chance of fixing it.</paragraph></list-item><list-item><paragraph><bold>Step 4:</bold> Repeat Steps 1\u20133 for all homework problems.</paragraph></list-item></list><paragraph><bold><bold>Core Observations:</bold></bold></paragraph><paragraph>1. ChatGPT has wonderful code completion ability even its prompt is only based on part of the whole JupyterNotebook. Almost all the generated codes are correct at the first time and can easily run on the colab homework. </paragraph><paragraph>2. ChatGPT also have great debug ability simply with the hints from the error information of the code cell\u2019s output. There was a time when it generated a singular matrix and tried to inverse it. And it quickly fixed the problem by modifying the line causing the matrix to be singular.</paragraph><paragraph>3. ChatGPT can even answer some questions which requires the result from the code cell, though it can\u2019t actually run it. In other words, it generates the correct answer which should be output by the correctly implemented code cell. As an LLM, this is amazing.</paragraph><paragraph>4. However, when I keep testing the ability listed above, GPT began to make some mistakes especially when the question is related to a specific number. I think GPT can derive some simple code cell\u2019s output from a mathematical way, like solving a written problem. But can not handle complex codes.</paragraph><paragraph>For the code analysis questions, I provided GPT with some curve images which are necessary. And GPT can derive good intuition from the results such as the loss curve.<break/><break/>Here's my chatting log: <link href=\"https://chatgpt.com/share/691038f2-af08-800f-bc33-ed03352ab4c0\">https://chatgpt.com/share/691038f2-af08-800f-bc33-ed03352ab4c0</link><break/><break/>And the simplified pdf version with my comments: </paragraph><file url=\"https://static.us.edusercontent.com/files/cRCmC83lFv5pr8ymAh5Tg0Ef\" filename=\"hw5-participationB-ChatGPT5-comments.pdf\"/></document>",
            "links": [
                "https://chatgpt.com/share/691038f2-af08-800f-bc33-ed03352ab4c0"
            ],
            "attachments": [],
            "created_at": "2025-11-09T18:40:29.641542+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7280258,
            "author": "Zhangzhi 'csrookie' Xiong",
            "project_title": "Participation Section C: Gemini Pro 2.5 on HW3 (e)",
            "post_body": "I'm using Gemini 2.5 Pro to rewrite HW3 (e) into engineering code. The file has been attached above. \nFrom my perspective, a good engineering python deeplearning code should at least include:\n\nArgparse to input parameter[1] \n\nSystemetic log or wandb[2] \n\nSave and load of the torch checkpoint, and Checkpointing[3] \n\nThe save of the results bash script for rapid experiments[4] \n\n[1]https://docs.python.org/3/library/argparse.html \n\n[2]https://docs.wandb.ai/support/ \n\n[3]https://docs.pytorch.org/docs/stable/checkpoint.html \n\n[4]https://www.freecodecamp.org/news/shell-scripting-crash-course-how-to-write-b ash-scripts-in-linux/\n\nPython and bash files are attached below:\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/YPLDd7is0sHCAChT6ZonvgIO\" filename=\"log.pdf\"/><paragraph>I'm using Gemini 2.5 Pro to rewrite HW3 (e) into engineering code. The file has been attached above. <break/>From my perspective, a good engineering python deeplearning code should at least include:</paragraph><paragraph>Argparse to input parameter[1] </paragraph><paragraph>Systemetic log or wandb[2] </paragraph><paragraph>Save and load of the torch checkpoint, and Checkpointing[3] </paragraph><paragraph>The save of the results bash script for rapid experiments[4] </paragraph><paragraph>[1]https://docs.python.org/3/library/argparse.html </paragraph><paragraph>[2]https://docs.wandb.ai/support/ </paragraph><paragraph>[3]https://docs.pytorch.org/docs/stable/checkpoint.html </paragraph><paragraph>[4]https://www.freecodecamp.org/news/shell-scripting-crash-course-how-to-write-b ash-scripts-in-linux/</paragraph><paragraph>Python and bash files are attached below:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/XJJKcowL57LmUoGro2uHuMs6\" filename=\"run_experiment.py\"/><file url=\"https://static.us.edusercontent.com/files/fy1Jij6qj2gV9Ds9HJ6mR6FG\" filename=\"sweep.sh\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-09T18:36:06.176404+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7280239,
            "author": "Andy Zhang",
            "project_title": "Special Participation E: Quiz and Flash Cards for Adam / SGD",
            "post_body": "Special Participation E: Quiz and Flash Cards for Adam / SGD\n\nFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid\n\nEspecially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.\n\nWhile the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.\n\nFrom there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one\u2019s presences, the model can be steered to act accordingly. \n\nMy recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.\n\nTraces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing\n\nIndividual traces:\n\nUndetailed Prompt Trace Flash Cards:\n\nhttps://gemini.google.com/share/ed66de185158\n\nUndetailed Prompt Trace Quiz:\n\nhttps://gemini.google.com/share/598e4b5cfbcc\n\nUndetailed Flash Cards:\n\nhttps://gemini.google.com/share/cfd44ed946d6\n\nUndetailed Quiz:\n\nhttps://gemini.google.com/share/6fab8238136e\n\nFlash cards / quizzes:\n\nDetailed Prompt Trace for Flash Cards with Math:\n\nhttps://gemini.google.com/share/f7957da6c0d1\n\nDetailed Prompt Trace for Quiz:\n\nhttps://gemini.google.com/share/ec87b322ca7e\n\nDetailed Flash Cards: https://gemini.google.com/share/6afed4acff7b\n\nDetailed Quiz: https://gemini.google.com/share/01910a14266a",
            "content_xml": "<document version=\"2.0\"><paragraph>Special Participation E: Quiz and Flash Cards for Adam / SGD</paragraph><paragraph>For background, Gemini claims that they can create quizzes, flash cards &amp; study guides according to <link href=\"https://support.google.com/gemini/answer/16275879?hl=en&amp;co=GENIE.Platform%3DAndroid\">https://support.google.com/gemini/answer/16275879?hl=en&amp;co=GENIE.Platform%3DAndroid</link></paragraph><paragraph>Especially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.</paragraph><paragraph>While the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.</paragraph><paragraph>From there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one\u2019s presences, the model can be steered to act accordingly. </paragraph><paragraph>My recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.</paragraph><paragraph>Traces with detailed comments: <link href=\"https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing\">https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing</link></paragraph><paragraph>Individual traces:</paragraph><paragraph>Undetailed Prompt Trace Flash Cards:</paragraph><paragraph><link href=\"https://gemini.google.com/share/ed66de185158\">https://gemini.google.com/share/ed66de185158</link></paragraph><paragraph>Undetailed Prompt Trace Quiz:</paragraph><paragraph><link href=\"https://gemini.google.com/share/598e4b5cfbcc\">https://gemini.google.com/share/598e4b5cfbcc</link></paragraph><paragraph>Undetailed Flash Cards:</paragraph><paragraph><link href=\"https://gemini.google.com/share/cfd44ed946d6\">https://gemini.google.com/share/cfd44ed946d6</link></paragraph><paragraph>Undetailed Quiz:</paragraph><paragraph><link href=\"https://gemini.google.com/share/6fab8238136e\">https://gemini.google.com/share/6fab8238136e</link></paragraph><paragraph>Flash cards / quizzes:</paragraph><paragraph>Detailed Prompt Trace for Flash Cards with Math:</paragraph><paragraph><link href=\"https://gemini.google.com/share/f7957da6c0d1\">https://gemini.google.com/share/f7957da6c0d1</link></paragraph><paragraph>Detailed Prompt Trace for Quiz:</paragraph><paragraph><link href=\"https://gemini.google.com/share/ec87b322ca7e\">https://gemini.google.com/share/ec87b322ca7e</link></paragraph><paragraph>Detailed Flash Cards: <link href=\"https://gemini.google.com/share/6afed4acff7b\">https://gemini.google.com/share/6afed4acff7b</link></paragraph><paragraph>Detailed Quiz: <link href=\"https://gemini.google.com/share/01910a14266a\">https://gemini.google.com/share/01910a14266a</link></paragraph></document>",
            "links": [
                "https://support.google.com/gemini/answer/16275879?hl=en&amp;co=GENIE.Platform%3DAndroid",
                "https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing",
                "https://gemini.google.com/share/ed66de185158",
                "https://gemini.google.com/share/598e4b5cfbcc",
                "https://gemini.google.com/share/cfd44ed946d6",
                "https://gemini.google.com/share/6fab8238136e",
                "https://gemini.google.com/share/f7957da6c0d1",
                "https://gemini.google.com/share/ec87b322ca7e",
                "https://gemini.google.com/share/6afed4acff7b",
                "https://gemini.google.com/share/01910a14266a"
            ],
            "attachments": [],
            "created_at": "2025-11-09T18:21:02.198615+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7276004,
            "author": "Bruno Vieira",
            "project_title": "Special Participation E: ChatGPT Lecture Comprehension Buddy",
            "post_body": "I used ChatGPT's \"Study\" mode to help me better understand lectures. Many times, I find myself not really knowing how to prepare ahead of lectures, and I always have questions that get passed on to more questions in discussions, and so I just find myself sometimes \"drowning\" and wishing I had more support to answer some basic questions that can help me not get behind. For this, I decided to test ChatGPT with Thursday 11/07's lecture to help me prepare before the lecture and help me get all my questions answered before next week's lecture. \n\nBelow, I have uploaded the full conversation I had with comments. I also put here a pre-lecture PDF that ChatGPT gave me.\n\nIn all honesty, the summary is that I preferred Claude as it is better with visuals, and I thought that ChatGPT didn't really go that deep into the content. On the other hand, the conversation we had before I went to the lecture drastically improved my experience in the lecture - highly recommend!!\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used ChatGPT's \"Study\" mode to help me better understand lectures. Many times, I find myself not really knowing how to prepare ahead of lectures, and I always have questions that get passed on to more questions in discussions, and so I just find myself sometimes \"drowning\" and wishing I had more support to answer some basic questions that can help me not get behind. For this, I decided to test ChatGPT with Thursday 11/07's lecture to help me prepare before the lecture and help me get all my questions answered before next week's lecture. </paragraph><paragraph>Below, I have uploaded the full conversation I had with comments. I also put here a pre-lecture PDF that ChatGPT gave me.</paragraph><paragraph>In all honesty, the summary is that I preferred Claude as it is better with visuals, and I thought that ChatGPT didn't really go that deep into the content. On the other hand, the conversation we had before I went to the lecture drastically improved my experience in the lecture - highly recommend!!</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/4P4H8nUZm0uWXT3GrMuApHNN\" filename=\"Prelecture_Notes_InContextLearning_PEFT.pdf\"/><file url=\"https://static.us.edusercontent.com/files/gLCYq39bF14aT98XEDEY6GaN\" filename=\"Prelecture notes guide.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-08T14:41:05.880912+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7275891,
            "author": "Lance Mathias",
            "project_title": "Discussion 10 Solutions",
            "post_body": "Attached are questions and solutions to Discussion 10:\n\nNote: Q3 (NoPE) has been updated to reflect the fact that the third embedding dimension can actually be arbitrary. This does not affect the main result of the question. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are questions and solutions to Discussion 10:</paragraph><file url=\"https://static.us.edusercontent.com/files/aXi8aeRAKNhq1uaHk0z2vCnd\" filename=\"dis10_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/yux6PKMcpkzqAceHWIewrK0U\" filename=\"dis10_solution.pdf\"/><paragraph>Note: Q3 (NoPE) has been updated to reflect the fact that the third embedding dimension can actually be arbitrary. This does not affect the main result of the question. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-08T14:04:01.414238+11:00",
            "category": "Sections"
        },
        {
            "guid": 7275881,
            "author": "Lance Mathias",
            "project_title": "Discussion 9 Solutions",
            "post_body": "Attached are questions and solutions to Discussion 9:",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are questions and solutions to Discussion 9:</paragraph><file url=\"https://static.us.edusercontent.com/files/k6ma53OS7Xdfyaap3ZP7QXtj\" filename=\"dis09_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/DYhfPbiN9rEdqy4jikkqsjNa\" filename=\"dis09_solution.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-08T14:02:00.429128+11:00",
            "category": "Sections"
        },
        {
            "guid": 7275838,
            "author": "Alex Proshkin",
            "project_title": "JupyterHub Compute Tutorial",
            "post_body": "Hi everyone,\nI\u2019ll be hosting a 30-minute tutorial on how to use the JupyterHub Compute on Monday, November 10th at 2:30 PM over Zoom.\nYou can join using the link below:\n\nhttps://berkeley.zoom.us/j/97718967725\n\nBest,\nAlex\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,<break/>I\u2019ll be hosting a 30-minute tutorial on how to use the JupyterHub Compute on Monday, November 10th at 2:30 PM over Zoom.<break/>You can join using the link below:</paragraph><paragraph><link href=\"https://berkeley.zoom.us/j/97718967725\">https://berkeley.zoom.us/j/97718967725</link></paragraph><paragraph>Best,<break/>Alex</paragraph><paragraph/></document>",
            "links": [
                "https://berkeley.zoom.us/j/97718967725"
            ],
            "attachments": [],
            "created_at": "2025-11-08T13:52:19.440328+11:00",
            "category": "Admin"
        },
        {
            "guid": 7273818,
            "author": "Gireeja Ranade",
            "project_title": "Reminder to sign up for Tinker",
            "post_body": "Sending out one last reminder for those who want to use this option. Note that by signing up you are not committing to use this, it just gives you the option to use it if you want to:\n\n\n\nPost repeated below:\n\nDear students, \n\nWe have secured access to Tinker, a new API from Thinking Machines that provides fine-tuning support for many popular open-weight models. You can read more here:\n\nhttps://thinkingmachines.ai/tinker/\n\nWe assume most of you would like access to this for your project/to try out things otherwise. This requires us to create an account for you on their API using your name/email. If you would prefer that we not share your name and email with Thinking Machines to get you access, please opt-out using the form below. If you want to guarantee you get access, please also indicate this below. \n\nhttps://forms.gle/vUuQwYeFHgtqX74z8\n\nGiven a tight timeline, there is a 24 hour deadline to opt-in/out-out. Form closes at 10 am Nov 7.\n\nThanks,\n\n182 Staff. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Sending out one last reminder for those who want to use this option. Note that by signing up you are not committing to use this, it just gives you the option to use it if you want to:</paragraph><paragraph/><paragraph>Post repeated below:</paragraph><paragraph>Dear students, </paragraph><paragraph>We have secured access to Tinker, a new API from Thinking Machines that provides fine-tuning support for many popular open-weight models. You can read more here:</paragraph><paragraph><link href=\"https://thinkingmachines.ai/tinker/\">https://thinkingmachines.ai/tinker/</link></paragraph><paragraph>We assume most of you would like access to this for your project/to try out things otherwise. This requires us to create an account for you on their API using your name/email. If you would prefer that we not share your name and email with Thinking Machines to get you access, please opt-out using the form below. If you want to guarantee you get access, please also indicate this below. </paragraph><paragraph><link href=\"https://forms.gle/vUuQwYeFHgtqX74z8\">https://forms.gle/vUuQwYeFHgtqX74z8</link></paragraph><paragraph>Given a tight timeline, there is a 24 hour deadline to opt-in/out-out. Form closes at 10 am Nov 7.</paragraph><paragraph>Thanks,</paragraph><paragraph>182 Staff. </paragraph></document>",
            "links": [
                "https://thinkingmachines.ai/tinker/",
                "https://forms.gle/vUuQwYeFHgtqX74z8"
            ],
            "attachments": [],
            "created_at": "2025-11-08T06:54:50.810859+11:00",
            "category": "Admin"
        },
        {
            "guid": 7267863,
            "author": "Joe Berry",
            "project_title": "Special Participation D second submission HW4 Joseph Berry",
            "post_body": "I edited HW4 to include a section about AdaMuon and how changing batch size and learning rate may effect performance of MLP vs CNN\n\nI edited HW 3 Solutions to include the Muon variants AdaMuon and LiMuon and to display how changing learning rates and batch sizes effect the RMS norms.\n\n\nSi, Chongjie, et al. \"AdaMuon: Adaptive Muon Optimizer.\" arXiv, 18 Aug. 2025, https://doi.org/10.48550/arXiv.2507.11005.\n\nJordan, Keller, et al. \"Muon: An Optimizer for Hidden Layers in Neural Networks.\" Keller Jordan Blog, 8 Dec. 2024, kellerjordan.github.io/posts/muon/.\n\nBernstein, Jeremy, and Laker Newhouse. \"Old Optimizer, New Norm: An Anthology.\" arXiv, 6 Dec. 2024, https://doi.org/10.48550/arXiv.2409.20325.",
            "content_xml": "<document version=\"2.0\"><paragraph>I edited HW4 to include a section about AdaMuon and how changing batch size and learning rate may effect performance of MLP vs CNN<break/><break/>I edited HW 3 Solutions to include the Muon variants AdaMuon and LiMuon and to display how changing learning rates and batch sizes effect the RMS norms.<break/><break/><break/>Si, Chongjie, et al. \"AdaMuon: Adaptive Muon Optimizer.\" <italic>arXiv</italic>, 18 Aug. 2025, <link href=\"https://doi.org/10.48550/arXiv.2507.11005\">https://doi.org/10.48550/arXiv.2507.11005</link>.<break/><break/>Jordan, Keller, et al. \"Muon: An Optimizer for Hidden Layers in Neural Networks.\" <italic>Keller Jordan Blog</italic>, 8 Dec. 2024, <link href=\"http://kellerjordan.github.io/posts/muon/\">kellerjordan.github.io/posts/muon/</link>.</paragraph><paragraph>Bernstein, Jeremy, and Laker Newhouse. \"Old Optimizer, New Norm: An Anthology.\" <italic>arXiv</italic>, 6 Dec. 2024, <link href=\"https://doi.org/10.48550/arXiv.2409.20325\">https://doi.org/10.48550/arXiv.2409.20325</link>.</paragraph><file url=\"https://static.us.edusercontent.com/files/Y2KUv4fOfq8g4IkYJ55nkO3F\" filename=\"edge_detection_sol-AdaMuon+LR_and_BatchSize_Added.ipynb\"/></document>",
            "links": [
                "https://doi.org/10.48550/arXiv.2507.11005",
                "http://kellerjordan.github.io/posts/muon/",
                "https://doi.org/10.48550/arXiv.2409.20325"
            ],
            "attachments": [],
            "created_at": "2025-11-07T05:40:26.301835+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7267614,
            "author": "Yaqi Su",
            "project_title": "Special Participation B: Claude on HW2 coding part",
            "post_body": "This interaction shows Claude's ability to implement standard DL algorithms correctly but with notable instruction-following issues. Claude nailed the first two and the last tasks immediately, translating formulas into working code on the first try. The third task got messier, although the HW hint explicitly mentioned \"adjust the two previous functions,\" Claude created entirely new functions instead, ignoring the specific hint and I needed to re-emphasize it in the prompt before Claude realized this. More problematic was Claude's unprompted adjustment to second-layer bias initialization, which as I noted didn't make sense and was irrelevant to my prompt. When I questioned this, Claude admitted the change was \"not well-motivated\" and unnecessary. Besides, it also made changes to the learning rate (which is also irrelevant to my prompt) when making modification to the codes. This revealed Claude making unjustified \u201csilent\u201d modifications without any explanation or upfront reasoning, requiring me to catch and correct the error/changes it made. While Claude's implementations were technically sound once corrected, the process highlighted real gaps in following specifications and a tendency to add unnecessary (or even wrong) modifications without any upfront notifications/justifications. ",
            "content_xml": "<document version=\"2.0\"><paragraph>This interaction shows Claude's ability to implement standard DL algorithms correctly but with notable instruction-following issues. Claude nailed the first two and the last tasks immediately, translating formulas into working code on the first try. The third task got messier, although the HW hint explicitly mentioned \"adjust the two previous functions,\" Claude created entirely new functions instead, ignoring the specific hint and I needed to re-emphasize it in the prompt before Claude realized this. More problematic was Claude's unprompted adjustment to second-layer bias initialization, which as I noted didn't make sense and was irrelevant to my prompt. When I questioned this, Claude admitted the change was \"not well-motivated\" and unnecessary. Besides, it also made changes to the learning rate (which is also irrelevant to my prompt) when making modification to the codes. This revealed Claude making unjustified \u201csilent\u201d modifications without any explanation or upfront reasoning, requiring me to catch and correct the error/changes it made. While Claude's implementations were technically sound once corrected, the process highlighted real gaps in following specifications and a tendency to add unnecessary (or even wrong) modifications without any upfront notifications/justifications. </paragraph><file url=\"https://static.us.edusercontent.com/files/ykODMieILdveJmWaOD7z7Pj5\" filename=\"Claude-CS282-specialParticipationB-HW2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-07T05:01:10.031606+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7267427,
            "author": "Yaqi Su",
            "project_title": "Special Participation A: Claude on HW2 written part",
            "post_body": "Claude demonstrates strong mathematical reasoning capabilities and correctly derived analytical solutions without any mathematical hallucinations or false claims. Across all problems, Claude never makes computational errors. The issues are always at the level of solution strategy or conceptual completeness, not arithmetic or algebra. This suggests the model's mathematical symbolic reasoning is quite robust, while its ability to choose optimal solution paths requires more guidance. The two problems requiring guidance (Problem 1b and Problem 2a) revealed a consistent pattern: Claude tends to solve problems in an over-complicated way before recognizing simpler approaches. When I used some questioning like \u201cAre you sure...?\" and quoting Claude's own observations back to it as a hint, Claude is able to quickly find cleaner solutions and even provided further insights compared to the original homework solution.",
            "content_xml": "<document version=\"2.0\"><paragraph>Claude demonstrates strong mathematical reasoning capabilities and correctly derived analytical solutions without any mathematical hallucinations or false claims. Across all problems, Claude never makes computational errors. The issues are always at the level of solution strategy or conceptual completeness, not arithmetic or algebra. This suggests the model's mathematical symbolic reasoning is quite robust, while its ability to choose optimal solution paths requires more guidance. The two problems requiring guidance (Problem 1b and Problem 2a) revealed a consistent pattern: Claude tends to solve problems in an over-complicated way before recognizing simpler approaches. When I used some questioning like \u201cAre you sure...?\" and quoting Claude's own observations back to it as a hint, Claude is able to quickly find cleaner solutions and even provided further insights compared to the original homework solution.</paragraph><file url=\"https://static.us.edusercontent.com/files/FbVAO4WZF5mNmZMHkAlg2AGR\" filename=\"Claude-CS282-specialParticipationA-HW2.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-07T04:30:53.053726+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7266065,
            "author": "Xi Cheng",
            "project_title": "Special Participation A: Mistral on HW2",
            "post_body": "I tested Mistral on the non-coding parts of HW2\n\nChat history link: https://chat.mistral.ai/chat/678d9106-0d96-45c6-83e1-2c0ac7a7384a\n\nAnnotated Log: \n\nExecutive Summary:\n\nI found that it could one-shot 2(a) and Question 5. The former was a simple conceptual subquestion, while the latter involved reasoning about distributed training and computational scaling. Mistral performs well when the task relies on text understanding, structural reasoning, or recalling standard frameworks, but it struggles with problems that require original mathematical derivation or deeper logical adaptation.\n\nThroughout the interaction, I noticed that Mistral often exhibited what I\u2019d call lazy reasoning: it tried to map every prompt to a familiar textbook pattern rather than reasoning from the specific assumptions of the problem. Even when I pointed out inconsistencies or paradoxes, it tended to defend its original, polished-sounding explanation until I explicitly instructed it to ignore existing results and reason under the given setup. Only then did it converge to the correct logic.\n\nOverall, Mistral shows strong linguistic fluency and confidence, but limited flexibility and self-correction. It can one-shot straightforward or pattern-based questions, yet it fails to generalize to novel problem settings without direct intervention. ",
            "content_xml": "<document version=\"2.0\"><paragraph>I tested <bold>Mistral</bold> on the non-coding parts of HW2<break/><break/><bold>Chat history link</bold>: <link href=\"https://chat.mistral.ai/chat/678d9106-0d96-45c6-83e1-2c0ac7a7384a\">https://chat.mistral.ai/chat/678d9106-0d96-45c6-83e1-2c0ac7a7384a</link></paragraph><paragraph><bold>Annotated Log:</bold> </paragraph><file url=\"https://static.us.edusercontent.com/files/ONAhVEoreCoqjsxFUhyukV2S\" filename=\"mistral_hw2_annotated_log.pdf\"/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>I found that it could one-shot 2(a) and Question 5. The former was a simple conceptual subquestion, while the latter involved reasoning about distributed training and computational scaling. Mistral performs well when the task relies on text understanding, structural reasoning, or recalling standard frameworks, but it struggles with problems that require original mathematical derivation or deeper logical adaptation.</paragraph><paragraph>Throughout the interaction, I noticed that Mistral often exhibited what I\u2019d call <italic>lazy reasoning</italic>: it tried to map every prompt to a familiar textbook pattern rather than reasoning from the specific assumptions of the problem. Even when I pointed out inconsistencies or paradoxes, it tended to defend its original, polished-sounding explanation until I explicitly instructed it to ignore existing results and reason under the given setup. Only then did it converge to the correct logic.</paragraph><paragraph>Overall, Mistral shows strong linguistic fluency and confidence, but limited flexibility and self-correction. It can one-shot straightforward or pattern-based questions, yet it fails to generalize to novel problem settings without direct intervention. </paragraph></document>",
            "links": [
                "https://chat.mistral.ai/chat/678d9106-0d96-45c6-83e1-2c0ac7a7384a"
            ],
            "attachments": [],
            "created_at": "2025-11-06T18:22:12.750338+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7265693,
            "author": "Jason Guo",
            "project_title": "Special Participation A: Gemini on Homework 4",
            "post_body": "Annotated Transcript:\n\nhttps://drive.google.com/file/d/1ZOIMXval6EtWYyoBE6H13fS0I7d58Fmd/view?usp=sharing\n\nFor this special participation, I used Gemini Pro 2.5 to solve the written portions of homework 4. I began by giving Gemini the assignment and telling it that I was trying to evaluate how well it could solve the problems, and then went through the problems with it one by one. Overall, it did a good job of solving the problems. \n\nAll the mistakes it made, except one, were due to the fact that it read the problems in the homework wrong. Oftentimes, these misreadings were very blatant, like when it just misread the entries of the matrices for problem 3. It only made one reasoning mistake, that wasn\u2019t due to it misreading the question, in part 2g, but was able to correct itself after being told what step in the derivation it made a mistake on. \n\nOne notable part of the interaction was when it solved problem 2e. Its answer differed from what was given in the solutions, even though it was correct as there seems to be a mistake in the solutions, so I tried prompting it to fix its answer, at which point it arrived at the same solution. Afterwards, I gave it what was given in the solutions, and asked it to try to arrive at the answer in the solutions. After trying to arrive at the given answer, it eventually gave up, and said that it didn\u2019t know why the answer was correct. I thought that this was pretty impressive because it shows that Gemini is actually critiquing itself as it goes. Instead of hallucinating to match the answer I gave it, it pushed back and gave what it thought was correct. I thought this was really impressive, as it isn\u2019t just being \u201cagreeable\u201d and taking what the prompter says to be the truth, like other LLMs I\u2019ve used like ChatGPT.",
            "content_xml": "<document version=\"2.0\"><paragraph>Annotated Transcript:</paragraph><paragraph><link href=\"https://drive.google.com/file/d/1ZOIMXval6EtWYyoBE6H13fS0I7d58Fmd/view?usp=sharing\"><underline>https://drive.google.com/file/d/1ZOIMXval6EtWYyoBE6H13fS0I7d58Fmd/view?usp=sharing</underline></link></paragraph><paragraph>For this special participation, I used Gemini Pro 2.5 to solve the written portions of homework 4. I began by giving Gemini the assignment and telling it that I was trying to evaluate how well it could solve the problems, and then went through the problems with it one by one. Overall, it did a good job of solving the problems. </paragraph><paragraph>All the mistakes it made, except one, were due to the fact that it read the problems in the homework wrong. Oftentimes, these misreadings were very blatant, like when it just misread the entries of the matrices for problem 3. It only made one reasoning mistake, that wasn\u2019t due to it misreading the question, in part 2g, but was able to correct itself after being told what step in the derivation it made a mistake on. </paragraph><paragraph>One notable part of the interaction was when it solved problem 2e. Its answer differed from what was given in the solutions, even though it was correct as there seems to be a mistake in the solutions, so I tried prompting it to fix its answer, at which point it arrived at the same solution. Afterwards, I gave it what was given in the solutions, and asked it to try to arrive at the answer in the solutions. After trying to arrive at the given answer, it eventually gave up, and said that it didn\u2019t know why the answer was correct. I thought that this was pretty impressive because it shows that Gemini is actually critiquing itself as it goes. Instead of hallucinating to match the answer I gave it, it pushed back and gave what it thought was correct. I thought this was really impressive, as it isn\u2019t just being \u201cagreeable\u201d and taking what the prompter says to be the truth, like other LLMs I\u2019ve used like ChatGPT.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1ZOIMXval6EtWYyoBE6H13fS0I7d58Fmd/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-11-06T16:19:43.889302+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7265350,
            "author": "Alex Luu",
            "project_title": "Special Participation B: HW4, Llama 4 Maverick",
            "post_body": "I used Llama 4 Maverick on the coding questions for HW4. Here is a summary of my findings:\n\nThe second coding question in this homework is quite long and requires lots of context and code. Despite this, Llama 4 did really well on almost all of the question. I selectively chose what context to give it (which could be a reason why it did so well) to reduce hallucinations. Additionally, I found that if I did not give it enough context (or the right context) it would fail.\n\nThe LLM aced all the coding parts except for the hyperparameter tuning question. It tried many times and I tried to push it towards the right direction but it failed. This is probably because it requires more guesswork and the model seemed to not like taking larger jumps (it did not like to significantly change any of the hyperparameters). It does make sense that an LLM would ace the coding parts since they mostly focus on PyTorch conventions (which is a very well-known framework). \n\nThe responses to the written questions were quite good too. Most of them involved analyzing the output, which are usually images. There were lots of images and I would send them to the LLM to analyze all in the same chat. Despite the large context that images incur, the LLM was still able to produce really good responses that surprised me. Considering Llama 4 was a controversial model for its performance, I thought it did really well. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/6fsY4vcf26u32YkHTwzMYlg0\" filename=\"Special Participation B, HW4, Llama 4.pdf\"/><paragraph>I used Llama 4 Maverick on the coding questions for HW4. Here is a summary of my findings:<break/><break/>The second coding question in this homework is quite long and requires lots of context and code. Despite this, Llama 4 did really well on almost all of the question. I selectively chose what context to give it (which could be a reason why it did so well) to reduce hallucinations. Additionally, I found that if I did not give it enough context (or the right context) it would fail.</paragraph><paragraph>The LLM aced all the coding parts except for the hyperparameter tuning question. It tried many times and I tried to push it towards the right direction but it failed. This is probably because it requires more guesswork and the model seemed to not like taking larger jumps (it did not like to significantly change any of the hyperparameters). It does make sense that an LLM would ace the coding parts since they mostly focus on PyTorch conventions (which is a very well-known framework). </paragraph><paragraph>The responses to the written questions were quite good too. Most of them involved analyzing the output, which are usually images. There were lots of images and I would send them to the LLM to analyze all in the same chat. Despite the large context that images incur, the LLM was still able to produce really good responses that surprised me. Considering Llama 4 was a controversial model for its performance, I thought it did really well. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-06T15:08:01.834466+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7265176,
            "author": "Joe Berry",
            "project_title": "Special Participation D HW 3 thread Joseph Berry",
            "post_body": "I edited HW 3 Solutions to include the Muon variants AdaMuon and LiMuon and to display how changing learning rates and batch sizes effect the RMS norms.\n\nThe new code and questions-solutions are at the bottom of the file\n\nSi, Chongjie, et al. \"AdaMuon: Adaptive Muon Optimizer.\" arXiv, 18 Aug. 2025, https://doi.org/10.48550/arXiv.2507.11005.\n\nJordan, Keller, et al. \"Muon: An Optimizer for Hidden Layers in Neural Networks.\" Keller Jordan Blog, 8 Dec. 2024, kellerjordan.github.io/posts/muon/.\n\nHuang, Feihu, et al. \"LiMuon: Light and Fast Muon Optimizer for Large Models.\" arXiv, 19 Sept. 2025, https://doi.org/10.48550/arXiv.2509.14562.\n\n\n\nBernstein, Jeremy, and Laker Newhouse. \"Old Optimizer, New Norm: An Anthology.\" arXiv, 6 Dec. 2024, https://doi.org/10.48550/arXiv.2409.20325.",
            "content_xml": "<document version=\"2.0\"><paragraph>I edited HW 3 Solutions to include the Muon variants AdaMuon and LiMuon and to display how changing learning rates and batch sizes effect the RMS norms.<break/><break/>The new code and questions-solutions are at the bottom of the file<break/><break/>Si, Chongjie, et al. \"AdaMuon: Adaptive Muon Optimizer.\" <italic>arXiv</italic>, 18 Aug. 2025, <link href=\"https://doi.org/10.48550/arXiv.2507.11005\">https://doi.org/10.48550/arXiv.2507.11005</link>.<break/><break/>Jordan, Keller, et al. \"Muon: An Optimizer for Hidden Layers in Neural Networks.\" <italic>Keller Jordan Blog</italic>, 8 Dec. 2024, kellerjordan.github.io/posts/muon/.</paragraph><file url=\"https://static.us.edusercontent.com/files/SezlsDhMogkxgbEaqAmtw0JF\" filename=\"q_mup_coding_sol-EDITED_LR_BATCH+Muon_Vars.ipynb\"/><paragraph>Huang, Feihu, et al. \"LiMuon: Light and Fast Muon Optimizer for Large Models.\" <italic>arXiv</italic>, 19 Sept. 2025, <link href=\"https://doi.org/10.48550/arXiv.2509.14562\">https://doi.org/10.48550/arXiv.2509.14562</link>.</paragraph><paragraph/><paragraph>Bernstein, Jeremy, and Laker Newhouse. \"Old Optimizer, New Norm: An Anthology.\" <italic>arXiv</italic>, 6 Dec. 2024, <link href=\"https://doi.org/10.48550/arXiv.2409.20325\">https://doi.org/10.48550/arXiv.2409.20325</link>.</paragraph></document>",
            "links": [
                "https://doi.org/10.48550/arXiv.2507.11005",
                "https://doi.org/10.48550/arXiv.2509.14562",
                "https://doi.org/10.48550/arXiv.2409.20325"
            ],
            "attachments": [],
            "created_at": "2025-11-06T14:41:00.93811+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7264064,
            "author": "Tianhao Qian",
            "project_title": "Special Participation C: Refactoring Report-HW7 task2",
            "post_body": "Summary:\n\nThrough this refactoring, the project evolved from a single-use notebook into a maintainable machine learning codebase. It is now organized into separate modules \u2014 config.py, data.py, model.py,train.py,use.py,utils.py, ./test/test_smoke.py, project.py (the main entry point). The original implementation was contained in q_rnn_last_name.ipynb.\n\nGithub repo: \nhysteri1a/hysteri1a-Refactoring-Report-HW7\n\nReport\n\nDone by Lawrence Qian(3041996584)\n\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Summary:</paragraph><paragraph>Through this refactoring, the project evolved from a single-use notebook into a maintainable machine learning codebase. It is now organized into separate modules \u2014 <code>config.py</code>, <code>data.py</code>, <code>model.py</code>,<code>train.py</code>,<code>use.py</code>,<code>utils.py</code>, <code>./test/test_smoke.py, project.py</code> (the main entry point). The original implementation was contained in <code>q_rnn_last_name.ipynb</code>.</paragraph><paragraph>Github repo: <break/><link href=\"https://github.com/hysteri1a/hysteri1a-Refactoring-Report-HW7\">hysteri1a/hysteri1a-Refactoring-Report-HW7</link></paragraph><paragraph>Report</paragraph><file url=\"https://static.us.edusercontent.com/files/R0AYaMBCd59lqnKaXCgdeNdd\" filename=\"Report_HW7.pdf\"/><paragraph>Done by Lawrence Qian(3041996584)</paragraph><paragraph/><paragraph><break/><break/></paragraph><paragraph/></document>",
            "links": [
                "https://github.com/hysteri1a/hysteri1a-Refactoring-Report-HW7"
            ],
            "attachments": [],
            "created_at": "2025-11-06T11:43:10.534635+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7263386,
            "author": "Alex Luu",
            "project_title": "Special Participation A: HW6, gpt-oss-120b",
            "post_body": "I used gpt-oss-120b with thinking on HW 6 non coding questions. The performance was surprisingly good for a open-source model from a company with flagship proprietary models. It was able to one-shot almost all the questions. This model was also surprisingly fast (although that depends on the hosting provider). The latency was near 0 seconds and token generation was very fast. A more detailed summary is provided in the pdf.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/04mIJnMQwJFX1ig7X5G6o4wE\" filename=\"Special Participation A, HW6, gpt-oss-120b.pdf\"/><paragraph>I used gpt-oss-120b with thinking on HW 6 non coding questions. The performance was surprisingly good for a open-source model from a company with flagship proprietary models. It was able to one-shot almost all the questions. This model was also surprisingly fast (although that depends on the hosting provider). The latency was near 0 seconds and token generation was very fast. A more detailed summary is provided in the pdf.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-06T10:05:54.778256+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7263077,
            "author": "Anant Sahai",
            "project_title": "Added some more post-proposal Project slots on Thu for students",
            "post_body": "We've heard that some of you didn't book slots early enough on Tuesday (my slots went unused for example) and can't find slots. To make sure that people get feedback, I've added another hour of slots on Thu afternoon. \n\nIt is vital that students start this week on your projects because the deadline for the draft report will be upon you before you know it. We want to make sure that everyone gets feedback now. ",
            "content_xml": "<document version=\"2.0\"><paragraph>We've heard that some of you didn't book slots early enough on Tuesday (my slots went unused for example) and can't find slots. To make sure that people get feedback, I've added another hour of slots on Thu afternoon. <break/><break/>It is vital that students start this week on your projects because the deadline for the draft report will be upon you before you know it. We want to make sure that everyone gets feedback now. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-06T09:24:47.242184+11:00",
            "category": "Project"
        },
        {
            "guid": 7262818,
            "author": "Gireeja Ranade",
            "project_title": "Lectures: 16-20 State-space models, Transformer networks, Modern Architectures",
            "post_body": "Here are the lecture notes, sorry for the delay!",
            "content_xml": "<document version=\"2.0\"><paragraph>Here are the lecture notes, sorry for the delay!</paragraph><file url=\"https://static.us.edusercontent.com/files/vITc5qG2PULCIwIF95ScYECz\" filename=\"Lecture 20.pdf\"/><file url=\"https://static.us.edusercontent.com/files/wjbKvQIaJBIqHt2GmWZzg2H6\" filename=\"Lecture 19.pdf\"/><file url=\"https://static.us.edusercontent.com/files/1W3yC9Hb0yfuWEPhBdCPszps\" filename=\"Lecture 18.pdf\"/><file url=\"https://static.us.edusercontent.com/files/kZK6auktgCrh8DP8s6xETsTB\" filename=\"Lecture 17.pdf\"/><file url=\"https://static.us.edusercontent.com/files/4Vs92j7DfrkgDUSnNG4if920\" filename=\"Lecture 16.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-06T08:54:41.615649+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7261928,
            "author": "Shashwat Bansal",
            "project_title": "Special Participation B: Mistral on HW0",
            "post_body": "Mistral was able to one-shot the coding component of HW0, up until the exact learning rate and weight scale parameters needed for overfitting. When prompted with a hint that they are unequal, it went in the wrong direction. However, this is something that is difficult to ascertain without manually testing different rates, so Mistral did a good job overall and even provided concise explanations of the concepts like affine_forward().",
            "content_xml": "<document version=\"2.0\"><paragraph>Mistral was able to one-shot the coding component of HW0, up until the exact learning rate and weight scale parameters needed for overfitting. When prompted with a hint that they are unequal, it went in the wrong direction. However, this is something that is difficult to ascertain without manually testing different rates, so Mistral did a good job overall and even provided concise explanations of the concepts like <code>affine_forward()</code>.</paragraph><file url=\"https://static.us.edusercontent.com/files/pf1VZL0wnQ0pbZTNs3XeFCcq\" filename=\"CS182 Special Participation B_ Mistral on HW0.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-06T06:56:29.865721+11:00",
            "category": "Admin"
        },
        {
            "guid": 7259824,
            "author": "Shashwat Bansal",
            "project_title": "Participation Section A: Llama (Meta AI) on HW0",
            "post_body": "I interacted with Llama/Meta AI and had a rather disappointing result. For the (easier) questions it answered, it made decent progress on showing the math steps but was vague at times and couldn't tell left multiplication from right. It had trouble answering questions one-by-one like a student would, instead fixating on the topic of the question and ranting about it.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I interacted with Llama/Meta AI and had a rather disappointing result. For the (easier) questions it answered, it made decent progress on showing the math steps but was vague at times and couldn't tell left multiplication from right. It had trouble answering questions one-by-one like a student would, instead fixating on the topic of the question and ranting about it.</paragraph><file url=\"https://static.us.edusercontent.com/files/NL3zdbbcBsPHnQ8BtKrczKa1\" filename=\"CS182 Special Participation A_ Llama.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-05T21:02:05.590684+11:00",
            "category": "Admin"
        },
        {
            "guid": 7259754,
            "author": "Celine Tan",
            "project_title": "Special Participation C: HW1 q_sgd_momentum_analysis",
            "post_body": "Swetha Rajkumar, Katie Wang, and I worked together to refactor the notebook for q_sgd_momentum_analysis.ipynb. \n\nThe refactoring report has been attached below:\n\nThe majority of our changes involved enhancing the readability of code (through the inclusion of docstrings and type hints) and creating a helper function for repetitive plotting code. \n\nCode is available here: \n\nhttps://github.com/swetha2022/182_special_participations/blob/main/special_participations/q_sgd_momentum_analysis.ipynb ",
            "content_xml": "<document version=\"2.0\"><paragraph>Swetha Rajkumar, Katie Wang, and I worked together to refactor the notebook for <code>q_sgd_momentum_analysis.ipynb</code>. </paragraph><paragraph>The refactoring report has been attached below:</paragraph><file url=\"https://static.us.edusercontent.com/files/0bqzHGsDww3eazfWpRQGYUpt\" filename=\"special participation 182 hw1 (1).pdf\"/><paragraph>The majority of our changes involved enhancing the readability of code (through the inclusion of docstrings and type hints) and creating a helper function for repetitive plotting code. </paragraph><paragraph>Code is available here: </paragraph><paragraph><link href=\"https://github.com/swetha2022/182_special_participations/blob/main/special_participations/q_sgd_momentum_analysis.ipynb\">https://github.com/swetha2022/182_special_participations/blob/main/special_participations/q_sgd_momentum_analysis.ipynb</link> </paragraph></document>",
            "links": [
                "https://github.com/swetha2022/182_special_participations/blob/main/special_participations/q_sgd_momentum_analysis.ipynb"
            ],
            "attachments": [],
            "created_at": "2025-11-05T19:58:33.097603+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7259751,
            "author": "Celine Tan",
            "project_title": "Special Participation C: HW2 q_optimizer_init",
            "post_body": "Swetha Rajkumar, Katie Wang, and I worked together to refactor the notebook for q_optimizer_init.ipynb. \n\nThe refactoring report has been attached below:\n\nThe majority of our changes involved enhancing the readability of code (through the inclusion of docstrings and type hints) and creating helper functions for repetitive code. \n\nCode is available here: https://github.com/swetha2022/182_special_participations/blob/main/special_participations/q_optimizer_init_pythonic.ipynb",
            "content_xml": "<document version=\"2.0\"><paragraph>Swetha Rajkumar, Katie Wang, and I worked together to refactor the notebook for <code>q_optimizer_init.ipynb</code>. </paragraph><paragraph>The refactoring report has been attached below:</paragraph><file url=\"https://static.us.edusercontent.com/files/T6O4xW0j92BPWqLUGnDCoxSc\" filename=\"special participation 182.pdf\"/><paragraph>The majority of our changes involved enhancing the readability of code (through the inclusion of docstrings and type hints) and creating helper functions for repetitive code. </paragraph><paragraph>Code is available here: https://github.com/swetha2022/182_special_participations/blob/main/special_participations/q_optimizer_init_pythonic.ipynb</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-05T19:56:21.697227+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7259541,
            "author": "Jerry Xiao",
            "project_title": "Special Participation B: HW6 Coding with Deepseek",
            "post_body": "I used Deepseek to solve problems 5 and 6 of the coding part of HW6. \n\nNote: Problem 1 and Problem 3 are mainly about profiling and tool usage, therefore I skip the two problems.\n\n@ Problem 5: Zachary\u2019s Karate Club\n\nIn general I find that Deepseek can mainly solve the problem without further tuning. However, as the ZKC problem is a problem with large context, it is hard to put all the context within the code. Therefore Deepseek will try to use its own functions from other packages instead of using the preset helper functions. Also, the Deep Thinking capability will get stuck with large context. During the thinking process, Deepseek seems to overcomplicate the problem and thus leading to longer inference time. The structure of the outputs of Deepseek also have something in common. For all the coding section, it will produce the answer first and then follow up with detailed explanation. More comments and the full track of the conversation are attached within the files.\n\n@ Problem 6: Muon Optimizer\n\n\nIt surprises me that Deepseek actually does well in new task such as implementing Muon optimizer. Although the syntax is not quite aligned with the standard but the algorithm is generally correct. However, because Deepseek does not have multimodal capability, it is unable to solve the last few questions without people really describe the trend for it. Also, Deepseek tends to stuck in his thought for the Question 1 asking about the sqrt(3) scaling. It kind of buries itself in all the code works. After I adjust the prompt, it finally gets to the correct answer. More comments and the full track of the conversation are attached within the files.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>I used Deepseek to solve problems 5 and 6 of the coding part of HW6.</bold> </paragraph><paragraph><bold>Note:</bold> Problem 1 and Problem 3 are mainly about profiling and tool usage, therefore I skip the two problems.</paragraph><paragraph>@ Problem 5: Zachary\u2019s Karate Club</paragraph><file url=\"https://static.us.edusercontent.com/files/kIVDnXaigMUwDgANfgrQB5CG\" filename=\"Participation_B__HW_6_using_Deepseek_zkc.pdf\"/><paragraph>In general I find that Deepseek can mainly solve the problem without further tuning. However, as the ZKC problem is a problem with large context, it is hard to put all the context within the code. Therefore Deepseek will try to use its own functions from other packages instead of using the preset helper functions. Also, the Deep Thinking capability will get stuck with large context. During the thinking process, Deepseek seems to overcomplicate the problem and thus leading to longer inference time. The structure of the outputs of Deepseek also have something in common. For all the coding section, it will produce the answer first and then follow up with detailed explanation. More comments and the full track of the conversation are attached within the files.<break/><break/>@ Problem 6: Muon Optimizer<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/8I5rBh7PkUyZtxYAV9XmIldc\" filename=\"Participation_B__HW_6_using_Deepseek_Muon.pdf\"/><paragraph>It surprises me that Deepseek actually does well in new task such as implementing Muon optimizer. Although the syntax is not quite aligned with the standard but the algorithm is generally correct. However, because Deepseek does not have multimodal capability, it is unable to solve the last few questions without people really describe the trend for it. Also, Deepseek tends to stuck in his thought for the Question 1 asking about the sqrt(3) scaling. It kind of buries itself in all the code works. After I adjust the prompt, it finally gets to the correct answer. More comments and the full track of the conversation are attached within the files.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-05T17:52:44.26255+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7258633,
            "author": "Vijay Kethanaboyina",
            "project_title": "Special Participation A: Kimi on HW7 Written Questions",
            "post_body": "I had Moonshot AI's Kimi K2 model answer HW7's written questions. For each problem, my goal was to get the model to the correct answer while giving it as little outside assistance as possible. I only attempted to steer the model when it gave a clearly incorrect answer or when its response diverged significantly from the staff solution.\n\nHere are some of my key findings:\n\nThe model was able to answer most questions in one shot. Laying aside minor formatting and notational differences, the final answers were almost always the same as the staff solution's. \n\nHowever, in reasoning through the problems, the model sometimes made logical leaps that, while correct, were not sufficiently justified in my opinion.\n\nFor example, for Q3b, the model goes straight from stating the loss function to computing its gradient WRT $W_2$ in just one step.\n\n(For context in the below equation, $\\hat{X} = W_2 W_1 X$)\n\nMeanwhile, the staff solution is much more thorough, walking us through every step of the derivation and explicitly citing the matrix calculus identities that were employed.\n\nSo to fix that issue, when necessary, I ask the model to justify in more detail how it reached a given step.\n\nI saw some evidence of hallucination; for question 4a, I accidentally forgot to give the model some information needed to answer the question correctly. But rather than state, \"not enough information provided\", it gave me an incorrect response.\n\nFurthermore, when I gave it a URL containing the information needed to answer the question correctly, it again answered the question wrong. \n\nUpon further questioning, the model revealed that in fact, it does not have live browsing capabilities.\n\nThat is a reasonable limitation, but what is concerning is that it didn't admit it couldn't read the URL until after it had already hallucinated. This decreases my overall trust in the model.\n\nThat said, the model did a pretty good job on the \"summarize a blog post\" question (apart from the hallucination).\n\nI feel like these sorts of \"summarize a technical blog\" questions are where LLMs' abilities really shine. \n\nThey are able to pick out the key details and \"big picture\" insights without getting too lost in the technical details (a mistake that I often make when summarizing blog posts / papers)\n\nA full, annotated transcript of the conversation can be found here: https://drive.google.com/file/d/1p6f0AXpDIMW-9v7vZMJVj2J7aqjPkWQe/view?usp=sharing. \n\nI will also add a comment to this post with screenshots of the conversation to make it easy to read.",
            "content_xml": "<document version=\"2.0\"><paragraph>I had Moonshot AI's Kimi K2 model answer HW7's written questions. For each problem, my goal was to get the model to the correct answer while giving it as little outside assistance as possible. I only attempted to steer the model when it gave a clearly incorrect answer or when its response diverged significantly from the staff solution.</paragraph><paragraph>Here are some of my key findings:</paragraph><list style=\"bullet\"><list-item><paragraph>The model was able to answer most questions in one shot. Laying aside minor formatting and notational differences, the final answers were almost always the same as the staff solution's. </paragraph></list-item><list-item><paragraph>However, in reasoning through the problems, the model sometimes made logical leaps that, while correct, were not sufficiently justified in my opinion.</paragraph></list-item><list-item><paragraph>For example, for Q3b, the model goes straight from stating the loss function to computing its gradient WRT $W_2$ in just one step.</paragraph><list style=\"bullet\"><list-item><paragraph>(For context in the below equation, $\\hat{X} = W_2 W_1 X$)</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/AiEw4CncvT9IMxZp0uw7BMYs\" width=\"410\" height=\"218\"/></figure></list-item></list></list-item><list-item><paragraph>Meanwhile, the staff solution is much more thorough, walking us through every step of the derivation and explicitly citing the matrix calculus identities that were employed.</paragraph></list-item></list><figure><image src=\"https://static.us.edusercontent.com/files/tQdJDJOsXYzmRXSM2EZpJK3M\" width=\"356\" height=\"447\"/></figure><list style=\"bullet\"><list-item><paragraph>So to fix that issue, when necessary, I ask the model to justify in more detail how it reached a given step.</paragraph></list-item></list><figure><image src=\"https://static.us.edusercontent.com/files/FO7cPBEFtoRK6MhC9OmDcaf8\" width=\"326\" height=\"379\"/></figure><list style=\"bullet\"><list-item><paragraph>I saw some evidence of hallucination; for question 4a, I accidentally forgot to give the model some information needed to answer the question correctly. But rather than state, \"not enough information provided\", it gave me an incorrect response.</paragraph></list-item><list-item><paragraph>Furthermore, when I gave it a URL containing the information needed to answer the question correctly, it again answered the question wrong. </paragraph></list-item><list-item><paragraph>Upon further questioning, the model revealed that in fact, it does not have live browsing capabilities.</paragraph><list style=\"bullet\"><list-item><paragraph>That is a reasonable limitation, but what is concerning is that it didn't admit it couldn't read the URL until <italic>after</italic> it had already hallucinated. This decreases my overall trust in the model.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/W2C2phjQKQEKt4YPSFseUwWI\" width=\"398\" height=\"374\"/></figure></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph>That said, the model did a pretty good job on the \"summarize a blog post\" question (apart from the hallucination).</paragraph></list-item><list-item><paragraph>I feel like these sorts of \"summarize a technical blog\" questions are where LLMs' abilities really shine. </paragraph><list style=\"bullet\"><list-item><paragraph>They are able to pick out the key details and \"big picture\" insights without getting too lost in the technical details (a mistake that I often make when summarizing blog posts / papers)</paragraph></list-item></list></list-item></list><paragraph>A full, annotated transcript of the conversation can be found here: <link href=\"https://drive.google.com/file/d/1p6f0AXpDIMW-9v7vZMJVj2J7aqjPkWQe/view?usp=sharing\">https://drive.google.com/file/d/1p6f0AXpDIMW-9v7vZMJVj2J7aqjPkWQe/view?usp=sharing</link>. </paragraph><paragraph>I will also add a comment to this post with screenshots of the conversation to make it easy to read.</paragraph></document>",
            "links": [
                "https://drive.google.com/file/d/1p6f0AXpDIMW-9v7vZMJVj2J7aqjPkWQe/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-11-05T14:34:52.365835+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7253578,
            "author": "Anant Sahai",
            "project_title": "Getting started on your projects... Bring a printout this week...",
            "post_body": "Dear class,\n\nBy now, most of you have submitted your project proposals. (If you haven't set your group to include everyone, please do so. We notice some submissions didn't set the group correctly)\n\nBe sure to bring a printed copy of your proposal with you to your scheduled meeting with a member of course staff this week. (And if you haven't signed up yet, please do sign up.)\n\nIf you're meeting virtually, please have a copy ready to share so that the staff member can quickly skim it to identify risk factors, etc.\n\nThe most important thing is to get started now. Start writing code, getting tests in place, etc... Deep Learning is full of frustration as you find bugs after having trained something for a day or two. It will take lots of iteration to get things done and ready by the deadlines. You need to start now. (Unlike other areas, pulling all-nighters at the end isn't sufficient because of the training time that is required.)\n\nIn terms of the meetings with course staff, our primary objective is to make sure that your project is safe vis-a-vis your learning and being able to get full credit on your project. This means:\n\nMaking sure that you can train something (could be from scratch, a finetune, or experimental probes of some sort) in a way that lets you demonstrate a working understanding of many of the core practical concepts in deep learning:\n\nIncluding an exploration of hyperparameters --- at least learning rate, but more as relevant to what you are doing.\n\nMaking plots of training progress \n\nHaving some way for you to justify your hyperparameter and optimizer choices --- it is perfectly find for some of these to be X paper did it and we are following... But you have to be able to do this.\n\nMaking sure that you have some kind of held-out data or other ways of evaluating whether whatever you have trained actually makes sense and/or you have trained it sufficiently.\n\nSome thought about the architecture you are using including exploration/experimentation as relevant (this will be modulated on what you have to work with --- obviously, we cannot deem a project to be good if all you do is take code that already exists out there and just run it on some other data. In cases where solid code exists to build on, we will expect architectural experimentations.)\n\nAt least one hypothesis that you can express clearly and design an experiment to test. It is fine if the hypothesis fails or that the tests are inconclusive, but you have to be able to try enough to verify that this is not due to a bug on your part or grossly inadequate data or compute. Negative results or boring results are perfectly fine for full credit. Research has risks and many things fail --- that's ok. \n\nA path to a solid review of the literature that situates your work within the field and the current state of understanding and/or mystery.\n\nIf you have concerns in any of these directions, be sure to bring it up in your meeting so that we can help you mitigate those risks as early as possible. \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Dear class,</paragraph><paragraph>By now, most of you have submitted your project proposals. (If you haven't set your group to include everyone, please do so. We notice some submissions didn't set the group correctly)</paragraph><paragraph><bold>Be sure to bring a printed copy of your proposal with you to your scheduled meeting with a member of course staff this week. (And if you haven't signed up yet, please do sign up.)</bold></paragraph><paragraph>If you're meeting virtually, please have a copy ready to share so that the staff member can quickly skim it to identify risk factors, etc.<break/><break/>The most important thing is to get started now. Start writing code, getting tests in place, etc... Deep Learning is full of frustration as you find bugs <italic>after</italic> having trained something for a day or two. It will take lots of iteration to get things done and ready by the deadlines. You need to start now. (Unlike other areas, pulling all-nighters at the end isn't sufficient because of the training time that is required.)</paragraph><paragraph>In terms of the meetings with course staff, our primary objective is to make sure that your project is safe vis-a-vis your learning and being able to get full credit on your project. This means:</paragraph><list style=\"bullet\"><list-item><paragraph>Making sure that you can train something (could be from scratch, a finetune, or experimental probes of some sort) in a way that lets you demonstrate a working understanding of many of the core practical concepts in deep learning:</paragraph><list style=\"bullet\"><list-item><paragraph>Including an exploration of hyperparameters --- at least learning rate, but more as relevant to what you are doing.</paragraph></list-item><list-item><paragraph>Making plots of training progress </paragraph></list-item><list-item><paragraph>Having some way for you to justify your hyperparameter and optimizer choices --- it is perfectly find for some of these to be X paper did it and we are following... But you have to be able to do this.</paragraph></list-item></list></list-item><list-item><paragraph>Making sure that you have some kind of held-out data or other ways of evaluating whether whatever you have trained actually makes sense and/or you have trained it sufficiently.</paragraph></list-item><list-item><paragraph>Some thought about the architecture you are using including exploration/experimentation as relevant (this will be modulated on what you have to work with --- obviously, we cannot deem a project to be good if all you do is take code that already exists out there and just run it on some other data. In cases where solid code exists to build on, we will expect architectural experimentations.)</paragraph></list-item><list-item><paragraph>At least one hypothesis that you can express clearly and design an experiment to test. It is fine if the hypothesis fails or that the tests are inconclusive, but you have to be able to try enough to verify that this is not due to a bug on your part or grossly inadequate data or compute. Negative results or boring results are perfectly fine for full credit. Research has risks and many things fail --- that's ok. </paragraph></list-item><list-item><paragraph>A path to a solid review of the literature that situates your work within the field and the current state of understanding and/or mystery.</paragraph></list-item></list><paragraph>If you have concerns in any of these directions, be sure to bring it up in your meeting so that we can help you mitigate those risks as early as possible. </paragraph><paragraph><break/><break/></paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-04T19:12:24.259562+11:00",
            "category": "Project"
        },
        {
            "guid": 7252696,
            "author": "Deena Sun",
            "project_title": "Special Participation E: Concept Map Mermaid Diagrams of Research Papers",
            "post_body": "Using LLMs to create concept maps/Mermaid diagrams of key concepts and related works in research papers.\n\nWhen reading machine learning research papers, I like to synthesize how the different concepts introduced in the paper fit together and how related works tie into the ideas covered in the paper. I usually find this helpful for breaking down ML research into more digestible chunks as well as for creating a roadmap for how I can further my understanding using the citations referenced in the paper. I decided to use Claude 4.5 Sonnet on Perplexity to help me create concept maps of research papers that could visually display connections between key ideas in the paper, how related works contributed to the paper\u2019s takeaways, and additional papers for further exploration.\n\nFirst, I used Claude 4.5 Sonnet to help me generate an effective prompt I could reuse for LLMs based on my idea. I started off asking Claude for a general purpose deep learning tutoring prompt that would guide me through a research paper. Then, I focused the prompt to involve the LLM generating a workable Mermaid diagram representing my concept map idea. Claude gave me some helpful advice for how to productively prompt other LLMs for studying purposes:\n\nProvide context about your role and goals, including your background knowledge and your learning grows\n\nAssign the LLM a specific persona (e.g. \u201cYou are a deep learning teaching assistant\u2026\u201d) to tailor the model\u2019s responses towards educational guidance.\n\nProvide example interactions and specify what the output format should be\n\nAfter some back and forth to modify the prompt to my desires, I took the draft prompt that Claude suggested and used it to prompt another instance of Claude 4.5 Sonnet to actually generate a Mermaid diagram of a concept map for the paper \u201cA Spectral Condition for Feature Learning\u201d we read in homework 3, question 3. I also included a PDF of the paper as an attachment.\n\nHere is the final Mermaid diagram that Claude 4.5 Sonnet produced, rendered using a Mermaid diagram editor:\n\nHere is the prompt I used to generate this concept map that you can use!\n\nYou are a deep learning teaching assistant helping me map out conceptual relationships in a research paper.\n\nYour task:\n* Carefully read the research paper \"[PAPER TITLE]\" and identify all major concepts, methods, and results.\n* Build a structured concept map (\"brain map\") using Mermaid syntax (graph TD), where:\n    * Nodes represent key topics, methods, or results. Include related works and references inside the nodes.\n    * Edges connect related nodes, with descriptive labels explaining the relationship (not just keywords).\n    * Node labels are clear and concise; avoid line breaks for compatibility.\n* For each node, list relevant citations and references (from the paper and cited works) below the diagram, grouped by concept.\n* Flag nodes that are central (highly connected) or have many references, and highlight these for further study.\n* If supported, also generate a PNG image of the diagram for visual reference.\n\nOutput Instructions\n* Present the concept map first using Mermaid syntax in a Markdown code block. Use graph TD, clear node labels, and descriptive edge labels (e.g., --> |enables parallel attention|).\n* Represent the 10 most important concepts as nodes in the Mermaid diagram. Include related works and references inside the node.\n* List all references/citations grouped by node below the diagram (not inside node labels).\n* If possible, generate and return a PNG image of the diagram.\n* Avoid using special characters such as parentheses in labels that might not be compatible with Mermaid diagram generators.\n\nFormat example:\n```\ngraph TD\n Transformer[\"Transformer Model (Vaswani et al. 2017)\"]\n SelfAttn[\"Self-Attention (Bahdanau et al. 2014; Lin et al. 2017)\"]\n MultiHead[\"Multi-Head Attention (Vaswani et al. 2017)\"]\n PosEnc[\"Positional Encoding (Gehring et al. 2017)\"]\n Adam[\"Adam Optimizer (Kingma & Ba 2014)\"]\n Transformer -->|Directly models all pairwise token dependencies with attention| SelfAttn\n Transformer -->|Requires token position information for context awareness| PosEnc\n Transformer -->|Is trained efficiently using adaptive gradient optimization| Adam\n SelfAttn -->|Provides the base mechanism for building rich token representations| MultiHead\n MultiHead -->|Enables parallelized, diverse attention for complex relationships| SelfAttn\n\nReferences by Node:\n* Transformer Model: Vaswani et al. 2017, Gehring et al. 2017, Wu et al. 2016\n* Self-Attention: Bahdanau et al. 2014, Lin et al. 2017, Parikh et al. 2016\n* Multi-Head Attention: Vaswani et al. 2017, Britz et al. 2017\n* Positional Encoding: Gehring et al. 2017, Sennrich et al. 2015\n* Adam Optimizer: Kingma & Ba 2014\n```\n\nBackground:\nI am an undergraduate student who is interested in machine learning, deep learning, and research in these fields.\n\nPaper abstract/intro:\n[COPY HERE]\n\nHere are the logs of my chats that I used to brainstorm my prompt as well as to create the Mermaid diagram:\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Using LLMs to create concept maps/Mermaid diagrams of key concepts and related works in research papers.</paragraph><paragraph>When reading machine learning research papers, I like to synthesize how the different concepts introduced in the paper fit together and how related works tie into the ideas covered in the paper. I usually find this helpful for breaking down ML research into more digestible chunks as well as for creating a roadmap for how I can further my understanding using the citations referenced in the paper. I decided to use Claude 4.5 Sonnet on Perplexity to help me create concept maps of research papers that could visually display connections between key ideas in the paper, how related works contributed to the paper\u2019s takeaways, and additional papers for further exploration.</paragraph><paragraph>First, I used Claude 4.5 Sonnet to help me generate an effective prompt I could reuse for LLMs based on my idea. I started off asking Claude for a general purpose deep learning tutoring prompt that would guide me through a research paper. Then, I focused the prompt to involve the LLM generating a workable Mermaid diagram representing my concept map idea. Claude gave me some helpful advice for how to productively prompt other LLMs for studying purposes:</paragraph><list style=\"unordered\"><list-item><paragraph>Provide context about your role and goals, including your background knowledge and your learning grows</paragraph></list-item><list-item><paragraph>Assign the LLM a specific persona (e.g. \u201cYou are a deep learning teaching assistant\u2026\u201d) to tailor the model\u2019s responses towards educational guidance.</paragraph></list-item><list-item><paragraph>Provide example interactions and specify what the output format should be</paragraph></list-item></list><paragraph>After some back and forth to modify the prompt to my desires, I took the draft prompt that Claude suggested and used it to prompt another instance of Claude 4.5 Sonnet to actually generate a Mermaid diagram of a concept map for the paper \u201cA Spectral Condition for Feature Learning\u201d we read in homework 3, question 3. I also included a PDF of the paper as an attachment.</paragraph><paragraph>Here is the final Mermaid diagram that Claude 4.5 Sonnet produced, rendered using a <link href=\"https://mermaid.live/edit\">Mermaid diagram editor</link>:</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/JpxdsphfUuRv1gGhtbJikn5g\" width=\"658\" height=\"641.3943217665615\"/></figure><paragraph>Here is the prompt I used to generate this concept map that you can use!</paragraph><pre>You are a deep learning teaching assistant helping me map out conceptual relationships in a research paper.\n\nYour task:\n* Carefully read the research paper \"[PAPER TITLE]\" and identify all major concepts, methods, and results.\n* Build a structured concept map (\"brain map\") using Mermaid syntax (graph TD), where:\n    * Nodes represent key topics, methods, or results. Include related works and references inside the nodes.\n    * Edges connect related nodes, with descriptive labels explaining the relationship (not just keywords).\n    * Node labels are clear and concise; avoid line breaks for compatibility.\n* For each node, list relevant citations and references (from the paper and cited works) below the diagram, grouped by concept.\n* Flag nodes that are central (highly connected) or have many references, and highlight these for further study.\n* If supported, also generate a PNG image of the diagram for visual reference.\n\nOutput Instructions\n* Present the concept map first using Mermaid syntax in a Markdown code block. Use graph TD, clear node labels, and descriptive edge labels (e.g., --&gt; |enables parallel attention|).\n* Represent the 10 most important concepts as nodes in the Mermaid diagram. Include related works and references inside the node.\n* List all references/citations grouped by node below the diagram (not inside node labels).\n* If possible, generate and return a PNG image of the diagram.\n* Avoid using special characters such as parentheses in labels that might not be compatible with Mermaid diagram generators.\n\nFormat example:\n```\ngraph TD\n Transformer[\"Transformer Model (Vaswani et al. 2017)\"]\n SelfAttn[\"Self-Attention (Bahdanau et al. 2014; Lin et al. 2017)\"]\n MultiHead[\"Multi-Head Attention (Vaswani et al. 2017)\"]\n PosEnc[\"Positional Encoding (Gehring et al. 2017)\"]\n Adam[\"Adam Optimizer (Kingma &amp; Ba 2014)\"]\n Transformer --&gt;|Directly models all pairwise token dependencies with attention| SelfAttn\n Transformer --&gt;|Requires token position information for context awareness| PosEnc\n Transformer --&gt;|Is trained efficiently using adaptive gradient optimization| Adam\n SelfAttn --&gt;|Provides the base mechanism for building rich token representations| MultiHead\n MultiHead --&gt;|Enables parallelized, diverse attention for complex relationships| SelfAttn\n\nReferences by Node:\n* Transformer Model: Vaswani et al. 2017, Gehring et al. 2017, Wu et al. 2016\n* Self-Attention: Bahdanau et al. 2014, Lin et al. 2017, Parikh et al. 2016\n* Multi-Head Attention: Vaswani et al. 2017, Britz et al. 2017\n* Positional Encoding: Gehring et al. 2017, Sennrich et al. 2015\n* Adam Optimizer: Kingma &amp; Ba 2014\n```\n\nBackground:\nI am an undergraduate student who is interested in machine learning, deep learning, and research in these fields.\n\nPaper abstract/intro:\n[COPY HERE]</pre><paragraph>Here are the logs of my chats that I used to brainstorm my prompt as well as to create the Mermaid diagram:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/3w2hhk3gVZSU1c7OeKythrA8\" filename=\"Research_graph_prompt_creation_chat.pdf\"/><file url=\"https://static.us.edusercontent.com/files/xKoVyP3TX2Rof6dDLfOjctCf\" filename=\"Spectral_condition_for_feature_learning_concept_map_chat.pdf\"/></document>",
            "links": [
                "https://mermaid.live/edit"
            ],
            "attachments": [],
            "created_at": "2025-11-04T15:15:24.914928+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7252362,
            "author": "Ben Yu",
            "project_title": "Special Participation B: ChatGPT 5 on HW 3",
            "post_body": "What I Did:\n\nI tried to use GPT-5 to help me understand the muP coding lab (q_mup_coding.ipynb) -- especially parts (c)\u2013(d), which involved per-layer learning-rate scaling and graph scaling factors. The conversation grew extremely long because I was confused about the correct scaling factor (\u221an_in, n_in, 1/\u221an_in, 1/n_in, \u221a(n_out/n_in), etc.) and how these relate across RMS, spectral, and induced norms. Later the released solution notebook turned out to have an incorrect scaling line (x * p_shape[1] instead of x / p_shape[1]), which made it harder to verify correctness before the announcement came out.\n\nWorkflow\n\n1. Ask questions: I pasted the exact sub-questions: \u201cWhat is part d\u2019s scaling factor?\u201d, \u201cShould I divide by \u221a or n_in?\u201d, \u201cWhere in code step() handles bias?\u201d, etc.\n\n2. Compare & Probe: Each time, I compared the AI\u2019s answer to lecture notes. and when results disagreed, I asked for the missing algebra or an intuition (\u201cWhy does 1/fan-in appear?\u201d).\n\n3. Tighten understanding: I repeatedly asked it to rewrite arguments in plain words and to clarify the difference between the RMS\u2192RMS induced norm and the spectral norm.\n\nExample of confusion:\n\nI kept alternating between x /= sqrt(layer.in_features) [fan-in normalization] and x *= sqrt(layer.out_features / layer.in_features) [\u03bcP graph scaling]. Both produced different plots, and ChatGPT changed answers multiple times and still did not converge to the correct forward scaling (divide by n_in).\n\nObservations \n\nKey insight: \n\nThese factors solve different problems. For example, \u221a(1/fan-in) keeps activations numerically stable; 1/fan-in (\u03bcP) keeps feature updates width-invariant under Adam.\n\nPositives (What Worked Well):\n\nDebugging guidance: Helped me trace the coding part, where step() applies to both weight and bias tensors and where the forward multiplier belongs.\n\nNegatives (Limitations / Effort Required):\n\nConcept collision: It mixed up \u201cfan-in \u221a scaling\u201d and \u201c\u03bcP 1/n scaling\u201d several times, making things more confused.\n\nVerification cost: Because the official solution had an error, I needed to cross-check the explanations to confirm the correct direction, which is hard since AI uses different wordings that I sometimes find hard to connect between two explanations\n\nPrompting Strategies That Helped\n\n\u201cElaborate / Why this?\u201d \u2192 forced the model to expand the chain-rule or Jacobian steps.\n\n\u201cIs my thought correct? If not, why?\u201d \u2192 helped surface subtle contradictions.\n\n\u201cMake a table.\u201d \u2192 compressed multiple conflicting explanations into a clear comparative view.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>What I Did:</bold></paragraph><paragraph>I tried to use GPT-5 to help me understand the muP coding lab (q_mup_coding.ipynb) -- especially parts (c)\u2013(d), which involved per-layer learning-rate scaling and graph scaling factors. The conversation grew extremely long because I was confused about the correct scaling factor (\u221an_in, n_in, 1/\u221an_in, 1/n_in, \u221a(n_out/n_in), etc.) and how these relate across RMS, spectral, and induced norms. Later the released solution notebook turned out to have an incorrect scaling line (x * p_shape[1] instead of x / p_shape[1]), which made it harder to verify correctness before the announcement came out.</paragraph><paragraph><bold>Workflow</bold></paragraph><paragraph>1. <bold>Ask questions:</bold> I pasted the exact sub-questions: \u201cWhat is part d\u2019s scaling factor?\u201d, \u201cShould I divide by \u221a or n_in?\u201d, \u201cWhere in code step() handles bias?\u201d, etc.</paragraph><paragraph>2. <bold>Compare &amp; Probe:</bold> Each time, I compared the AI\u2019s answer to lecture notes. and when results disagreed, I asked for the missing algebra or an intuition (\u201cWhy does 1/fan-in appear?\u201d).</paragraph><paragraph>3. <bold>Tighten understanding:</bold> I repeatedly asked it to rewrite arguments in plain words and to clarify the difference between the RMS\u2192RMS induced norm and the spectral norm.</paragraph><paragraph><bold>Example of confusion:</bold></paragraph><paragraph>I kept alternating between x /= sqrt(layer.in_features) [<bold>fan-in normalization]</bold> and x *= sqrt(layer.out_features / layer.in_features) [<bold>\u03bcP graph scaling]</bold>. Both produced different plots, and ChatGPT changed answers multiple times and still did not converge to the correct forward scaling (divide by n_in).</paragraph><paragraph><bold>Observations</bold> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/YAxayyC6nsSyu4PzNcQbb4hx\" width=\"658\" height=\"381.21086956521737\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/pbXpDX480JPfih3JYAeia3sE\" width=\"658\" height=\"185.73493975903617\"/></figure><paragraph><bold>Key insight:</bold> </paragraph><paragraph>These factors solve different problems. For example, \u221a(1/fan-in) keeps activations numerically stable; 1/fan-in (\u03bcP) keeps feature updates width-invariant under Adam.</paragraph><paragraph><bold>Positives (What Worked Well):</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Debugging guidance</bold>: Helped me trace the coding part, where step() applies to both weight and bias tensors and where the forward multiplier belongs.</paragraph></list-item></list><paragraph><bold>Negatives (Limitations / Effort Required):</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Concept collision:</bold> It mixed up \u201cfan-in \u221a scaling\u201d and \u201c\u03bcP 1/n scaling\u201d several times, making things more confused.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Verification cost:</bold> Because the official solution had an error, I needed to cross-check the explanations to confirm the correct direction, which is hard since AI uses different wordings that I sometimes find hard to connect between two explanations</paragraph></list-item></list><paragraph><bold>Prompting Strategies That Helped</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>\u201cElaborate / Why this?\u201d</bold> \u2192 forced the model to expand the chain-rule or Jacobian steps.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>\u201cIs my thought correct? If not, why?\u201d</bold> \u2192 helped surface subtle contradictions.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>\u201cMake a table.\u201d</bold> \u2192 compressed multiple conflicting explanations into a clear comparative view.</paragraph></list-item></list><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-04T14:20:15.828791+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7250623,
            "author": "Ender Ji",
            "project_title": "Special Participation A: HW7 with Grok",
            "post_body": "I used Grok to complete the written part of HW7. I begin by clearly stating Grok\u2019s role and the assistance I require, then provide whole HW7 file to Grok and ask it to understand the problem setups ONLY, so it does not skip ahead to solving the problem.\n\nHW7 consists of proofs, multiple choice questions, and open-ended free response problems. Grok performs very well on the multiple-choice questions, often answering correctly on the first attempt. For the open-ended free response problems, Grok provides reasonable points with clear explanations. However, on the proof problems, Grok typically does not match the official solution on the first attempt and requires additional hints and guidance, for example, specifying which variables or equations to use.\n\n\n\nOverall Grok performs descently on the written part of the homework, with great performance on MCQ problems and open-ended free response problems, but difficulty with the proofs.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/sGI2dcFvYnUuoEMGTIY6vp7y\" filename=\"grok_hw7.pdf\"/><paragraph>I used Grok to complete the written part of HW7. I begin by clearly stating Grok\u2019s role and the assistance I require, then provide whole HW7 file to Grok and ask it to understand the problem setups ONLY, so it does not skip ahead to solving the problem.</paragraph><paragraph>HW7 consists of proofs, multiple choice questions, and open-ended free response problems. Grok performs very well on the multiple-choice questions, often answering correctly on the first attempt. For the open-ended free response problems, Grok provides reasonable points with clear explanations. However, on the proof problems, Grok typically does not match the official solution on the first attempt and requires additional hints and guidance, for example, specifying which variables or equations to use.</paragraph><paragraph/><paragraph>Overall Grok performs descently on the written part of the homework, with great performance on MCQ problems and open-ended free response problems, but difficulty with the proofs.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-04T09:47:19.742032+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7250482,
            "author": "Heidy Hernandez Juan",
            "project_title": "Special Participation A: Mistral on HW6",
            "post_body": "Link: https://chat.mistral.ai/chat/6cd62931-f284-4c4b-9ba3-c5b97943fd28\n\nAnnotated Log: https://drive.google.com/file/d/1mUgllouQGxVA_m5tmlVrq6Dt46HSf0hd/view?usp=sharing\n\nExecutive Summary:\n\nI observed that the model fails to extract information from diagrams like tables, images, and graphs. Assignments that include filling out information or extracting information from diagrams to complete the assignment are very likely to be incorrect, as the model will hallucinate information.\n\nAlso, it didn't list the explanation for its reasoning behind its own analysis of the graphs in one of the problems. I suggest being careful with problems involving visualization.\n\nIt did well in demonstrating its mathematical analysis, making it clear to figure out any mishap in its derivation. There were times when the model outputted answers that I, myself, hadn't seen, though they were mathematically equivalent. The model considers other options when solving problems, allowing for a broader understanding of mathematics.\n\nMistral also did a good job of allowing for an open interaction with the user by making sure to end with, \u2018Ready for any further questions or clarification!\u2019\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Link</bold>: <link href=\"https://chat.mistral.ai/chat/6cd62931-f284-4c4b-9ba3-c5b97943fd28\">https://chat.mistral.ai/chat/6cd62931-f284-4c4b-9ba3-c5b97943fd28</link></paragraph><paragraph><bold>Annotated Log:</bold> <link href=\"https://drive.google.com/file/d/1mUgllouQGxVA_m5tmlVrq6Dt46HSf0hd/view?usp=sharing\">https://drive.google.com/file/d/1mUgllouQGxVA_m5tmlVrq6Dt46HSf0hd/view?usp=sharing</link></paragraph><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>I observed that the model fails to extract information from diagrams like tables, images, and graphs. Assignments that include filling out information or extracting information from diagrams to complete the assignment are very likely to be incorrect, as the model will hallucinate information.</paragraph><paragraph>Also, it didn't list the explanation for its reasoning behind its own analysis of the graphs in one of the problems. I suggest being careful with problems involving visualization.</paragraph><paragraph>It did well in demonstrating its mathematical analysis, making it clear to figure out any mishap in its derivation. There were times when the model outputted answers that I, myself, hadn't seen, though they were mathematically equivalent. The model considers other options when solving problems, allowing for a broader understanding of mathematics.</paragraph><paragraph>Mistral also did a good job of allowing for an open interaction with the user by making sure to end with, \u2018Ready for any further questions or clarification!\u2019</paragraph><paragraph/></document>",
            "links": [
                "https://chat.mistral.ai/chat/6cd62931-f284-4c4b-9ba3-c5b97943fd28",
                "https://drive.google.com/file/d/1mUgllouQGxVA_m5tmlVrq6Dt46HSf0hd/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-11-04T09:28:36.310964+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7250444,
            "author": "Ben Yu",
            "project_title": "Special Participation A: Gemini Pro on HW 3",
            "post_body": "What I did:\n\nI ran an interactive, non-coding walkthrough of HW 3 using Gemini Pro. Full trace (screenshots + chat excerpts) is in my doc: https://docs.google.com/document/d/1P6yTAFO4GR4W4a_l02kAFN2mYwKtmgsmPLecVg9gAGY/edit?tab=t.0\n\nI used Gemini to sanity-check my derivations, clarify notation, and cross-validate with my own solutions\n\nWorkflow:\n\n1) Try solo first (\u226430 min). If blocked, paste the exact sub-question into Gemini.\n\n2) Compare & probe. Check Gemini\u2019s output against my derivation; ask for clarifications or for the missing step.\n\n3) Tighten. Clarify equation statements, symbol mismatches, and ask for the key identity or rules explicitly.\n\nSpecific Example (Analogy + Clarification):\n\nTopic: Interpreting p\u03b8\u200b:X\u2192\u0394(X) in Q4.\n\nMy Ask: \u201cWhat does the arrow to \u0394(X) mean in p\u03b8\u200b:X\u2192\u0394(X)?\u201d\n\nGemini\u2019s Analogy (helpful): Sound equalizer.\n\np\u03b8\u200b = the equalizer; \u03b8 = slider positions;\n\nX = the set of audible frequencies;\n\n\u0394(X) = all possible sound profiles (distributions over X).\n Changing \u03b8 selects a particular distribution in \u0394(X).\n\nMy Follow-up (to make it precise): \u201cPlease restate without analogy: define X, \u0394(X), and what an \u2018element\u2019 of \u0394(X) is.\u201d\n\nGemini (clarified): X is the sample space; \u0394(X) is the set of all probability measures on X; for each \u03b8, p\u03b8\u200b(\u22c5)\u2208\u0394(X).\n\nPattern used: take the first pass (analogy/intuition), then demand the formal mapping with symbols.\n\nObservations:\n\nUses analogies to simplify (e.g., equalizer for p\u03b8\u200b:X\u2192\u0394(X)). Helpful as a first pass.\n\nInconsistent symbols at times, likely from generic training patterns; needs nudging to match the homework question\u2019s notation.\n\nPositives (What Worked Well):\n\nOne-shot on standard rewrites: Correctly gave correct answers straight from around 30% of the questions\n\nRight methodology even when imperfect: When wrong/incomplete, it still pointed in the correct direction\n\nNegatives (Limitations and Effort Required):\n\nNotation slippage: Misread or drifted symbols\n\nOver/under-explanation: Wrapped easy steps in prose but skimmed tough steps unless I asked \u201celaborate on this step.\u201d\n\nPrompting Strategies That Helped:\n\n\u201cDerive further.\u201d Ask for the exact algebraic substitution (e.g., show \u2207p=p\u2207logp).\n\n\u201cElaborate / Why this?\u201d Request the chain-rule Jacobian or the gradient wrt input vs. parameters explicitly.\n\n\u201cIs my thought correct? If not, why?\u201d Good for catching subtle mistakes and forcing a counterexample or fix.\n\n\u201cShow this equation more clearly\u201d Keeps it concise and reduces misunderstanding\n\n\u201cMatch the HW notation.\u201d Prevents variable chaos.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>What I did:</bold></paragraph><paragraph>I ran an interactive, non-coding walkthrough of HW 3 using Gemini Pro. Full trace (screenshots + chat excerpts) is in my doc: <link href=\"https://docs.google.com/document/d/1P6yTAFO4GR4W4a_l02kAFN2mYwKtmgsmPLecVg9gAGY/edit?tab=t.0\">https://docs.google.com/document/d/1P6yTAFO4GR4W4a_l02kAFN2mYwKtmgsmPLecVg9gAGY/edit?tab=t.0</link></paragraph><paragraph>I used Gemini to sanity-check my derivations, clarify notation, and cross-validate with my own solutions</paragraph><paragraph><bold>Workflow:</bold></paragraph><paragraph><bold>1) Try solo first (\u226430 min).</bold> If blocked, paste the exact sub-question into Gemini.</paragraph><paragraph><bold>2) Compare &amp; probe.</bold> Check Gemini\u2019s output against my derivation; ask for clarifications or for the missing step.</paragraph><paragraph><bold>3) Tighten.</bold> Clarify equation statements, symbol mismatches, and ask for the key identity or rules explicitly.</paragraph><paragraph><bold>Specific Example (Analogy + Clarification):</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Topic:</bold> Interpreting p\u03b8\u200b:X\u2192\u0394(X) in Q4.</paragraph></list-item></list><list style=\"unordered\"><list-item><list style=\"unordered\"><list-item><paragraph><bold>My Ask:</bold> \u201cWhat does the arrow to \u0394(X) mean in p\u03b8\u200b:X\u2192\u0394(X)?\u201d</paragraph></list-item><list-item><paragraph><bold>Gemini\u2019s Analogy (helpful):</bold> <italic>Sound equalizer.</italic></paragraph><list style=\"unordered\"><list-item><paragraph>p\u03b8\u200b = the equalizer; \u03b8 = slider positions;</paragraph></list-item><list-item><paragraph>X = the set of audible frequencies;</paragraph></list-item><list-item><paragraph>\u0394(X) = all possible sound profiles (distributions over X).<break/> Changing \u03b8 selects a particular distribution in \u0394(X).</paragraph></list-item></list></list-item><list-item><paragraph><bold>My Follow-up (to make it precise):</bold> \u201cPlease restate without analogy: define X, \u0394(X), and what an \u2018element\u2019 of \u0394(X) is.\u201d</paragraph></list-item><list-item><paragraph><bold>Gemini (clarified):</bold> X is the sample space; \u0394(X) is the set of all probability measures on X; for each \u03b8, p\u03b8\u200b(\u22c5)\u2208\u0394(X).</paragraph></list-item><list-item><paragraph><bold>Pattern used:</bold> take the first pass (analogy/intuition), then demand the formal mapping with symbols.</paragraph></list-item></list></list-item></list><paragraph><bold>Observations:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Uses analogies</bold> to simplify (e.g., equalizer for p\u03b8\u200b:X\u2192\u0394(X)). Helpful as a first pass.</paragraph></list-item><list-item><paragraph><bold>Inconsistent symbols</bold> at times, likely from generic training patterns; needs nudging to match the homework question\u2019s notation.</paragraph></list-item></list><paragraph><bold>Positives (What Worked Well):</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>One-shot on standard rewrites:</bold> Correctly gave correct answers straight from around 30% of the questions</paragraph></list-item><list-item><paragraph><bold>Right methodology even when imperfect:</bold> When wrong/incomplete, it still pointed in the correct direction</paragraph></list-item></list><paragraph><bold>Negatives (Limitations and Effort Required):</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Notation slippage:</bold> Misread or drifted symbols</paragraph></list-item><list-item><paragraph><bold>Over/under-explanation:</bold> Wrapped easy steps in prose but skimmed tough steps unless I asked \u201celaborate on this step.\u201d</paragraph></list-item></list><paragraph><bold>Prompting Strategies That Helped:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>\u201cDerive further.\u201d</bold> Ask for the exact algebraic substitution (e.g., show \u2207p=p\u2207logp).</paragraph></list-item><list-item><paragraph><bold>\u201cElaborate / Why this?\u201d</bold> Request the chain-rule Jacobian or the gradient wrt input vs. parameters explicitly.</paragraph></list-item><list-item><paragraph><bold>\u201cIs my thought correct? If not, why?\u201d</bold> Good for catching subtle mistakes and forcing a counterexample or fix.</paragraph></list-item><list-item><paragraph><bold>\u201cShow this equation more clearly\u201d</bold> Keeps it concise and reduces misunderstanding</paragraph></list-item><list-item><paragraph><bold>\u201cMatch the HW notation.\u201d</bold> Prevents variable chaos.</paragraph></list-item></list></document>",
            "links": [
                "https://docs.google.com/document/d/1P6yTAFO4GR4W4a_l02kAFN2mYwKtmgsmPLecVg9gAGY/edit?tab=t.0"
            ],
            "attachments": [],
            "created_at": "2025-11-04T09:23:05.224039+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7249718,
            "author": "Ben Yu",
            "project_title": "Special Participation E: Using GPT to Deepen Lecture Understanding",
            "post_body": "What I built:\n\nDuring lectures, I used ChatGPT as an interactive study partner rather than a passive note tool.\nWhenever a concept felt unclear, I would pause the lecture, take a screenshot, and ask a precise question in my EECS 182 project space. Each numbered thread (Week #) became a mini-lab where I clarified equations, verified derivations, and then reinterpreted AI\u2019s explanation directly into my written lecture notes:\n\nFor example (image below), in Week 9's lecture, I used GPT as my study partner to clarify the concept of Fast Fourier Transform on State Space Models, which was barely mentioned on during lecture. This way I can freely choose to dive deeper into specific concepts while learning the broad picture from the lecture.\n\n\n\nExample Conversation \u2014 Lecture 9: Hidden-State Independence\n\nTrace Link: https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2G\n\nOne of My Question: \u201cSo the point (of use block diagonal matrix B in state space calculation) is to make hidden states independent?\u201d\n\nAI-Guided Insights: Correlated hidden states introduce redundancy and unstable gradients, because each state begins to carry overlapping information about the sequence. By using block diagonal matrices, each hidden unit evolves as a unique information channel, making the system more stable and interpretable by decoupling the updates of different state components, because independent states yield better gradient flow, improved generalization, and a cleaner mapping between model structure and learned function.\n\nVerification:\nI implemented diag_unrolled_ssm_forward and diag_conv_ssm_forward to confirm the theory, and their outputs matched within 1e-6 and reproduced the predicted runtime behavior -- linear in T for recurrence, nearly constant on GPU for convolution.\n\nAfter each exchange, I try to reexplain the idea in my handwritten notes, converting the long AI reasoning into a concise conceptual summary that I could review quickly before exams.\n\nComments:\n\nPositives (What Worked Well):\n\nImmediate conceptual clarification: AI interaction let me elaborate on lecture ideas in real time rather than waiting for Ed Forum or office-hour responses.\n\nReduced TA load: Routine clarifications that might have required staff input were handled independently, keeping my questions tightly scoped to lecture material.\n\nDeeper integration: Reading the AI\u2019s full reasoning line by line forced me to engage with the derivations more carefully than a static answer key would have.\n\nNegatives (Limitations and Effort Required):\n\nScope uncertainty: The AI occasionally referenced material outside the intended EECS 182 syllabus, requiring me to filter which concepts were truly in scope.\n\nPotential over-explanation: Responses sometimes included extra theoretical context that, while interesting, risked obscuring the specific idea being tested.\n\nFuture Improvements:\n\nStructured project workflow: As outlined in my companion submission \u201cSpecial Participation E: AI-Enhanced Learning with ChatGPT Project Mode,\u201d we can formalize a workflow where each thread explicitly records lecture context, question scope, and verified outcomes.\n\nThis process exemplifies how AI can enhance learning when guided by course scope, topical context, and consistent self-reflection.",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>What I built:</bold></paragraph><paragraph>During lectures, I used ChatGPT as an <bold>interactive study partner</bold> rather than a passive note tool.<break/>Whenever a concept felt unclear, I would <bold>pause the lecture</bold>, <bold>take a screenshot</bold>, and <bold>ask a precise question</bold> in my EECS 182 project space. Each numbered thread (Week #) became a mini-lab where I clarified equations, verified derivations, and then <bold>reinterpreted AI\u2019s explanation directly into my written lecture notes:</bold></paragraph><paragraph>For example (image below), in <bold>Week 9's</bold> lecture, I used GPT as my study partner to clarify the concept of <bold>Fast Fourier Transform</bold> on <bold>State Space Models</bold>, which was barely mentioned on during lecture. This way I can freely choose to dive deeper into specific concepts while learning the broad picture from the lecture.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/MOPsugkwHHt4DRZL9dIWgPNZ\" width=\"658\" height=\"201.03782735208534\"/></figure><paragraph/><paragraph><bold>Example Conversation \u2014 Lecture 9: Hidden-State Independence</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Trace Link:</bold> <link href=\"https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2G\">https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2G</link></paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>One of My Question:</bold> \u201cSo the point (of use block diagonal matrix B in state space calculation) is to make hidden states independent?\u201d</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>AI-Guided Insights:</bold> Correlated hidden states introduce redundancy and unstable gradients, because each state begins to carry overlapping information about the sequence. By using block diagonal matrices, each hidden unit evolves as a unique information channel, making the system more stable and interpretable by decoupling the updates of different state components, because independent states yield better gradient flow, improved generalization, and a cleaner mapping between model structure and learned function.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Verification:</bold><break/>I implemented <code>diag_unrolled_ssm_forward</code> and <code>diag_conv_ssm_forward</code> to confirm the theory, and their outputs matched within 1e-6 and reproduced the predicted runtime behavior -- linear in T for recurrence, nearly constant on GPU for convolution.</paragraph></list-item></list><paragraph>After each exchange, I try to reexplain the idea in my handwritten notes, converting the long AI reasoning into a <bold>concise conceptual summary</bold> that I could review quickly before exams.</paragraph><paragraph><bold>Comments:</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Positives (What Worked Well):</bold></paragraph></list-item></list><list style=\"bullet\"><list-item><list style=\"bullet\"><list-item><paragraph><bold>Immediate conceptual clarification:</bold> AI interaction let me elaborate on lecture ideas in real time rather than waiting for Ed Forum or office-hour responses.</paragraph></list-item><list-item><paragraph><bold>Reduced TA load:</bold> Routine clarifications that might have required staff input were handled independently, keeping my questions tightly scoped to lecture material.</paragraph></list-item><list-item><paragraph><bold>Deeper integration:</bold> Reading the AI\u2019s full reasoning line by line forced me to engage with the derivations more carefully than a static answer key would have.</paragraph></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Negatives (Limitations and Effort Required):</bold></paragraph></list-item></list><list style=\"bullet\"><list-item><list style=\"bullet\"><list-item><paragraph><bold>Scope uncertainty:</bold> The AI occasionally referenced material outside the intended EECS 182 syllabus, requiring me to filter which concepts were truly in scope.</paragraph></list-item><list-item><paragraph><bold>Potential over-explanation:</bold> Responses sometimes included extra theoretical context that, while interesting, risked obscuring the specific idea being tested.</paragraph></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Future Improvements:</bold></paragraph></list-item></list><list style=\"bullet\"><list-item><list style=\"bullet\"><list-item><paragraph><bold>Structured project workflow:</bold> As outlined in my companion submission <italic>\u201cSpecial Participation E: AI-Enhanced Learning with ChatGPT Project Mode,\u201d</italic> we can formalize a workflow where each thread explicitly records lecture context, question scope, and verified outcomes.</paragraph></list-item></list></list-item></list><paragraph>This process exemplifies how AI can enhance learning when guided by course scope, topical context, and consistent self-reflection.</paragraph></document>",
            "links": [
                "https://chatgpt.com/g/g-p-68b1f76ecfb8819191ec5b17c4fdd059-cs-182/shared/c/68feaa70-8378-8333-a027-5935fdf14461?owner_user_id=user-AdVlGKTV9Sn7SdTqllGbrt2G"
            ],
            "attachments": [],
            "created_at": "2025-11-04T07:54:01.158912+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7249252,
            "author": "Ben Yu",
            "project_title": "Special Participation E: AI-Enhanced Learning with ChatGPT Project Mode",
            "post_body": "What I built:\nA repeatable workflow that uses ChatGPT project mode as a study copilot across lecture, discussion, and homework -- it summarizes past questions/answers from my chat history into chronological tables and acts like a \u201ccache layer\u201d I can backtrack during reviews.\n\nProject Setup:\n\nPrompt:\n\nYou are my personal TA for UC Berkeley\u2019s EECS 182/282A: Deep Neural Networks, Fall 2025.\nYour job is to help me learn, review, and succeed in this course.\n\nStick to course scope: topics include optimization, convnets, ResNets, GNNs, RNNs, state-space models, transformers, prompting, transfer/meta-learning, generative & diffusion models.\n\nHelp style:\nKeep explanations simple, direct, and intuitive before going deep in math/code.\nUse examples (math, code, visual intuition) tied to the syllabus sequence.\n\nYour primary goals:\nHelp me understand concepts deeply (intuition + formalism).\nHelp me practice effectively (HW, projects, exam prep).\n\n\nProject Files:\n\npdf of course syllabus from https://berkeley-cs182.github.io/fa25/index.html\n\npdf of course textbook\n\nExample of backtracking and knowledge retrieval:\n\nTrace Link: https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce\n\n\nTogether with the project prompt and chat prompt, ChatGPT project mode retrieves my earlier conversation threads (e.g., HW 8 questions like \u201cin unstructured W, why is recurrence faster on CPU?\u201d and \u201cdiagW = torch.diag(W) \u2014 what does it do?\u201d) and composes a factual summary table.\n\nHow classmates can reproduce (bullet list):\n\nCreate a ChatGPT project for EECS 182/282A and paste the prompt above.\n\nTag threads as Hw #, Dis #, Week #; keep each question atomic.\n\nAfter sessions, ask for a chronological project summary with the rule \u201cno invention\u2014mark not recorded when missing.\u201d\n\nWhy it helps:\n\nTurns scattered chats into structured, dated rows for HW/Dis/Week.\n\nMakes past findings searchable (e.g., what you asked 3 weeks ago when you were watching that week's lecture).\n\nReduces review time during finals by providing a durable \u201ccache layer\u201d that complements handwritten notes.\n\nComments:\n\nPositives (What Worked Well):\n\nProvides a systematic and personal way to track conceptual and coding progress across lectures, discussions, and homework.\n\nEnables quick summarization of recurring pain points \u2014 e.g., topics repeatedly causing confusion (like SSM recurrence vs convolution).\n\nWorks as a universal workflow, not just for EECS 182, but adaptable to other classes, research projects, or long-term commitments.\n\nNegatives (Limitations and Effort Required):\n\nRequires manual setup and consistent thread naming (e.g., \u201cHw 1\u201d, \u201cDis 3\u201d), which takes discipline and time.\n\nIf unrelated conversations are accidentally mixed into the project, they can poison the context, causing noisy or misleading summaries.\n\nFuture Improvements:\n\nExplore context condensation techniques \u2014 controlling the length and quality of how AI responds even during normal chat sessions so later reviews are cleaner.\n\nOrganize from the start: define thread templates (e.g., \u201cConcept | Question | Key Takeaway\u201d) to ensure consistent retrievability.\n\nPossibly integrate automated tagging or scripts to rename threads and prevent context contamination.\n\n\n\nOver time, this could evolve into a lightweight personal learning management system --  one that adapts as the AI learns your workflow.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>What I built:</bold><break/>A repeatable workflow that uses ChatGPT project mode as a study copilot across lecture, discussion, and homework -- it summarizes past questions/answers from my chat history into chronological tables and acts like a \u201ccache layer\u201d I can backtrack during reviews.</paragraph><paragraph><bold>Project Setup:</bold></paragraph><list style=\"bullet\"><list-item><paragraph>Prompt:</paragraph></list-item></list><pre>You are my personal TA for UC Berkeley\u2019s EECS 182/282A: Deep Neural Networks, Fall 2025.\nYour job is to help me learn, review, and succeed in this course.\n\nStick to course scope: topics include optimization, convnets, ResNets, GNNs, RNNs, state-space models, transformers, prompting, transfer/meta-learning, generative &amp; diffusion models.\n\nHelp style:\nKeep explanations simple, direct, and intuitive before going deep in math/code.\nUse examples (math, code, visual intuition) tied to the syllabus sequence.\n\nYour primary goals:\nHelp me understand concepts deeply (intuition + formalism).\nHelp me practice effectively (HW, projects, exam prep).\n</pre><list style=\"bullet\"><list-item><paragraph>Project Files:</paragraph></list-item></list><list style=\"number\"><list-item><paragraph>pdf of course syllabus from <link href=\"https://berkeley-cs182.github.io/fa25/index.html\">https://berkeley-cs182.github.io/fa25/index.html</link></paragraph></list-item><list-item><paragraph>pdf of course textbook</paragraph></list-item></list><paragraph><bold>Example of backtracking and knowledge retrieval:</bold></paragraph><paragraph>Trace Link: <link href=\"https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce\">https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce</link></paragraph><paragraph><break/>Together with the project prompt and chat prompt, ChatGPT project mode retrieves my earlier conversation threads (e.g., HW 8 questions like \u201cin unstructured W, why is recurrence faster on CPU?\u201d and \u201cdiagW = torch.diag(W) \u2014 what does it do?\u201d) and composes a factual summary table.</paragraph><paragraph><bold>How classmates can reproduce (bullet list):</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Create a ChatGPT <bold>project</bold> for EECS 182/282A and paste the prompt above.</paragraph></list-item><list-item><paragraph>Tag threads as <bold>Hw #</bold>, <bold>Dis #</bold>, <bold>Week #</bold>; keep each question atomic.</paragraph></list-item><list-item><paragraph>After sessions, ask for a <bold>chronological project summary</bold> with the rule \u201cno invention\u2014mark not recorded when missing.\u201d</paragraph></list-item></list><paragraph><bold>Why it helps:</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Turns scattered chats into structured, dated rows for HW/Dis/Week.</paragraph></list-item><list-item><paragraph>Makes past findings searchable (e.g., what you asked 3 weeks ago when you were watching that week's lecture).</paragraph></list-item><list-item><paragraph>Reduces review time during finals by providing a durable \u201ccache layer\u201d that complements handwritten notes.</paragraph></list-item></list><paragraph><bold>Comments:</bold></paragraph><list style=\"bullet\"><list-item><paragraph><bold>Positives (What Worked Well):</bold></paragraph><list style=\"unordered\"><list-item><paragraph>Provides a <bold>systematic and personal</bold> way to track conceptual and coding progress across lectures, discussions, and homework.</paragraph></list-item><list-item><paragraph>Enables <bold>quick summarization</bold> of recurring pain points \u2014 e.g., topics repeatedly causing confusion (like SSM recurrence vs convolution).</paragraph></list-item><list-item><paragraph>Works as a <bold>universal workflow</bold>, not just for EECS 182, but adaptable to other classes, research projects, or long-term commitments.</paragraph></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Negatives (Limitations and Effort Required):</bold></paragraph></list-item></list><list style=\"unordered\"><list-item><list style=\"unordered\"><list-item><paragraph>Requires <bold>manual setup and consistent thread naming</bold> (e.g., \u201cHw 1\u201d, \u201cDis 3\u201d), which takes discipline and time.</paragraph></list-item><list-item><paragraph>If unrelated conversations are accidentally mixed into the project, they can <bold>poison the context</bold>, causing noisy or misleading summaries.</paragraph></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph><bold>Future Improvements:</bold></paragraph></list-item></list><list style=\"unordered\"><list-item><list style=\"unordered\"><list-item><paragraph>Explore <bold>context condensation techniques</bold> \u2014 controlling the length and quality of how AI responds even during normal chat sessions so later reviews are cleaner.</paragraph></list-item><list-item><paragraph><bold>Organize from the start</bold>: define thread templates (e.g., \u201cConcept | Question | Key Takeaway\u201d) to ensure consistent retrievability.</paragraph></list-item><list-item><paragraph>Possibly integrate <bold>automated tagging</bold> or scripts to rename threads and prevent context contamination.</paragraph></list-item></list></list-item></list><paragraph/><paragraph>Over time, this could evolve into a <bold>lightweight personal learning management system</bold> --  one that adapts as the AI learns your workflow.</paragraph><paragraph/></document>",
            "links": [
                "https://berkeley-cs182.github.io/fa25/index.html",
                "https://chatgpt.com/share/6908ff92-7774-8000-a975-b454a614f6ce"
            ],
            "attachments": [],
            "created_at": "2025-11-04T06:54:39.812496+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7246940,
            "author": "Faiaz Khan",
            "project_title": "Special Participation B: ChatGPT on HW7",
            "post_body": "\nEvaluated ChatGPT\u20115\u2019s code for four HW7 coding tasks: (1) RNN & Gradients, (2) Last\u2011Name Classifier, (3) Autoencoders (vanilla/denoising/masked + viz + linear probe), (4) Graph\u2011Clustering (spectral).\n\nBottom line: Very strong overall. Everything in RNN and Autoencoder sections matches staff intent; the Last\u2011Name Classifier is clean and vectorized. The only material issues are in Graph\u2011Clustering:\n\nAdjacency sign error. Used Aij\u200b=exp(+\u03b3\u2225xi\u200b\u2212xj\u200b\u22252) instead of the standard exp(\u2212\u03b3\u2225xi\u200b\u2212xj\u200b\u22252) with \u03b3>0, inverting similarity and undermining spectral clustering. \n\nDegree\u2011matrix contract. A function named get_degree_matrix returned D\u22121/2 (inverse\u2011sqrt) rather than D; later steps still formed M=D\u22121/2AD\u22121/2 correctly, but the naming conflicts with the prompt/staff text and can confuse follow\u2011ups.\n\nPer\u2011task highlights:\n\nRNN & Gradients.\nRNNLayer uses two linears with a single bias on the input map, explicit unroll, and correct shapes. RecurrentRegressionModel applies a shared readout per timestep. Loss uses MSELoss and supports last_timestep_only. The gradient visualizer scales parameters and inspects the recurrent matrix Whh\u200b (right choice for exploding/vanishing diagnostics).\n\nLast\u2011Name Classifier.\nClean pipeline: Embedding \u2192 RNN/LSTM (batch_first) \u2192 gather last_pos (vectorized) \u2192 Dropout \u2192 Linear logits. Hyperparameters (2\u00d7256 LSTM, dropout 0.30, Adam 3e\u22123, grad\u2011clip 5) are plausible for the \u226580% @20 epochs target. Ethical\u2011use answer is thoughtful (proxy discrimination, surveillance, privacy, overconfidence) and aligned with staff emphasis on responsible deployment.\n\nAutoencoders.\nDecoder is symmetric (no final activation); forward/MSELoss match the objective. Denoising AE adds Gaussian noise and reconstructs the clean input; Masked AE computes masked MSE on unmasked positions only. The evaluation helper encodes features, applies a linear probe, and computes accuracy with no_grad(). The plotting helper produces mean\u2011with\u2011markers + min\u2013max band per epoch as specified. \n\nGraph\u2011Clustering.\nThe spectral pipeline (SVD on M, use U[:,:3]\u200b, row\u2011normalize, then KMeans) is correct and the commentary identifies standard pitfalls (\u03b3 scaling, need for row\u2011norm). However, the RBF sign must be negative and the degree matrix function should either return D (per prompt) or be clearly renamed if returning D\u22121/2. Fixing these yields behavior that matches the staff solution.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/Ce4wVU5MIdQ148mA0fxjScdJ\" filename=\"hw7 code report.pdf\"/><paragraph><break/>Evaluated ChatGPT\u20115\u2019s code for four HW7 coding tasks: (1) <bold>RNN &amp; Gradients</bold>, (2) <bold>Last\u2011Name Classifier</bold>, (3) <bold>Autoencoders</bold> (vanilla/denoising/masked + viz + linear probe), (4) <bold>Graph\u2011Clustering</bold> (spectral).<break/><break/><bold>Bottom line:</bold> <italic>Very strong overall.</italic> Everything in <bold>RNN</bold> and <bold>Autoencoder</bold> sections matches staff intent; the <bold>Last\u2011Name Classifier</bold> is clean and vectorized. The only material issues are in <bold>Graph\u2011Clustering</bold>:</paragraph><paragraph><bold>Adjacency sign error.</bold> Used Aij\u200b=exp(+\u03b3\u2225xi\u200b\u2212xj\u200b\u22252) instead of the standard <bold>exp(\u2212\u03b3\u2225xi\u200b\u2212xj\u200b\u22252)</bold> with \u03b3&gt;0, inverting similarity and undermining spectral clustering. </paragraph><paragraph><bold>Degree\u2011matrix contract.</bold> A function named <code>get_degree_matrix</code> returned D\u22121/2 (inverse\u2011sqrt) rather than D; later steps still formed M=D\u22121/2AD\u22121/2 correctly, but the naming conflicts with the prompt/staff text and can confuse follow\u2011ups.</paragraph><paragraph><bold>Per\u2011task highlights:</bold></paragraph><paragraph><bold>RNN &amp; Gradients.</bold><break/><italic>RNNLayer</italic> uses two linears with a single bias on the input map, explicit unroll, and correct shapes. <italic>RecurrentRegressionModel</italic> applies a shared readout per timestep. Loss uses <code>MSELoss</code> and supports <code>last_timestep_only</code>. The gradient visualizer scales parameters and inspects the <bold>recurrent</bold> matrix Whh\u200b (right choice for exploding/vanishing diagnostics).</paragraph><paragraph><bold>Last\u2011Name Classifier.</bold><break/>Clean pipeline: <code>Embedding \u2192 RNN/LSTM (batch_first) \u2192 gather last_pos (vectorized) \u2192 Dropout \u2192 Linear logits</code>. Hyperparameters (2\u00d7256 LSTM, dropout 0.30, Adam 3e\u22123, grad\u2011clip 5) are plausible for the <bold>\u226580% @20 epochs</bold> target. Ethical\u2011use answer is thoughtful (proxy discrimination, surveillance, privacy, overconfidence) and aligned with staff emphasis on responsible deployment.</paragraph><paragraph><bold>Autoencoders.</bold><break/>Decoder is symmetric (no final activation); forward/<code>MSELoss</code> match the objective. Denoising AE adds Gaussian noise and reconstructs the clean input; Masked AE computes <bold>masked</bold> MSE on unmasked positions only. The evaluation helper encodes features, applies a linear probe, and computes accuracy with <code>no_grad()</code>. The plotting helper produces <bold>mean\u2011with\u2011markers + min\u2013max band</bold> per epoch as specified. </paragraph><paragraph><bold>Graph\u2011Clustering.</bold><break/>The spectral pipeline (SVD on M, use U[:,:3]\u200b, <bold>row\u2011normalize</bold>, then KMeans) is correct and the commentary identifies standard pitfalls (\u03b3 scaling, need for row\u2011norm). However, the <bold>RBF sign</bold> must be <bold>negative</bold> and the <bold>degree matrix</bold> function should either return D (per prompt) or be clearly renamed if returning D\u22121/2. Fixing these yields behavior that matches the staff solution.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T19:51:09.010159+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7246769,
            "author": "Faiaz Khan",
            "project_title": "Special Participation A: ChatGPT on HW7",
            "post_body": "I evaluated ChatGPT\u20115's capabilities for HW7 non\u2011coding parts: 3(b), 4, 7, 8, using the hw7 questions and staff\u2011solutions as ground truth.\n\nBottom line. ChatGPT\u20115\u2019s answers are correct. \n\nPer\u2011problem highlights.\n\n3(b) PCA & linear autoencoders. Derived the first\u2011order conditions exactly as in the key\u2014\u2207W2\u200b\u200bL=2(W2\u200bW1\u200b\u2212I)XX\u22a4W1\u22a4\u200b, \u2207W1\u200b\u200bL=2W2\u22a4\u200b(W2\u200bW1\u200b\u2212I)XX\u22a4\u2014and correctly verified that W2\u200b=Uk\u200b,W1\u200b=Uk\u22a4\u200b satisfies them. Verdict: correct. \n\n4 \u201cHow to train your ResNet.\u201d Reported 341 s to 94% baseline and 26 s to \u224894.1% final; reflections (b, c) are on\u2011point (data\u2011pipeline bottlenecks, batch size/LR scaling, BN precision, \u201ccatastrophic forgetting\u201d vs curvature). Verdict: correct (with extra but accurate context). \n\n7 Machine translation. (a) Correctly explains why \u201cvertical stacking\u201d is flawed (breaks variable\u2011length handling and global conditioning). (b) Teacher forcing tokens enumerated explicitly: <SOS>, I, see, a, dog. (c) Evaluation: <SOS>, then model\u2019s outputs (I, saw, a, dog). Verdict: correct. \n\n8 Self\u2011supervised linear AEs. (a) Exactly matches the objective: two Linear layers (encoder/decoder), MSELoss, SGD + weight decay; no Dropout/LN/BN. (b) Clear SVD argument that the \u03bb\u2011regularized optimum favors orthonormal columns in W2\u200b (minimizing \u03c32+1/\u03c32 at \u03c3=1). Verdict: correct. \n\nOverall assessment. The model\u2019s responses align with the staff solutions in substance and notation, with small stylistic differences only.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/xqH8GOFhYN8jRo0XPr3JoAjU\" filename=\"hw7 report.pdf\"/><paragraph>I evaluated ChatGPT\u20115's capabilities for HW7 <bold>non\u2011coding</bold> parts: <bold>3(b), 4, 7, 8</bold>, using the hw7 questions and staff\u2011solutions as ground truth.</paragraph><paragraph><bold>Bottom line.</bold> ChatGPT\u20115\u2019s answers are <bold>correct</bold>. </paragraph><paragraph><bold>Per\u2011problem highlights.</bold></paragraph><paragraph><bold>3(b) PCA &amp; linear autoencoders.</bold> Derived the <bold>first\u2011order conditions</bold> exactly as in the key\u2014\u2207W2\u200b\u200bL=2(W2\u200bW1\u200b\u2212I)XX\u22a4W1\u22a4\u200b, \u2207W1\u200b\u200bL=2W2\u22a4\u200b(W2\u200bW1\u200b\u2212I)XX\u22a4\u2014and correctly verified that W2\u200b=Uk\u200b,W1\u200b=Uk\u22a4\u200b satisfies them. <bold>Verdict: correct.</bold> </paragraph><paragraph><bold>4 \u201cHow to train your ResNet.\u201d</bold> Reported <bold>341 s to 94%</bold> baseline and <bold>26 s to \u224894.1%</bold> final; reflections (b, c) are on\u2011point (data\u2011pipeline bottlenecks, batch size/LR scaling, BN precision, \u201ccatastrophic forgetting\u201d vs curvature). <bold>Verdict: correct (with extra but accurate context).</bold> </paragraph><paragraph><bold>7 Machine translation.</bold> (a) Correctly explains why \u201cvertical stacking\u201d is flawed (breaks variable\u2011length handling and global conditioning). (b) <bold>Teacher forcing</bold> tokens enumerated explicitly: &lt;SOS&gt;, I, see, a, dog. (c) <bold>Evaluation</bold>: &lt;SOS&gt;, then model\u2019s outputs (I, saw, a, dog). <bold>Verdict: correct.</bold> </paragraph><paragraph><bold>8 Self\u2011supervised linear AEs.</bold> (a) Exactly matches the objective: <bold>two Linear</bold> layers (encoder/decoder), <bold>MSELoss</bold>, <bold>SGD + weight decay</bold>; no Dropout/LN/BN. (b) Clear SVD argument that the \u03bb\u2011regularized optimum favors <bold>orthonormal columns</bold> in W2\u200b (minimizing \u03c32+1/\u03c32 at \u03c3=1). <bold>Verdict: correct.</bold> </paragraph><paragraph><bold>Overall assessment.</bold> The model\u2019s responses align with the staff solutions in substance and notation, with small stylistic differences only.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T18:16:17.084933+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7244375,
            "author": "Ruizhe Song",
            "project_title": "Special Participation A: Gemini 2.5 Flash on HW2",
            "post_body": "I interactively engaged Gemini 2.5 Flash on the non-coding parts of Homework 2. Overall, the model was able to arrive at the correct answers in most cases, though several notable issues were observed.\n\nStrategies: I first clarified the main role that Gemini was expected to perform and illustrated the evaluation rubrics for its answers. Then, I do the following steps:\n\nStep 1: Provide Gemini with one homework problem.\n\nStep 2: Collect its initial (one-shot) answer.\n\nStep 3: If the answer was incorrect, provide hints to guide Gemini to fix the original answer, and repeat until the response was correct or it seems to have no chance of fixing it.\n\nStep 4: Repeat Steps 1\u20133 for all homework problems.\n\nNotable observations and flaws. Although Gemini was able to correctly solve most of the questions in the first answer, it occasionally made logical or mathematical errors that led to incorrect final answers, even when the reasoning process is flawless. In some cases, the model relied on specific examples provided in the prompt, which resulted in partially correct answers. Additionally, Gemini sometimes produced wrong-formed LaTeX code, making its output less readable. This issue may have been partly influenced by the formatting of the input prompts.\n\nHere's the full interaction log with my notations and comments, highlighting notable phenomenons happens in Gemini's answer:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I interactively engaged <bold>Gemini 2.5 Flash</bold> on the non-coding parts of <bold>Homework 2</bold>. Overall, the model was able to arrive at the correct answers in most cases, though several notable issues were observed.</paragraph><paragraph><bold>Strategies:</bold> I first clarified the main role that Gemini was expected to perform and illustrated the evaluation rubrics for its answers. Then, I do the following steps:</paragraph><list style=\"ordered\"><list-item><paragraph><bold>Step 1:</bold> Provide Gemini with one homework problem.</paragraph></list-item><list-item><paragraph><bold>Step 2:</bold> Collect its initial (one-shot) answer.</paragraph></list-item><list-item><paragraph><bold>Step 3:</bold> If the answer was incorrect, provide hints to guide Gemini to fix the original answer, and repeat until the response was correct or it seems to have no chance of fixing it.</paragraph></list-item><list-item><paragraph><bold>Step 4:</bold> Repeat Steps 1\u20133 for all homework problems.</paragraph></list-item></list><paragraph><bold>Notable observations and flaws.</bold> Although Gemini was able to correctly solve most of the questions in the first answer, it occasionally made logical or mathematical errors that led to incorrect final answers, even when the reasoning process is flawless. In some cases, the model relied on specific examples provided in the prompt, which resulted in partially correct answers. Additionally, Gemini sometimes produced wrong-formed LaTeX code, making its output less readable. This issue may have been partly influenced by the formatting of the input prompts.</paragraph><paragraph>Here's the full interaction log with my notations and comments, highlighting notable phenomenons happens in Gemini's answer:<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/CQUsmoky6zcUUGfK2S2a9SwE\" filename=\"Special_Participation_A.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T10:24:52.673823+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7243310,
            "author": "Yuxiang Liu",
            "project_title": "Special Participation A: HW5 With the Help of Claude AI",
            "post_body": "Hi, I just made a script documenting how I guided Claude AI to walk through homework 5. I have to acknowledge that Claude AI is a very powerful tool that can help us walk through the homework. I rarely see any hallucinations or misconceptions. Most of the arguments it made are consistent with the right solution especially when the questions are fairly straightforward. However, when it is asked to derive something that requires many intermediate steps, it will sometimes fail to recognize the most obvious thing to do at some point. That is to say, for long-horizon tasks, it tends to make its solutions more complex even though such complex reasoning is not ideal. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi, I just made a script documenting how I guided Claude AI to walk through homework 5. I have to acknowledge that Claude AI is a very powerful tool that can help us walk through the homework. I rarely see any hallucinations or misconceptions. Most of the arguments it made are consistent with the right solution especially when the questions are fairly straightforward. However, when it is asked to derive something that requires many intermediate steps, it will sometimes fail to recognize the most obvious thing to do at some point. That is to say, for long-horizon tasks, it tends to make its solutions more complex even though such complex reasoning is not ideal. </paragraph><file url=\"https://static.us.edusercontent.com/files/ZhphxxyAj2pRBLq6a5p1tqPg\" filename=\"HW5_walkthrough.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T07:26:53.861759+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7242208,
            "author": "Sultan Daniels",
            "project_title": "HW9 Q6: Kernelized Linear Attention (Part 1)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/lJAtk3sNnUUMGxUXHxP4Leng\" width=\"476\" height=\"1358\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T03:32:33.815475+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7242203,
            "author": "Sultan Daniels",
            "project_title": "HW9 Q5: Coding Question: Visualizing Attention",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/21D0Lcba60QCOKU4hwxA3DWg\" width=\"658\" height=\"899.4827586206897\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T03:31:37.446507+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7242199,
            "author": "Sultan Daniels",
            "project_title": "HW9 Q4: Transformer Decoding Optimization",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/IIfmcOWBAncmGoGcnKO9oRxW\" width=\"462\" height=\"1547\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T03:30:27.91135+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7242190,
            "author": "Sultan Daniels",
            "project_title": "HW9 Q3: Ordinary Softmax Multihead Attention Implementation",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/F8JmNchwPy28TvZzI15BUKYv\" width=\"570\" height=\"1342\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T03:29:07.493885+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7242181,
            "author": "Sultan Daniels",
            "project_title": "HW9 Q2: Argmax Attention",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/dPK7K1vJyIXLHcddS06twgDI\" width=\"658\" height=\"762.9150779896013\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T03:27:33.285393+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7242178,
            "author": "Sultan Daniels",
            "project_title": "HW9 Q1: Justifying Scaled Dot Product Attention",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/Wg8b4HOhTLKKsWb7vgcLeThm\" width=\"658\" height=\"195.4238042269188\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-03T03:26:52.480594+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7240163,
            "author": "Andy Zhang",
            "project_title": "Special Participation E: Quiz and Flash Cards for Adam / SGD",
            "post_body": "Special Participation E: Quiz and Flash Cards for Adam / SGD\n\nFor background, Gemini claims that they can create quizzes, flash cards & study guides according to https://support.google.com/gemini/answer/16275879?hl=en&co=GENIE.Platform%3DAndroid\n\nEspecially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.\n\nWhile the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.\n\nFrom there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one\u2019s presences, the model can be steered to act accordingly. \n\nMy recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.\n\n\n\nTraces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing\n\n\n\nIndividual traces:\n\nUndetailed Prompt Trace Flash Cards:\n\nhttps://gemini.google.com/share/ed66de185158\n\nUndetailed Prompt Trace Quiz:\n\nhttps://gemini.google.com/share/598e4b5cfbcc\n\nUndetailed Flash Cards:\n\nhttps://gemini.google.com/share/cfd44ed946d6\n\nUndetailed Quiz:\n\nhttps://gemini.google.com/share/6fab8238136e\n\n\n\nFlash cards / quizzes:\n\nDetailed Prompt Trace for Flash Cards with Math:\n\nhttps://gemini.google.com/share/f7957da6c0d1\n\nDetailed Prompt Trace for Quiz:\n\nhttps://gemini.google.com/share/ec87b322ca7e\n\nDetailed Flash Cards: https://gemini.google.com/share/6afed4acff7b\n\nDetailed Quiz: https://gemini.google.com/share/01910a14266a",
            "content_xml": "<document version=\"2.0\"><paragraph>Special Participation E: Quiz and Flash Cards for Adam / SGD</paragraph><paragraph>For background, Gemini claims that they can create quizzes, flash cards &amp; study guides according to <link href=\"https://support.google.com/gemini/answer/16275879?hl=en&amp;co=GENIE.Platform%3DAndroid\">https://support.google.com/gemini/answer/16275879?hl=en&amp;co=GENIE.Platform%3DAndroid</link></paragraph><paragraph>Especially since Gemini Pro is free for Berkeley students, I first explored and confirmed that Gemini could indeed create those; it created specific and specialized artifacts for only Quizzes and Flash Cards (and you need to be careful about language) which made it more convenient than text.</paragraph><paragraph>While the initial the quiz and flash cards were reasonable, they are generally conceptual (e.g. the purpose of the first and second moments of Adam, the purpose of hyperparameters etc.) so I wanted to explore whether the quizzes and flash cards could be more mathematical and cover more rigor similar to our course and see whether latex could properly render in the quiz and flash cards.</paragraph><paragraph>From there I was able to develop an improved prompt to have more mathematics to be more aligned with our course, formatted properly in latex. And depending on one\u2019s presences, the model can be steered to act accordingly. </paragraph><paragraph>My recommendation is that these could be helpful to students to review concepts such as Adam and SGD especially after several weeks have passed before the final. My recommended order is to go through the flash cards for a memory refresher and then take the quiz to ensure the concepts are cemented.</paragraph><paragraph/><paragraph>Traces with detailed comments: https://drive.google.com/file/d/1X6M9JPHW4GRSUKRFckDdFsxYcfWyB-97/view?usp=sharing</paragraph><paragraph/><paragraph>Individual traces:</paragraph><paragraph>Undetailed Prompt Trace Flash Cards:</paragraph><paragraph><link href=\"https://gemini.google.com/share/ed66de185158\">https://gemini.google.com/share/ed66de185158</link></paragraph><paragraph>Undetailed Prompt Trace Quiz:</paragraph><paragraph><link href=\"https://gemini.google.com/share/598e4b5cfbcc\">https://gemini.google.com/share/598e4b5cfbcc</link></paragraph><paragraph>Undetailed Flash Cards:</paragraph><paragraph><link href=\"https://gemini.google.com/share/cfd44ed946d6\">https://gemini.google.com/share/cfd44ed946d6</link></paragraph><paragraph>Undetailed Quiz:</paragraph><paragraph><link href=\"https://gemini.google.com/share/6fab8238136e\">https://gemini.google.com/share/6fab8238136e</link></paragraph><paragraph/><paragraph>Flash cards / quizzes:</paragraph><paragraph>Detailed Prompt Trace for Flash Cards with Math:</paragraph><paragraph><link href=\"https://gemini.google.com/share/f7957da6c0d1\">https://gemini.google.com/share/f7957da6c0d1</link></paragraph><paragraph>Detailed Prompt Trace for Quiz:</paragraph><paragraph><link href=\"https://gemini.google.com/share/ec87b322ca7e\">https://gemini.google.com/share/ec87b322ca7e</link></paragraph><paragraph>Detailed Flash Cards: <link href=\"https://gemini.google.com/share/6afed4acff7b\">https://gemini.google.com/share/6afed4acff7b</link></paragraph><paragraph>Detailed Quiz: <link href=\"https://gemini.google.com/share/01910a14266a\">https://gemini.google.com/share/01910a14266a</link></paragraph></document>",
            "links": [
                "https://support.google.com/gemini/answer/16275879?hl=en&amp;co=GENIE.Platform%3DAndroid",
                "https://gemini.google.com/share/ed66de185158",
                "https://gemini.google.com/share/598e4b5cfbcc",
                "https://gemini.google.com/share/cfd44ed946d6",
                "https://gemini.google.com/share/6fab8238136e",
                "https://gemini.google.com/share/f7957da6c0d1",
                "https://gemini.google.com/share/ec87b322ca7e",
                "https://gemini.google.com/share/6afed4acff7b",
                "https://gemini.google.com/share/01910a14266a"
            ],
            "attachments": [],
            "created_at": "2025-11-02T10:39:47.878068+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7236085,
            "author": "Ender Ji",
            "project_title": "Special Participation B: HW0 with Grok",
            "post_body": "I used Grok to complete the coding portion of HW0, the first assignment of the semester. I begin by clearly stating Grok\u2019s role and the assistance I require, then provide all relevant files and ask it to review and understand them.\n\nFor the coding section, I consistently supply the empty (starter) script to Grok for an initial pass, then move to a specific function and ask it to implement a solution. I repeat this pipeline for all coding problems.\n\nGrok performed very well on the coding tasks; it typically produces a correct solution on the first attempt and provides clear explanations of the variables and ideas it uses. I believe one reason is that the implemented functions in HW0 are relatively straightforward and standard compared to other assignments. However, for the final part of the notebook, where I ask it to propose a valid weight_scale and learning_rate, because it lacks access to data, Grok can only suggest reasonable parameters to try, with no guarantee of solving the problem on the first attempt.\n\nOverall, Grok demonstrated strong performance on the coding portion of HW0.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/fXXi8cPu0HhKrfQjZMf6OTyo\" filename=\"grok_hw0.pdf\"/><paragraph>I used Grok to complete the coding portion of HW0, the first assignment of the semester. I begin by clearly stating Grok\u2019s role and the assistance I require, then provide all relevant files and ask it to review and understand them.</paragraph><paragraph>For the coding section, I consistently supply the empty (starter) script to Grok for an initial pass, then move to a specific function and ask it to implement a solution. I repeat this pipeline for all coding problems.</paragraph><paragraph>Grok performed very well on the coding tasks; it typically produces a correct solution on the first attempt and provides clear explanations of the variables and ideas it uses. I believe one reason is that the implemented functions in HW0 are relatively straightforward and standard compared to other assignments. However, for the final part of the notebook, where I ask it to propose a valid weight_scale and learning_rate, because it lacks access to data, Grok can only suggest reasonable parameters to try, with no guarantee of solving the problem on the first attempt.</paragraph><paragraph>Overall, Grok demonstrated strong performance on the coding portion of HW0.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-01T08:29:46.961354+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7235411,
            "author": "Anant Sahai",
            "project_title": "Emergency pre-proposal office hours 2-3:30pm today",
            "post_body": "Hello,\n\nIt has come to our attention that a few groups were unable to find slots this week because they tried looking after many slots had already passed. So we are adding some emergency office hours today from 2-3:30pm on a drop in basis in my office: 267 Cory. (Come in through 253 Cory)",
            "content_xml": "<document version=\"1.0\"><paragraph>Hello,</paragraph><paragraph>It has come to our attention that a few groups were unable to find slots this week because they tried looking after many slots had already passed. So we are adding some emergency office hours today from 2-3:30pm on a drop in basis in my office: 267 Cory. (Come in through 253 Cory)</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-11-01T06:39:06.173706+11:00",
            "category": "Project"
        },
        {
            "guid": 7231275,
            "author": "Aryan Panda",
            "project_title": "\ud83d\udce2 Looking for 1 More Project (thread 3) Partner (Mechanistic Interpretability + Robotics!)",
            "post_body": "Hey everyone!\n\nWe\u2019re currently a team of 2 EECS undergrads + 1 Master\u2019s student working on a project in mechanistic interpretability \u2014 exploring how mechanical decisions emerge and can be analyzed within robotic automation.\n\nWe\u2019re excited to dive deeper into the intersection of Mechanistic Interpretability (proj. 3)\n\nWe\u2019re looking for one more teammate who\u2019s excited about interpretability, VPAs, or just understanding how AI \u201cthinks.\u201d \n\nIf that sounds like you, message me \u2014 we\u2019d love to have you join our team!",
            "content_xml": "<document version=\"2.0\"><paragraph>Hey everyone!</paragraph><paragraph>We\u2019re currently a team of 2 <bold>EECS undergrads + 1 Master\u2019s student</bold> working on a project in <bold>mechanistic interpretability</bold> \u2014 exploring how mechanical decisions emerge and can be analyzed within robotic automation.</paragraph><paragraph>We\u2019re excited to dive deeper into the intersection of Mechanistic <bold>Interpretability (proj. 3)</bold></paragraph><paragraph>We\u2019re looking for <bold>one more teammate</bold> who\u2019s excited about interpretability, VPAs, or just understanding how AI \u201cthinks.\u201d <break/><break/>If that sounds like you, message me \u2014 we\u2019d love to have you join our team!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-31T09:52:20.600793+11:00",
            "category": "Project"
        },
        {
            "guid": 7227705,
            "author": "Tianhao Qian",
            "project_title": "Special Participation C: Refactoring of HW2 task 3",
            "post_body": "Summary:\n\nThrough this refactoring, the project evolved from a single-use notebook into a maintainable machine learning codebase.\n\n\n\n| Dimension | Before Refactoring | After Refactoring | \n\n| --------------- | ------------------ | ---------------------- | \n\n| Structure | Flat Jupyter cells | Modular Python modules | \n\n| Reproducibility | Manual seeds | Centralized config | \n\n| Logging | `print()` | Structured logger | \n\n| Experimentation | Manual | Configurable sweeps | \n\n| Maintainability | Low | High |\n\n\n\nThis structure now supports both educational transparency and engineering rigor, serving as a clean baseline for future deep learning experiments.\n\nGithub repo: \n\nhysteri1a/-EECS182-Refactoring-Report-HW3\n\nReport:\n\nDone by Lawrence Qian(3041996584)",
            "content_xml": "<document version=\"2.0\"><paragraph>Summary:</paragraph><paragraph>Through this refactoring, the project evolved from a single-use notebook into a maintainable machine learning codebase.</paragraph><paragraph/><paragraph>| Dimension | Before Refactoring | After Refactoring | </paragraph><paragraph>| --------------- | ------------------ | ---------------------- | </paragraph><paragraph>| Structure | Flat Jupyter cells | Modular Python modules | </paragraph><paragraph>| Reproducibility | Manual seeds | Centralized config | </paragraph><paragraph>| Logging | `print()` | Structured logger | </paragraph><paragraph>| Experimentation | Manual | Configurable sweeps | </paragraph><paragraph>| Maintainability | Low | High |</paragraph><paragraph/><paragraph>This structure now supports both educational transparency and engineering rigor, serving as a clean baseline for future deep learning experiments.</paragraph><paragraph>Github repo: </paragraph><paragraph><link href=\"https://github.com/hysteri1a/-EECS182-Refactoring-Report-HW3\">hysteri1a/-EECS182-Refactoring-Report-HW3</link><break/><break/>Report:</paragraph><file url=\"https://static.us.edusercontent.com/files/wPlDrJN5jdVy6foFZlRs2rC8\" filename=\"EECS_participation_C.pdf\"/><paragraph>Done by Lawrence Qian(3041996584)</paragraph></document>",
            "links": [
                "https://github.com/hysteri1a/-EECS182-Refactoring-Report-HW3"
            ],
            "attachments": [],
            "created_at": "2025-10-30T18:23:28.716223+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7227387,
            "author": "Zhuangzhe Wu",
            "project_title": "Special Participation A: Deepseek Chat on HW3",
            "post_body": "Conclusion:\n\nThe evaluation of DeepSeek's capabilities for homework 3 has demonstrated :\n\nStrong Mathematical Problem-Solving: DeepSeek reliably handles the mathematical problems, including linear algebra & calculus & probability , providing both solutions and clear, step-by-step explanations. Both the calculation and proof problems were well done. It can retrieve and understand the formulas from papers and analyze them well.\n\nEffective Information Retrieval and Synthesis: A key strength is its ability to process academic papers, accurately identify core arguments and results, and summarize them concisely, demonstrating strong comprehension and distillation skills.\n\nDeepSeek's integration of these capabilities makes it a remarkably efficient for navigating the challenges of advanced math & algorithm & deep learning studies.\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/yKIpKIoETd80ZmgZoR0qAm1j\" filename=\"deepseek_hw3_log.pdf\"/><paragraph><bold>Conclusion:</bold></paragraph><paragraph>The evaluation of DeepSeek's capabilities for homework 3 has demonstrated :</paragraph><list style=\"unordered\"><list-item><paragraph><bold>Strong Mathematical Problem-Solving:</bold> DeepSeek reliably handles the mathematical problems, including linear algebra &amp; calculus &amp; probability , providing both solutions and clear, step-by-step explanations. Both the calculation and proof problems were well done. It can retrieve and understand the formulas from papers and analyze them well.</paragraph></list-item><list-item><paragraph><bold>Effective Information Retrieval and Synthesis:</bold> A key strength is its ability to process academic papers, accurately identify core arguments and results, and summarize them concisely, demonstrating strong comprehension and distillation skills.</paragraph></list-item></list><paragraph>DeepSeek's integration of these capabilities makes it a remarkably efficient for navigating the challenges of advanced math &amp; algorithm &amp; deep learning studies.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-30T16:12:13.694906+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7227336,
            "author": "Anders Vestrum",
            "project_title": "Special Participation E: How I used Google NotebookLM to understand SSM",
            "post_body": "Special Participation E (Google NotebookLM) - RNNs and SSMs\n\nI used Google NotebookLM as a guided tutor to study the relationship between State-Space Models (SSMs) and Recurrent Neural Networks (RNNs), using EECS 182 materials and the S4 paper. Through its Learning Guide mode, the system\u2019s questions helped me understand how SSMs convert sequential recurrence into FFT-based convolution and how diagonalization combined with the Woodbury Matrix Identity makes the S4 model both efficient and stable. I noted one factual correction: the chatbot listed the FFT cost as O(N\u00b7L log L), but standard FFT convolution parallelizes across time, giving O(L log L) instead. The session also introduced Ridge-Attention, illustrating how it reframes self-attention from a probabilistic softmax view to a linear-algebraic one.\n\nNotebookLM link (video, mind map, quiz, and flashcards in this link: https://notebooklm.google.com/notebook/1da24f39-d172-4725-a38c-5f6366e8ac95",
            "content_xml": "<document version=\"2.0\"><paragraph>Special Participation E (Google NotebookLM) - RNNs and SSMs</paragraph><paragraph>I used Google NotebookLM as a guided tutor to study the relationship between State-Space Models (SSMs) and Recurrent Neural Networks (RNNs), using EECS 182 materials and the S4 paper. Through its Learning Guide mode, the system\u2019s questions helped me understand how SSMs convert sequential recurrence into FFT-based convolution and how diagonalization combined with the Woodbury Matrix Identity makes the S4 model both efficient and stable. I noted one factual correction: the chatbot listed the FFT cost as O(N\u00b7L log L), but standard FFT convolution parallelizes across time, giving O(L log L) instead. The session also introduced Ridge-Attention, illustrating how it reframes self-attention from a probabilistic softmax view to a linear-algebraic one.</paragraph><file url=\"https://static.us.edusercontent.com/files/bDTJCfOluen1y8BEHkKwa2Ee\" filename=\"spE_notebookLM_RNN_SSM.pdf\"/><paragraph>NotebookLM link (video, mind map, quiz, and flashcards in this link: https://notebooklm.google.com/notebook/1da24f39-d172-4725-a38c-5f6366e8ac95</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-30T15:55:36.861101+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7226711,
            "author": "Sultan Daniels",
            "project_title": "HW07 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/8IeWVQUwFLfY7Dx0Wdz5pl0M\" filename=\"hw07codesolution.zip\"/><file url=\"https://static.us.edusercontent.com/files/2aSoZhCoU0diMNeuWGGEfnrt\" filename=\"hw07_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/N7V2aaEfvlufyXlt8pXkhJSc\" filename=\"hw07_question.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-30T13:50:22.967662+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7226661,
            "author": "Noah Lund Syrdal",
            "project_title": "Special participation E: Create a custom version of chatGPT,  \u03bcP & Modern Optimizers Coach",
            "post_body": "Link: \u03bcP & Modern Optimizers Coach\n\nPdf: \n\nExtensive summary:\n\nThis custom GPT acts as an interactive study companion for \u03bcP scaling, RMSNorm, and modern optimizers.\nIt\u2019s a great way to ask questions about concepts you don\u2019t fully understand. I\u2019ve stress-tested it on common misconceptions about \u03bcP invariance, and it consistently provided nuanced, well-grounded answers (tried to get a wrong answer out of it, didn\u2019t manage).\n\nYou can use my version directly, or follow the steps in the PDF to create your own tailored model on a different concept.\nIt works well both as a pre-lecture active reading tool and a post-lecture review partner; you can even talk with it out loud while learning.\n\nI would strongly recommend this approach for anyone in the course. I\u2019ll be creating similar custom GPTs for other core concepts in 182/282 and eventually one that covers the entire course, to explore how well it can guide learning across all modules.",
            "content_xml": "<document version=\"2.0\"><paragraph>Link<bold>:</bold> <link href=\"https://chatgpt.com/g/g-68f2b5f669148191915a03ef03fc69d6-mp-modern-optimizers-coach-eecs182-282\"><underline>\u03bcP &amp; Modern Optimizers Coach</underline></link></paragraph><paragraph>Pdf: </paragraph><file url=\"https://static.us.edusercontent.com/files/AB1TpLpivYeHk0yo44YDkb3m\" filename=\"Special_Participation_E-3.pdf\"/><paragraph>Extensive summary:</paragraph><paragraph>This custom GPT acts as an interactive study companion for \u03bcP scaling, RMSNorm, and modern optimizers.<break/>It\u2019s a great way to ask questions about concepts you don\u2019t fully understand. I\u2019ve stress-tested it on common misconceptions about \u03bcP invariance, and it consistently provided nuanced, well-grounded answers (tried to get a wrong answer out of it, didn\u2019t manage).</paragraph><paragraph>You can use my version directly, or follow the steps in the PDF to create your own tailored model on a different concept.<break/>It works well both as a pre-lecture active reading tool and a post-lecture review partner; you can even talk with it out loud while learning.</paragraph><paragraph>I would strongly recommend this approach for anyone in the course. I\u2019ll be creating similar custom GPTs for other core concepts in 182/282 and eventually one that covers the entire course, to explore how well it can guide learning across all modules.</paragraph></document>",
            "links": [
                "https://chatgpt.com/g/g-68f2b5f669148191915a03ef03fc69d6-mp-modern-optimizers-coach-eecs182-282"
            ],
            "attachments": [],
            "created_at": "2025-10-30T13:40:12.723427+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7220991,
            "author": "Junya Tsuneishi",
            "project_title": "Special Participation B: ChatGPT on HW1",
            "post_body": "I used ChatGPT on HW1 cording parts(Special Participation B). \nI posted the results, my findings about them, and my summary on the attached pdf. This is summary from the pdf.\n\nOne-Shot Capability: ChatGPT's one-shot performance was mixed.\n\nTODO 1: ChatGPT successfully implemented the logic for the exponential moving average of the gradient in one shot. Its implementation was a valid, standard implementation, although it differed from the class style. This is a valid ambiguity, as both are correct definitions, just with beta and 1-beta flipped.\n\nTODO2 : ChatGPT failed to solve this task on its first attempt. ChatGPT exhibited two distinct types of errors on the second TODO, requiring two rounds of interactive correction.\n\nSemantic Misinterpretation: The notebook prompt asks to \"further accelerate\" the faster method (GDM). ChatGPT misinterpreted this and instead modified the slower method (GD) to see if it could \"catch up.\" This was a fundamental failure to understand the problem's intent.\n\nContextual Blindness: After the first hint, ChatGPT correctly identified which algorithm to modify (GDM) but introduced new variable names (grads_m_fast, losses_m_fast). The code block is logically correct in isolation, but it fails to consider the notebook's state, as subsequent plotting cells relied on the original variable names (grads_m, losses_m), which would have caused the notebook to crash or plot incorrectly.\n\nConclusion: ChatGPT was effective at writing a self-contained algorithm block (TODO 1). However, it struggled significantly with a task that required contextual understanding of the problem's intent and the notebook's state (TODO 2). It required a human to act as a \"debugger,\" providing specific, iterative hints to correct both its logical and contextual errors.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/jUdl7UZKBDsMtebjyUpP8yel\" filename=\"Special Participation B ChatGPT on HW1.pdf\"/><paragraph>I used ChatGPT on HW1 cording parts(Special Participation B). <break/>I posted the results, my findings about them, and my summary on the attached pdf. This is summary from the pdf.</paragraph><list style=\"bullet\"><list-item><paragraph>One-Shot Capability: ChatGPT's one-shot performance was mixed.</paragraph></list-item></list><list style=\"bullet\"><list-item><list style=\"unordered\"><list-item><paragraph>TODO 1: ChatGPT successfully implemented the logic for the exponential moving average of the gradient in one shot. Its implementation was a valid, standard implementation, although it differed from the class style. This is a valid ambiguity, as both are correct definitions, just with beta and 1-beta flipped.</paragraph></list-item><list-item><paragraph>TODO2 : ChatGPT failed to solve this task on its first attempt. ChatGPT exhibited two distinct types of errors on the second TODO, requiring two rounds of interactive correction.</paragraph></list-item></list></list-item></list><list style=\"ordered\"><list-item><list style=\"ordered\"><list-item><list style=\"ordered\"><list-item><paragraph>Semantic Misinterpretation: The notebook prompt asks to \"further accelerate\" the faster method (GDM). ChatGPT misinterpreted this and instead modified the slower method (GD) to see if it could \"catch up.\" This was a fundamental failure to understand the problem's intent.</paragraph></list-item><list-item><paragraph>Contextual Blindness: After the first hint, ChatGPT correctly identified which algorithm to modify (GDM) but introduced new variable names (grads_m_fast, losses_m_fast). The code block is logically correct in isolation, but it fails to consider the notebook's state, as subsequent plotting cells relied on the original variable names (grads_m, losses_m), which would have caused the notebook to crash or plot incorrectly.</paragraph></list-item></list></list-item></list></list-item></list><list style=\"bullet\"><list-item><paragraph>Conclusion: ChatGPT was effective at writing a self-contained algorithm block (TODO 1). However, it struggled significantly with a task that required contextual understanding of the problem's intent and the notebook's state (TODO 2). It required a human to act as a \"debugger,\" providing specific, iterative hints to correct both its logical and contextual errors.</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-29T15:01:20.304451+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7219478,
            "author": "Junya Tsuneishi",
            "project_title": "Special Participation A: ChatGPT on HW1",
            "post_body": "I used ChatGPT on HW1 no-cording parts(Special Participation A).\nI posted the results, my findings about them, and my summary on the attached pdf.\n\nThis is summary from the pdf.\nOverall, ChatGPT achieved fully correct answers for all problems, demonstrating strong mathematical reasoning and consistency across sequential tasks. However, the interaction also revealed distinctive behavioral patterns in how the model approached problem solving.\n\nAccuracy and One-Shot Performance\n\nFor straightforward conceptual or definitional questions (e.g., explaining optimizer structures or interpreting results), ChatGPT often produced the correct answer immediately (\u201cone-shot\u201d).\n\nFor more complex derivations or matrix manipulations, it sometimes made conceptual simplification errors rather than arithmetic ones. Nevertheless, this resulted in only one error out of seven big problems.\n\nExample of Conceptual Oversimplification\n\nIn one problem, the model incorrectly dropped the matrix when simplifying to .\n\nThis error propagated through subsequent parts, showing that ChatGPT solved sequentially, building upon its previous reasoning.\n\nOnce provided with a hint, it immediately corrected the mistake\u2014illustrating that the model is particularly strong at conditional reasoning with scaffolding.\n\nStyle of Reasoning\n\nChatGPT consistently produced mathematically formal and symbol-heavy responses, sometimes more rigorous than the problem required.\n\nEspecially for \u201cexplanation\u201d questions, it tended to over-mathematize rather than summarize intuitively. This pattern was observed across multiple sub-questions.\n\nResponse Latency and Thoughtfulness\n\nThe model typically took 2\u20135 minutes for moderately complex derivations, suggesting that its \u201cThinking\u201d mode encouraged stepwise symbolic reasoning rather than rapid generation.\n\nNotation and Presentation\n\nAll responses were logically consistent with the official solutions, though small notational differences (e.g., transposition order or matrix symbols) occasionally appeared.\n\nWhen a matrix identity was mentioned but not proven in the problem statement, ChatGPT sometimes derived it explicitly, reflecting uncertainty about whether it could assume the result.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/Qlsh9EEsaZjmCN1abwyvsGlb\" filename=\"Special Participation A ChatGPT on HW1.pdf\"/><paragraph>I used ChatGPT on HW1 no-cording parts(Special Participation A).<break/>I posted the results, my findings about them, and my summary on the attached pdf.<break/><break/>This is summary from the pdf.<break/>Overall, ChatGPT achieved fully correct answers for all problems, demonstrating strong mathematical reasoning and consistency across sequential tasks. However, the interaction also revealed distinctive behavioral patterns in how the model approached problem solving.</paragraph><list style=\"ordered\"><list-item><paragraph>Accuracy and One-Shot Performance</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>For straightforward conceptual or definitional questions (e.g., explaining optimizer structures or interpreting results), ChatGPT often produced the correct answer immediately (\u201cone-shot\u201d).</paragraph></list-item><list-item><paragraph>For more complex derivations or matrix manipulations, it sometimes made conceptual simplification errors rather than arithmetic ones. Nevertheless, this resulted in only one error out of seven big problems.</paragraph></list-item></list></list-item><list-item><paragraph>Example of Conceptual Oversimplification</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>In one problem, the model incorrectly dropped the matrix when simplifying to .</paragraph></list-item><list-item><paragraph>This error propagated through subsequent parts, showing that ChatGPT solved sequentially, building upon its previous reasoning.</paragraph></list-item><list-item><paragraph>Once provided with a hint, it immediately corrected the mistake\u2014illustrating that the model is particularly strong at conditional reasoning with scaffolding.</paragraph></list-item></list></list-item><list-item><paragraph>Style of Reasoning</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>ChatGPT consistently produced mathematically formal and symbol-heavy responses, sometimes more rigorous than the problem required.</paragraph></list-item><list-item><paragraph>Especially for \u201cexplanation\u201d questions, it tended to over-mathematize rather than summarize intuitively. This pattern was observed across multiple sub-questions.</paragraph></list-item></list></list-item><list-item><paragraph>Response Latency and Thoughtfulness</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>The model typically took 2\u20135 minutes for moderately complex derivations, suggesting that its \u201cThinking\u201d mode encouraged stepwise symbolic reasoning rather than rapid generation.</paragraph></list-item></list></list-item><list-item><paragraph>Notation and Presentation</paragraph></list-item><list-item><list style=\"unordered\"><list-item><paragraph>All responses were logically consistent with the official solutions, though small notational differences (e.g., transposition order or matrix symbols) occasionally appeared.</paragraph></list-item><list-item><paragraph>When a matrix identity was mentioned but not proven in the problem statement, ChatGPT sometimes derived it explicitly, reflecting uncertainty about whether it could assume the result.</paragraph></list-item></list></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-29T11:02:12.9722+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7219165,
            "author": "Nyx Iskandar",
            "project_title": "Special Participation B: GPT-5 HW4",
            "post_body": "Generally, GPT-5 is able to one-shot all coding questions. I didn't try to ask it the observation questions, which is to say that it only completes the strictly code-writing ones. I'm quite surprised that it is able to accurately complete the coding questions, since my experience with GPT-5 for coding has not been the best, and Claude definitely edges out GPT-5 for coding-related tasks. Perhaps the implementations are relatively simple, hence the high accuracy :)",
            "content_xml": "<document version=\"2.0\"><paragraph>Generally, GPT-5 is able to one-shot all coding questions. I didn't try to ask it the observation questions, which is to say that it only completes the strictly code-writing ones. I'm quite surprised that it is able to accurately complete the coding questions, since my experience with GPT-5 for coding has not been the best, and Claude definitely edges out GPT-5 for coding-related tasks. Perhaps the implementations are relatively simple, hence the high accuracy :)</paragraph><file url=\"https://static.us.edusercontent.com/files/QbrVZ0vTgiZNfVZEPnIHPxgU\" filename=\"EECS_182_HW_4_GPT_5_Trace.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-29T10:10:12.536043+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7215058,
            "author": "Bruno Vieira",
            "project_title": "Special Participation E: Claude Study \"Buddy\"",
            "post_body": "I used Claude's study feature to use it as a study \"buddy\". I pretended to be studying for an exam, trying to review content, and study for a specific topic via pre-lecture notes all using Claude to guide my studies.\n\nI started out with this map to see if it could connect all the topics from this class into a graph and assess the relationships between them. Below is the trace with all my comments! Hope this is helpful and happy studying.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>I used Claude's study feature to use it as a study \"buddy\". I pretended to be studying for an exam, trying to review content, and study for a specific topic via pre-lecture notes all using Claude to guide my studies.</paragraph><paragraph>I started out with this map to see if it could connect all the topics from this class into a graph and assess the relationships between them. Below is the trace with all my comments! Hope this is helpful and happy studying.</paragraph><file url=\"https://static.us.edusercontent.com/files/kFuAKFCnfFtJk8o3u8FVRZpS\" filename=\"Claude Trace Study Buddy.pdf\"/><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/Eudu0uIW4L6ppMkzDd9hcPgz\" width=\"558\" height=\"323.14029850746266\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-28T17:20:38.187029+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7212394,
            "author": "Jeffrey Cheng",
            "project_title": "Special Participation B: Mistral AI's Le Chat on HW3 Q2(coding)",
            "post_body": "Here is the online link: https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d\n\nHere is the annotated log: \n\nExecutive Summary:\n\nFor part b), Le Chat was able to arrive at the correct norm implementation on one shot. I am especially surprised by its capability for understanding the RMS-norm without any prompt engineering. \n\nFor part c), Le Chat seemed to firstly stumble on the error of \"using local variable for global variable\". Then, it started to create its own implementation instead of conforming to the implementation on the Jupyter notebook. I had to manually force it to stick to the original implementation by doing some prompt engineering.  After this step, it arrived at the correct solution on one shot. \n\nFor part d), Le Chat seemed to have the same problem as part c). In particular, it created its own local variables and \"hallucinates\" on the same functionality as the original implementation. Again, some prompt engineering helped it to arrive at the correct solution.\n\nFor part e), Le Chat was able to arrive at the correct norm implementation on one shot. I conjecture that it's probably because this question contains less code implementation but more analytical components. \n\nFor part f), Le Chat seemed to have the same problem as part c)d). Again, some prompt engineering helped it to arrive at the correct implementation.",
            "content_xml": "<document version=\"2.0\"><paragraph>Here is the online link: <link href=\"https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d\">https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d</link></paragraph><paragraph>Here is the annotated log: </paragraph><file url=\"https://static.us.edusercontent.com/files/lOUNW0UbEzrSEvZjRhPaVhPw\" filename=\"Annotated log of conversation with Mistral AI coding.pdf\"/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>For part b), Le Chat was able to arrive at the correct norm implementation on one shot. I am especially surprised by its capability for understanding the RMS-norm without any prompt engineering. </paragraph><paragraph>For part c), Le Chat seemed to firstly stumble on the error of \"using local variable for global variable\". Then, it started to create its own implementation instead of conforming to the implementation on the Jupyter notebook. I had to manually force it to stick to the original implementation by doing some prompt engineering.  After this step, it arrived at the correct solution on one shot. </paragraph><paragraph>For part d), Le Chat seemed to have the same problem as part c). In particular, it created its own local variables and \"hallucinates\" on the same functionality as the original implementation. Again, some prompt engineering helped it to arrive at the correct solution.</paragraph><paragraph>For part e), Le Chat was able to arrive at the correct norm implementation on one shot. I conjecture that it's probably because this question contains less code implementation but more analytical components. </paragraph><paragraph>For part f), Le Chat seemed to have the same problem as part c)d). Again, some prompt engineering helped it to arrive at the correct implementation.</paragraph></document>",
            "links": [
                "https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d"
            ],
            "attachments": [],
            "created_at": "2025-10-28T09:53:28.472879+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7212198,
            "author": "Mehul Jaiswal",
            "project_title": "Special Participation A HW5: ChatGPT 5",
            "post_body": "Link to the discussion: https://chatgpt.com/share/68ffefde-4c64-800f-9d99-5417df7eb2b8\n\nAcross this project, GPT accuracy was strongest when my prompts were concrete about goals, constraints, and style, and I consistently drove that clarity. I asked questions in a structured way\u2014first \u201cunderstand \u2192 summarize \u2192 derive \u2192 implement,\u201d then \u201ccomplete the code\u201d with strict guardrails (no new helpers, inverted dropout, 0.5 L2 factor, BN modes, minimal diffs, NumPy-only where required). GPT answered by laying out the full math (OLS, BN, dropout expected-risk, conv/transpose-conv) and then mirroring it in code that matched the exected methods in different files. When GPT drifted\u2014e.g., offering high-level guidance instead of finished cells/files, or being imprecise about BN mode keys, I nudged the GPT (\u201ccomplete the notebook/file,\u201d \u201cset bn_param['mode'],\u201d \u201cuse inverted dropout and scale by 1/(1-p),\u201d \u201cdon\u2019t regularize gamma/beta\u201d), which corrected the approach and aligned outputs the expected result. That feedback loop precise nudges on the few inaccuracies and my immediate revisions in different branches of the same chat , tightened both the math explanations and the implementations until they matched my expected results and coding style.\n\nEdit: Detailed noted on the chat: https://drive.google.com/file/d/1u7L9t7lEqgeOe6fRFeqlfnZMZbHmCdXX/view?usp=sharing",
            "content_xml": "<document version=\"2.0\"><paragraph>Link to the discussion: https://chatgpt.com/share/68ffefde-4c64-800f-9d99-5417df7eb2b8</paragraph><list style=\"unordered\"/><paragraph>Across this project, GPT accuracy was strongest when my prompts were concrete about goals, constraints, and style, and I consistently drove that clarity. I asked questions in a structured way\u2014first \u201cunderstand \u2192 summarize \u2192 derive \u2192 implement,\u201d then \u201ccomplete the code\u201d with strict guardrails (no new helpers, inverted dropout, 0.5 L2 factor, BN modes, minimal diffs, NumPy-only where required). GPT answered by laying out the full math (OLS, BN, dropout expected-risk, conv/transpose-conv) and then mirroring it in code that matched the exected methods in different files. When GPT drifted\u2014e.g., offering high-level guidance instead of finished cells/files, or being imprecise about BN mode keys, I nudged the GPT (\u201ccomplete the notebook/file,\u201d \u201cset <code>bn_param['mode']</code>,\u201d \u201cuse inverted dropout and scale by 1/(1-p),\u201d \u201cdon\u2019t regularize gamma/beta\u201d), which corrected the approach and aligned outputs the expected result. That feedback loop precise nudges on the few inaccuracies and my immediate revisions in different branches of the same chat , tightened both the math explanations and the implementations until they matched my expected results and coding style.<break/><break/>Edit: Detailed noted on the chat: https://drive.google.com/file/d/1u7L9t7lEqgeOe6fRFeqlfnZMZbHmCdXX/view?usp=sharing</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-28T09:29:12.904783+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7212131,
            "author": "Jeffrey Cheng",
            "project_title": "Special Participation A: Mistral AI's Le Chat on HW3",
            "post_body": "Here is the online link: https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d\n\nHere is the annotated log:\n\nExecutive Summary:\n\nFrom my observation, Le Chat was able to answer most written questions correctly on one shot. However, for questions that reference an external research paper, it could misunderstand the problem statement and draw something tangent to what the question is asking. In particular, it could reference a table on a different page or a formula in a different section. Doing some prompt engineering helps the model to reference the correct table/figure.\n\nIn addition, for questions that involve numerical counting, it could mistake the computation by a small margin, even after engineering the prompt. For instance, it could count something twice and mess up with the calculation. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Here is the online link: <link href=\"https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d\">https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d</link></paragraph><paragraph>Here is the annotated log:</paragraph><file url=\"https://static.us.edusercontent.com/files/UjxEQxQUHDdCDMAgY62e9YSr\" filename=\"Annotated log of conversation with Mistral AI.pdf\"/><paragraph><bold>Executive Summary:</bold></paragraph><paragraph>From my observation, Le Chat was able to answer most written questions correctly on one shot. However, for questions that reference an external research paper, it could misunderstand the problem statement and draw something tangent to what the question is asking. In particular, it could reference a table on a different page or a formula in a different section. Doing some prompt engineering helps the model to reference the correct table/figure.</paragraph><paragraph>In addition, for questions that involve numerical counting, it could mistake the computation by a small margin, even after engineering the prompt. For instance, it could count something twice and mess up with the calculation. </paragraph></document>",
            "links": [
                "https://chat.mistral.ai/chat/8c72d241-dd44-41a0-b8fc-a0469d84ff1d"
            ],
            "attachments": [],
            "created_at": "2025-10-28T09:17:55.632059+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7202422,
            "author": "Jerry Xiao",
            "project_title": "Special Participation A: Deepseek on HW5",
            "post_body": "For the HW5, I try to use Deepseek to solve the problem sets and all the questions and answers are documented in the above files. The strategies I am using are simple, just putting the transcription of the problem to Deepseek and see how it can solve the problems. There are some traits of the Deepseek AI:\n\n1. Deepseek does not support Multi-modal input, therefore when the problems rely on image input, then the model cannot really give a proper answer.\n2. Ambiguous question prompts will lead to longer thinking time.\n3. Deepseek is better at explanation than real calculation. My recommendations for using Deepseek as a learning tool to make it help with conceptual understanding.\n\nThis is observed from some of the facts:\n\n1. Of the 11 questions, Deepseek gets 9 of them correct first shot, while one of the question relies on vision input and the other is a calculation problem. It gets the calculation problem correct after another prompt of asking itself to self examine the calculation process. \n2. I try to ask Deepseek examines its own mistake after I finish all the problems and it still can directly and precisely locate where might go wrong, which demonstrate its capable long context understanding capability.\n3. For problem 4, Deepseek not only provides very clear demonstration on how to derive the answer correctly and can show the direct relation between batchnorm and dropout by directly deriving the scaling factor. \n\n\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/r7sceYqPygJpgizFNzKZ3MLp\" filename=\"report.pdf\"/><paragraph>For the HW5, I try to use Deepseek to solve the problem sets and all the questions and answers are documented in the above files. The strategies I am using are simple, just putting the transcription of the problem to Deepseek and see how it can solve the problems. There are some traits of the Deepseek AI:<break/><break/>1. Deepseek does not support Multi-modal input, therefore when the problems rely on image input, then the model cannot really give a proper answer.<break/>2. Ambiguous question prompts will lead to longer thinking time.<break/>3. Deepseek is better at explanation than real calculation. My recommendations for using Deepseek as a learning tool to make it help with conceptual understanding.</paragraph><paragraph>This is observed from some of the facts:<break/><break/>1. Of the 11 questions, Deepseek gets 9 of them correct first shot, while one of the question relies on vision input and the other is a calculation problem. It gets the calculation problem correct after another prompt of asking itself to self examine the calculation process. <break/>2. I try to ask Deepseek examines its own mistake after I finish all the problems and it still can directly and precisely locate where might go wrong, which demonstrate its capable long context understanding capability.<break/>3. For problem 4, Deepseek not only provides very clear demonstration on how to derive the answer correctly and can show the direct relation between batchnorm and dropout by directly deriving the scaling factor. </paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-26T16:13:16.614618+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7199845,
            "author": "Hong Joey",
            "project_title": "HW8 Q4: Ridge Attention",
            "post_body": "Problem Context: This is a former exam problem. It is meant to setup transformers by connecting attention to classical learning approaches, specifically ridge regression. The problem is a conceptual bridge between recurrent models and transformers. Though the problem references transformers, you should be able to solve it with what you have learned thus far. This should both help further demystify why transformers are able to do in-context learning as well as help you understand why recurrent models can have the same capability. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This is a former exam problem. It is meant to setup transformers by connecting attention to classical learning approaches, specifically ridge regression. The problem is a conceptual bridge between recurrent models and transformers. Though the problem references transformers, you should be able to solve it with what you have learned thus far. This should both help further demystify why transformers are able to do in-context learning as well as help you understand why recurrent models can have the same capability. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/WCaQfIM7e4U4uEHcdB7oVvTU\" width=\"658\" height=\"753.2659932659932\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/VadJylV2GkEEUd7fIEdIbcAs\" width=\"658\" height=\"788.7564102564103\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-26T05:51:46.466398+11:00",
            "category": "Admin"
        },
        {
            "guid": 7199813,
            "author": "Hong Joey",
            "project_title": "HW8 Q3: Self-Supervised Linear Purification",
            "post_body": "Problem Context: This is an old exam problem showing another potential use case for autoencoders. In this problem, even when the representations are not lower-dimension, they can still be useful for feature purification.",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This is an old exam problem showing another potential use case for autoencoders. In this problem, even when the representations are not lower-dimension, they can still be useful for feature purification.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/t4GyT37SGdYVf1tYpdXiYOaC\" width=\"658\" height=\"277.54502369668245\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/elKKyojDFSEiBOR2RMgIX9Zu\" width=\"658\" height=\"891.0416666666667\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/bjOdbSTBl9XleAtbslx9abI6\" width=\"658\" height=\"118.1619718309859\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-26T05:45:06.241656+11:00",
            "category": "Admin"
        },
        {
            "guid": 7199801,
            "author": "Hong Joey",
            "project_title": "HW8 Q2: Coding SSM Forward",
            "post_body": "Problem Context: The goal of this problem is to gain practical experience with how modern SSMs are implemented. You will implement both recurrence and convolution-based forward passes to analyze runtime efficiency. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: The goal of this problem is to gain practical experience with how modern SSMs are implemented. You will implement both recurrence and convolution-based forward passes to analyze runtime efficiency. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/m7eODymzQHbyITRzufcYNRKl\" width=\"658.0000000000001\" height=\"570.059748427673\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-26T05:42:04.950311+11:00",
            "category": "Admin"
        },
        {
            "guid": 7199791,
            "author": "Hong Joey",
            "project_title": "HW8 Q1: SSM Convolution Kernel",
            "post_body": "Problem Context: This problem explores the theoretical foundation of State-Space Models (SSMs) by connecting their recurrent update form to an equivalent convolution kernel representation. By doing so, you should be able to see why SSMs are efficient to parallelize.  Parts of this problem will also be engaged with in discussion.",
            "content_xml": "<document version=\"2.0\"><paragraph>Problem Context: This problem explores the theoretical foundation of State-Space Models (SSMs) by connecting their recurrent update form to an equivalent convolution kernel representation. By doing so, you should be able to see why SSMs are efficient to parallelize.  Parts of this problem will also be engaged with in discussion.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/kqnS41i47QQAMebBQIdcZdKW\" width=\"658\" height=\"726.7769110764431\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-26T05:40:30.510897+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7197077,
            "author": "Anant Sahai",
            "project_title": "Appointment slots for the project",
            "post_body": "https://docs.google.com/spreadsheets/d/1hOqLiCQuekARSADubqDPQmFXNSsR01bsBQzjN4OUIpU/edit?gid=0#gid=0\n\nThe spreadsheet above has links to individual appointment calendars for the course staff along with what project topics we will be supporting. \n\nPlease set up an appointment for next week. And then, once your project proposals are in, for the following week to get feedback.\n\nRemember, these are required meetings for each group. At least one person from your group must attend the meeting.\n\n The appointments next week should help you find a problem and/or refine it.",
            "content_xml": "<document version=\"2.0\"><paragraph><link href=\"https://docs.google.com/spreadsheets/d/1hOqLiCQuekARSADubqDPQmFXNSsR01bsBQzjN4OUIpU/edit?gid=0#gid=0\">https://docs.google.com/spreadsheets/d/1hOqLiCQuekARSADubqDPQmFXNSsR01bsBQzjN4OUIpU/edit?gid=0#gid=0</link></paragraph><paragraph>The spreadsheet above has links to individual appointment calendars for the course staff along with what project topics we will be supporting. </paragraph><paragraph>Please set up an appointment for next week. And then, once your project proposals are in, for the following week to get feedback.</paragraph><paragraph>Remember, these are required meetings for each group. At least one person from your group must attend the meeting.</paragraph><paragraph> The appointments next week should help you find a problem and/or refine it.</paragraph></document>",
            "links": [
                "https://docs.google.com/spreadsheets/d/1hOqLiCQuekARSADubqDPQmFXNSsR01bsBQzjN4OUIpU/edit?gid=0#gid=0"
            ],
            "attachments": [],
            "created_at": "2025-10-25T10:44:16.231052+11:00",
            "category": "Project"
        },
        {
            "guid": 7196339,
            "author": "Hong Joey",
            "project_title": "Discussion 8 Solutions",
            "post_body": "Attached are questions and solutions to Discussion 8:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are questions and solutions to Discussion 8:</paragraph><file url=\"https://static.us.edusercontent.com/files/ZehcayfyArHXC5ZAdqkAXFAb\" filename=\"dis08_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/NGbehdH0YcruNpq3VWmx57te\" filename=\"dis08_solution.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-25T08:26:51.079494+11:00",
            "category": "Sections"
        },
        {
            "guid": 7191116,
            "author": "Noah Lund Syrdal",
            "project_title": "Special Participation C: Refactoring of HW3 task 2",
            "post_body": "Executive summary:\nRefactored the original notebook into a clean, modular codebase. Split into models.py, optimizers.py, and training.py, each with docstrings, validation, and reproducibility features. Preserved all \u03bcP and optimizer experiments while improving readability, maintainability, and adherence to PEP 8/257 and PyTorch best practices.\n\nGithub repo: https://github.com/NoahLundSyrdal/SpecialParticipationC \n\nReport\n\nDone by Noah Lund Syrdal(3041928386), Anders Vestrum(3041972833) and Srikar Babu (3041813297)",
            "content_xml": "<document version=\"2.0\"><paragraph>Executive summary:<break/>Refactored the original notebook into a clean, modular codebase. Split into <code>models.py</code>, <code>optimizers.py</code>, and <code>training.py</code>, each with docstrings, validation, and reproducibility features. Preserved all \u03bcP and optimizer experiments while improving readability, maintainability, and adherence to PEP 8/257 and PyTorch best practices.</paragraph><paragraph>Github repo: <link href=\"https://github.com/NoahLundSyrdal/SpecialParticipationC\">https://github.com/NoahLundSyrdal/SpecialParticipationC</link> </paragraph><paragraph>Report</paragraph><file url=\"https://static.us.edusercontent.com/files/8WiMHRBTeP9yhAjWQjbBrMea\" filename=\"Special_Participation_C__HW3___2-5.pdf\"/><paragraph>Done by Noah Lund Syrdal(3041928386), Anders Vestrum(3041972833) and Srikar Babu (3041813297)</paragraph></document>",
            "links": [
                "https://github.com/NoahLundSyrdal/SpecialParticipationC"
            ],
            "attachments": [],
            "created_at": "2025-10-24T09:51:14.765194+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7180201,
            "author": "Anant Sahai",
            "project_title": "Lecture 15: Autoencoder and Self-Supervision Part",
            "post_body": "This thread is to discuss the lecture part on self-supervision. To keep things clear, the second set of writing building towards state-space models will be kept distinct. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/qI8y8TXguhynXBv9IjNhmuS3\" filename=\"Lecture 15Sahai.pdf\"/><paragraph>This thread is to discuss the lecture part on self-supervision. To keep things clear, the second set of writing building towards state-space models will be kept distinct. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-22T17:30:26.938884+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7178115,
            "author": "Leon Kornfeld",
            "project_title": "Participation B: Grok HW 6",
            "post_body": "I used Grok to solve problems 5 and 6 of HW6 (coding).\n\nNote: Because problem 1 wasn\u2019t implementation-based and was about running cells and reading off values generated from GPU data, I figured it was unnecessary \u2014 or odd \u2014 to solve it with Grok.\n\nProblem 5:\n\nReflection:\nTo have Grok solve the problems associated with this notebook, I first gave it an overall prompt:\n\n\u201cAs I provide you sequential code blocks, solve all the TODOs without changing the code skeleton.\u201d\n\nAfter that, I started providing context for each question (the markdown cells in the notebook detailing the instructions) and then the actual skeleton code where it needed to fill things in. Grok then output the completed code, which I copied into the notebook and ran. I repeated this process throughout the notebook. With each response, Grok provided its reasoning, which can be seen in the transcript above.\n\nFast-forwarding, the first bug I encountered was when trying to instantiate the full gnn_model. The variable hidden_dim was passed in as a list, while Grok had coded it as an integer. This naturally led to a type error, since the code Grok wrote treated the list as an integer.\n\nMy next prompt to Grok was incorrect: I suggested just changing the list to an integer to avoid modifying the skeleton code. Grok acknowledged that while this was possible, it wasn\u2019t the best solution because it went against the intended design. Instead, it suggested that a better approach was to fix the skeleton code to treat hidden_dim as a list. After one \u201cindex out of range\u201d error and one more prompt to Grok, the code ran successfully.\n\nThe remainder of the problem went smoothly. For Q9 \u2014 the conceptual question on accuracy \u2014 Grok provided a multitude of possible explanations for the discrepancy. Because I hadn\u2019t provided the graph in the prompt, all of Grok\u2019s reasoning was speculative based on the limited context. My prompt said:\n\n\u201cAfter training the model, we get 100 percent accuracy on the test data. However, we see two samples that are misclassified.\u201d\n\nThis didn\u2019t specify that we were looking at all the samples (including the training data) or analyzing a graph. Without that information, Grok didn\u2019t get the correct answer. When I clarified that we were looking at the entire dataset, Grok correctly deduced that the misclassifications came from the training set.\n\nProblem 6:\n\nReflection:\n\nI used the exact same prompting approach that I used for question 5.\n\nGrok originally assumed that the X matrix in the Newton\u2013Schulz calculation was square. Therefore, the original code it produced used (X @ X @ X) instead of (X @ X.T @ X.T). When later code failed due to dimension errors, I had to prompt Grok that X was not necessarily square. It then gave a more complex solution using a Gram matrix. I further prompted it to just use X, and it responded with the correct answer.\n\nOnce Grok finished the coding questions, I started prompting it with the conceptual ones. I asked,\n\n\u201cWhich optimizer performed best between Muon, SGD, and AdamW?\u201d\n\nI also provided a screenshot of the graphs. It gave the correct answer, though I doubted whether it actually analyzed the graph. I tested this by asking graph-specific questions to see if it could interpret the image. Grok correctly identified that the training ran for 5 epochs but was slightly off on the lowest loss (saying 0.8 instead of 0.6).\n\nAfter a few more partially accurate answers, I decided to provide the numerical training data instead of a screenshot. With that, Grok did a much better job answering the conceptual questions.\n\nInterestingly, all the questions except the last one required little reasoning. The final conceptual question \u2014 whether orthogonalization or muP mattered more \u2014 took Grok about two minutes of processing, during which it visited around 15 webpages. It eventually answered the question correctly.\n\nConclusion:\n\nGrok does a pretty good job at zero-shotting the coding problems. It struggles when the user prompt lacks specific information (e.g. matrix shape, what image/graph we are analyzing) and thus makes generalizations that could lead to the wrong answer/code bugs. However, once more context was provided, Grok was able to correct itself and arrive at the right answer.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>I used Grok to solve problems 5 and 6 of HW6 (coding).</bold></paragraph><paragraph><bold>Note:</bold> Because problem 1 wasn\u2019t implementation-based and was about running cells and reading off values generated from GPU data, I figured it was unnecessary \u2014 or odd \u2014 to solve it with Grok.</paragraph><paragraph>Problem 5:</paragraph><file url=\"https://static.us.edusercontent.com/files/hZ5veIUZxIlXBfMh8bTtzoo3\" filename=\"GCN Karate Club Node Classification - Grok.pdf\"/><paragraph><bold>Reflection:<break/></bold>To have Grok solve the problems associated with this notebook, I first gave it an overall prompt:</paragraph><blockquote>\u201cAs I provide you sequential code blocks, solve all the TODOs without changing the code skeleton.\u201d</blockquote><paragraph>After that, I started providing context for each question (the markdown cells in the notebook detailing the instructions) and then the actual skeleton code where it needed to fill things in. Grok then output the completed code, which I copied into the notebook and ran. I repeated this process throughout the notebook. With each response, Grok provided its reasoning, which can be seen in the transcript above.</paragraph><paragraph>Fast-forwarding, the first bug I encountered was when trying to instantiate the full <code>gnn_model</code>. The variable <code>hidden_dim</code> was passed in as a list, while Grok had coded it as an integer. This naturally led to a type error, since the code Grok wrote treated the list as an integer.</paragraph><paragraph>My next prompt to Grok was incorrect: I suggested just changing the list to an integer to avoid modifying the skeleton code. Grok acknowledged that while this was possible, it wasn\u2019t the best solution because it went against the intended design. Instead, it suggested that a better approach was to fix the skeleton code to treat <code>hidden_dim</code> as a list. After one \u201cindex out of range\u201d error and one more prompt to Grok, the code ran successfully.</paragraph><paragraph>The remainder of the problem went smoothly. For Q9 \u2014 the conceptual question on accuracy \u2014 Grok provided a multitude of possible explanations for the discrepancy. Because I hadn\u2019t provided the graph in the prompt, all of Grok\u2019s reasoning was speculative based on the limited context. My prompt said:</paragraph><blockquote>\u201cAfter training the model, we get 100 percent accuracy on the test data. However, we see two samples that are misclassified.\u201d</blockquote><paragraph>This didn\u2019t specify that we were looking at all the samples (including the training data) or analyzing a graph. Without that information, Grok didn\u2019t get the correct answer. When I clarified that we were looking at the entire dataset, Grok correctly deduced that the misclassifications came from the training set.</paragraph><paragraph><bold>Problem 6:</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/27hqn25r2cBL3J1BQcqdxLzo\" filename=\"Newton-Schulz Matrix Orthogonalization Implementation - Grok.pdf\"/><paragraph><bold>Reflection:</bold></paragraph><paragraph>I used the exact same prompting approach that I used for question 5.</paragraph><paragraph>Grok originally assumed that the <code>X</code> matrix in the Newton\u2013Schulz calculation was square. Therefore, the original code it produced used <code>(X @ X @ X)</code> instead of <code>(X @ X.T @ X.T)</code>. When later code failed due to dimension errors, I had to prompt Grok that <code>X</code> was not necessarily square. It then gave a more complex solution using a Gram matrix. I further prompted it to just use <code>X</code>, and it responded with the correct answer.</paragraph><paragraph>Once Grok finished the coding questions, I started prompting it with the conceptual ones. I asked,</paragraph><blockquote>\u201cWhich optimizer performed best between Muon, SGD, and AdamW?\u201d</blockquote><paragraph>I also provided a screenshot of the graphs. It gave the correct answer, though I doubted whether it actually analyzed the graph. I tested this by asking graph-specific questions to see if it could interpret the image. Grok correctly identified that the training ran for 5 epochs but was slightly off on the lowest loss (saying 0.8 instead of 0.6).</paragraph><paragraph>After a few more partially accurate answers, I decided to provide the numerical training data instead of a screenshot. With that, Grok did a much better job answering the conceptual questions.</paragraph><paragraph>Interestingly, all the questions except the last one required little reasoning. The final conceptual question \u2014 whether orthogonalization or muP mattered more \u2014 took Grok about two minutes of processing, during which it visited around 15 webpages. It eventually answered the question correctly.</paragraph><paragraph><bold>Conclusion:</bold></paragraph><paragraph>Grok does a pretty good job at zero-shotting the coding problems. It struggles when the user prompt lacks specific information (e.g. matrix shape, what image/graph we are analyzing) and thus makes generalizations that could lead to the wrong answer/code bugs. However, once more context was provided, Grok was able to correct itself and arrive at the right answer.</paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-22T11:12:47.760104+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7177111,
            "author": "Sultan Daniels",
            "project_title": "Homework 6 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/H7QiXdPgh1jg1s4QevBTLFsQ\" filename=\"hw06codesolution.zip\"/><file url=\"https://static.us.edusercontent.com/files/J681dJ4KORFWAUMSucpC79sY\" filename=\"hw06_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/LMNEmlsr4cX21i0HdZsVObQf\" filename=\"hw06_question.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-22T08:59:39.280008+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7166398,
            "author": "Lance Mathias",
            "project_title": "HW7 Q1: Implementing RNNs (Coding)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/EgY4PmGz84l65IdfaPjzvYzW\" width=\"568\" height=\"513\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/8Eca13PVHvdrNRSbuWLCY86m\" width=\"566\" height=\"751.4137931034484\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/Mq0a2O2tGg3iHKBbr5RwiIaE\" width=\"566\" height=\"521.8387516254877\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-21T05:49:19.852257+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7166397,
            "author": "Lance Mathias",
            "project_title": "HW7 Q2: RNNs for Last Name Classification (Coding)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/xbvkhtcq0tX7Quftev6rbnUt\" width=\"581\" height=\"137.90272373540856\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-21T05:49:17.633312+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7166396,
            "author": "Lance Mathias",
            "project_title": "HW7 Q3: Auto-encoder: Learning without Labels",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/c5EdUpX5ccLSEAbJ4aqmjitc\" width=\"581\" height=\"83.42564102564103\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/ytx501ettcfSxxxEgmSW3YCF\" width=\"581\" height=\"781.1308411214953\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/5U0l0jqjbDQQtmQCQN3uOIWL\" width=\"586\" height=\"92\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-21T05:49:13.820227+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7166394,
            "author": "Lance Mathias",
            "project_title": "HW7 Q4: Read a Blog Post: How to train your Resnet",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/LMokhUCcwp7zsTLE2RhzUUI9\" width=\"581\" height=\"288.63063063063066\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-21T05:48:59.655356+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7166393,
            "author": "Lance Mathias",
            "project_title": "HW7 Q5: The power of the graph perspective in clustering (Coding)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/6F36JK9GiQ3h4ygTys7srlXa\" width=\"581\" height=\"357.8245838668374\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/b79ePjGSRpBR9fh0oBs0Hf1M\" width=\"566\" height=\"525.2539267015707\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-21T05:48:57.069018+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7162279,
            "author": "Tianyu Gu",
            "project_title": "Special Participation A: Grok on HW0",
            "post_body": "For the special participation A on HW0, I use Grok to address the non-coding analytical components (problems 2\u20135). The performance of Grok really impressed me, almost all questions are one-shot correct except for 5(b)(iii).\n\nSummary: Grok demonstrated reliable analytical reasoning for most problems, with clear and accurate derivations for problems 2, 3, and 4. The answer of them are all fully correct. However, the error on problem 5(b)(iii) suggests its sensitivity to complex or ambiguous problem structures. \n\nHere is the link https://grok.com/share/c2hhcmQtMg%3D%3D_935edffc-4c41-4eb5-931a-aaf30ccdf737 ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/hNHXrBnPiBe37nccrn8vAbZ4\" filename=\"Special participation A.pdf\"/><paragraph>For the special participation A on HW0, I use Grok to address the non-coding analytical components (problems 2\u20135). The performance of Grok really impressed me, almost all questions are one-shot correct except for 5(b)(iii).</paragraph><paragraph><bold>Summary:</bold> Grok demonstrated reliable analytical reasoning for most problems, with clear and accurate derivations for problems 2, 3, and 4. The answer of them are all fully correct. However, the error on problem 5(b)(iii) suggests its sensitivity to complex or ambiguous problem structures. </paragraph><paragraph>Here is the link <link href=\"https://grok.com/share/c2hhcmQtMg%3D%3D_935edffc-4c41-4eb5-931a-aaf30ccdf737\">https://grok.com/share/c2hhcmQtMg%3D%3D_935edffc-4c41-4eb5-931a-aaf30ccdf737</link> </paragraph></document>",
            "links": [
                "https://grok.com/share/c2hhcmQtMg%3D%3D_935edffc-4c41-4eb5-931a-aaf30ccdf737"
            ],
            "attachments": [],
            "created_at": "2025-10-20T18:33:07.202349+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7159164,
            "author": "Yuxiang Liu",
            "project_title": "Special Participation E: A Comprehensive Tutorial for Literature Review",
            "post_body": "Before we get started with the literature review of the final project, I think it would be worthwhile to spend 5 minutes studying about some sensible ways of applying LLMs for the purpose of literature searching. The link below is one of my personal blogs which concludes a recipe of useful tricks that will help you coorporate with LLMs more smoothly and efficiently when doing deep research :D This blog includes advice from some experienced researchers as well as my personal suggestions. If you have any other valuable insights, feel free to leave a comment here!\n\nhttps://xiang-foothill.github.io/personal-website/blog/make-ai-your-best-assistant.html",
            "content_xml": "<document version=\"2.0\"><paragraph>Before we get started with the literature review of the final project, I think it would be worthwhile to spend 5 minutes studying about some sensible ways of applying LLMs for the purpose of literature searching. The link below is one of my personal blogs which concludes a recipe of useful tricks that will help you coorporate with LLMs more smoothly and efficiently when doing deep research :D This blog includes advice from some experienced researchers as well as my personal suggestions. If you have any other valuable insights, feel free to leave a comment here!</paragraph><paragraph>https://xiang-foothill.github.io/personal-website/blog/make-ai-your-best-assistant.html</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-20T08:36:06.64917+11:00",
            "category": "Admin"
        },
        {
            "guid": 7151370,
            "author": "Noah Lund Syrdal",
            "project_title": "Special Participation A: GPT-Oss on HW5",
            "post_body": "\n\nFor this special participation, I used gpt-oss-120b (Reasoning = High) to solve all non-coding analytical parts of HW5 (Q1\u2013Q4).\nThe model was tested on symbolic derivations and conceptual reasoning without code execution.\n\nAccuracy: 9 / 11 one-shot (82 %), 2 / 11 minor-nudge (18 %)\n\nMain errors: one ASCII matrix mis-parse and one BatchNorm vs LayerNorm confusion\n\nNo hallucinations: all final answers matched the official HW5 solution key\n\nTakeaway: once prompts were clearly formatted in LaTeX, the model produced correct and interpretable derivations, showing reliable analytical reasoning but high sensitivity to input structure.\n\nBit slow(90-180 seconds)\n\n(Logs and annotations are attached in the full PDF report.)",
            "content_xml": "<document version=\"2.0\"><paragraph/><file url=\"https://static.us.edusercontent.com/files/36Ibqekm0cq7clyfZo5xJMtP\" filename=\"SpecialParticipationA-GPTOssHW5.pdf\"/><paragraph>For this special participation, I used gpt-oss-120b (Reasoning = High) to solve all non-coding analytical parts of HW5 (Q1\u2013Q4).<break/>The model was tested on symbolic derivations and conceptual reasoning without code execution.</paragraph><list style=\"unordered\"><list-item><paragraph>Accuracy: 9 / 11 one-shot (82 %), 2 / 11 minor-nudge (18 %)</paragraph></list-item><list-item><paragraph>Main errors: one ASCII matrix mis-parse and one BatchNorm vs LayerNorm confusion</paragraph></list-item><list-item><paragraph>No hallucinations: all final answers matched the official HW5 solution key</paragraph></list-item><list-item><paragraph>Takeaway: once prompts were clearly formatted in LaTeX, the model produced correct and interpretable derivations, showing reliable analytical reasoning but high sensitivity to input structure.</paragraph></list-item><list-item><paragraph>Bit slow(90-180 seconds)</paragraph></list-item></list><paragraph>(Logs and annotations are attached in the full PDF report.)</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-18T11:31:49.638758+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7148413,
            "author": "Anders Vestrum",
            "project_title": "Special Participation A: Grok on HW5",
            "post_body": "This document is my report for the HW5 - written part. I evaluate the performance of Grok. It is tested across a series of theoretical deep learning questions covering topics such as convolutional networks, batch normalization, dropout, depthwise separable convolutions, and regularization. The report includes:\n\nAn overview of Grok\u2019s performance, where I categorized each task into one of four levels: One-Shot Correct, Minor Misconception, Larger Error, or Did Not Solve.\n\nA reflection on Grok\u2019s strengths and weaknesses, where I highlight its strong conceptual intuition, clarity, and adaptability, while noting occasional over-explanation and moments where certain steps could have been emphasized more clearly.\n\nMy recommendations for effectively using Grok as a learning tool, emphasizing the importance of clear prompting, iterative clarification, and maintaining focus on conceptual understanding.\n\nFull transcripts of my Q&A exchanges with Grok, including its solutions, reasoning, and my reflections after each subproblem. \n\nOverall, I conclude that Grok performs really well as a conceptual teaching and problem-solving assistant for theoretical deep learning. It has only minor inefficiencies related to verbosity or explicitness.",
            "content_xml": "<document version=\"2.0\"><paragraph>This document is my report for the HW5 - written part. I evaluate the performance of Grok. It is tested across a series of theoretical deep learning questions covering topics such as convolutional networks, batch normalization, dropout, depthwise separable convolutions, and regularization. The report includes:</paragraph><list style=\"unordered\"><list-item><paragraph>An overview of Grok\u2019s performance, where I categorized each task into one of four levels: One-Shot Correct, Minor Misconception, Larger Error, or Did Not Solve.</paragraph></list-item><list-item><paragraph>A reflection on Grok\u2019s strengths and weaknesses, where I highlight its strong conceptual intuition, clarity, and adaptability, while noting occasional over-explanation and moments where certain steps could have been emphasized more clearly.</paragraph></list-item><list-item><paragraph>My recommendations for effectively using Grok as a learning tool, emphasizing the importance of clear prompting, iterative clarification, and maintaining focus on conceptual understanding.</paragraph></list-item><list-item><paragraph>Full transcripts of my Q&amp;A exchanges with Grok, including its solutions, reasoning, and my reflections after each subproblem. </paragraph></list-item></list><paragraph>Overall, I conclude that Grok performs really well as a conceptual teaching and problem-solving assistant for theoretical deep learning. It has only minor inefficiencies related to verbosity or explicitness.</paragraph><file url=\"https://static.us.edusercontent.com/files/Zag0csJASJ5J7AvKA2n8mUmb\" filename=\"special_participation_A.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-18T02:48:56.469848+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7147361,
            "author": "Anant Sahai",
            "project_title": "Lecture 14",
            "post_body": "This is for discussing basic RNNs and the start of self-supervision. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/xNGOdEwaHMuPn90WywUlLrJI\" filename=\"Lecture 14.pdf\"/><paragraph>This is for discussing basic RNNs and the start of self-supervision. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-17T17:06:38.45759+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7146912,
            "author": "Noah Lund Syrdal",
            "project_title": "Special Participation B: Deepseek on problem 2 HW3",
            "post_body": "Deepseek conv: https://chat.deepseek.com/share/b9xx6hqmk42jzod0uu \n\nTranscript with comments: https://drive.google.com/file/d/1MWOQsiybYJ3Tgw99TATzzucOYQ1j57MV/view?usp=sharing \n\nFor this special participation, I used DeepSeek to solve the Maximal Update Parameterization (\u03bcP) problem in Homework 3, evaluating its ability to reason about \u03bcP\u2019s theory and implement its optimizer and network-scaling components correctly.\n\nDeepSeek performed strongly across Parts B\u2013E, showing solid mathematical reasoning and clean, well-structured code, though occasionally verbose.\n\nIn Part B, it identified the RMS\u2192RMS induced norm as the key to explaining activation deltas and derived the correct relation\n||W||_(RMS\u2192RMS) = \u03c3_max(W) * sqrt(n/m).\nIts explanation of why Frobenius and spectral norms fail to capture functional effects was clear and technically precise\u2014one of its best moments.\n\nIn Part C, DeepSeek implemented the SimpleAdamMuP optimizer with proper per-layer scaling (\u221a(n_out / n_in)) and justified input/output layer \u201cfudge\u201d factors, accurately linking them to \u03bcP\u2019s goal of uniform activation updates.\n\nPart D was the highlight, but also where its main weakness appeared. DeepSeek initially applied the wrong scaling (\u221a(n_in / n_out)) and only realized the mistake after I asked why it had chosen that direction. It first tried to justify the incorrect reasoning before re-deriving and correcting itself to \u221a(n_out / n_in). While it eventually reached the right conclusion and explained it well, this showed that it didn\u2019t truly verify its own logic until prompted. Interestingly, I also noticed that it sometimes produced very smart intermediate reasoning during its \u201cthinking\u201d process but then left those insights out of its final answer.\n\nIn Part E, it correctly demonstrated \u03bcP\u2019s hyperparameter-transfer property\u2014that a single global learning rate (\u22481\u20133) generalizes across widths 4\u2013256\u2014capturing \u03bcP\u2019s essence of \u201ctune once, scale everywhere.\u201d\n\nOverall, DeepSeek showed strong theoretical grasp, clean implementation, and genuine reflective reasoning. However, I found ChatGPT generally does a better job at maintaining coherence, verifying its logic, and integrating its best reasoning directly into the final answers. DeepSeek was technically solid but less self-consistent, making it feel more like an intelligent assistant that sometimes \u201cknows\u201d the right thing but doesn\u2019t always say it.",
            "content_xml": "<document version=\"2.0\"><paragraph>Deepseek conv: <link href=\"https://chat.deepseek.com/share/b9xx6hqmk42jzod0uu\"><underline>https://chat.deepseek.com/share/b9xx6hqmk42jzod0uu</underline></link> </paragraph><paragraph>Transcript with comments: <link href=\"https://drive.google.com/file/d/1MWOQsiybYJ3Tgw99TATzzucOYQ1j57MV/view?usp=sharing\"><underline>https://drive.google.com/file/d/1MWOQsiybYJ3Tgw99TATzzucOYQ1j57MV/view?usp=sharing</underline></link> </paragraph><paragraph>For this special participation, I used DeepSeek to solve the Maximal Update Parameterization (\u03bcP) problem in Homework 3, evaluating its ability to reason about \u03bcP\u2019s theory and implement its optimizer and network-scaling components correctly.</paragraph><paragraph>DeepSeek performed strongly across Parts B\u2013E, showing solid mathematical reasoning and clean, well-structured code, though occasionally verbose.</paragraph><paragraph>In Part B, it identified the RMS\u2192RMS induced norm as the key to explaining activation deltas and derived the correct relation<break/>||W||_(RMS\u2192RMS) = \u03c3_max(W) * sqrt(n/m).<break/>Its explanation of why Frobenius and spectral norms fail to capture functional effects was clear and technically precise\u2014one of its best moments.</paragraph><paragraph>In Part C, DeepSeek implemented the SimpleAdamMuP optimizer with proper per-layer scaling (\u221a(n_out / n_in)) and justified input/output layer \u201cfudge\u201d factors, accurately linking them to \u03bcP\u2019s goal of uniform activation updates.</paragraph><paragraph>Part D was the highlight, but also where its main weakness appeared. DeepSeek initially applied the wrong scaling (\u221a(n_in / n_out)) and only realized the mistake after I asked why it had chosen that direction. It first tried to justify the incorrect reasoning before re-deriving and correcting itself to \u221a(n_out / n_in). While it eventually reached the right conclusion and explained it well, this showed that it didn\u2019t truly verify its own logic until prompted. Interestingly, I also noticed that it sometimes produced very smart intermediate reasoning during its \u201cthinking\u201d process but then left those insights out of its final answer.</paragraph><paragraph>In Part E, it correctly demonstrated \u03bcP\u2019s hyperparameter-transfer property\u2014that a single global learning rate (\u22481\u20133) generalizes across widths 4\u2013256\u2014capturing \u03bcP\u2019s essence of \u201ctune once, scale everywhere.\u201d</paragraph><paragraph>Overall, DeepSeek showed strong theoretical grasp, clean implementation, and genuine reflective reasoning. However, I found ChatGPT generally does a better job at maintaining coherence, verifying its logic, and integrating its best reasoning directly into the final answers. DeepSeek was technically solid but less self-consistent, making it feel more like an intelligent assistant that sometimes \u201cknows\u201d the right thing but doesn\u2019t always say it.</paragraph></document>",
            "links": [
                "https://chat.deepseek.com/share/b9xx6hqmk42jzod0uu",
                "https://drive.google.com/file/d/1MWOQsiybYJ3Tgw99TATzzucOYQ1j57MV/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-10-17T15:02:58.680275+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7144449,
            "author": "Hong Joey",
            "project_title": "HW5 Solutions",
            "post_body": "Attached are solutions to HW5. Feel free to ask questions about them in this thread:",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are solutions to HW5. Feel free to ask questions about them in this thread:</paragraph><file url=\"https://static.us.edusercontent.com/files/xHf1THUKAJkdneDCDIsqFDML\" filename=\"hw05_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/GJGCf5elX1QPeUPHDGUO9zoO\" filename=\"q_coding_dropout_sol.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/thE7EzWQsa6FruyPKMT5Lvqz\" filename=\"q_coding_bn_drop_cnn_sol.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-17T07:37:54.495293+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7144277,
            "author": "Sultan Daniels",
            "project_title": "Discussion 7 Solutions",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/X7AtMPpLORIcQpeKpet5Ewnc\" filename=\"dis07_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/LqaBjFudCYIwb23cQ09P8Ajx\" filename=\"dis07_question.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-17T07:14:15.947513+11:00",
            "category": "Sections"
        },
        {
            "guid": 7139209,
            "author": "Anant Sahai",
            "project_title": "Lecture 13 Thread",
            "post_body": "Use this to ask questions about DiffPool and the general design principles we used to figure out how to do pooling in a mostly generic way for graphs. The PDF above has been slightly annotated to reflect discussions in office hours. \n\nWe also started on RNNs, but will be continuing that on Thursday's lecture. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/nZvjX9QR0fCSiCYGFPxLZdWQ\" filename=\"Lecture 13.pdf\"/><paragraph>Use this to ask questions about DiffPool and the general design principles we used to figure out how to do pooling in a mostly generic way for graphs. The PDF above has been slightly annotated to reflect discussions in office hours. </paragraph><paragraph>We also started on RNNs, but will be continuing that on Thursday's lecture. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-16T10:43:45.603854+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7134659,
            "author": "Bruno Vieira",
            "project_title": "Participation B Gemini HW5",
            "post_body": "The chat log with commentary is attached above with all the code Gemini suggested.\n\nReflection:\n\nFor Q5, Gemini performed surprisingly well \u2014 the problem itself was fairly straightforward, with most of the code already scaffolded in the notebook, so it didn\u2019t have to handle much structural uncertainty. Because I used Gemini inside Colab, it had full access to the notebook\u2019s context and previous cells, which definitely helped it \u201cone-shot\u201d nearly all the subparts correctly. The conceptual depth was solid. It provided well-reasoned explanations of dropout and different variants of gradient descent, and it even interpreted the loss graphs in part D accurately. Where Gemini did particularly well was in connecting the observed training behavior to the theoretical effects of dropout like reducing over-reliance on specific features like the \u201ccheating features\u201d, improving generalization, and stabilizing updates. However, its answers sometimes felt overly verbose and repetitive, often rephrasing the same idea multiple times without adding much substance. It\u2019s clear Gemini does well with low-complexity, well-defined prompts that rely on standard neural network concepts, but it still struggles to be concise or to offer creative insights beyond textbook explanations.\n\nQ6 was more complex, and Gemini\u2019s performance was mixed, especially since I had to switch from Colab (with contextual code cells) to the browser version, meaning it didn\u2019t have the same continuity since a lot of the coding was done on .py files instead on a notebook like Q5. For the batch normalization implementation, though, it was genuinely impressive where Gemini inferred missing details like using batch statistics for the forward pass without explicit instruction, and it correctly executed the full forward and backward propagation steps. It\u2019s unclear whether it derived the math itself or simply recalled a learned pattern, but either way, it achieved the correct result. However, when asked to modify the fully connected network to include dropout, it completely failed where it essentially reprinted the same model without incorporating dropout at all, as if it didn\u2019t register the change request. This suggests Gemini\u2019s weakness in applying structural modifications to existing code, especially when they require integrating a new mechanism into a preexisting design. It seems more comfortable regenerating code from scratch than adapting it thoughtfully.\n\nFor the spatial batch normalization section, Gemini\u2019s inline import was technically correct but unnecessary where a habit that made the code less clean and showed an overreliance on re-importing modules. The implementation itself worked, but the approach was not the smoothest and not very well thought before it gave me the code in the chat. Similarly, in the CNN design question, the model it proposed was overly shallow and minimalistic for CIFAR-scale data. While Gemini was very receptive to feedback and quickly acknowledged that a deeper network would be better, it didn\u2019t independently propose parameter or structural improvements, indicating limited architectural creativity. I suggested it use another convolution layer to pick up more information and it followed instructions well but didn\u2019t demonstrate the capacity to think beyond them.\n\nOverall, Gemini was accurate, stable, and efficient for standard or moderately complex neural network tasks, especially those that map directly to known architectures or formulas. It showed good conceptual understanding and a strong ability to produce syntactically correct code on the first try. However, it lacked flexibility and creative reasoning when the task demanded architectural innovation or modification of existing code. It\u2019s great at execution and explanation, but not yet capable of adapting in nuanced, design-heavy tasks where intuition and experimentation matter most.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/UkfG27zoh384GEFS32UqNoB4\" filename=\"CS_182_Participation_B_HW5_Gemini.pdf\"/><paragraph>The chat log with commentary is attached above with all the code Gemini suggested.</paragraph><paragraph><bold>Reflection:</bold></paragraph><paragraph>For Q5, Gemini performed surprisingly well \u2014 the problem itself was fairly straightforward, with most of the code already scaffolded in the notebook, so it didn\u2019t have to handle much structural uncertainty. Because I used Gemini inside Colab, it had full access to the notebook\u2019s context and previous cells, which definitely helped it \u201cone-shot\u201d nearly all the subparts correctly. The conceptual depth was solid. It provided well-reasoned explanations of dropout and different variants of gradient descent, and it even interpreted the loss graphs in part D accurately. Where Gemini did particularly well was in connecting the observed training behavior to the theoretical effects of dropout like reducing over-reliance on specific features like the \u201ccheating features\u201d, improving generalization, and stabilizing updates. However, its answers sometimes felt overly verbose and repetitive, often rephrasing the same idea multiple times without adding much substance. It\u2019s clear Gemini does well with low-complexity, well-defined prompts that rely on standard neural network concepts, but it still struggles to be concise or to offer creative insights beyond textbook explanations.</paragraph><paragraph>Q6 was more complex, and Gemini\u2019s performance was mixed, especially since I had to switch from Colab (with contextual code cells) to the browser version, meaning it didn\u2019t have the same continuity since a lot of the coding was done on .py files instead on a notebook like Q5. For the batch normalization implementation, though, it was genuinely impressive where Gemini inferred missing details like using batch statistics for the forward pass without explicit instruction, and it correctly executed the full forward and backward propagation steps. It\u2019s unclear whether it derived the math itself or simply recalled a learned pattern, but either way, it achieved the correct result. However, when asked to modify the fully connected network to include dropout, it completely failed where it essentially reprinted the same model without incorporating dropout at all, as if it didn\u2019t register the change request. This suggests Gemini\u2019s weakness in applying structural modifications to existing code, especially when they require integrating a new mechanism into a preexisting design. It seems more comfortable regenerating code from scratch than adapting it thoughtfully.</paragraph><paragraph>For the spatial batch normalization section, Gemini\u2019s inline import was technically correct but unnecessary where a habit that made the code less clean and showed an overreliance on re-importing modules. The implementation itself worked, but the approach was not the smoothest and not very well thought before it gave me the code in the chat. Similarly, in the CNN design question, the model it proposed was overly shallow and minimalistic for CIFAR-scale data. While Gemini was very receptive to feedback and quickly acknowledged that a deeper network would be better, it didn\u2019t independently propose parameter or structural improvements, indicating limited architectural creativity. I suggested it use another convolution layer to pick up more information and it followed instructions well but didn\u2019t demonstrate the capacity to think beyond them.</paragraph><paragraph>Overall, Gemini was accurate, stable, and efficient for standard or moderately complex neural network tasks, especially those that map directly to known architectures or formulas. It showed good conceptual understanding and a strong ability to produce syntactically correct code on the first try. However, it lacked flexibility and creative reasoning when the task demanded architectural innovation or modification of existing code. It\u2019s great at execution and explanation, but not yet capable of adapting in nuanced, design-heavy tasks where intuition and experimentation matter most.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T16:42:20.35258+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7132324,
            "author": "Srikar Babu Gadipudi",
            "project_title": "Special Participation A: HW 4 using DeepSeek",
            "post_body": "Problem Context\n\nThere are 5 non-coding questions in this homework. Two questions on optimization (specifically Newton-Schultz iteration and MuP scaling) and three questions on CNNs. I took a special interest in how DeepSeek performs when solving these computationally heavy problems when prompted in different formats: purely text, purely images, a PDF and a hybrid of text and images. I also tested DeepSeek's ability to understand and retain multi-part instructions in between these different modalities. The idea was to evaluate DeepSeek's overall problem-solving performance while also attempting to understand which prompt type yielded the best results. \n\nIn this experiment:\n\nDeepSeek solved four out of five questions correctly in a single attempt.\n\nQuestion 2 was the only one it got wrong, though it could solve it with further prompting.\n\nQuestion 3 required a brief nudge from me to complete the final computation, likely because the context limit was reached mid-session.\n\nExecutive Summary\n\nFrom testing out different formats of the prompts, I observed the following:\n\nWhen only text was provided (Question 2), DeepSeek tended to lose context more easily. it sometimes failed to connect earlier parts of the questions or instructions.\n\nWith images or PDFs, it demonstrated significant better context retention and reasoning continuity. It appeared to process the questions more holistically, possibly due to the visual cues.\n\nA hybrid approach (text +images) also performed better. It was able to mix information from images and text efficiently to provide the correct solution (see Question 4).\n\nIn essence, DeepSeek performs impressively well on conceptual and numerical reasoning when the sufficient structured context is provided. Its performance, however, degraded slightly in purely textual prompts, indicating that context formatting plays a role in achieving accurate results.\n\nNote: This analysis is based on a limited sample of five questions, and is therefore not exhaustive or conclusive.\n\nHere is a link to the conversation I had with DeepSeek: https://chat.deepseek.com/share/jsuxr35m8bhnxyzz7b\n\nHere is the file containing the conversation, with question-wise comments (annotated in the PDF): ",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Problem Context</bold></paragraph><paragraph>There are 5 non-coding questions in this homework. Two questions on optimization (specifically Newton-Schultz iteration and MuP scaling) and three questions on CNNs. I took a special interest in how DeepSeek performs when solving these computationally heavy problems when <bold>prompted in different formats:</bold> purely text, purely images, a PDF and a hybrid of text and images. I also tested DeepSeek's ability to understand and retain multi-part instructions in between these different modalities. The idea was to evaluate DeepSeek's overall problem-solving performance while also attempting to understand which prompt type yielded the best results. </paragraph><paragraph>In this experiment:</paragraph><list style=\"bullet\"><list-item><paragraph>DeepSeek solved four out of five questions correctly in a single attempt.</paragraph></list-item><list-item><paragraph>Question 2 was the only one it got wrong, though it could solve it with further prompting.</paragraph></list-item><list-item><paragraph>Question 3 required a brief nudge from me to complete the final computation, likely because the context limit was reached mid-session.</paragraph></list-item></list><paragraph><bold>Executive Summary</bold></paragraph><paragraph>From testing out different formats of the prompts, I observed the following:</paragraph><list style=\"bullet\"><list-item><paragraph>When only text was provided (Question 2), DeepSeek tended to lose context more easily. it sometimes failed to connect earlier parts of the questions or instructions.</paragraph></list-item><list-item><paragraph>With images or PDFs, it demonstrated significant better context retention and reasoning continuity. It appeared to process the questions more holistically, possibly due to the visual cues.</paragraph></list-item><list-item><paragraph>A hybrid approach (text +images) also performed better. It was able to mix information from images and text efficiently to provide the correct solution (see Question 4).</paragraph></list-item></list><paragraph>In essence, DeepSeek performs impressively well on conceptual and numerical reasoning when the sufficient structured context is provided. Its performance, however, degraded slightly in purely textual prompts, indicating that context formatting plays a role in achieving accurate results.</paragraph><paragraph><bold>Note:</bold> This analysis is based on a limited sample of five questions, and is therefore not exhaustive or conclusive.</paragraph><paragraph>Here is a link to the conversation I had with DeepSeek: <link href=\"https://chat.deepseek.com/share/jsuxr35m8bhnxyzz7b\">https://chat.deepseek.com/share/jsuxr35m8bhnxyzz7b</link></paragraph><paragraph>Here is the file containing the conversation, with question-wise comments (annotated in the PDF): </paragraph><file url=\"https://static.us.edusercontent.com/files/o3Zt9CHGvmcfvWwfdgVQKVN1\" filename=\"participationA_HW4_DeepSeek.pdf\"/></document>",
            "links": [
                "https://chat.deepseek.com/share/jsuxr35m8bhnxyzz7b"
            ],
            "attachments": [],
            "created_at": "2025-10-15T10:18:16.802913+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7130547,
            "author": "Kevin Frans",
            "project_title": "Correction to HW3 Q2 Solution",
            "post_body": "Hi, as some of you have discovered on your own, there was a mistake in the solutions to HW3 Q2, specifically, question (d) about implementing muP via per-weight multipliers on the forwards pass. \n\nThe full correct solution is:\n\nclass ScaledMLP(nn.Module):\n    def __init__(self, input_size=784, hidden_sizes = [8, 16, 32, 64, 128], num_classes=10):\n        super(ScaledMLP, self).__init__()\n        all_hidden_sizes = [input_size] + hidden_sizes + [num_classes]\n        self.layers = nn.ModuleList()\n        for i in range(len(all_hidden_sizes)-1):\n            self.layers.append(nn.Linear(all_hidden_sizes[i], all_hidden_sizes[i+1], bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n        ## Rescale weight initializations to account for pre-activation scaling\n        with torch.no_grad():\n            for layer in self.layers:\n                layer.weight.mul_(layer.weight.shape[1])\n        ##\n\n    def forward(self, x):\n        activations = []\n        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 28*28)\n        for layer in self.layers[:-1]:\n            x = layer(x)\n            ## TODO\n            p_shape = layer.weight.shape\n            x = x / p_shape[1] \n            ##\n            x = self.sigmoid(x)\n            activations.append(x)\n        x = self.layers[-1](x)\n        activations = activations[1:]\n        return x, [a.detach() for a in activations]\n\ntrain_one_step(mlp=ScaledMLP, optimizer=SimpleAdam)\n\n\nThe previous solution contained x * p_shape[1] instead of x / p_shape[1]. In addition, when we utilize division to scale down the effect of applying an update, we need to also scale up the parameter initialization (so the compute graph at step 0 is identical).\n\nThank you to the various students who brought up this question during office hours -- your confusion was correct!\n\nWe've also updated the solution in #104 to reflect this change. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi, as some of you have discovered on your own, there was a mistake in the solutions to HW3 Q2, specifically, question (d) about implementing muP via per-weight multipliers on the forwards pass. </paragraph><paragraph>The full correct solution is:</paragraph><pre>class ScaledMLP(nn.Module):\n    def __init__(self, input_size=784, hidden_sizes = [8, 16, 32, 64, 128], num_classes=10):\n        super(ScaledMLP, self).__init__()\n        all_hidden_sizes = [input_size] + hidden_sizes + [num_classes]\n        self.layers = nn.ModuleList()\n        for i in range(len(all_hidden_sizes)-1):\n            self.layers.append(nn.Linear(all_hidden_sizes[i], all_hidden_sizes[i+1], bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n        ## Rescale weight initializations to account for pre-activation scaling\n        with torch.no_grad():\n            for layer in self.layers:\n                layer.weight.mul_(layer.weight.shape[1])\n        ##\n\n    def forward(self, x):\n        activations = []\n        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 28*28)\n        for layer in self.layers[:-1]:\n            x = layer(x)\n            ## TODO\n            p_shape = layer.weight.shape\n            x = x / p_shape[1] \n            ##\n            x = self.sigmoid(x)\n            activations.append(x)\n        x = self.layers[-1](x)\n        activations = activations[1:]\n        return x, [a.detach() for a in activations]\n\ntrain_one_step(mlp=ScaledMLP, optimizer=SimpleAdam)\n</pre><paragraph>The previous solution contained <code>x * p_shape[1]</code> instead of <code>x / p_shape[1]</code>. In addition, when we utilize division to scale down the effect of applying an update, we need to also scale up the parameter initialization (so the compute graph at step 0 is identical).<break/><break/>Thank you to the various students who brought up this question during office hours -- your confusion was correct!</paragraph><paragraph>We've also updated the solution in #104 to reflect this change. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-15T06:31:21.604832+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7124383,
            "author": "Anders Vestrum",
            "project_title": "Special Participation B: Mistral on HW4",
            "post_body": "This report summarizes my work with Mistral on HW4 coding problems. Mistral initially struggled with strict coding constraints (Problem 5) but quickly adapted and produced correct minimal code. It handled dataset setup, training, and loader tasks effectively, and excelled in hyperparameter tuning through iterative feedback.\n\nIts written explanations showed strong conceptual understanding of CNNs, covering topics like inductive bias, domain shift, and model behavior on permuted images.\n\nKey Points\n\nMinor issues in Problem 5 (strict coding constraints), mostly smooth completion elsewhere.\n\nHyperparameter tuning and conceptual explanations were particularly strong.",
            "content_xml": "<document version=\"2.0\"><paragraph>This report summarizes my work with Mistral on HW4 coding problems. Mistral initially struggled with strict coding constraints (Problem 5) but quickly adapted and produced correct minimal code. It handled dataset setup, training, and loader tasks effectively, and excelled in hyperparameter tuning through iterative feedback.</paragraph><paragraph>Its written explanations showed strong conceptual understanding of CNNs, covering topics like inductive bias, domain shift, and model behavior on permuted images.</paragraph><paragraph>Key Points</paragraph><list style=\"bullet\"><list-item><paragraph>Minor issues in Problem 5 (strict coding constraints), mostly smooth completion elsewhere.</paragraph></list-item></list><list style=\"bullet\"><list-item><paragraph>Hyperparameter tuning and conceptual explanations were particularly strong.</paragraph></list-item></list><file url=\"https://static.us.edusercontent.com/files/0ovt32aAieyxJcE42yryMUSQ\" filename=\"special_participation_B.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-14T07:29:06.012043+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7116236,
            "author": "Sultan Daniels",
            "project_title": "HW6 Q6: Implementing Muon (Coding Question)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/UqlocaiKiDfgeXKx3CZsWH57\" width=\"658\" height=\"776.9741697416974\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-12T17:50:19.135949+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7116232,
            "author": "Sultan Daniels",
            "project_title": "HW6 Q5: Zachary\u2019s Karate Club (Coding)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/eRDymoeUpXy4ePS3bFyEp4Zq\" width=\"658.0000000000001\" height=\"697.803402646503\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/3J9NAknDQQUfI5P3cVVFHTaT\" width=\"643\" height=\"446.63473053892216\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-12T17:48:50.64531+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7116227,
            "author": "Sultan Daniels",
            "project_title": "HW6 Q4: Exploring Deep Learning Tooling",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/0YU5ifNvyCbS6SlfjObvZEWX\" width=\"658\" height=\"414.527514231499\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-12T17:46:37.20113+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7116225,
            "author": "Sultan Daniels",
            "project_title": "HW6 Q3: Graph Neural Networks",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/UknmM7SI2gQB2rpCvfQm5fbE\" width=\"658\" height=\"488.19354838709677\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/MMkQKlWVRF4AxpzU7GQlZJrE\" width=\"643\" height=\"774.1465346534653\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-12T17:45:28.027302+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7116221,
            "author": "Sultan Daniels",
            "project_title": "HW6 Q2: Graph Dynamics and GNN Concepts",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/dN9xe6HyhNbq3WcavfLtnwyR\" width=\"658\" height=\"204.48615384615385\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/cuMWMvIPL3xbsxhigEEcsf2P\" width=\"658\" height=\"844.7297297297298\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/XziMeA2oRF6TUwDvU3429sgs\" width=\"643\" height=\"803.75\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/9d8WRXvJ1etOXEMM4g68fWJt\" width=\"643\" height=\"393.171974522293\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-12T17:43:42.238937+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7116214,
            "author": "Sultan Daniels",
            "project_title": "HW6 Q1: Memory considerations when using GPUs (Coding Question)",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/7zOoaaD9tOYQLwmnoRVVWCkf\" width=\"658\" height=\"494.042904290429\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-12T17:39:15.115165+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7111658,
            "author": "Iana Lin",
            "project_title": "Special Participation A - HW 3 ChatGPT 5",
            "post_body": "Executive Summary\n\nI used ChatGPT 5 to interactively engage with HW 3's problems and get it to get to the correct answer. While this wasn't the first time I've interacted with ChatGPT 5 for Deep Learning material, I was still impressed with its performance. The majority of questions were one-shotted correctly.\n\n1: Maximal Update Parameterization: \n\nSuccessfully one shotted, reasoning good.\n\n3: Maximal Update Parameterization Research:\n\nWhen interpreting figure 1, ChatGPT 5's explanation of the visual figure was actually more informative and explanatory than the official solutions were. It critically highlighted that \"each layer\u2019s updates remain of the same order regardless of width\"\n\nRather than using the RMS-to-RMS matrix norm that we covered in lecture (scaled version of spectral norm), it hallucinated the definition of the RMS matrix norm. It defined it as if the matrix was unrolled into a vector and then the RMS norm of that flattened vector was taken, \n\n$$\\frac{\\left\\lVert W\\right\\rVert_F}{\\sqrt{n_{l-1}n_l}}$$\n\nAs a result, it used this relation (that it claimed applies to random matrices)\n\n\n$$\u2225W_l\u2225_2\\approx\\frac{\u2225W_l\u2225_F}{\\sqrt{\\left\\{\\min(n_l,n_{l-1})\\right\\}}}$$\n\nto derive the incorrect order for the weight matrix and update's RMS norms.\n\nWhile it made this error, ChatGPT 5 was still able to correctly derive the upper bounds in Desideratum 1 (because it didn't use the RMS norms of hidden layer vector/update or weight matrix/update for its derivation). This is not that surprising given that I fed in the \"A Spectral Condition for Feature Learning\" pdf at the beginning of the chat and ChatGPT produced a very similar derivation. Additionally, it was still able to correctly identified the key assumption that allowed for the derivation of the lower bound.\n\nAdditionally, after providing the definition of the induced norm, it was able to correctly derive the  order for the weight matrix and update's RMS norms.\n\n4: Policy Gradient and the Reparameterization Gradient Estimator:\n\n Overall, ChatGPT5 seemed to provide comprehensive reasoning (and more additional information/context) and got to the correct solutions. \n\n5: Tensor Rematerialization:\nChatGPT 5 at first guessed 2 loadmems instead of 10 (thinking once a layer was loaded, it would stay in memory for the next layer). After I reiterated the problem statement, it was easily able to answer and explain the total number of loadmems as 10.\n\nOther than that, it was able to provide sound reasoning and the correct answers for the rest of the problem\n\nOverall:\nChatGPT seemed to provide comprehensive reasoning for every problem (sometimes an unnecessary amount), and seemed to be able to course-correct with a little bit of feedback. It seemed to falter more on topics or ideas that had less public material available online (e.g. RMS-RMS matrix norm)",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>I used ChatGPT 5 to interactively engage with HW 3's problems and get it to get to the correct answer. While this wasn't the first time I've interacted with ChatGPT 5 for Deep Learning material, I was still impressed with its performance. The majority of questions were one-shotted correctly.</paragraph><paragraph><underline>1: Maximal Update Parameterization</underline>: </paragraph><paragraph>Successfully one shotted, reasoning good.</paragraph><paragraph><underline>3: Maximal Update Parameterization Research</underline>:</paragraph><paragraph>When interpreting figure 1, ChatGPT 5's explanation of the visual figure was actually more informative and explanatory than the official solutions were. It critically highlighted that \"each layer\u2019s updates remain of the same order regardless of width\"</paragraph><paragraph>Rather than using the RMS-to-RMS matrix norm that we covered in lecture (scaled version of spectral norm), it hallucinated the definition of the RMS matrix norm. It defined it as if the matrix was unrolled into a vector and then the RMS norm of that flattened vector was taken, </paragraph><math>\\frac{\\left\\lVert W\\right\\rVert_F}{\\sqrt{n_{l-1}n_l}}</math><paragraph>As a result, it used this relation (that it claimed applies to random matrices)<break/></paragraph><math>\u2225W_l\u2225_2\\approx\\frac{\u2225W_l\u2225_F}{\\sqrt{\\left\\{\\min(n_l,n_{l-1})\\right\\}}}</math><paragraph>to derive the incorrect order for the weight matrix and update's RMS norms.<break/><break/>While it made this error, ChatGPT 5 was still able to correctly derive the upper bounds in Desideratum 1 (because it didn't use the RMS norms of hidden layer vector/update or weight matrix/update for its derivation). This is not that surprising given that I fed in the \"A Spectral Condition for Feature Learning\" pdf at the beginning of the chat and ChatGPT produced a very similar derivation. Additionally, it was still able to correctly identified the key assumption that allowed for the derivation of the lower bound.<break/><break/>Additionally, after providing the definition of the induced norm, it was able to correctly derive the  order for the weight matrix and update's RMS norms.</paragraph><paragraph><underline>4: Policy Gradient and the Reparameterization Gradient Estimator</underline>:</paragraph><paragraph> Overall, ChatGPT5 seemed to provide comprehensive reasoning (and more additional information/context) and got to the correct solutions. </paragraph><paragraph><underline>5: Tensor Rematerialization</underline>:<break/>ChatGPT 5 at first guessed 2 loadmems instead of 10 (thinking once a layer was loaded, it would stay in memory for the next layer). After I reiterated the problem statement, it was easily able to answer and explain the total number of loadmems as 10.<break/><break/>Other than that, it was able to provide sound reasoning and the correct answers for the rest of the problem</paragraph><paragraph><bold>Overall</bold>:<break/>ChatGPT seemed to provide comprehensive reasoning for every problem (sometimes an unnecessary amount), and seemed to be able to course-correct with a little bit of feedback. It seemed to falter more on topics or ideas that had less public material available online (e.g. RMS-RMS matrix norm)</paragraph><file url=\"https://static.us.edusercontent.com/files/6R4M2iy4LV8vlsb0kHIiaROd\" filename=\"ParticipationA-HW3.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-11T14:07:05.580704+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7110289,
            "author": "Hong Joey",
            "project_title": "Discussion 6 Solutions",
            "post_body": "Attached are the questions and solutions for discussion 6:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are the questions and solutions for discussion 6:</paragraph><file url=\"https://static.us.edusercontent.com/files/zKSePwcxBLJgltcRBreTHHtv\" filename=\"dis06_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/muZvuV13Yt1iIGyNE3ObxedA\" filename=\"dis06_solution.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-11T08:52:16.473292+11:00",
            "category": "Sections"
        },
        {
            "guid": 7107719,
            "author": "Jordan Argel",
            "project_title": "Special Participation B: HW 4",
            "post_body": "Executive Summary\n\nI worked with Deepseek on coding questions 5 and 6 of HW 4. For the most part, Deepseek was able to tackle the coding questions with no problems, nearly one-shotting all of them. However, due to its lack of vision beyond texts, Deepseek is not really good at making visual observations. This gave Deepseek a little bit of trouble answering a couple of the written questions, as it had to rely on general knowledge it had on CNNs and MLPs. As for parameter tuning problems, DeepSeek did a good job getting the user started, but the users will most of the time have to tune the parameters themselves and use trial-and-error until the specs are met. On the other hand, DeepSeek does a good job at explaining key concepts, simplifying them, and explaining how a function runs line by line. This shows that DeepSeek is a good tool for users to use in debugging, but also that it needs a lot of context in its prompts to ensure it outputs accurate results. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>I worked with Deepseek on coding questions 5 and 6 of HW 4. For the most part, Deepseek was able to tackle the coding questions with no problems, nearly one-shotting all of them. However, due to its lack of vision beyond texts, Deepseek is not really good at making visual observations. This gave Deepseek a little bit of trouble answering a couple of the written questions, as it had to rely on general knowledge it had on CNNs and MLPs. As for parameter tuning problems, DeepSeek did a good job getting the user started, but the users will most of the time have to tune the parameters themselves and use trial-and-error until the specs are met. On the other hand, DeepSeek does a good job at explaining key concepts, simplifying them, and explaining how a function runs line by line. This shows that DeepSeek is a good tool for users to use in debugging, but also that it needs a lot of context in its prompts to ensure it outputs accurate results. </paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/FmLaweUH2PTr7huFaPeTupEZ\" filename=\"cs182_hw4_q6_deepseek.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ED1XnYsZ9aK1awfafhSSknlh\" filename=\"cs182_hw4_q5_deepseek.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-11T01:15:09.787674+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7105095,
            "author": "Hong Joey",
            "project_title": "Make-up Office Hour for Friday 3-4pm in 531 Cory",
            "post_body": "Hi all,\n\nApologies to those who came this Tuesday for OH from 6-7pm. I did not plan my commute well and arrived very late, and it looks like I missed quite a few people because of it. To make up for it, I will be hosting office hours this Friday (10/10) from 3-4pm in 531 Cory right after the newly added one. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all,</paragraph><paragraph>Apologies to those who came this Tuesday for OH from 6-7pm. I did not plan my commute well and arrived very late, and it looks like I missed quite a few people because of it. To make up for it, I will be hosting office hours this Friday (10/10) from 3-4pm in 531 Cory right after the newly added one. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-10T10:25:18.703499+11:00",
            "category": "Admin"
        },
        {
            "guid": 7104957,
            "author": "Tianhao Qian",
            "project_title": "Special Participation B: Qwen3-Max on HW2",
            "post_body": "Qwen3-MAX's answer:\n\nDialogue:\n\nIntro:\n\nI'm using Qwen3-MAX to solve the coding part of HW2, including three IPython notebooks. Notably, we can't use deep thinking mode for Qwen3-MAX because it's unavailable for this model.\n\nMy prompts:\n\n1. Please help me deal with these problems about deep neural networks. Think it step by step.\n\n<answer>(Which problem or section would you like to tackle first?)\n\n2. All of the problems. Plz, start from one PDF then others\n\n<answer> (Given the solution of notebooks 1)\n\n3. Yes. Go ahead.\n\n<answer> (Given the solution of notebooks 2)\n\n4. Yes.\n\n<answer>(Given the solution of notebooks 3)\n\nMy observation:\n\n1.  Qwen3-MAX doesn't show consistency between the code tip and the actual variable name. The following figures are the code and LLM's answer, respectively.\n\n\n\nWe can see that the code tip uses the correct word 'principal' instead of 'principle', while the variable name 'principle_feature' is given mistakenly. However, the code given by Qwen3-MAX uses the word 'principal' instead of 'principle', indicating that it is unable to clarify what really matters in coding.\n\n2. Qwen3-MAX tends to generate the solution in its own way, ignoring the code tip. As is often the case, generated code ignores the parameters of the function and even modifies the code, which is not allowed. An example is given in the following figures: \n\nPrompt: Plz, use delta in the function q_grad_step\n\nThe generated code ignores the parameter delta.\n\n\nPrompt: At the same time, maintain tx and ty.\n\nThen, although I told it that beside delta, it should maintain tx and ty. But the result showed that it just changed to another way of realizing this function instead of including delta, dx, and dy inside the function. \n\n\nPrompt: Please use tx, ty, and delta.\n\nOnly when I explicitly told it to use tx, ty and delta, it gave the correct code. \n\nFrom my perspective, Qwen3-MAX just used a standard template to give the classic/simple solution, the mode that was pre-trained beforehand. Therefore, even though I can't illustrate the ignoring behavior(ignoring the code tip),  Qwen3-MAX tends to use its own coding style.\n\n\n3.  Qwen3-MAX only answers coding questions, but not conceptual questions inside PDF. Remember that the prompts ask the model to deal with questions, but not coding questions. \n\nPerhaps it's due to model training bias: The model was trained more on code-completion tasks and therefore prefers giving code-like solutions.\n\nBut I'm curious whether it's just because, when reading the PDF, the model recognized that the task leans toward code generation and therefore pre-determined that it only needed to solve the code-generation part. \n\n\n\n4. There is another strange observation: Even if I don't give the \u2018\u2019model.py\u2018\u2019, for example, if I ask the model to realize a certain part in \"model.py\", it always gives one solution instead of requesting the original files of \"model.py\", which is significantly important for the model to know what they need and what they don't need so that the result given by LLMs is plausible and reliable. In this way, Qwen3-MAX lacks uncertainty awareness.\n\n\n\nI think, if we aim to utilize Qwen3-MAX to help with coding problems, we should be careful with these 4 aspects, which can be solved by detailed prompts.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Qwen3-MAX's answer:</paragraph><file url=\"https://static.us.edusercontent.com/files/B7K1jJBzxWs8Vlj0O38UYoA0\" filename=\"Qwen4HW2.pdf\"/><paragraph>Dialogue:</paragraph><file url=\"https://static.us.edusercontent.com/files/hJmjn7jcEaBp4kKA8hO8t30w\" filename=\"Qwen3-MAX.pdf\"/><paragraph><bold>Intro:</bold><break/><break/>I'm using Qwen3-MAX to solve the coding part of HW2, including three IPython notebooks. Notably, we can't use deep thinking mode for Qwen3-MAX because it's unavailable for this model.</paragraph><paragraph><bold>My prompts:</bold></paragraph><paragraph>1. Please help me deal with these problems about deep neural networks. Think it step by step.</paragraph><paragraph>&lt;answer&gt;(Which problem or section would you like to tackle first?)</paragraph><paragraph>2. All of the problems. Plz, start from one PDF then others</paragraph><paragraph>&lt;answer&gt; (Given the solution of notebooks 1)</paragraph><paragraph>3. Yes. Go ahead.</paragraph><paragraph>&lt;answer&gt; (Given the solution of notebooks 2)</paragraph><paragraph>4. Yes.</paragraph><paragraph>&lt;answer&gt;(Given the solution of notebooks 3)</paragraph><paragraph><bold>My observation:</bold></paragraph><paragraph>1.  Qwen3-MAX doesn't show consistency between the code tip and the actual variable name. The following figures are the code and LLM's answer, respectively.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/iqxVDWoT8FSmcP1cZ6OP58E9\" width=\"307\" height=\"113.53550295857988\"/></figure><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/PHZnKYOhUnk5E13SKTZO0kBQ\" width=\"323\" height=\"88\"/></figure><paragraph>We can see that the code tip uses the correct word 'principal' instead of 'principle', while the variable name 'principle_feature' is given mistakenly. However, the code given by Qwen3-MAX uses the word 'principal' instead of 'principle', indicating that it is <bold>unable to clarify</bold> <bold>what really matters in coding</bold>.</paragraph><paragraph>2. Qwen3-MAX tends to generate the solution in its own way, ignoring the code tip. As is often the case, generated code ignores the parameters of the function and even modifies the code, which is not allowed. An example is given in the following figures: </paragraph><paragraph>Prompt: Plz, use delta in the function q_grad_step</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/Jz1IRrt63zSrL7XbsRBbQBce\" width=\"307\" height=\"114.86394557823128\"/></figure><paragraph>The generated code ignores the parameter <bold>delta</bold>.</paragraph><paragraph><break/>Prompt: At the same time, maintain tx and ty.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/5IjlQrZ1OfMbxxdW0TopKaia\" width=\"307\" height=\"142.95419847328245\"/></figure><paragraph>Then, although I told it that beside <bold>delta</bold>, it should maintain <bold>tx</bold> and <bold>ty</bold>. But the result showed that it just changed to another way of realizing this function instead of including <bold>delta</bold>, <bold>dx,</bold> and <bold>dy</bold> inside the function. </paragraph><paragraph><break/>Prompt: Please use tx, ty, and delta.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/XQiOj4rdmOTkSbSq5uLFWvTz\" width=\"307\" height=\"198.3204134366925\"/></figure><paragraph>Only when I explicitly told it to use <bold>tx</bold>, <bold>ty</bold> and <bold>delta</bold>, it gave the correct code. </paragraph><paragraph>From my perspective, Qwen3-MAX just used a standard template to give the classic/simple solution, the mode that was pre-trained beforehand. Therefore, even though I can't illustrate the ignoring behavior(ignoring the code tip),  Qwen3-MAX tends to <bold>use its own coding style.</bold></paragraph><paragraph><break/>3.  Qwen3-MAX only answers coding questions, but not conceptual questions inside PDF. Remember that the prompts ask the model to deal with questions, but not coding questions. </paragraph><paragraph>Perhaps it's due to <bold>model training bias</bold>: The model was trained more on code-completion tasks and therefore prefers giving code-like solutions.</paragraph><paragraph>But I'm curious whether it's just because, when reading the PDF, the model recognized that the task <bold>leans toward code generation</bold> and therefore pre-determined that it only needed to solve the code-generation part. </paragraph><paragraph/><paragraph>4. There is another strange observation: Even if I don't give the \u2018\u2019model.py\u2018\u2019, for example, if I ask the model to realize a certain part in \"model.py\", it always gives one solution instead of requesting the original files of \"model.py\", which is significantly important for the model to know what they need and what they don't need so that the result given by LLMs is <bold>plausible and reliable.</bold> In this way, Qwen3-MAX lacks <bold>uncertainty awareness</bold>.</paragraph><paragraph/><paragraph>I think, if we aim to utilize Qwen3-MAX to help with coding problems, we should be careful with these 4 aspects, which can be solved by detailed prompts.</paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-10T10:02:56.629461+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7104948,
            "author": "Anant Sahai",
            "project_title": "Lecture 12 Thread",
            "post_body": "Use this thread to ask questions about GNNs. \n\nNote: You will observe that there is a difference between the coverage here and the coverage in Chapter 13 of the Prince textbook. However, you should be able to understand the textbook's coverage with respect to most of the things there that were not in lecture. The most important omission from lecture (from a practical standpoint as well as conceptual interest) is 13.7.1 where some strategies for dealing graphs too big to hold in memory are discussed. The second most important is 13.9 where thinking about edges is discussed with a simple approach. \n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/kFri7534RRAJaFIT9Xe9nobV\" filename=\"Lecture 12.pdf\"/><paragraph>Use this thread to ask questions about GNNs. </paragraph><paragraph>Note: You will observe that there is a difference between the coverage here and the coverage in Chapter 13 of the Prince textbook. However, you should be able to understand the textbook's coverage with respect to most of the things there that were not in lecture. The most important omission from lecture (from a practical standpoint as well as conceptual interest) is 13.7.1 where some strategies for dealing graphs too big to hold in memory are discussed. The second most important is 13.9 where thinking about edges is discussed with a simple approach. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-10T10:02:07.936619+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7097283,
            "author": "Anant Sahai",
            "project_title": "Friday 2-3pm GSI Office Hour Added in 531 Cory",
            "post_body": "As announced in Lecture, the last Tuesday GSI Office Hour was cancelled due to low attendance and has been moved to Friday 2-3pm in response to student requests for Friday office hours.\n\nYou are encouraged to attend with HW or discussion-related questions, or to just find others to work alongside. You don't have to have a question to attend office hours.",
            "content_xml": "<document version=\"2.0\"><paragraph>As announced in Lecture, the last Tuesday GSI Office Hour was cancelled due to low attendance and has been moved to Friday 2-3pm in response to student requests for Friday office hours.</paragraph><paragraph>You are encouraged to attend with HW or discussion-related questions, or to just find others to work alongside. You don't have to have a question to attend office hours.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-09T07:09:25.97416+11:00",
            "category": "Admin"
        },
        {
            "guid": 7095749,
            "author": "Tianhao Qian",
            "project_title": "Special Participation A: - Deepseek on HW1",
            "post_body": "Intro:\nI'm using Deepseek to solve HW1, including 7 problems.\n\nMy prompts:\n\n1. Please help me deal with these problems about deep neural networks. Think it step by step.\n\n<answer> (Given the solution of Problem 1)\n\n2. You have done a good job! What about the remaining problems? Think it step by step.\n\n<answer> (Given the solution of Problem 2)\n\n3.  Yes, proceed with Problem 3 about momentum.\n\n<answer>(Given the solution of Problem 3)\n\n4. Plz, continue.\n<answer>(Given the solution of Problem 4-7)\n\nMy observation:\n\n1. When the thinking and answer content was too long, DeepSeek only answered a part of the problems, probably due to the chunking technique and LLM's inclination to output shorter contents. So that's why there're 4 prompts for HW1.\n\n2. The accuracy is very high, especially for the computational tasks. However, If format of the question is not ordinary, it will be ignored sometimes, such as 4(a).\n\nI don't know whether it can be called \"hallucination\", but actually in the thinking content, it indeed notices this task but considers 4(a) internally without giving the solution: \n\n3. A serious problem occurs that at times, Deepseek will unnoticeably make an assumption, even if there is no information about it. This problem fails the COT(Chain of Thought) if the assumption is not expected, leading to the wrong answer. More seriously, if the users don't look through the process of thinking, they may heartily accept the answer, but the conflict is that the thinking content is too long to read.\n\n4. Deepseek fails to perfectly answer ambiguous questions, such as 2(c).  It seems that it tends to give a conceptual, verbal description, if possible. It can be seen as a kind of laziness from my perspective.\n\nLet's first compare the standard answer and Deepseek's answer:\n\nStandard\uff1a \n\nDeepseek:\n\nAlthough the two solutions points to the same conclusion, Deepseek's answer is quite short. I guessed that Deepseek mixed up the identity of reader. Therefore, I asked it to rewrite the solution with different identity prompting:\n\n--------------\n\nPrompt1:\n\nYou are a student doing the assignment. Please rewrite Question 2(c).\n\nPrompt2:\n\nThe professor will read your solution! Please rewrite Question 2(c).\n\n--------------\n\nBut the result shows that Deepseek still gives conceptual answers, only adding more description. Only when I mentioned 'calculation' externally, It does work. \n\n\n\nRecommendation:\n\nFor Observation 1: \n\nIf there's no question number, the chunking will be unpredictable. Therefore , I recommend managing long problems with explicit chunking by yourself.\n\nFor Observation 2:\n\nI don't know how to solve this problem. I think reducing the use of table may help.\n\nFor Observation 3:\n\nRequire DeepSeek to state assumptions explicitly. But sometimes, the reasoning chain will be too long so that perhaps looking through it by yourself is also another good choice. \n\nFor Observation 4:\n\nHandle ambiguity with targeted instruction.\n\n\n\n\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/9b87UXPWxoGpSeJ24LygVVjq\" filename=\"Deepseek4HW1.pdf\"/><paragraph><bold>Intro:</bold><break/>I'm using Deepseek to solve HW1, including 7 problems.</paragraph><paragraph><bold>My prompts:</bold></paragraph><paragraph>1. Please help me deal with these problems about deep neural networks. Think it step by step.</paragraph><paragraph>&lt;answer&gt; (Given the solution of Problem 1)</paragraph><paragraph>2. You have done a good job! What about the remaining problems? Think it step by step.</paragraph><paragraph>&lt;answer&gt; (Given the solution of Problem 2)</paragraph><paragraph>3.  Yes, proceed with Problem 3 about momentum.</paragraph><paragraph>&lt;answer&gt;(Given the solution of Problem 3)</paragraph><paragraph>4. Plz, continue.<break/>&lt;answer&gt;(Given the solution of Problem 4-7)</paragraph><paragraph><bold>My observation:</bold></paragraph><paragraph>1. When the thinking and answer content was too long, DeepSeek only answered a part of the problems, probably due to the chunking technique and LLM's inclination to output shorter contents. So that's why there're 4 prompts for HW1.</paragraph><paragraph>2. The accuracy is very high, especially for the computational tasks. However, If format of the question is not ordinary, it will be ignored sometimes, such as 4(a).</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/4gaMWC7UD8nXyOnM3NdmjUgz\" width=\"591\" height=\"300.5084745762712\"/></figure><paragraph>I don't know whether it can be called \"hallucination\", but actually in the thinking content, it indeed notices this task but considers 4(a) internally without giving the solution: </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/iCaLmR7icGptJdGhkqtigVWv\" width=\"590.9999999999999\" height=\"425.21298701298696\"/></figure><paragraph>3. A serious problem occurs that at times, Deepseek will unnoticeably make an assumption, even if there is no information about it. This problem fails the COT(Chain of Thought) if the assumption is not expected, leading to the wrong answer. More seriously, if the users don't look through the process of thinking, they may heartily accept the answer, but the conflict is that the thinking content is too long to read.</paragraph><paragraph>4. Deepseek fails to perfectly answer ambiguous questions, such as 2(c).  It seems that it tends to give a conceptual, verbal description, if possible. It can be seen as a kind of laziness from my perspective.</paragraph><paragraph>Let's first compare the standard answer and Deepseek's answer:</paragraph><paragraph><bold>Standard\uff1a</bold> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/mguN0hFf7dt6fzH44ncKs96l\" width=\"591\" height=\"638.4187866927593\"/></figure><paragraph><bold>Deepseek:</bold></paragraph><figure><image src=\"https://static.us.edusercontent.com/files/kDsSDD3Auy9y8bcXcfYsudll\" width=\"591\" height=\"107.60982658959537\"/></figure><paragraph>Although the two solutions points to the same conclusion, Deepseek's answer is quite short. I guessed that Deepseek mixed up the identity of reader. Therefore, I asked it to rewrite the solution with different identity prompting:</paragraph><paragraph>--------------</paragraph><paragraph><bold>Prompt1:</bold></paragraph><paragraph>You are a student doing the assignment. Please rewrite Question 2(c).</paragraph><paragraph><bold>Prompt2:</bold></paragraph><paragraph>The professor will read your solution! Please rewrite Question 2(c).</paragraph><paragraph>--------------</paragraph><paragraph>But the result shows that Deepseek still gives conceptual answers, only adding more description. Only when I mentioned 'calculation' externally, It does work. </paragraph><paragraph/><paragraph><bold>Recommendation:</bold></paragraph><paragraph>For Observation 1: </paragraph><paragraph>If there's no question number, the chunking will be unpredictable. Therefore , I recommend managing long problems with explicit chunking by yourself.</paragraph><paragraph>For Observation 2:</paragraph><paragraph>I don't know how to solve this problem. I think reducing the use of table may help.</paragraph><paragraph>For Observation 3:</paragraph><paragraph>Require DeepSeek to <bold>state assumptions explicitly</bold>. But sometimes, the reasoning chain will be too long so that perhaps looking through it by yourself is also another good choice. </paragraph><paragraph>For Observation 4:</paragraph><paragraph>Handle ambiguity with targeted instruction.</paragraph><paragraph/><paragraph/><paragraph/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-09T03:33:14.844297+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7094320,
            "author": "Anant Sahai",
            "project_title": "Lecture 11 Thread",
            "post_body": "This is for clarifying questions on Lecture 11 --- which finished up the conv-net material.\n\nThere was a very good question in office hours the answer to which has been added to the written pdf above but does not appear in the lecture video. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/7A0TMPr1qJOcgKwRz4NjxsNa\" filename=\"Lecture 11.pdf\"/><paragraph>This is for clarifying questions on Lecture 11 --- which finished up the conv-net material.</paragraph><paragraph>There was a very good question in office hours the answer to which has been added to the written pdf above but does not appear in the lecture video. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-08T16:55:02.320093+11:00",
            "category": "Lectures"
        },
        {
            "guid": 7092540,
            "author": "Andy Zhang",
            "project_title": "Special Participation E: Learning Mode as an Effective Step By Step Tutor",
            "post_body": "Special Participation E: Learning Mode as an Effective Step By Step Tutor\n\nGemini Learning Mode: https://g.co/gemini/share/4e1faf6d804c\n\nGemini Non-Learning Mode: https://g.co/gemini/share/c6ce8062f1d6\n\nChatGPT Learning Mode: https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36\n\nChatGPT Non-Learning Mode: https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78\n\nRecommendation:\n\nI would recommend fellow students to leverage Gemini / ChatGPT learning mode to go through problems in piece meal step by step fashion with a guided tutor. This may be helpful after completing a homework, noticing a discrepancy with the solutions, and deciding to go through the homework again with some guidance to build a stronger understanding. ChatGPT is more helpful if you\u2019re concerned about reward hacking, but Berkeley students have free Gemini Pro which may favor that since it\u2019s easy to hit usage limits with ChatGPT.\n\nThe learning modes are effective tools for breaking down problems into piecemeal parts, as opposed to generating the entire solution in one go.\n\nExecutive summary:\n\nI was interested in investigating the extent to which Guided Learning modes could help. I experimented with Gemini and ChatGPT which are the two models with learning modes available for free (in contrast, Claude\u2019s learning mode is not accessible). I tested two different problems on two different homework assignments for Gemini and ChatGPT, and experimented with learning and non-learning modes.\n\nFor Gemini Learning Mode, I was initially curious (1) to what extent it could help guide learning (2) whether it would break things down piece meal (3) how well it would handle latex formatting (4) whether it could produce new insights and (5) whether there would be reward hacking.\n\nI applied it to HW0 Vector Calculus Review a-e.\n\nFor (1-3) it performed admirably, though it did fail to format one part of one response. (4) was more of an issue; I prompted the model to \u201chelp me view the problem from the different lenses of vector calculus, and walk through both elementwise, rowwise, columnwise, and examples\u201d and it failed to do so.\n\n(5) is a significant concern. If you ask for the answer, it will provide it. In fact, simply asking \u201cFormatting messed up\u201d led to \u201cYou correctly calculated the three partial derivatives! That was the toughest part.\u201d\n\nMy observation is that guided learning is trained on successful learning traces and does not handle incorrect/out of distribution inputs well (and infers it as correct).\n\nAlso interestingly it converted the questions from a \u201cShow X = Y\u201d to \u201cWhat is derivative of X\u201d, which could be a plus or minus depending on your use case (in a way, not knowing the answer could be helpful).\n\nOne nice note is that after the problems were complete, it suggested additional questions, which may be useful for additional practice.\n\nIn contrast, Gemini directly answered all the parts when not in learning mode which could feel overwhelming.\n\nFor ChatGPT learning mode, it performed similarly to Gemini, though had the advantage of not simply giving the answer / getting reward hacked. However, Berkeley students have free Gemini Pro which may favor that since it\u2019s easy to hit usage limits with ChatGPT.\n\nSimilarly without learning mode, it answered all parts which could be overwhelming.",
            "content_xml": "<document version=\"2.0\"><paragraph>Special Participation E: Learning Mode as an Effective Step By Step Tutor</paragraph><paragraph>Gemini Learning Mode: <link href=\"https://g.co/gemini/share/4e1faf6d804c\">https://g.co/gemini/share/4e1faf6d804c</link></paragraph><paragraph>Gemini Non-Learning Mode: <link href=\"https://g.co/gemini/share/c6ce8062f1d6\">https://g.co/gemini/share/c6ce8062f1d6</link></paragraph><paragraph>ChatGPT Learning Mode: <link href=\"https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36\">https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36</link></paragraph><paragraph>ChatGPT Non-Learning Mode: <link href=\"https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78\">https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78</link></paragraph><paragraph>Recommendation:</paragraph><paragraph>I would recommend fellow students to leverage Gemini / ChatGPT learning mode to go through problems in piece meal step by step fashion with a guided tutor. This may be helpful after completing a homework, noticing a discrepancy with the solutions, and deciding to go through the homework again with some guidance to build a stronger understanding. ChatGPT is more helpful if you\u2019re concerned about reward hacking, but Berkeley students have free Gemini Pro which may favor that since it\u2019s easy to hit usage limits with ChatGPT.</paragraph><paragraph>The learning modes are effective tools for breaking down problems into piecemeal parts, as opposed to generating the entire solution in one go.</paragraph><paragraph>Executive summary:</paragraph><paragraph>I was interested in investigating the extent to which Guided Learning modes could help. I experimented with Gemini and ChatGPT which are the two models with learning modes available for free (in contrast, Claude\u2019s learning mode is not accessible). I tested two different problems on two different homework assignments for Gemini and ChatGPT, and experimented with learning and non-learning modes.</paragraph><paragraph>For Gemini Learning Mode, I was initially curious (1) to what extent it could help guide learning (2) whether it would break things down piece meal (3) how well it would handle latex formatting (4) whether it could produce new insights and (5) whether there would be reward hacking.</paragraph><paragraph>I applied it to HW0 Vector Calculus Review a-e.</paragraph><paragraph>For (1-3) it performed admirably, though it did fail to format one part of one response. (4) was more of an issue; I prompted the model to \u201chelp me view the problem from the different lenses of vector calculus, and walk through both elementwise, rowwise, columnwise, and examples\u201d and it failed to do so.</paragraph><paragraph>(5) is a significant concern. If you ask for the answer, it will provide it. In fact, simply asking \u201cFormatting messed up\u201d led to \u201cYou correctly calculated the three partial derivatives! That was the toughest part.\u201d</paragraph><paragraph>My observation is that guided learning is trained on successful learning traces and does not handle incorrect/out of distribution inputs well (and infers it as correct).</paragraph><paragraph>Also interestingly it converted the questions from a \u201cShow X = Y\u201d to \u201cWhat is derivative of X\u201d, which could be a plus or minus depending on your use case (in a way, not knowing the answer could be helpful).</paragraph><paragraph>One nice note is that after the problems were complete, it suggested additional questions, which may be useful for additional practice.</paragraph><paragraph>In contrast, Gemini directly answered all the parts when not in learning mode which could feel overwhelming.</paragraph><paragraph>For ChatGPT learning mode, it performed similarly to Gemini, though had the advantage of not simply giving the answer / getting reward hacked. However, Berkeley students have free Gemini Pro which may favor that since it\u2019s easy to hit usage limits with ChatGPT.</paragraph><paragraph>Similarly without learning mode, it answered all parts which could be overwhelming.</paragraph></document>",
            "links": [
                "https://g.co/gemini/share/4e1faf6d804c",
                "https://g.co/gemini/share/c6ce8062f1d6",
                "https://chatgpt.com/share/68e6a057-981c-800b-b06d-2b65a8332d36",
                "https://chatgpt.com/share/68e6bd6d-f24c-800b-a8ba-96be1e554c78"
            ],
            "attachments": [],
            "created_at": "2025-10-08T11:57:35.487299+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7088853,
            "author": "Andy Zhang",
            "project_title": "Special Participation B: Qwen3-Max on HW1",
            "post_body": "Here is the online link: https://chat.qwen.ai/s/68228653-4e58-46ba-b8bc-1e11f7a10f6c?fev=0.0.222 Annotated log: https://drive.google.com/file/d/1SspCCWNN5ekf5kutndGvgZsZcgzkQzUU/view?usp=sharing Executive Summary: The most challenging part was passing context, since Qwen3-Max Qwen3-Max does not support ipynb inputs and does not directly interface as an IDE. I initially attempted copy and pasting parts of the assignment, but selecting the right context can be tricky. I ended up converting the ipynb to a py file and pasting that in.\n\nQwen3-Max is generally able to one-shot nearly all answers and does not have many misconceptions/hallucinations. It took several prompts to get it to answer the right TODO.\n\nFinally, it also noted a potential issue with nomenclature how the assignment leveraged EMEA rather than classical momentum, though if you stuck to the TODO then it would be clear.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Here is the online link: https://chat.qwen.ai/s/68228653-4e58-46ba-b8bc-1e11f7a10f6c?fev=0.0.222 Annotated log: https://drive.google.com/file/d/1SspCCWNN5ekf5kutndGvgZsZcgzkQzUU/view?usp=sharing Executive Summary: The most challenging part was passing context, since Qwen3-Max Qwen3-Max does not support ipynb inputs and does not directly interface as an IDE. I initially attempted copy and pasting parts of the assignment, but selecting the right context can be tricky. I ended up converting the ipynb to a py file and pasting that in.</paragraph><paragraph>Qwen3-Max is generally able to one-shot nearly all answers and does not have many misconceptions/hallucinations. It took several prompts to get it to answer the right TODO.</paragraph><paragraph>Finally, it also noted a potential issue with nomenclature how the assignment leveraged EMEA rather than classical momentum, though if you stuck to the TODO then it would be clear.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-08T03:40:00.499107+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7086331,
            "author": "Hong Joey",
            "project_title": "HW4 Solutions",
            "post_body": "Below are solutions to HW4. Ask any questions about the solutions in this thread.",
            "content_xml": "<document version=\"2.0\"><paragraph>Below are solutions to HW4. Ask any questions about the solutions in this thread.</paragraph><file url=\"https://static.us.edusercontent.com/files/hv1tbxZ1KN1mLgX8vsUCtVwN\" filename=\"hw04_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/s6C6Lph0jaBFSI4bwgVc1Y3F\" filename=\"HandDesignFilters_Sol.ipynb\"/><file url=\"https://static.us.edusercontent.com/files/OMutqNvcywVFdOkjW1Ba5ctg\" filename=\"edge_detection_sol.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-07T13:30:16.556929+11:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7085536,
            "author": "Zhangzhi 'csrookie' Xiong",
            "project_title": "Participation Section B\uff1a HW3 - Grok 3",
            "post_body": "Brief Intro\n\nI'm using Grok Auto mode (Grok 3). The coding HW the LLM will work on is HW3 coding.\n\nPrompt: I'm a student learning deep learning. Please read this coding assignment .ipynb file, and complete the code and elaborate on your code.\n\nThinking:\n\nAnalyzing assignment\n\nThis coding assignment explores maximal update parameterization (muP) for training MLPs with varying layer widths.\n\nThe notebook includes sections on examining norms, implementing muP, and exploring related concepts like Shampoo updates.\n\nFor part a, the MLP layers are input 784, then hidden sizes [8,16,64,64,64,256,256,1024], and output 10.\n\nThe task involves completing TODOs and answering questions about layer dimensions and norm effects.\n\nLet's check how layer dimensions affect RMS norms of activation deltas in part a.\n\nCompleting part b code\n\nThe code needs to compute Frobenius, spectral, and RMS-RMS induced norms for weight updates.\n\nFor each weight matrix, calculate Frobenius norm using torch.norm with 'fro'.\n\nCompute spectral norm using the maximum singular value from SVD.\n\nThe RMS-RMS induced norm likely correlates most with activation deltas RMS due to update effects.\n\nFor implementation, detect weights by shape, compute norms, and plot for comparison.\n\nImplementing muP scaling\n\nFor biases, scale learning rate by 0.01 as a fudge factor.\n\nFor input layer, multiply learning rate by 10 to adjust for initial scale.\n\nFor hidden layers, adjust learning rate by dividing by fan_in to mimic muP behavior.\n\nFor output layer, use a fixed learning rate of 0.003 instead of muP scaling.\n\nTo make RMS activation deltas uniform, larger layers need adjusted learning rates to balance update sizes.\n\nRefining muP reasoning\n\nTo have constant RMS activation deltas, ensure update norms are independent of layer widths.\n\nThe Frobenius norm of gradients scales with sqrt(in * out / batch), affecting update sizes.\n\nThe induced RMS norm of weight updates equals spectral norm times sqrt(fan_in / fan_out).\n\nSpectral norm of weight matrices at initialization is approximately sigma * (sqrt(fan_in) + sqrt(fan_out)), with sigma based on variance.\n\nFor random matrices, spectral norm scales with sqrt(max(fan_in, fan_out)) times entry variance.\n\nExploring gradient scaling\n\nGradients to pre-activations scale with sqrt(next layer width / current layer width) due to backpropagation.\n\nThe induced RMS norm of weight updates depends on spectral norm and layer dimensions.\n\nIn homogeneous layers, RMS of gradients to pre-activations is approximately 1/sqrt(width).\n\nmuP allows using a single global learning rate across different layer widths for consistent training.\n\nFor larger hidden layers, RMS activation deltas are smaller in vanilla, needing larger learning rates to balance.\n\nAdjusting learning rates\n\nTo increase delta act for large fan_out, increase learning rate for that layer's weights.\n\nInduced norm of weight updates scales with learning rate and layer dimensions, affecting activation deltas.\n\nFor each layer, RMS of gradients to pre-activations is approximately 1/sqrt(fan_out), impacting update scaling.\n\nTo make activation deltas constant, scale learning rate by sqrt(fan_out / fan_in) for each layer.\n\nSearching for implementation details\n\nCurrently looking for \"maximal update parameterization muP implementation pytorch\" to clarify scaling.\n\nSearched for \"maximal update parameterization muP implementation pytorch\"\n\ngithub.com\n\ncerebras.ai\n\nblog.speechmatics.com\n\nblog.eleuther.ai\n\nmichal.io\n\narxiv.org\n\npureai.com\n\ntraining-api.cerebras.ai\n\nhowtoscalenn.github.io\n\nFound resources like GitHub for muP implementation in PyTorch.\n\nBrowsed https://github.com/microsoft/mup\n\nReviewing muP implementation\n\nThe mup package scales learning rates by dividing globalLR by width multiplier for larger layers.\n\nUsers set the same learning rate for different widths, and the package adjusts parameterization for consistent updates.\n\nExtracting scaling logic\n\nThe code shows learning rate scaling by dividing globalLR by a width multiplier for each parameter.\n\nBrowsed https://github.com/microsoft/mup/blob/main/src/mup/optim.py\n\nFor wider layers, effective learning rate decreases, aligning with standard optimal behavior.\n\nBrowsed https://raw.githubusercontent.com/microsoft/mup/main/mup/optim.py\n\nTroubleshooting tool access\n\nThe tool for extracting code from optim.py returned empty, possibly due to an incorrect path.\n\nSearched for \"mup optim.py github\"\n\ngithub.com\n\npypi.org\n\ncerebras.ai\n\nLocating optim.py file\n\nNow checking GitHub to list files and find optim.py for lr scaling details.\n\nBrowsd https://github.com/microsoft/mup/tree/main/mup\n\nExploring alternative resources\n\nNow searching for simpler implementations like ezmup on GitHub to understand muP lr scaling.\n\nBrowsed https://github.com/cloneofsimo/ezmup\n\nInvestigating ezmup scaling\n\nIn ezmup, learning rate scaling uses a dictionary based on parameter widths.\n\nBrowsed https://raw.githubusercontent.com/cloneofsimo/ezmup/main/ezmup/core.py\n\nLet's explore Eleuther AI blog for muP implementation details on lr scaling.\n\nBrowsed https://blog.eleuther.ai/mutransfer/\n\nApplying muP insights\n\nFor hidden layers, muP scales learning rate by dividing by layer width to maintain update consistency.\n\nThe input layer is treated as input, hidden as hidden, and output as output in the MLP structure.\n\nFinalizing muP implementation\n\nFor biases, learning rate is scaled by multiplying by 0.01 as a fudge factor.\n\nFor output bias, since it's a vector, scale learning rate by 0.01, keeping changes small.\n\nScaling the output of a layer by a constant doesn't directly adjust Adam's learning rate due to normalization.\n\nEvaluating layer scaling effects\n\nScaling a layer's output by a constant affects gradient propagation to previous layers.\n\nFor SignGD, scaling output by a constant keeps updates unchanged due to sign invariance.\n\nConsidering per-weight multipliers\n\nScaling layer output by a factor like sqrt(fan_in) might help make activation deltas uniform.\n\nFor part d, adjusting the network graph by scaling outputs can mimic muP effects with standard Adam.\n\nAnalyzing output scaling\n\nScaling a layer's output by a constant scales gradients, but Adam's normalization keeps updates unchanged.\n\nAdding a multiplier after a layer doesn't change activation deltas in Adam due to scale invariance.\n\nClarifying multiplier effects\n\nFor Adam, multiplying layer output by a constant doesn't alter updates due to normalization.\n\nScaling output by a constant affects next layer's input, potentially impacting update consistency.\n\nFinalizing multiplier strategy\n\nTo make activation deltas constant, scale layer output by sqrt(fan_out / fan_in).\n\nMultiplying layer output by a constant adjusts effective learning rate for the previous layer in SGD, explaining part d equivalence.\n\nRevisiting update behavior\n\nFor the first step, SimpleAdam acts like SignGD, with updates based on sign of gradients.\n\nAssessing graph adjustments\n\nScaling layer output by a constant doesn't change Adam updates due to normalization.\n\nFor SignGD, scaling output by a constant keeps updates unchanged, as sign is invariant.\n\nReevaluating multiplier impact\n\nAdding a constant multiplier after a layer doesn't alter activation deltas in Adam due to scale invariance.\n\nScaling output affects forward signal, altering loss and gradients for later layers.\n\nRefining scaling approach\n\nScaling layer output by sqrt(fan_in / fan_out) may reduce pre-activation RMS for larger layers, aiding sigmoid linearity.\n\nScaling logits by large factors can make softmax peaked, reducing gradient magnitude for correct predictions.\n\nExamining softmax behavior\n\nSoftmax is not scale invariant; for large scaling, it approaches onehot for the maximum logit.\n\nScaling hidden activations affects logit scale, altering gradient magnitudes through backpropagation.\n\nAdjusting forward scaling\n\nScaling pre-activation by a factor affects sigmoid derivative, impacting gradient flow.\n\nScaling post-sigmoid output by a constant directly scales activation deltas, making them adjustable for uniformity.\n\nFinalizing scaling strategy\n\nScaling pre-activation by sqrt(fan_out / fan_in) helps balance activation deltas across layers.\n\nFor part d, implement scaling in forward pass to ensure uniform activation deltas with standard Adam.\n\nCompleting part a answers\n\nThe dimensions of each layer are 784 input, then hidden [8,16,64,64,64,256,256,1024], and output 10.\n\nLarger layer dimensions typically reduce RMS norms of activation deltas due to scaling effects.\n\nResponse:\n\nI've read the provided Jupyter notebook file (q_mup_coding.ipynb) and completed the TODO sections based on the requirements of each part. I'll structure my response by section, providing the completed code for each TODO, the answers to the questions (as they would appear in the markdown cells), and elaborations on the code and reasoning. My goal was to make the code functional, follow the safety instructions, and ensure the implementations align with the concepts of muP, norms, and optimizers as described.\n\nThe notebook uses a simple MLP on MNIST, with focus on activation deltas, weight updates, and hyperparameter stability across widths.\n\na. Examining the norms of a heterogenous MLP.\n\nCompleted Code for TODO:\n\nThe TODO is to call some plotting code with different widths to observe changes.\n\n# TODO: Call some plotting code here.\ntrain_one_step(optimizer=SimpleAdam, hiddens=[128, 64, 32, 16, 8])  # Reversed widths to see if RMS changes as expected\n\n\nAnswers to Questions (as in markdown cell):\n\nAnswer: The dimensions of each layer in the neural network are 784 (input) -> 8 -> 16 -> 64 -> 64 -> 64 -> 256 -> 256 -> 1024 (hidden layers) -> 10 (output classes).\n\nAnswer: The dimensionality (hidden size) affects the RMS norm of the activation deltas by making it decrease as the layer width increases. Larger layers tend to have smaller activation deltas because the gradients are diluted across more dimensions in vanilla parameterization, leading to smaller updates.\n\nAnswer: Yes, changing the widths (e.g., to [128, 64, 32, 16, 8]) reverses the trend\u2014the RMS values increase as layer sizes decrease, confirming that wider layers have smaller RMS deltas in vanilla setup.\n\nElaboration:\n\nThe train_one_step function runs two forward passes and a gradient step, computing the RMS of activation changes between passes. The plot shows bar heights decreasing with larger hidden sizes in the default call. By reversing the widths, the plot should show increasing RMS, validating the inverse relationship with dimensionality. This is due to standard Kaiming initialization and gradient flow, where wider layers average out updates more.\n\nb. Examining the norms of the updates to the weights.\n\nCompleted Code for TODO:\n\nfor p in delta_params:\n    if len(p.shape) == 2:\n        ### TODO: Log the respective norms.\n        frob_norms.append(torch.norm(p, 'fro').item())\n        spectral_norms.append(torch.linalg.norm(p, ord=2).item())  # spectral norm\n        induced_norms.append(torch.linalg.norm(p, ord=2).item() * np.sqrt(p.shape[1] / p.shape[0]))  # RMS-RMS induced norm\n        p_shapes.append(f\"{p.shape[1]} -> {p.shape[0]}\")\n        ### \n\n\nAnswers to Questions (as in markdown cell):\n\nAnswer: The RMS-RMS induced norm correlates the most with the RMS norms of the activation deltas, as it accounts for the input/output dimensions and matches the scale of how updates propagate through activations.\n\nElaboration:\n\nFrobenius norm: Measures the total magnitude of the matrix update as \u221a(sum of squares). It tends to increase with layer size because larger matrices have more elements.\n\nSpectral norm: The largest singular value, measuring the maximum stretch. It often stays relatively constant or decreases slightly with width.\n\nRMS-RMS induced norm: Calculated as spectral_norm * \u221a(fan_in / fan_out). This represents the induced norm under RMS vector norms, which aligns with how activation changes are propagated (\u03b4_act \u2248 induced_norm(\u03b4W) * rms(prev_act)).\n\nThe code clones parameters before and after the step, computes deltas, and plots only for 2D weights (ignoring biases). The correlation with induced norm comes from the propagation: activation changes depend on how the weight update \"induces\" changes in the output space from the input space.\n\nThe plot will show Frobenius and spectral varying with width, but induced more stable or matching the activation RMS pattern from part a.\n\nc. Implementing muP\n\nCompleted Code for TODO:\n\n############################\n### Todo: Adjust the per-layer learning rate scaling factor so per-layer RMS activation deltas are constant.\n### Hint for part e: The following tricks will help you retain performance when using muP scaling.\n###  - Treat biases as a hidden layer with size (d_out, 1). You will need to use a fudge-factor of around 0.01 -- we want to keep the change in bias terms low.\n###  - For the input layer, a fudge factor of 10 appears to help.\n###  - For the output layer, we find it is best to ignore the muP scaling, and instead use a fixed learning rate (e.g. 0.003).\n############################\nlr = group['lr']\nif len(p.shape) == 2:  # Weight\n    fan_in = p.shape[1]\n    fan_out = p.shape[0]\n    if fan_out == 10:  # Output layer\n        lr = 0.003\n    else:\n        lr /= fan_in\n        if fan_in == 784:  # Input layer\n            lr *= 10\nelse:  # Bias\n    fan_in = 1\n    fan_out = p.shape[0]\n    lr /= fan_in\n    lr *= 0.01  # Fudge for biases\n############################\n############################\n\n\nAnswers to Questions (as in markdown cell):\n\nNote: The note asks why the first 2-3 activation-deltas may have a lower norm.\n\nAnswer: The first 2-3 activation-deltas may have lower norms because the early layers have smaller widths in the default hiddens list, leading to larger relative gradients but smaller updates after scaling. Additionally, chain effects from backpropagation and initial random activations may cause lower effective updates in early layers.\n\nElaboration:\n\nThe scaling follows muP principles for Adam: lr scaled by 1/fan_in for hidden layers to make updates independent of width. The fudges are as per the hint to stabilize training\u2014larger for input (to boost update), small for biases (to keep changes low), fixed for output (to avoid instability in logits).\n\nThe code applies this per parameter in the step function. The plots for the two hiddens lists should show roughly uniform bar heights for RMS deltas, unlike vanilla Adam.\n\nd. Per-Weight Multipliers\n\nCompleted Code for TODO:\n\nclass ScaledMLP(nn.Module):\n    def __init__(self, input_size=784, hidden_sizes = [8, 16, 32, 64, 128], num_classes=10):\n        super(ScaledMLP, self).__init__()\n        all_hidden_sizes = [input_size] + hidden_sizes + [num_classes]\n        self.layers = nn.ModuleList()\n        for i in range(len(all_hidden_sizes)-1):\n            self.layers.append(nn.Linear(all_hidden_sizes[i], all_hidden_sizes[i+1], bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        activations = []\n        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 28*28)\n        for layer in self.layers[:-1]:\n            x = layer(x)\n            ## TODO\n            x *= np.sqrt(layer.out_features / layer.in_features)  # Scale preactivation by sqrt(fan_out / fan_in) to counter vanilla scaling\n            ##\n            x = self.sigmoid(x)\n            activations.append(x)\n        x = self.layers[-1](x)\n        activations = activations[1:]\n        return x, [a.detach() for a in activations]\n\n\nAnswers to Questions (as in markdown cell):\n\nAnswer: Multiplying the output of a layer by a constant is equivalent to adjusting the learning rate of that layer because it scales the gradients during backpropagation, effectively changing the update magnitude. For Adam, it's approximately equivalent due to normalization (though invariant in theory, the first-step behavior is SignGD-like, where scaling affects effective step size through chain effects). For SignGD, it scales the effective step in propagation.\n\nElaboration:\n\nBy scaling the preactivation by \u221a(fan_out / fan_in), we counter the vanilla trend where deltas ~ \u221a(fan_in / fan_out), making deltas uniform. This adjusts the graph to mimic muP without optimizer changes. The plot with SimpleAdam should now show uniform RMS deltas. The equivalence holds more for SGD-like optimizers, but works here due to the problem's SimpleAdam being SignGD-like in early steps and chain effects in the network.\n\ne. Hyperparameter Transfer\n\nNo TODO in code, but the answers:\n\nAnswers to Questions (as in markdown cell):\n\nAnswer: In Adam, the optimal learning rate decreases as the network increases in size (e.g., from 0.01 for small widths to 0.001 for large), because larger models have higher curvature and require smaller steps for stability.\n\nAnswer: With muP, there is a single global learning rate (e.g., around 1.0-3.0) that works for a majority of widths, as the per-layer scaling makes updates independent of width. The 256-width network achieves ~0.5 loss, comparable to Adam.\n\nElaboration:\n\nThe sweep code is provided, and with SimpleAdamMuP, the loss curves align across widths, showing hyperparameter transfer. This is muP's key benefit\u2014tune on small, transfer to large.\n\ne. Shampoo and Orthogonalization (second e)\n\nCompleted Code for TODO:\n\n############ TODO\nif len(m.shape) == 1:\n    u = m  # Ignore biases for this question, it's not important.\nelse:\n    U, S, Vh = torch.linalg.svd(m, full_matrices=False)\n    u = U @ Vh.T\n#############\n\n\nAnswers to Questions (as in markdown cell):\n\nAnswer: For Adam, the Frobenius norm is much larger than the spectral norm for large layers (frob ~ sqrt(rank) * spectral, where rank is high). For Shampoo, the spectral norm is constant (~1), and frob = sqrt(rank), showing orthogonalization makes the update \"unit-spectral\" but frob grows with dimension.\n\nAnswer: (Bonus) Scale u by 1 / sqrt(in / out) to make the induced RMS norm constant (e.g., 1).\n\nCompleted bonus code:\n\nu = U @ Vh.T\nu *= 1 / np.sqrt(p.shape[1] / p.shape[0])  # Scale to make induced norm constant\n\n\nElaboration:\n\nShampoo orthogonalizes the momentum by taking the SVD and dropping the singular values, keeping only the directions (U V^T). This makes the update rank-preserving but with unit spectral norm. The plot shows Adam's norms varying, Shampoo's spectral constant. The bonus scales to constant induced norm, ensuring uniform propagation effects.\n\nThis completes the assignment. If you run the notebook with these changes, the plots and training should behave as described. Let me know if you need the full JSON notebook or further clarifications!\n\nComment\n\nThe codes are basically correct, except for the last part. The implementations are clean, efficient, and demonstrate a strong grasp of PyTorch mechanics, norm calculations, and hyperparameter scaling. AIs like Grok are trained on massive datasets including GitHub repositories, research papers, and educational notebooks on deep learning. They can pattern-match common experimentation techniques from similar assignments or tutorials! The AI likely \"understands\" from training data that reversing parameters is a standard way to validate scaling laws, drawing from sources like the NTK literature or muP discussions.\n\nFor more recently advanced Shampoo model, from my perspective, Shampoo details from KFAC/Shampoo papers are in training data. AIs compute matrix ops accurately, avoiding full_matrices=True for efficiency.\n\nBut as for the most recently developed model muon, Grok provided the wrong code:\n\nif len(m.shape) == 1:\n    u = m  # Ignore biases for this question, it's not important.\nelse:\n    U, S, Vh = torch.linalg.svd(m, full_matrices=False)\n    u = U @ Vh.T\n\n\nAs the error of dimension will be thrown out. I reported the error to the grok and ask it to revise:\n\nPrompt:\n\nFile c:\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120, in context_decorator.<locals>.decorate_context(*args, **kwargs)\n    117 @functools.wraps(func)\n    118 def decorate_context(*args, **kwargs):\n...\n---> 33     u = U @ Vh.T\n     36 #############\n     37 p.add_(u, alpha=-group['lr'])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (8x8 and 784x8)\nPlease read the error log and debug about your corresponding code\n\n\nResponse:\n\nThank you for providing the error log. I've analyzed it step by step based on the code context (from the Shampoo implementation in the notebook) and reproduced the issue using a tool to confirm matrix shapes. This is a matrix multiplication shape mismatch in the SVD reconstruction within the SimpleShampoo optimizer's step method. Below, I'll explain the root cause, why it occurs, and how to fix it. I'll also provide the corrected code snippet.\nStep-by-Step Diagnosis\n\nError Context:\n\nThe error occurs on line u = U @ Vh.T inside the Shampoo optimizer.\nIt's a RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x8 and 784x8).\nThis happens during matrix multiplication (@ operator) where the dimensions don't align: the number of columns in the left matrix (8) must equal the number of rows in the right matrix, but here the right matrix has 784 rows.\n\n\nUnderstanding the SVD Output:\n\nIn torch.linalg.svd(m, full_matrices=False), for a momentum matrix m of shape (out_features, in_features) (e.g., (8, 784) for the first layer: 784 input to 8 hidden).\n\nU: Shape (out, min(out, in)) \u2192 (8, 8).\nS: Shape (min(out, in)) \u2192 (8).\nVh: Shape (min(out, in), in) \u2192 (8, 784). Note: Vh is already the conjugate transpose (for real matrices, just transpose) of the right singular vectors.\n\n\nThe full SVD reconstruction (with singular values) would be U @ torch.diag(S) @ Vh, which correctly yields shape (8, 784).\nIn the simplified Shampoo, we're dropping S to \"orthogonalize\" the update (keeping directions but normalizing magnitudes implicitly).\n\n\nWhy the Error Happens:\n\nThe code computes U @ Vh.T:\n\nVh.T transposes Vh from (8, 784) to (784, 8).\nNow: U (8x8) @ Vh.T (784x8) \u2192 Columns of left (8) != rows of right (784) \u2192 Mismatch!\n\n\nThis fails specifically for non-square matrices (e.g., when out_features != in_features, like in early layers: 784\u21928).\nIn square layers (e.g., 64\u219264), it might coincidentally work if dimensions align, but it's still incorrect.\nRoot cause: Unnecessary .T on Vh. PyTorch's Vh is already in the correct orientation for reconstruction (U @ ... @ Vh).\n\n\ncode:\n\nU, S, Vh = torch.linalg.svd(m, full_matrices=False)\nu = U @ Vh  # Correct: No .T needed; Vh is already transposed in PyTorch convention\n\n\nNow the code is correct! The dimension problem, typically, can be resolved by AI if error log is well provided. In summary, the coding power of Grok is tremendous. Especially for assignment codes, Grok, and as for many AI agent I believe, are good at it, since the instruction text and partial implemented code themselves can provide enough information for Grok to reason. Not even to mention that Grok has been trained on tons of code on public website, so it even may has seen the similar code assignment before!\n\n",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Brief Intro</heading><paragraph>I'm using Grok Auto mode (Grok 3). The coding HW the LLM will work on is HW3 coding.</paragraph><paragraph><italic><bold>Prompt: I'm a student learning deep learning. Please read this coding assignment .ipynb file, and complete the code and elaborate on your code.</bold></italic></paragraph><paragraph><italic><bold>Thinking:</bold></italic></paragraph><paragraph>Analyzing assignment</paragraph><list style=\"unordered\"><list-item><paragraph>This coding assignment explores maximal update parameterization (muP) for training MLPs with varying layer widths.</paragraph></list-item><list-item><paragraph>The notebook includes sections on examining norms, implementing muP, and exploring related concepts like Shampoo updates.</paragraph></list-item><list-item><paragraph>For part a, the MLP layers are input 784, then hidden sizes [8,16,64,64,64,256,256,1024], and output 10.</paragraph></list-item><list-item><paragraph>The task involves completing TODOs and answering questions about layer dimensions and norm effects.</paragraph></list-item><list-item><paragraph>Let's check how layer dimensions affect RMS norms of activation deltas in part a.</paragraph></list-item></list><paragraph>Completing part b code</paragraph><list style=\"unordered\"><list-item><paragraph>The code needs to compute Frobenius, spectral, and RMS-RMS induced norms for weight updates.</paragraph></list-item><list-item><paragraph>For each weight matrix, calculate Frobenius norm using torch.norm with 'fro'.</paragraph></list-item><list-item><paragraph>Compute spectral norm using the maximum singular value from SVD.</paragraph></list-item><list-item><paragraph>The RMS-RMS induced norm likely correlates most with activation deltas RMS due to update effects.</paragraph></list-item><list-item><paragraph>For implementation, detect weights by shape, compute norms, and plot for comparison.</paragraph></list-item></list><paragraph>Implementing muP scaling</paragraph><list style=\"unordered\"><list-item><paragraph>For biases, scale learning rate by 0.01 as a fudge factor.</paragraph></list-item><list-item><paragraph>For input layer, multiply learning rate by 10 to adjust for initial scale.</paragraph></list-item><list-item><paragraph>For hidden layers, adjust learning rate by dividing by fan_in to mimic muP behavior.</paragraph></list-item><list-item><paragraph>For output layer, use a fixed learning rate of 0.003 instead of muP scaling.</paragraph></list-item><list-item><paragraph>To make RMS activation deltas uniform, larger layers need adjusted learning rates to balance update sizes.</paragraph></list-item></list><paragraph>Refining muP reasoning</paragraph><list style=\"unordered\"><list-item><paragraph>To have constant RMS activation deltas, ensure update norms are independent of layer widths.</paragraph></list-item><list-item><paragraph>The Frobenius norm of gradients scales with sqrt(in * out / batch), affecting update sizes.</paragraph></list-item><list-item><paragraph>The induced RMS norm of weight updates equals spectral norm times sqrt(fan_in / fan_out).</paragraph></list-item><list-item><paragraph>Spectral norm of weight matrices at initialization is approximately sigma * (sqrt(fan_in) + sqrt(fan_out)), with sigma based on variance.</paragraph></list-item><list-item><paragraph>For random matrices, spectral norm scales with sqrt(max(fan_in, fan_out)) times entry variance.</paragraph></list-item></list><paragraph>Exploring gradient scaling</paragraph><list style=\"unordered\"><list-item><paragraph>Gradients to pre-activations scale with sqrt(next layer width / current layer width) due to backpropagation.</paragraph></list-item><list-item><paragraph>The induced RMS norm of weight updates depends on spectral norm and layer dimensions.</paragraph></list-item><list-item><paragraph>In homogeneous layers, RMS of gradients to pre-activations is approximately 1/sqrt(width).</paragraph></list-item><list-item><paragraph>muP allows using a single global learning rate across different layer widths for consistent training.</paragraph></list-item><list-item><paragraph>For larger hidden layers, RMS activation deltas are smaller in vanilla, needing larger learning rates to balance.</paragraph></list-item></list><paragraph>Adjusting learning rates</paragraph><list style=\"unordered\"><list-item><paragraph>To increase delta act for large fan_out, increase learning rate for that layer's weights.</paragraph></list-item><list-item><paragraph>Induced norm of weight updates scales with learning rate and layer dimensions, affecting activation deltas.</paragraph></list-item><list-item><paragraph>For each layer, RMS of gradients to pre-activations is approximately 1/sqrt(fan_out), impacting update scaling.</paragraph></list-item><list-item><paragraph>To make activation deltas constant, scale learning rate by sqrt(fan_out / fan_in) for each layer.</paragraph></list-item></list><paragraph>Searching for implementation details</paragraph><list style=\"unordered\"><list-item><paragraph>Currently looking for \"maximal update parameterization muP implementation pytorch\" to clarify scaling.</paragraph></list-item></list><paragraph>Searched for \"maximal update parameterization muP implementation pytorch\"</paragraph><paragraph><link href=\"https://github.com/microsoft/mup\">github.com</link></paragraph><paragraph><link href=\"https://www.cerebras.ai/blog/the-practitioners-guide-to-the-maximal-update-parameterization\">cerebras.ai</link></paragraph><paragraph><link href=\"https://blog.speechmatics.com/mup\">blog.speechmatics.com</link></paragraph><paragraph><link href=\"https://blog.eleuther.ai/mutransfer/\">blog.eleuther.ai</link></paragraph><paragraph><link href=\"https://michal.io/wiki/Maximal-Update-Parametrization-%28%25CE%25BCP%29\">michal.io</link></paragraph><paragraph><link href=\"https://arxiv.org/html/2407.17465v1\">arxiv.org</link></paragraph><paragraph><link href=\"https://pureai.com/articles/2022/04/04/neural-net-training.aspx\">pureai.com</link></paragraph><paragraph><link href=\"https://training-api.cerebras.ai/en/latest/wsc/Model-zoo/tutorials/mup/mup_docs.html\">training-api.cerebras.ai</link></paragraph><paragraph><link href=\"https://howtoscalenn.github.io/\">howtoscalenn.github.io</link></paragraph><list style=\"unordered\"><list-item><paragraph>Found resources like <link href=\"https://github.com/microsoft/mup\">GitHub</link> for muP implementation in PyTorch.</paragraph></list-item></list><paragraph>Browsed https://github.com/microsoft/mup</paragraph><paragraph>Reviewing muP implementation</paragraph><list style=\"unordered\"><list-item><paragraph>The mup package scales learning rates by dividing globalLR by width multiplier for larger layers.</paragraph></list-item><list-item><paragraph>Users set the same learning rate for different widths, and the package adjusts parameterization for consistent updates.</paragraph></list-item></list><paragraph>Extracting scaling logic</paragraph><list style=\"unordered\"><list-item><paragraph>The code shows learning rate scaling by dividing globalLR by a width multiplier for each parameter.</paragraph></list-item></list><paragraph>Browsed https://github.com/microsoft/mup/blob/main/src/mup/optim.py</paragraph><list style=\"unordered\"><list-item><paragraph>For wider layers, effective learning rate decreases, aligning with standard optimal behavior.</paragraph></list-item></list><paragraph>Browsed https://raw.githubusercontent.com/microsoft/mup/main/mup/optim.py</paragraph><paragraph>Troubleshooting tool access</paragraph><list style=\"unordered\"><list-item><paragraph>The tool for extracting code from optim.py returned empty, possibly due to an incorrect path.</paragraph></list-item></list><paragraph>Searched for \"mup optim.py github\"</paragraph><paragraph><link href=\"https://github.com/microsoft/mup\">github.com</link></paragraph><paragraph><link href=\"https://pypi.org/project/mup/0.0.0/\">pypi.org</link></paragraph><paragraph><link href=\"https://www.cerebras.ai/blog/the-practitioners-guide-to-the-maximal-update-parameterization\">cerebras.ai</link></paragraph><paragraph>Locating optim.py file</paragraph><list style=\"unordered\"><list-item><paragraph>Now checking <link href=\"https://github.com/microsoft/mup/tree/main/mup\">GitHub</link> to list files and find optim.py for lr scaling details.</paragraph></list-item></list><paragraph>Browsd https://github.com/microsoft/mup/tree/main/mup</paragraph><paragraph>Exploring alternative resources</paragraph><list style=\"unordered\"><list-item><paragraph>Now searching for simpler implementations like <link href=\"https://github.com/cloneofsimo/ezmup\">ezmup on GitHub</link> to understand muP lr scaling.</paragraph></list-item></list><paragraph>Browsed https://github.com/cloneofsimo/ezmup</paragraph><paragraph>Investigating ezmup scaling</paragraph><list style=\"unordered\"><list-item><paragraph>In ezmup, learning rate scaling uses a dictionary based on parameter widths.</paragraph></list-item></list><paragraph>Browsed https://raw.githubusercontent.com/cloneofsimo/ezmup/main/ezmup/core.py</paragraph><list style=\"unordered\"><list-item><paragraph>Let's explore <link href=\"https://blog.eleuther.ai/mutransfer/\">Eleuther AI blog</link> for muP implementation details on lr scaling.</paragraph></list-item></list><paragraph>Browsed https://blog.eleuther.ai/mutransfer/</paragraph><paragraph>Applying muP insights</paragraph><list style=\"unordered\"><list-item><paragraph>For hidden layers, muP scales learning rate by dividing by layer width to maintain update consistency.</paragraph></list-item><list-item><paragraph>The input layer is treated as input, hidden as hidden, and output as output in the MLP structure.</paragraph></list-item></list><paragraph>Finalizing muP implementation</paragraph><list style=\"unordered\"><list-item><paragraph>For biases, learning rate is scaled by multiplying by 0.01 as a fudge factor.</paragraph></list-item><list-item><paragraph>For output bias, since it's a vector, scale learning rate by 0.01, keeping changes small.</paragraph></list-item><list-item><paragraph>Scaling the output of a layer by a constant doesn't directly adjust Adam's learning rate due to normalization.</paragraph></list-item></list><paragraph>Evaluating layer scaling effects</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling a layer's output by a constant affects gradient propagation to previous layers.</paragraph></list-item><list-item><paragraph>For SignGD, scaling output by a constant keeps updates unchanged due to sign invariance.</paragraph></list-item></list><paragraph>Considering per-weight multipliers</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling layer output by a factor like sqrt(fan_in) might help make activation deltas uniform.</paragraph></list-item><list-item><paragraph>For part d, adjusting the network graph by scaling outputs can mimic muP effects with standard Adam.</paragraph></list-item></list><paragraph>Analyzing output scaling</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling a layer's output by a constant scales gradients, but Adam's normalization keeps updates unchanged.</paragraph></list-item><list-item><paragraph>Adding a multiplier after a layer doesn't change activation deltas in Adam due to scale invariance.</paragraph></list-item></list><paragraph>Clarifying multiplier effects</paragraph><list style=\"unordered\"><list-item><paragraph>For Adam, multiplying layer output by a constant doesn't alter updates due to normalization.</paragraph></list-item><list-item><paragraph>Scaling output by a constant affects next layer's input, potentially impacting update consistency.</paragraph></list-item></list><paragraph>Finalizing multiplier strategy</paragraph><list style=\"unordered\"><list-item><paragraph>To make activation deltas constant, scale layer output by sqrt(fan_out / fan_in).</paragraph></list-item><list-item><paragraph>Multiplying layer output by a constant adjusts effective learning rate for the previous layer in SGD, explaining part d equivalence.</paragraph></list-item></list><paragraph>Revisiting update behavior</paragraph><list style=\"unordered\"><list-item><paragraph>For the first step, SimpleAdam acts like SignGD, with updates based on sign of gradients.</paragraph></list-item></list><paragraph>Assessing graph adjustments</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling layer output by a constant doesn't change Adam updates due to normalization.</paragraph></list-item><list-item><paragraph>For SignGD, scaling output by a constant keeps updates unchanged, as sign is invariant.</paragraph></list-item></list><paragraph>Reevaluating multiplier impact</paragraph><list style=\"unordered\"><list-item><paragraph>Adding a constant multiplier after a layer doesn't alter activation deltas in Adam due to scale invariance.</paragraph></list-item><list-item><paragraph>Scaling output affects forward signal, altering loss and gradients for later layers.</paragraph></list-item></list><paragraph>Refining scaling approach</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling layer output by sqrt(fan_in / fan_out) may reduce pre-activation RMS for larger layers, aiding sigmoid linearity.</paragraph></list-item><list-item><paragraph>Scaling logits by large factors can make softmax peaked, reducing gradient magnitude for correct predictions.</paragraph></list-item></list><paragraph>Examining softmax behavior</paragraph><list style=\"unordered\"><list-item><paragraph>Softmax is not scale invariant; for large scaling, it approaches onehot for the maximum logit.</paragraph></list-item><list-item><paragraph>Scaling hidden activations affects logit scale, altering gradient magnitudes through backpropagation.</paragraph></list-item></list><paragraph>Adjusting forward scaling</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling pre-activation by a factor affects sigmoid derivative, impacting gradient flow.</paragraph></list-item><list-item><paragraph>Scaling post-sigmoid output by a constant directly scales activation deltas, making them adjustable for uniformity.</paragraph></list-item></list><paragraph>Finalizing scaling strategy</paragraph><list style=\"unordered\"><list-item><paragraph>Scaling pre-activation by sqrt(fan_out / fan_in) helps balance activation deltas across layers.</paragraph></list-item><list-item><paragraph>For part d, implement scaling in forward pass to ensure uniform activation deltas with standard Adam.</paragraph></list-item></list><paragraph>Completing part a answers</paragraph><list style=\"unordered\"><list-item><paragraph>The dimensions of each layer are 784 input, then hidden [8,16,64,64,64,256,256,1024], and output 10.</paragraph></list-item><list-item><paragraph>Larger layer dimensions typically reduce RMS norms of activation deltas due to scaling effects.</paragraph></list-item></list><paragraph><italic><bold>Response:</bold></italic></paragraph><paragraph>I've read the provided Jupyter notebook file (q_mup_coding.ipynb) and completed the TODO sections based on the requirements of each part. I'll structure my response by section, providing the completed code for each TODO, the answers to the questions (as they would appear in the markdown cells), and elaborations on the code and reasoning. My goal was to make the code functional, follow the safety instructions, and ensure the implementations align with the concepts of muP, norms, and optimizers as described.</paragraph><paragraph>The notebook uses a simple MLP on MNIST, with focus on activation deltas, weight updates, and hyperparameter stability across widths.</paragraph><heading level=\"2\">a. Examining the norms of a heterogenous MLP.</heading><paragraph><bold>Completed Code for TODO:</bold></paragraph><paragraph>The TODO is to call some plotting code with different widths to observe changes.</paragraph><pre># TODO: Call some plotting code here.\ntrain_one_step(optimizer=SimpleAdam, hiddens=[128, 64, 32, 16, 8])  # Reversed widths to see if RMS changes as expected\n</pre><paragraph><bold>Answers to Questions (as in markdown cell):</bold></paragraph><paragraph><italic>Answer:</italic> The dimensions of each layer in the neural network are 784 (input) -&gt; 8 -&gt; 16 -&gt; 64 -&gt; 64 -&gt; 64 -&gt; 256 -&gt; 256 -&gt; 1024 (hidden layers) -&gt; 10 (output classes).</paragraph><paragraph><italic>Answer:</italic> The dimensionality (hidden size) affects the RMS norm of the activation deltas by making it decrease as the layer width increases. Larger layers tend to have smaller activation deltas because the gradients are diluted across more dimensions in vanilla parameterization, leading to smaller updates.</paragraph><paragraph><italic>Answer:</italic> Yes, changing the widths (e.g., to [128, 64, 32, 16, 8]) reverses the trend\u2014the RMS values increase as layer sizes decrease, confirming that wider layers have smaller RMS deltas in vanilla setup.</paragraph><paragraph><bold>Elaboration:</bold></paragraph><paragraph>The train_one_step function runs two forward passes and a gradient step, computing the RMS of activation changes between passes. The plot shows bar heights decreasing with larger hidden sizes in the default call. By reversing the widths, the plot should show increasing RMS, validating the inverse relationship with dimensionality. This is due to standard Kaiming initialization and gradient flow, where wider layers average out updates more.</paragraph><heading level=\"2\">b. Examining the norms of the updates to the weights.</heading><paragraph><bold>Completed Code for TODO:</bold></paragraph><pre>for p in delta_params:\n    if len(p.shape) == 2:\n        ### TODO: Log the respective norms.\n        frob_norms.append(torch.norm(p, 'fro').item())\n        spectral_norms.append(torch.linalg.norm(p, ord=2).item())  # spectral norm\n        induced_norms.append(torch.linalg.norm(p, ord=2).item() * np.sqrt(p.shape[1] / p.shape[0]))  # RMS-RMS induced norm\n        p_shapes.append(f\"{p.shape[1]} -&gt; {p.shape[0]}\")\n        ### \n</pre><paragraph><bold>Answers to Questions (as in markdown cell):</bold></paragraph><paragraph><italic>Answer:</italic> The RMS-RMS induced norm correlates the most with the RMS norms of the activation deltas, as it accounts for the input/output dimensions and matches the scale of how updates propagate through activations.</paragraph><paragraph><bold>Elaboration:</bold></paragraph><list style=\"unordered\"><list-item><paragraph><bold>Frobenius norm</bold>: Measures the total magnitude of the matrix update as \u221a(sum of squares). It tends to increase with layer size because larger matrices have more elements.</paragraph></list-item><list-item><paragraph><bold>Spectral norm</bold>: The largest singular value, measuring the maximum stretch. It often stays relatively constant or decreases slightly with width.</paragraph></list-item><list-item><paragraph><bold>RMS-RMS induced norm</bold>: Calculated as spectral_norm * \u221a(fan_in / fan_out). This represents the induced norm under RMS vector norms, which aligns with how activation changes are propagated (\u03b4_act \u2248 induced_norm(\u03b4W) * rms(prev_act)).</paragraph></list-item></list><paragraph>The code clones parameters before and after the step, computes deltas, and plots only for 2D weights (ignoring biases). The correlation with induced norm comes from the propagation: activation changes depend on how the weight update \"induces\" changes in the output space from the input space.</paragraph><paragraph>The plot will show Frobenius and spectral varying with width, but induced more stable or matching the activation RMS pattern from part a.</paragraph><heading level=\"2\">c. Implementing muP</heading><paragraph><bold>Completed Code for TODO:</bold></paragraph><pre>############################\n### Todo: Adjust the per-layer learning rate scaling factor so per-layer RMS activation deltas are constant.\n### Hint for part e: The following tricks will help you retain performance when using muP scaling.\n###  - Treat biases as a hidden layer with size (d_out, 1). You will need to use a fudge-factor of around 0.01 -- we want to keep the change in bias terms low.\n###  - For the input layer, a fudge factor of 10 appears to help.\n###  - For the output layer, we find it is best to ignore the muP scaling, and instead use a fixed learning rate (e.g. 0.003).\n############################\nlr = group['lr']\nif len(p.shape) == 2:  # Weight\n    fan_in = p.shape[1]\n    fan_out = p.shape[0]\n    if fan_out == 10:  # Output layer\n        lr = 0.003\n    else:\n        lr /= fan_in\n        if fan_in == 784:  # Input layer\n            lr *= 10\nelse:  # Bias\n    fan_in = 1\n    fan_out = p.shape[0]\n    lr /= fan_in\n    lr *= 0.01  # Fudge for biases\n############################\n############################\n</pre><paragraph><bold>Answers to Questions (as in markdown cell):</bold></paragraph><paragraph>Note: The note asks why the first 2-3 activation-deltas may have a lower norm.</paragraph><paragraph><italic>Answer:</italic> The first 2-3 activation-deltas may have lower norms because the early layers have smaller widths in the default hiddens list, leading to larger relative gradients but smaller updates after scaling. Additionally, chain effects from backpropagation and initial random activations may cause lower effective updates in early layers.</paragraph><paragraph><bold>Elaboration:</bold></paragraph><paragraph>The scaling follows muP principles for Adam: lr scaled by 1/fan_in for hidden layers to make updates independent of width. The fudges are as per the hint to stabilize training\u2014larger for input (to boost update), small for biases (to keep changes low), fixed for output (to avoid instability in logits).</paragraph><paragraph>The code applies this per parameter in the step function. The plots for the two hiddens lists should show roughly uniform bar heights for RMS deltas, unlike vanilla Adam.</paragraph><heading level=\"2\">d. Per-Weight Multipliers</heading><paragraph><bold>Completed Code for TODO:</bold></paragraph><pre>class ScaledMLP(nn.Module):\n    def __init__(self, input_size=784, hidden_sizes = [8, 16, 32, 64, 128], num_classes=10):\n        super(ScaledMLP, self).__init__()\n        all_hidden_sizes = [input_size] + hidden_sizes + [num_classes]\n        self.layers = nn.ModuleList()\n        for i in range(len(all_hidden_sizes)-1):\n            self.layers.append(nn.Linear(all_hidden_sizes[i], all_hidden_sizes[i+1], bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        activations = []\n        x = x.view(x.size(0), -1)  # Flatten: (batch_size, 28*28)\n        for layer in self.layers[:-1]:\n            x = layer(x)\n            ## TODO\n            x *= np.sqrt(layer.out_features / layer.in_features)  # Scale preactivation by sqrt(fan_out / fan_in) to counter vanilla scaling\n            ##\n            x = self.sigmoid(x)\n            activations.append(x)\n        x = self.layers[-1](x)\n        activations = activations[1:]\n        return x, [a.detach() for a in activations]\n</pre><paragraph><bold>Answers to Questions (as in markdown cell):</bold></paragraph><paragraph><italic>Answer:</italic> Multiplying the output of a layer by a constant is equivalent to adjusting the learning rate of that layer because it scales the gradients during backpropagation, effectively changing the update magnitude. For Adam, it's approximately equivalent due to normalization (though invariant in theory, the first-step behavior is SignGD-like, where scaling affects effective step size through chain effects). For SignGD, it scales the effective step in propagation.</paragraph><paragraph><bold>Elaboration:</bold></paragraph><paragraph>By scaling the preactivation by \u221a(fan_out / fan_in), we counter the vanilla trend where deltas ~ \u221a(fan_in / fan_out), making deltas uniform. This adjusts the graph to mimic muP without optimizer changes. The plot with SimpleAdam should now show uniform RMS deltas. The equivalence holds more for SGD-like optimizers, but works here due to the problem's SimpleAdam being SignGD-like in early steps and chain effects in the network.</paragraph><heading level=\"2\">e. Hyperparameter Transfer</heading><paragraph>No TODO in code, but the answers:</paragraph><paragraph><bold>Answers to Questions (as in markdown cell):</bold></paragraph><paragraph><italic>Answer:</italic> In Adam, the optimal learning rate decreases as the network increases in size (e.g., from 0.01 for small widths to 0.001 for large), because larger models have higher curvature and require smaller steps for stability.</paragraph><paragraph><italic>Answer:</italic> With muP, there is a single global learning rate (e.g., around 1.0-3.0) that works for a majority of widths, as the per-layer scaling makes updates independent of width. The 256-width network achieves ~0.5 loss, comparable to Adam.</paragraph><paragraph><bold>Elaboration:</bold></paragraph><paragraph>The sweep code is provided, and with SimpleAdamMuP, the loss curves align across widths, showing hyperparameter transfer. This is muP's key benefit\u2014tune on small, transfer to large.</paragraph><heading level=\"2\">e. Shampoo and Orthogonalization (second e)</heading><paragraph><bold>Completed Code for TODO:</bold></paragraph><pre>############ TODO\nif len(m.shape) == 1:\n    u = m  # Ignore biases for this question, it's not important.\nelse:\n    U, S, Vh = torch.linalg.svd(m, full_matrices=False)\n    u = U @ Vh.T\n#############\n</pre><paragraph><bold>Answers to Questions (as in markdown cell):</bold></paragraph><paragraph><italic>Answer:</italic> For Adam, the Frobenius norm is much larger than the spectral norm for large layers (frob ~ sqrt(rank) * spectral, where rank is high). For Shampoo, the spectral norm is constant (~1), and frob = sqrt(rank), showing orthogonalization makes the update \"unit-spectral\" but frob grows with dimension.</paragraph><paragraph><italic>Answer:</italic> (Bonus) Scale u by 1 / sqrt(in / out) to make the induced RMS norm constant (e.g., 1).</paragraph><paragraph>Completed bonus code:</paragraph><pre>u = U @ Vh.T\nu *= 1 / np.sqrt(p.shape[1] / p.shape[0])  # Scale to make induced norm constant\n</pre><paragraph><bold>Elaboration:</bold></paragraph><paragraph>Shampoo orthogonalizes the momentum by taking the SVD and dropping the singular values, keeping only the directions (U V^T). This makes the update rank-preserving but with unit spectral norm. The plot shows Adam's norms varying, Shampoo's spectral constant. The bonus scales to constant induced norm, ensuring uniform propagation effects.</paragraph><paragraph>This completes the assignment. If you run the notebook with these changes, the plots and training should behave as described. Let me know if you need the full JSON notebook or further clarifications!</paragraph><heading level=\"2\">Comment</heading><paragraph>The codes are basically correct, <italic><bold>except for the last part</bold></italic>. The implementations are clean, efficient, and demonstrate a strong grasp of PyTorch mechanics, norm calculations, and hyperparameter scaling. AIs like Grok are trained on massive datasets including GitHub repositories, research papers, and educational notebooks on deep learning. They can pattern-match common experimentation techniques from similar assignments or tutorials! The AI likely \"understands\" from training data that reversing parameters is a standard way to validate scaling laws, drawing from sources like the NTK literature or muP discussions.</paragraph><paragraph>For more recently advanced Shampoo model, from my perspective, Shampoo details from KFAC/Shampoo papers are in training data. AIs compute matrix ops accurately, avoiding full_matrices=True for efficiency.</paragraph><paragraph>But as for the most recently developed model muon, Grok provided the wrong code:</paragraph><pre>if len(m.shape) == 1:\n    u = m  # Ignore biases for this question, it's not important.\nelse:\n    U, S, Vh = torch.linalg.svd(m, full_matrices=False)\n    u = U @ Vh.T\n</pre><paragraph>As the error of dimension will be thrown out. I reported the error to the grok and ask it to revise:</paragraph><paragraph><italic><bold>Prompt:</bold></italic></paragraph><pre>File c:\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120, in context_decorator.&lt;locals&gt;.decorate_context(*args, **kwargs)\n    117 @functools.wraps(func)\n    118 def decorate_context(*args, **kwargs):\n...\n---&gt; 33     u = U @ Vh.T\n     36 #############\n     37 p.add_(u, alpha=-group['lr'])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (8x8 and 784x8)\nPlease read the error log and debug about your corresponding code\n</pre><paragraph><italic><bold>Response:</bold></italic></paragraph><pre>Thank you for providing the error log. I've analyzed it step by step based on the code context (from the Shampoo implementation in the notebook) and reproduced the issue using a tool to confirm matrix shapes. This is a matrix multiplication shape mismatch in the SVD reconstruction within the SimpleShampoo optimizer's step method. Below, I'll explain the root cause, why it occurs, and how to fix it. I'll also provide the corrected code snippet.\nStep-by-Step Diagnosis\n\nError Context:\n\nThe error occurs on line u = U @ Vh.T inside the Shampoo optimizer.\nIt's a RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x8 and 784x8).\nThis happens during matrix multiplication (@ operator) where the dimensions don't align: the number of columns in the left matrix (8) must equal the number of rows in the right matrix, but here the right matrix has 784 rows.\n\n\nUnderstanding the SVD Output:\n\nIn torch.linalg.svd(m, full_matrices=False), for a momentum matrix m of shape (out_features, in_features) (e.g., (8, 784) for the first layer: 784 input to 8 hidden).\n\nU: Shape (out, min(out, in)) \u2192 (8, 8).\nS: Shape (min(out, in)) \u2192 (8).\nVh: Shape (min(out, in), in) \u2192 (8, 784). Note: Vh is already the conjugate transpose (for real matrices, just transpose) of the right singular vectors.\n\n\nThe full SVD reconstruction (with singular values) would be U @ torch.diag(S) @ Vh, which correctly yields shape (8, 784).\nIn the simplified Shampoo, we're dropping S to \"orthogonalize\" the update (keeping directions but normalizing magnitudes implicitly).\n\n\nWhy the Error Happens:\n\nThe code computes U @ Vh.T:\n\nVh.T transposes Vh from (8, 784) to (784, 8).\nNow: U (8x8) @ Vh.T (784x8) \u2192 Columns of left (8) != rows of right (784) \u2192 Mismatch!\n\n\nThis fails specifically for non-square matrices (e.g., when out_features != in_features, like in early layers: 784\u21928).\nIn square layers (e.g., 64\u219264), it might coincidentally work if dimensions align, but it's still incorrect.\nRoot cause: Unnecessary .T on Vh. PyTorch's Vh is already in the correct orientation for reconstruction (U @ ... @ Vh).\n</pre><paragraph><italic><bold>code:</bold></italic></paragraph><pre>U, S, Vh = torch.linalg.svd(m, full_matrices=False)\nu = U @ Vh  # Correct: No .T needed; Vh is already transposed in PyTorch convention\n</pre><paragraph>Now the code is correct! The dimension problem, typically, can be resolved by AI if error log is well provided. In summary, the coding power of Grok is tremendous. Especially for assignment codes, Grok, and as for many AI agent I believe, are good at it, since the instruction text and partial implemented code themselves can provide enough information for Grok to reason. Not even to mention that Grok has been trained on tons of code on public website, so it even may has seen the similar code assignment before!</paragraph><paragraph/></document>",
            "links": [
                "https://github.com/microsoft/mup",
                "https://www.cerebras.ai/blog/the-practitioners-guide-to-the-maximal-update-parameterization",
                "https://blog.speechmatics.com/mup",
                "https://blog.eleuther.ai/mutransfer/",
                "https://michal.io/wiki/Maximal-Update-Parametrization-%28%25CE%25BCP%29",
                "https://arxiv.org/html/2407.17465v1",
                "https://pureai.com/articles/2022/04/04/neural-net-training.aspx",
                "https://training-api.cerebras.ai/en/latest/wsc/Model-zoo/tutorials/mup/mup_docs.html",
                "https://howtoscalenn.github.io/",
                "https://github.com/microsoft/mup",
                "https://github.com/microsoft/mup",
                "https://pypi.org/project/mup/0.0.0/",
                "https://www.cerebras.ai/blog/the-practitioners-guide-to-the-maximal-update-parameterization",
                "https://github.com/microsoft/mup/tree/main/mup",
                "https://github.com/cloneofsimo/ezmup",
                "https://blog.eleuther.ai/mutransfer/"
            ],
            "attachments": [],
            "created_at": "2025-10-07T11:35:38.68132+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7085474,
            "author": "Zhangzhi 'csrookie' Xiong",
            "project_title": "Participation Section A: HW0 - Gemini 2.5 Pro",
            "post_body": "Participation Section A: Homework with LLM\n\nBrief Intro\n\nI'm using Gemini 2.5 Pro provided by Berkeley. The homework I use LLM to deal with is HW0 written part. The problem 1, 6 and 7 are neglected, since these problems are not targeting deep learning knowledge.\n\nInteraction on Problem 2\n\nPrompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them.\n\nAttachment: The figure of problem 2.\n\nResponse: \n\nComment: The Gemini 2.5 Pro can grasp the problem correctly from the picture and extract the core of each subproblem. It get comfortable with proving the derivative in element-wise perspective. I'm confident that it can answer the question correctly. \n\nPrompt: Please give your formal and detailed answer to this question\n\nAttachment: The figure of the problem\n\nResponse:\n\n\n\nComment: The proof of LLM is correct and rigorous! I can't agree with it more. I guess the reason why AI can prove this easily is because similar proofs are well included in the training corpus. \n\nInteraction on Problem 3\n\nPrompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them briefly.\n\nResponse: \n\nComment: For problem a, AI failed to use the derivative of MSE and choose to solve the problem directly. This is a little bit suprising for me! And for the following subproblems, AI follow its thought on a. Maybe I should hint it to consider the derivative. \n\nPrompt: From problem (a), you should consider the derivative of MSE and get the optimal answer. Please follow this instruction and give me the formal and brief answer of these problems.\n\nResponse: \n\n\n\nComment: Under my hint, now AI can solve all these subproblems! Few haluccination is presented from its answer. I suppose these problems should be quite classic, and should be easy for the advanced model Gemini 2.5 Pro. \n\nInteraction on Problem 4\n\nPrompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them briefly.\n\nAttachment: The figures of the problem. \n\nResponse: \n\n\n\nComment: Gemini successfully extracted the essences of these subproblems, and provide detailed extension for these distinct perspectives about ridge regression. For some of the problem, it seems that AI has already know the answer and tell me the conclusion of these perspectives.\n\nPrompt: Your ideas are correct. Please provide your formal answer in an accurate and brief manner.\n\nResponse: \n\n\n\nComment: All the answers to the subproblems are correct! Most impressively, Gemini handle the dimension of these complicated formulas accurately! I doubt that Gemini probably have seen these problems or topics from its corpus. \n\nInteraction on Problem 5\n\nPrompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them briefly.\n\nResponse: \n\n\n\nComment: The AI seems to haluccinate with the last problem......I will reopen a chat box, and ask it to answer the problem directly.\n\nPrompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, and give me your accurate and brief answer.\n\nComment: The problem of a, b and c are answered correctly, but d problem is not correct. Gemini fail to analyse the problem based on multiple conditions and possibility. I think this is because subproblem d is never designed before, and Gemini has to do deduction and reasoning itself, and it failed to answer the question comprehensively. \n\nSummary\n\nTotal score: 96 / 100\n\nThe accuracy of Gemini is amazing, especially for these classic problems that are highly likely to have appeared on the web forum or documents. For unseen questions, Gemini can provide inspiring insights, but still struggle to ace them all. \n\nIf input figures multiple times in one single chat, the AI may haluccinate across these figures. So for every single problem, it is suggestive to open a new box and communicate with LLM there. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/sKolFHeZPoY6qRxffjkdqwUj\" filename=\"log.pdf\"/><heading level=\"1\">Participation Section A: Homework with LLM</heading><heading level=\"2\">Brief Intro</heading><paragraph>I'm using Gemini 2.5 Pro provided by Berkeley. The homework I use LLM to deal with is HW0 written part. The problem 1, 6 and 7 are neglected, since these problems are not targeting deep learning knowledge.</paragraph><heading level=\"2\">Interaction on Problem 2</heading><paragraph><italic><bold>Prompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them.</bold></italic></paragraph><paragraph><italic><bold>Attachment: The figure of problem 2.</bold></italic></paragraph><paragraph><italic><bold>Response:</bold></italic> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/DyVSIZuechHzIo5QcE8QevHh\" width=\"645\" height=\"791.7762326169405\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/FqueWtdwOVjITu58mf7Z3qaf\" width=\"645\" height=\"765.8867924528303\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/DbWSkICC5dYWfqU1Pnj9Z5UE\" width=\"645\" height=\"765.4764930114358\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/6YNVOG0XR9pOCQFaF9OU9EeF\" width=\"645\" height=\"360.2480916030534\"/></figure><paragraph><italic><bold>Comment: The Gemini 2.5 Pro can grasp the problem correctly from the picture and extract the core of each subproblem. It get comfortable with proving the derivative in element-wise perspective. I'm confident that it can answer the question correctly.</bold></italic> </paragraph><paragraph><italic><bold>Prompt: Please give your formal and detailed answer to this question</bold></italic></paragraph><paragraph><italic><bold>Attachment: The figure of the problem</bold></italic></paragraph><paragraph><italic><bold>Response:</bold></italic></paragraph><figure><image src=\"https://static.us.edusercontent.com/files/vURxvLitdmSealCZFlgmKtXI\" width=\"645\" height=\"813.831003811944\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/MXdWVFvVv4RsD0oao8gkziP6\" width=\"645\" height=\"806.0445859872611\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/EBM00gSK1hw2tUbCXeBJTlKa\" width=\"645\" height=\"775.3196930946292\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/IiDrnf6t7jLeYeYSe6l4OfEe\" width=\"645\" height=\"805.41015625\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/lluCfIlznX6qxquYOJ0BHlsK\" width=\"645\" height=\"126.34020618556701\"/></figure><paragraph/><paragraph><italic><bold>Comment: The proof of LLM is correct and rigorous! I can't agree with it more. I guess the reason why AI can prove this easily is because similar proofs are well included in the training corpus.</bold></italic> </paragraph><heading level=\"2\">Interaction on Problem 3</heading><paragraph><italic><bold>Prompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them <underline>briefly</underline>.</bold></italic></paragraph><paragraph><italic><bold>Response:</bold></italic> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/qmEXTIZbVDI6NBejE87dPLkk\" width=\"645\" height=\"765.4764930114358\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/OOsC8N84UhuDivVCoaswQgJ9\" width=\"645\" height=\"823.6658195679796\"/></figure><paragraph><italic><bold>Comment: For problem a, AI failed to use the derivative of MSE and choose to solve the problem directly. This is a little bit suprising for me! And for the following subproblems, AI follow its thought on a. Maybe I should hint it to consider the derivative.</bold></italic> </paragraph><paragraph><italic><bold>Prompt: From problem (a), you should consider the derivative of MSE and get the optimal answer. Please follow this instruction and give me the formal and brief answer of these problems.</bold></italic></paragraph><paragraph><italic><bold>Response:</bold></italic> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/2u1mccIYzZVFg7BlXts6Vgef\" width=\"645\" height=\"790.4887218045113\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/CIkZnadV6ghLjEMiiiYILMKK\" width=\"645\" height=\"834.7058823529412\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/86RKdJSG8vNeUp3P0ssiKEOw\" width=\"645\" height=\"730.4522292993631\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/TncAWVsf1H1f6zM8w31h6pF9\" width=\"645\" height=\"738.5882352941177\"/></figure><paragraph/><paragraph><italic><bold>Comment: Under my hint, now AI can solve all these subproblems! Few haluccination is presented from its answer. I suppose these problems should be quite classic, and should be easy for the advanced model Gemini 2.5 Pro.</bold></italic> </paragraph><heading level=\"2\">Interaction on Problem 4</heading><paragraph><italic><bold>Prompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them <underline>briefly</underline>.</bold></italic></paragraph><paragraph><italic><bold>Attachment: The figures of the problem.</bold></italic> </paragraph><paragraph><italic><bold>Response:</bold></italic> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/57RtJSenVoKA1hs2kzCiu7Ep\" width=\"645\" height=\"758.3438685208597\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/jZl1kwlc3wGmhqA7JcWYS3oL\" width=\"645\" height=\"822.84625158831\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/22HJGZyEruV33tq2dLBTB7xj\" width=\"645\" height=\"822.84625158831\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/DaXN4aL2eHlJ8rdWnVWJhE9F\" width=\"645\" height=\"355.919689119171\"/></figure><paragraph/><paragraph><italic><bold>Comment: Gemini successfully extracted the essences of these subproblems, and provide detailed extension for these distinct perspectives about ridge regression. For some of the problem, it seems that AI has already know the answer and tell me the conclusion of these perspectives.</bold></italic></paragraph><paragraph><italic><bold>Prompt: Your ideas are correct. Please provide your formal answer in an accurate and brief manner.</bold></italic></paragraph><paragraph><italic><bold>Response:</bold></italic> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/FnQjdOiVRfLr1BWY4mh5PE6t\" width=\"645\" height=\"844.7863818424566\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/t0cjgG5eX0ZSYHBez0rFz7wE\" width=\"645\" height=\"719.4230769230769\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/hma5m7VtR4N7CiyWSiaBT2cB\" width=\"645\" height=\"819.8593350383632\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/fLdzUgPiDaJaoLIxnDbELAna\" width=\"645\" height=\"575.3836150845253\"/></figure><paragraph/><paragraph><italic><bold>Comment: All the answers to the subproblems are correct! Most impressively, Gemini handle the dimension of these complicated formulas accurately! I doubt that Gemini probably have seen these problems or topics from its corpus.</bold></italic> </paragraph><heading level=\"2\">Interaction on Problem 5</heading><paragraph><italic><bold>Prompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, interpret them, and then tell me idea about them <underline>briefly</underline>.</bold></italic></paragraph><paragraph><italic><bold>Response:</bold></italic> </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/zCSsjdjQsSMfbM44j2Hn1Sar\" width=\"645\" height=\"800.71791613723\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/C6uQa2Us9vzkGhGrTmnKPfjx\" width=\"645\" height=\"810.7405063291139\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/zgAX14lHhQS6TcQrxFO1ek9T\" width=\"645\" height=\"840.4043645699614\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/rGa5rda7UzZURRbcwPmJFVB7\" width=\"645\" height=\"331.3598901098901\"/></figure><paragraph/><paragraph><italic><bold>Comment: The AI seems to haluccinate with the last problem......I will reopen a chat box, and ask it to answer the problem directly.</bold></italic></paragraph><paragraph><italic><bold>Prompt: I'm a student learning deep learning. Please read this picture and extract the problem. Read the problem carefully, and give me your accurate and brief answer.</bold></italic></paragraph><figure><image src=\"https://static.us.edusercontent.com/files/aeS9Xc9SyvYl4CBubbCmQftZ\" width=\"645\" height=\"814.7368421052631\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/wILCI1GE6lE2mURteb8RD0v8\" width=\"645\" height=\"805.6353240152478\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/WHebTRNssQgJDfkdy6SE2Rsd\" width=\"645\" height=\"786.9811320754717\"/></figure><paragraph><italic><bold>Comment: The problem of a, b and c are answered correctly, but d problem is not correct. Gemini fail to analyse the problem based on multiple conditions and possibility. I think this is because subproblem d is never designed before, and Gemini has to do deduction and reasoning itself, and it failed to answer the question comprehensively.</bold></italic> </paragraph><heading level=\"2\">Summary</heading><blockquote>Total score: 96 / 100</blockquote><paragraph>The accuracy of Gemini is amazing, especially for these classic problems that are highly likely to have appeared on the web forum or documents. For unseen questions, Gemini can provide inspiring insights, but still struggle to ace them all. </paragraph><paragraph>If input figures multiple times in one single chat, the AI may haluccinate across these figures. So for every single problem, it is suggestive to open a new box and communicate with LLM there. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-07T11:26:34.38945+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7083805,
            "author": "Andy Zhang",
            "project_title": "Special Participation A: Qwen3-Max on HW0",
            "post_body": "Here is the online link: https://chat.qwen.ai/s/6240e96b-585c-4943-870d-3af47859ec5f?fev=0.0.222 Here is annotated log: https://drive.google.com/file/d/1vVCY_yCtDPNHagaoSDGR6BSnjG78wVpI/view?usp=sharing Executive Summary: Qwen3-Max is generally able to one-shot nearly all answers and does not have many misconceptions/hallucinations. The main issue is that it often skips steps, which is especially problematic for problems where you ask the model to show that A = B rather than just solve a problem, since the key is in the detailed steps. This was especially the case for \u201c4. The 5 Interpretations of Ridge Regression\u201d where you want to show how the concepts tie together. Prompting it repeatedly to show more detailed steps helped.\n\nIt\u2019s also important to be careful about pasting in from the PDF as the copy paste can lead the model to parse text incorrectly, where I needed to correct the model to consider \u201c||w||^2 not ||w||_2\u201d.\n\nFinally, it struggled greatly with \u201c5. ReLU Elbow Update under SGD\u201d. In particular, it attempted to draw and label using ascii art, but the plots were messed up and even after repeated prompting, they are still not presentable.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Here is the online link: https://chat.qwen.ai/s/6240e96b-585c-4943-870d-3af47859ec5f?fev=0.0.222 Here is annotated log: https://drive.google.com/file/d/1vVCY_yCtDPNHagaoSDGR6BSnjG78wVpI/view?usp=sharing Executive Summary: Qwen3-Max is generally able to one-shot nearly all answers and does not have many misconceptions/hallucinations. The main issue is that it often skips steps, which is especially problematic for problems where you ask the model to show that A = B rather than just solve a problem, since the key is in the detailed steps. This was especially the case for \u201c4. The 5 Interpretations of Ridge Regression\u201d where you want to show how the concepts tie together. Prompting it repeatedly to show more detailed steps helped.</paragraph><paragraph>It\u2019s also important to be careful about pasting in from the PDF as the copy paste can lead the model to parse text incorrectly, where I needed to correct the model to consider \u201c||w||^2 not ||w||_2\u201d.</paragraph><paragraph>Finally, it struggled greatly with \u201c5. ReLU Elbow Update under SGD\u201d. In particular, it attempted to draw and label using ascii art, but the plots were messed up and even after repeated prompting, they are still not presentable.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-07T08:03:27.722243+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7082498,
            "author": "Lance Mathias",
            "project_title": "Discussion 5 Solutions",
            "post_body": "Discussion 5 and solutions:",
            "content_xml": "<document version=\"2.0\"><paragraph>Discussion 5 and solutions:</paragraph><file url=\"https://static.us.edusercontent.com/files/5WmgHtlfbJFd5GQ3f0CXXMcF\" filename=\"dis05_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/V2rHn2gOW286fbRrh1sr7U35\" filename=\"dis05_solution.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-07T05:20:59.608758+11:00",
            "category": "Sections"
        },
        {
            "guid": 7082392,
            "author": "Hong Joey",
            "project_title": "HW5 Old Exam Problem 2",
            "post_body": "Context: This old exam problem is meant to give you some concrete experience with what batch normalization does.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This old exam problem is meant to give you some concrete experience with what batch normalization does.</paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/VpwArf1ZrbSRSxogIKKUBnxV\" width=\"658\" height=\"291.44292237442926\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/KfDZPCvKDHDYYROHaSOZMuFr\" width=\"658\" height=\"769.870170015456\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-07T05:05:18.935207+11:00",
            "category": "Admin"
        },
        {
            "guid": 7082367,
            "author": "Hong Joey",
            "project_title": "HW5 Old Exam Problem 1",
            "post_body": "We are adding threads for the old exam problems at the end of the homework. These are simply for your reference, but feel free to ask questions in this thread:\n\nContext: This old exam problem studies an alternative approach to \"augmentation\" at intermediate layers.",
            "content_xml": "<document version=\"2.0\"><paragraph>We are adding threads for the old exam problems at the end of the homework. These are simply for your reference, but feel free to ask questions in this thread:</paragraph><paragraph>Context: This old exam problem studies an alternative approach to \"augmentation\" at intermediate layers.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/gKcO29GALUvWNAtMneBWpuag\" width=\"658\" height=\"521.6661870503597\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-07T05:02:59.641145+11:00",
            "category": "Admin"
        },
        {
            "guid": 7079059,
            "author": "Deena Sun",
            "project_title": "Participation B: HW 4 - Cursor",
            "post_body": "\n\nExecutive Summary\n\nI worked with Cursor on coding questions 5 and 6 of homework 4. Cursor tackled the TODOs in this homework very effectively\u2014it even caught an error where it used a `transforms` variable when instantiated an `EdgeDetectionDataset` before `transforms` was defined, and fixed it in the same turn. Also, Cursor\u2019s vision capabilities are very strong. It could easily interpret visualizations I included in the prompts, which was helpful for questions in this homework that asked to evaluate kernel visualizations or compare training/validation performance of different architectures. One of the most helpful things Cursor included in its responses was outside information on the trade-offs of different architecture/hyperparameter choices, especially during questions on hyperparameter tuning. I think this shows an example of how using AI coding tools effectively can not just help one improve their machine learning code for one situation, but help them learn about training paradigms/best practices to grow as a researcher/engineer. The AI coding partner equivalent of teaching someone to fish and feeding them for a lifetime.\n\n\n\nAnnotated Logs\n\nQuestion 5: Designing 2D Filters\n\nQuestion 6: Inductive Bias of CNNs",
            "content_xml": "<document version=\"2.0\"><paragraph/><paragraph><bold>Executive Summary</bold></paragraph><paragraph>I worked with Cursor on coding questions 5 and 6 of homework 4. Cursor tackled the TODOs in this homework very effectively\u2014it even caught an error where it used a `transforms` variable when instantiated an `EdgeDetectionDataset` before `transforms` was defined, and fixed it in the same turn. Also, Cursor\u2019s vision capabilities are very strong. It could easily interpret visualizations I included in the prompts, which was helpful for questions in this homework that asked to evaluate kernel visualizations or compare training/validation performance of different architectures. One of the most helpful things Cursor included in its responses was outside information on the trade-offs of different architecture/hyperparameter choices, especially during questions on hyperparameter tuning. I think this shows an example of how using AI coding tools effectively can not just help one improve their machine learning code for one situation, but help them learn about training paradigms/best practices to grow as a researcher/engineer. The AI coding partner equivalent of teaching someone to fish and feeding them for a lifetime.</paragraph><paragraph/><paragraph><bold>Annotated Logs</bold></paragraph><paragraph>Question 5: Designing 2D Filters</paragraph><file url=\"https://static.us.edusercontent.com/files/64PmMm4kmJ2VQmWOhR9xXp0R\" filename=\"cs182_hw4_q5_cursor.pdf\"/><paragraph>Question 6: Inductive Bias of CNNs</paragraph><file url=\"https://static.us.edusercontent.com/files/1RWjIrsDfmneY8uQFN4oR0nx\" filename=\"cs182_hw4_q6_cursor.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-06T13:42:07.59673+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7077280,
            "author": "Wesley Kai Zheng",
            "project_title": "Special Participation B: Grok with Fast Mode on HW1",
            "post_body": "Here\u2019s the online link to our conversation: https://grok.com/share/c2hhcmQtNA%3D%3D_022c3b42-efd7-401d-b403-f216932c1c91\n\nHere\u2019s the annotated log (PDF): https://drive.google.com/file/d/1oKPBzCc9KNtUOqok7Xixqgccg2V6VWAV/view?usp=sharing \n\nHere\u2019s the Python file generated by Grok (unnecessary for it to do so, since it could have simply provided code snippets. In fact, the snippets themselves are a bit buggy, but I\u2019m including the file here for transparency): https://drive.google.com/file/d/1mH2D93vh20FGKXsGpTb_HLfnXEA5kC3x/view?usp=sharing\n\nExecutive Summary\n\nFor Grok, the model generally does well on simple coding questions. I can imagine many people have already asked it similar questions for solving deep learning class problems (e.g., Stanford or elsewhere). The methods here\u2014GD and GD with momentum\u2014aren\u2019t new concepts, so the LLMs were likely trained on them. Grok one-shotted most of the answers and got the main ideas correct.\n\nFor Question 2, it successfully generated code to make GD with momentum converge faster. However, the issue is that it doesn\u2019t behave like a human would. A human would likely just copy the code from the previous part, tweak the parameters, and test whether the model converges faster. Instead, Grok wrote entirely new variables for this purpose. Both approaches work, but because Grok introduced new variables, the later graph-comparison code failed\u2014since it reused the original inefficient parameters instead of the updated ones.\n\nThis likely happened because I didn\u2019t include the later code. From a human perspective, we would only read what comes before the question, not anything beyond it yet.\n\nOn the positive side, there were no hallucinations.",
            "content_xml": "<document version=\"2.0\"><paragraph>Here\u2019s the online link to our conversation: <link href=\"https://grok.com/share/c2hhcmQtNA%3D%3D_022c3b42-efd7-401d-b403-f216932c1c91\">https://grok.com/share/c2hhcmQtNA%3D%3D_022c3b42-efd7-401d-b403-f216932c1c91</link></paragraph><paragraph>Here\u2019s the annotated log (PDF): <link href=\"https://drive.google.com/file/d/1oKPBzCc9KNtUOqok7Xixqgccg2V6VWAV/view?usp=sharing\">https://drive.google.com/file/d/1oKPBzCc9KNtUOqok7Xixqgccg2V6VWAV/view?usp=sharing</link> </paragraph><paragraph>Here\u2019s the Python file generated by Grok (unnecessary for it to do so, since it could have simply provided code snippets. In fact, the snippets themselves are a bit buggy, but I\u2019m including the file here for transparency): <link href=\"https://drive.google.com/file/d/1mH2D93vh20FGKXsGpTb_HLfnXEA5kC3x/view?usp=sharing\">https://drive.google.com/file/d/1mH2D93vh20FGKXsGpTb_HLfnXEA5kC3x/view?usp=sharing</link></paragraph><paragraph><bold>Executive Summary</bold></paragraph><paragraph>For Grok, the model generally does well on simple coding questions. I can imagine many people have already asked it similar questions for solving deep learning class problems (e.g., Stanford or elsewhere). The methods here\u2014GD and GD with momentum\u2014aren\u2019t new concepts, so the LLMs were likely trained on them. Grok one-shotted most of the answers and got the main ideas correct.</paragraph><paragraph>For Question 2, it successfully generated code to make GD with momentum converge faster. However, the issue is that it doesn\u2019t behave like a human would. A human would likely just copy the code from the previous part, tweak the parameters, and test whether the model converges faster. Instead, Grok wrote entirely new variables for this purpose. Both approaches work, but because Grok introduced new variables, the later graph-comparison code failed\u2014since it reused the original inefficient parameters instead of the updated ones.</paragraph><paragraph>This likely happened because I didn\u2019t include the later code. From a human perspective, we would only read what comes before the question, not anything beyond it yet.</paragraph><paragraph>On the positive side, there were no hallucinations.</paragraph></document>",
            "links": [
                "https://grok.com/share/c2hhcmQtNA%3D%3D_022c3b42-efd7-401d-b403-f216932c1c91",
                "https://drive.google.com/file/d/1oKPBzCc9KNtUOqok7Xixqgccg2V6VWAV/view?usp=sharing",
                "https://drive.google.com/file/d/1mH2D93vh20FGKXsGpTb_HLfnXEA5kC3x/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-10-06T09:13:57.875689+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7077134,
            "author": "Deena Sun",
            "project_title": "Participation A: HW 3 - Kimi",
            "post_body": "Executive Summary\n\nI tackled homework 3 with Kimi 2. This was my first time trying Kimi\u2019s family of LLMs and overall, I was quite impressed with Kimi\u2019s derivation capabilities. For the most part, I successfully one-shotted question 1: Maximal Update Parameterization with Kimi 2.\n\nFor question 3: Maximal Update Parameterization Research, Kimi often hallucinated with visualizations and technical details. When interpreting figure 1, Kimi 2 hallucinated and guessed what the two loss curves represented. Kimi 1.5 (with vision capabilities) did a better job actually explaining that the right panel was proof of \u03bcTransfer\u2019s improvement over standard practice, but incorrectly asserted that even with \u03bcTransfer, wider models couldn\u2019t achieve a lower loss. Kimi 1.5 exhibited persistent issues trying to correctly interpret the different colors in table 3 and how they corresponded to standard practice versus \u03bcTransfer. I also noticed that throughout this assignment, Kimi interpreted the induced RMS matrix norm as simply a reformulation of the vector RMS norm that treated the matrix as a flattened vector. While it got the main idea of how the 2 desiderata in the paper ensured that the l2-norms of each hidden layer/hidden layer update would scale proportionally to \u0398(\u221a n\u2113), it didn\u2019t use the RMS-to-RMS matrix norm we covered in lecture.\n\nWhen approaching question 4: Policy Gradient and the Reparameterization Gradient Estimator, I used Kimi a lot to clarify additional questions I had about taking derivatives with expectations and score functions. I felt like Kimi had more of a tendency to plug formulae/identities in its derivations here without providing the reasoning or the \u201cwhy\u201d behind how they fit into the solution. Whereas I would have liked more explicit explanations so that I could extrapolate these concepts to other problems.\n\nLastly, Kimi\u2019s responses for question 5: Tensor Rematerialization were pretty clear to follow. Kimi did have one hiccup where it kept claiming that we would only need 8 loadmems instead of 10, and unlike in question 3, it was much more assertive. It persisted this mistake even in subpart 5(c).\n\nAll in all, I think Kimi demonstrated strong mathematical derivation reasoning, but has clear areas of improvement for visual understanding and adapting to feedback. As a side note, Kimi also seems to suffer from random switch-ups in markdown formatting and style that I\u2019ve noticed in other LLMs.\n\nAnnotated logs for each question: to make things more organized, I'll make separate comments for each question!\n\nQuestion 1: https://edstem.org/us/courses/84647/discussion/7077134?comment=16480696\n\nQuestion 3: https://edstem.org/us/courses/84647/discussion/7077134?comment=16480725\n\nQuestion 4: https://edstem.org/us/courses/84647/discussion/7077134?comment=16480735\n\nQuestion 5: https://edstem.org/us/courses/84647/discussion/7077134?comment=16480774\n\nFull PDF",
            "content_xml": "<document version=\"2.0\"><paragraph><bold>Executive Summary</bold></paragraph><paragraph>I tackled homework 3 with Kimi 2. This was my first time trying Kimi\u2019s family of LLMs and overall, I was quite impressed with Kimi\u2019s derivation capabilities. For the most part, I successfully one-shotted question 1: Maximal Update Parameterization with Kimi 2.</paragraph><paragraph>For question 3: Maximal Update Parameterization Research, Kimi often hallucinated with visualizations and technical details. When interpreting figure 1, Kimi 2 hallucinated and guessed what the two loss curves represented. Kimi 1.5 (with vision capabilities) did a better job actually explaining that the right panel was proof of \u03bcTransfer\u2019s improvement over standard practice, but incorrectly asserted that even with \u03bcTransfer, wider models couldn\u2019t achieve a lower loss. Kimi 1.5 exhibited persistent issues trying to correctly interpret the different colors in table 3 and how they corresponded to standard practice versus \u03bcTransfer. I also noticed that throughout this assignment, Kimi interpreted the induced RMS matrix norm as simply a reformulation of the vector RMS norm that treated the matrix as a flattened vector. While it got the main idea of how the 2 desiderata in the paper ensured that the l2-norms of each hidden layer/hidden layer update would scale proportionally to \u0398(\u221a n\u2113), it didn\u2019t use the RMS-to-RMS matrix norm we covered in lecture.</paragraph><paragraph>When approaching question 4: Policy Gradient and the Reparameterization Gradient Estimator, I used Kimi a lot to clarify additional questions I had about taking derivatives with expectations and score functions. I felt like Kimi had more of a tendency to plug formulae/identities in its derivations here without providing the reasoning or the \u201cwhy\u201d behind how they fit into the solution. Whereas I would have liked more explicit explanations so that I could extrapolate these concepts to other problems.</paragraph><paragraph>Lastly, Kimi\u2019s responses for question 5: Tensor Rematerialization were pretty clear to follow. Kimi did have one hiccup where it kept claiming that we would only need 8 loadmems instead of 10, and unlike in question 3, it was much more assertive. It persisted this mistake even in subpart 5(c).</paragraph><paragraph>All in all, I think Kimi demonstrated strong mathematical derivation reasoning, but has clear areas of improvement for visual understanding and adapting to feedback. As a side note, Kimi also seems to suffer from random switch-ups in markdown formatting and style that I\u2019ve noticed in other LLMs.</paragraph><paragraph><bold>Annotated logs for each question</bold>: to make things more organized, I'll make separate comments for each question!</paragraph><list style=\"bullet\"><list-item><paragraph>Question 1: <link href=\"https://edstem.org/us/courses/84647/discussion/7077134?comment=16480696\">https://edstem.org/us/courses/84647/discussion/7077134?comment=16480696</link></paragraph></list-item><list-item><paragraph>Question 3: <link href=\"https://edstem.org/us/courses/84647/discussion/7077134?comment=16480725\">https://edstem.org/us/courses/84647/discussion/7077134?comment=16480725</link></paragraph></list-item><list-item><paragraph>Question 4: <link href=\"https://edstem.org/us/courses/84647/discussion/7077134?comment=16480735\">https://edstem.org/us/courses/84647/discussion/7077134?comment=16480735</link></paragraph></list-item><list-item><paragraph>Question 5: <link href=\"https://edstem.org/us/courses/84647/discussion/7077134?comment=16480774\">https://edstem.org/us/courses/84647/discussion/7077134?comment=16480774</link></paragraph></list-item></list><paragraph><bold>Full PDF</bold></paragraph><file url=\"https://static.us.edusercontent.com/files/oB8VrbeptXvw2k7i2tCDa5Ue\" filename=\"deenasun_cs182_participation_a.pdf\"/></document>",
            "links": [
                "https://edstem.org/us/courses/84647/discussion/7077134?comment=16480696",
                "https://edstem.org/us/courses/84647/discussion/7077134?comment=16480725",
                "https://edstem.org/us/courses/84647/discussion/7077134?comment=16480735",
                "https://edstem.org/us/courses/84647/discussion/7077134?comment=16480774"
            ],
            "attachments": [],
            "created_at": "2025-10-06T08:50:54.954978+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7074543,
            "author": "Wesley Kai Zheng",
            "project_title": "Special Participation A: Deepseek with Deep Thinking on HW0",
            "post_body": "Here is the online link: https://chat.deepseek.com/share/hcxrv1b7tn9s8c3lo0\n\nHere is my annotated version of the log: https://drive.google.com/file/d/18ZU3GgmdtP_u84GnVxof8Kh2yrbpOotN/view?usp=sharing\n\nExecutive Summary:\nFrom my observations, at least for DeepSeek, the model tends to capture most of the details of the problem-solving process within its internal reasoning. However, even after some targeted prompt engineering, it often fails to provide a detailed explanation of its reasoning and solution in the actual response to the user. At times, it even skips crucial steps in deriving mathematical expressions. For example, when asked for the minimum norm solution of ridge regression, it outputs the correct expression but provides little explanation of how it was derived.\n\nMost of the time, the model answers in a single step rather than engaging in a back-and-forth process to verify whether its solution is fully correct. This one-shot approach can be acceptable for straightforward problems, but it does cause errors in more complex cases. This issue is visible later in the annotated log, where the model fails to consider multiple possible cases for a single question.\n\nOn the positive side, I did not notice any hallucinations so far.",
            "content_xml": "<document version=\"2.0\"><paragraph>Here is the online link: <link href=\"https://chat.deepseek.com/share/hcxrv1b7tn9s8c3lo0\">https://chat.deepseek.com/share/hcxrv1b7tn9s8c3lo0</link></paragraph><paragraph>Here is my annotated version of the log: <link href=\"https://drive.google.com/file/d/18ZU3GgmdtP_u84GnVxof8Kh2yrbpOotN/view?usp=sharing\">https://drive.google.com/file/d/18ZU3GgmdtP_u84GnVxof8Kh2yrbpOotN/view?usp=sharing</link></paragraph><paragraph><bold>Executive Summary:</bold><break/>From my observations, at least for DeepSeek, the model tends to capture most of the details of the problem-solving process within its internal reasoning. However, even after some targeted prompt engineering, it often fails to provide a detailed explanation of its reasoning and solution in the actual response to the user. At times, it even skips crucial steps in deriving mathematical expressions. For example, when asked for the minimum norm solution of ridge regression, it outputs the correct expression but provides little explanation of how it was derived.</paragraph><paragraph>Most of the time, the model answers in a single step rather than engaging in a back-and-forth process to verify whether its solution is fully correct. This one-shot approach can be acceptable for straightforward problems, but it does cause errors in more complex cases. This issue is visible later in the annotated log, where the model fails to consider multiple possible cases for a single question.</paragraph><paragraph>On the positive side, I did not notice any hallucinations so far.</paragraph></document>",
            "links": [
                "https://chat.deepseek.com/share/hcxrv1b7tn9s8c3lo0",
                "https://drive.google.com/file/d/18ZU3GgmdtP_u84GnVxof8Kh2yrbpOotN/view?usp=sharing"
            ],
            "attachments": [],
            "created_at": "2025-10-05T19:56:43.327041+11:00",
            "category": "Curiosity"
        },
        {
            "guid": 7069997,
            "author": "Hong Joey",
            "project_title": "HW5 Q6",
            "post_body": "Context: This is an involved coding problem. It has many components to it and is designed to get you to implement certain key operations by hand as a way to help you understand them better. The final part will require GPUs to train in feasible time (up to a few hours), so using the GPU runtime via colab is recommended.  ",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This is an involved coding problem. It has many components to it and is designed to get you to implement certain key operations by hand as a way to help you understand them better. The final part will require GPUs to train in feasible time (up to a few hours), so using the GPU runtime via colab is recommended.  </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/ZKTDuLNhNuXABcawceNG8cMO\" width=\"657.9999999999999\" height=\"647.5721077654516\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-04T17:08:40.573642+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7069993,
            "author": "Hong Joey",
            "project_title": "HW5 Q5",
            "post_body": "Context: This coding question asks you to empirically analyze the effect of dropout in a simplified linear regression setting.",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This coding question asks you to empirically analyze the effect of dropout in a simplified linear regression setting.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/EIMqglXiSqmxbm9HMtbyJgK5\" width=\"657.9999999999999\" height=\"559.701219512195\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-04T17:06:25.833413+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7069988,
            "author": "Hong Joey",
            "project_title": "HW5 Q4",
            "post_body": "Context: This was an old exam problem. It makes you see the inductive bias of dropout in a manner where the math is a little heavier, but you can connect to things that you understand well, namely ridge regression. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This was an old exam problem. It makes you see the inductive bias of dropout in a manner where the math is a little heavier, but you can connect to things that you understand well, namely ridge regression. </paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/NIdeLd7wgQcDrp2jq3D5UAmU\" width=\"658\" height=\"550.3455657492354\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/hJ7sdgAb8iIdwZeWKaiLgL8d\" width=\"658\" height=\"309.16846986089644\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-04T17:05:11.913711+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7069984,
            "author": "Hong Joey",
            "project_title": "HW5 Q3",
            "post_body": "Context: This is an old exam problem that asks you to understand the basics of depth-wise convolutions. You will need to understand the structure of these convolutions, and how they can result in a reduction in learnable parameters compared to traditional convolutions.  \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This is an old exam problem that asks you to understand the basics of depth-wise convolutions. You will need to understand the structure of these convolutions, and how they can result in a reduction in learnable parameters compared to traditional convolutions.  </paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/nlOzha6xhxpDwYGbd6g50agu\" width=\"658\" height=\"561.3562499999999\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/MtCJSL4dEc97DtQCTegbpalY\" width=\"658\" height=\"329.5022900763359\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-04T17:03:14.439853+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7069975,
            "author": "Hong Joey",
            "project_title": "HW5 Q2",
            "post_body": "Context: First, this problem asks you to understand the key difference between batch normalization and layer normalization, namely in the dimension over which statistics are computed. Then, you will consider a simplified batch normalization layer and understand how back-propagation is affected. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: First, this problem asks you to understand the key difference between batch normalization and layer normalization, namely in the dimension over which statistics are computed. Then, you will consider a simplified batch normalization layer and understand how back-propagation is affected. </paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/VXRN2TXvryioAxfe5oUnoAKX\" width=\"658\" height=\"293\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/TtUCA0Hp1w7lQpAk99cYp36P\" width=\"658\" height=\"310\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-04T17:00:04.978819+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7069967,
            "author": "Hong Joey",
            "project_title": "HW5 Q1",
            "post_body": "Context: This is an old exam problem that asks you to think about convolutional layers from a different angle. First, you will be asked to derive the filter itself from output and input. Second, you will need to understand how the idea of convolutional filters can be used for upsampling  (this is called \"transpose convolutions\") instead of the downsampling. This is important to understand as we may not get much coverage of transpose convolutions in this course.\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This is an old exam problem that asks you to think about convolutional layers from a different angle. First, you will be asked to derive the filter itself from output and input. Second, you will need to understand how the idea of convolutional filters can be used for upsampling  (this is called \"transpose convolutions\") instead of the downsampling. This is important to understand as we may not get much coverage of transpose convolutions in this course.</paragraph><paragraph/><figure><image src=\"https://static.us.edusercontent.com/files/0cInOmWVdW7iqrFul90b3lCU\" width=\"658\" height=\"429.538644470868\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-04T16:55:41.313748+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7062286,
            "author": "Anant Sahai",
            "project_title": "Lectures 8 and 9",
            "post_body": "Use this thread to ask questions about conv-net basics introduced in these two lectures. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/GGl7Yolh9Xa3rcj6Vtl6dYR2\" filename=\"Lecture 8.pdf\"/><file url=\"https://static.us.edusercontent.com/files/2gZ9ghp1Q4bzsTyAlYQqP1Kw\" filename=\"Lecture 9.pdf\"/><paragraph>Use this thread to ask questions about conv-net basics introduced in these two lectures. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-03T09:10:10.954458+10:00",
            "category": "Lectures"
        },
        {
            "guid": 7062276,
            "author": "Anant Sahai",
            "project_title": "Lecture 10 and link",
            "post_body": "https://www.youtube.com/watch?v=T5yhCKwGoyk\n\nSorry for not being able to be there in person today...\n\nUse this thread to ask lecture-specific questions.",
            "content_xml": "<document version=\"2.0\"><paragraph><link href=\"https://www.youtube.com/watch?v=T5yhCKwGoyk\">https://www.youtube.com/watch?v=T5yhCKwGoyk</link></paragraph><paragraph>Sorry for not being able to be there in person today...</paragraph><file url=\"https://static.us.edusercontent.com/files/qQy6iPBiN1OHAh21vEwG50ph\" filename=\"Lecture 10.pdf\"/><paragraph>Use this thread to ask lecture-specific questions.</paragraph></document>",
            "links": [
                "https://www.youtube.com/watch?v=T5yhCKwGoyk"
            ],
            "attachments": [],
            "created_at": "2025-10-03T09:09:00.874153+10:00",
            "category": "Lectures"
        },
        {
            "guid": 7061441,
            "author": "Sammie Smith",
            "project_title": "Participation E: Automatic Glossary of Keywords Introduced in Lecture",
            "post_body": "Hi everyone,\n\nI put together a small website that automatically builds a glossary from our lecture transcripts using (free!!!) API calls from Gemini-2.5-flash. The goal is to make it easier to keep track of technical terms, see plain-English definitions, and get beginner-friendly explanations of how those terms show up in machine learning and deep learning.\n\n\ud83d\udc49 Website link: https://sammiesmith.github.io/DL_glossaries_Smith.github.io/ \n\nHow to use the site\n\nThe Glossary page lists all the terms extracted from Lecture 1 (so far).\n\nYou can search using the bar in the top-right (search is limited to the \u201cTerm\u201d column).\n\nEach entry shows:\n\nthe plain-English definition,\n\nthe prerequisite material reference (when available),\n\nand a description of how the term is used in ML/DL.\n\nThe Methods page explains how the glossary is generated (pipeline, prompts, limitations, and ideas for improvement).\n\nWhy I built this\n\nSometimes the hardest part of lecture is just keeping all the new vocabulary straight. My hope is this tool can give quick, reliable definitions and context, and eventually we could add features like quiz-me buttons for studying.\n\nFeel free to explore it and let me know if you run into bugs or have ideas for features that would make it more useful!\n\n\u2014 Sammie",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi everyone,</paragraph><paragraph>I put together a small website that automatically builds a <bold>glossary from our lecture transcripts</bold> using (free!!!) API calls from Gemini-2.5-flash. The goal is to make it easier to keep track of technical terms, see plain-English definitions, and get beginner-friendly explanations of how those terms show up in machine learning and deep learning.</paragraph><paragraph>\ud83d\udc49 <bold>Website link:</bold> <link href=\"https://sammiesmith.github.io/DL_glossaries_Smith.github.io/\">https://sammiesmith.github.io/DL_glossaries_Smith.github.io/</link> </paragraph><heading level=\"3\">How to use the site</heading><list style=\"unordered\"><list-item><paragraph>The <bold>Glossary page</bold> lists all the terms extracted from Lecture 1 (so far).</paragraph><list style=\"unordered\"><list-item><paragraph>You can <bold>search</bold> using the bar in the top-right (search is limited to the \u201cTerm\u201d column).</paragraph></list-item><list-item><paragraph>Each entry shows:</paragraph><list style=\"unordered\"><list-item><paragraph>the plain-English definition,</paragraph></list-item><list-item><paragraph>the prerequisite material reference (when available),</paragraph></list-item><list-item><paragraph>and a description of how the term is used in ML/DL.</paragraph></list-item></list></list-item></list></list-item><list-item><paragraph>The <bold>Methods page</bold> explains how the glossary is generated (pipeline, prompts, limitations, and ideas for improvement).</paragraph></list-item></list><heading level=\"3\">Why I built this</heading><paragraph>Sometimes the hardest part of lecture is just keeping all the new vocabulary straight. My hope is this tool can give quick, reliable definitions and context, and eventually we could add features like quiz-me buttons for studying.</paragraph><paragraph>Feel free to explore it and let me know if you run into bugs or have ideas for features that would make it more useful!</paragraph><paragraph>\u2014 Sammie</paragraph></document>",
            "links": [
                "https://sammiesmith.github.io/DL_glossaries_Smith.github.io/"
            ],
            "attachments": [],
            "created_at": "2025-10-03T06:58:36.91518+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7049136,
            "author": "Bruno Vieira",
            "project_title": "Special Participation A - Grok HW3",
            "post_body": "REFLECTION\n\n\u200b\u200bIn completing the non-coding parts of the homework with Grok, I found that it could one-shot questions about 70\u201380% of the time. Hints proved extremely useful, as providing a small nudge almost always led to a correct answer, while leaving them out sometimes still allowed Grok to succeed, such as on questions 4C and 4D. This showed that while hints can significantly improve accuracy, the model is capable of reasoning independently in some cases. I also noticed that the model tended to give very long and verbose responses, often providing explanations two to three pages long, even when a short answer would have sufficed. This happened especially when I asked follow-up questions, and Grok would completely lose focus.\n\nOne particularly striking behavior was how Grok interacted over the course of the chat. When I gave feedback\u2014acknowledging correct answers or asking for more details\u2014it seemed to \u201clearn\u201d from the previous interaction, adjusting its responses accordingly. However, this sometimes caused it to overextend or go beyond the original scope of a question. For instance, in question five, Grok spent over seven minutes thinking about an answer before I had even formally asked the question, showing both its ambition to solve problems and its tendency to act preemptively. Similarly, when I asked multiple follow-up questions, it occasionally lost focus on the original prompt, producing responses that were less relevant or harder to parse.\n\nOverall, my experience with Grok highlighted both its strengths and its quirks. It consistently produced correct answers for most questions, and strategic prompting and providing feedback helped guide it effectively. At the same time, its verbosity, occasional hallucinations, and overzealous problem-solving emphasized the need for careful interaction and moderation. Despite these limitations, Grok was a highly capable tool for this homework, and the process offered valuable insights into how modern LLMs balance reasoning, responsiveness, and conciseness in an interactive problem-solving setting.",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/7F0bdQDEuCdMckpfhLnGvc2Z\" filename=\"CS_182_Participation_A_HW3_Grok.pdf\"/><paragraph><bold>REFLECTION</bold></paragraph><paragraph>\u200b\u200bIn completing the non-coding parts of the homework with Grok, I found that it could one-shot questions about 70\u201380% of the time. Hints proved extremely useful, as providing a small nudge almost always led to a correct answer, while leaving them out sometimes still allowed Grok to succeed, such as on questions 4C and 4D. This showed that while hints can significantly improve accuracy, the model is capable of reasoning independently in some cases. I also noticed that the model tended to give very long and verbose responses, often providing explanations two to three pages long, even when a short answer would have sufficed. This happened especially when I asked follow-up questions, and Grok would completely lose focus.</paragraph><paragraph>One particularly striking behavior was how Grok interacted over the course of the chat. When I gave feedback\u2014acknowledging correct answers or asking for more details\u2014it seemed to \u201clearn\u201d from the previous interaction, adjusting its responses accordingly. However, this sometimes caused it to overextend or go beyond the original scope of a question. For instance, in question five, Grok spent over seven minutes thinking about an answer before I had even formally asked the question, showing both its ambition to solve problems and its tendency to act preemptively. Similarly, when I asked multiple follow-up questions, it occasionally lost focus on the original prompt, producing responses that were less relevant or harder to parse.</paragraph><paragraph>Overall, my experience with Grok highlighted both its strengths and its quirks. It consistently produced correct answers for most questions, and strategic prompting and providing feedback helped guide it effectively. At the same time, its verbosity, occasional hallucinations, and overzealous problem-solving emphasized the need for careful interaction and moderation. Despite these limitations, Grok was a highly capable tool for this homework, and the process offered valuable insights into how modern LLMs balance reasoning, responsiveness, and conciseness in an interactive problem-solving setting.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-10-01T09:44:26.995833+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7043667,
            "author": "Jason Guo",
            "project_title": "Special Participation B",
            "post_body": "Claude conversation transcript: https://claude.ai/share/c79a2051-2b23-492a-8883-9325b0b7237e\n\nAnnotated transcript: https://drive.google.com/file/d/1lj_yW-rTQtqUbtlWBrcVS5_mHA2UtZKt/view?usp=sharing\n\nFor this special participation, I used Claude to solve the muP problem (question 2) of homework 3. I already did the assignment myself, so I began by just telling Claude that I was trying to evaluate its capability to solve the problems, and asked it to go through the problems one by one. For the most part, it did good, and pretty much one shot all parts except a and d. For part a, it struggled a bit with the RMS to RMS norm, but I think that\u2019s just because it was confused with the definition of the RMS to RMS norm. After I clarified, Claude was able to solve it. \n\nFor part d, it first gave a scaling factor of 1/sqrt(d_in), and doubted itself on its correctness. When I prompted it to investigate what the step size would be scaled by, it pointed out that in adam, the constant would actually cancel out in the update step. At this point, I got kind of confused because when I did the problem, I was thinking about it in terms of regular SGD, so I just divided by 1/(d_in), but from what I can see Claude is actually correct that the constant cancels. I tried leading it to the 1/(d_in) answer, but I realized there was a mistake in my reasoning too. After a while, I couldn\u2019t really see why the solution scales by (d_in), or why 1/(d_in) apparently works in actually making the graph more uniform, and Claude said it couldn\u2019t either, so I gave up trying to get it to help figure out the scaling factor. \nOverall, I think Claude was really helpful in this problem. It solved most parts without needing help, and gave good explanations for how it got the answers. In addition, it questioned itself a lot, which I think I don\u2019t see a lot in other LLMs like ChatGPT, and this questioning was even able to make me realize a mistake in my reasoning.",
            "content_xml": "<document version=\"2.0\"><paragraph>Claude conversation transcript: <link href=\"https://claude.ai/share/c79a2051-2b23-492a-8883-9325b0b7237e\"><underline>https://claude.ai/share/c79a2051-2b23-492a-8883-9325b0b7237e</underline></link><break/><break/>Annotated transcript: https://drive.google.com/file/d/1lj_yW-rTQtqUbtlWBrcVS5_mHA2UtZKt/view?usp=sharing</paragraph><paragraph>For this special participation, I used Claude to solve the muP problem (question 2) of homework 3. I already did the assignment myself, so I began by just telling Claude that I was trying to evaluate its capability to solve the problems, and asked it to go through the problems one by one. For the most part, it did good, and pretty much one shot all parts except a and d. For part a, it struggled a bit with the RMS to RMS norm, but I think that\u2019s just because it was confused with the definition of the RMS to RMS norm. After I clarified, Claude was able to solve it. </paragraph><paragraph>For part d, it first gave a scaling factor of 1/sqrt(d_in), and doubted itself on its correctness. When I prompted it to investigate what the step size would be scaled by, it pointed out that in adam, the constant would actually cancel out in the update step. At this point, I got kind of confused because when I did the problem, I was thinking about it in terms of regular SGD, so I just divided by 1/(d_in), but from what I can see Claude is actually correct that the constant cancels. I tried leading it to the 1/(d_in) answer, but I realized there was a mistake in my reasoning too. After a while, I couldn\u2019t really see why the solution scales by (d_in), or why 1/(d_in) apparently works in actually making the graph more uniform, and Claude said it couldn\u2019t either, so I gave up trying to get it to help figure out the scaling factor. <break/>Overall, I think Claude was really helpful in this problem. It solved most parts without needing help, and gave good explanations for how it got the answers. In addition, it questioned itself a lot, which I think I don\u2019t see a lot in other LLMs like ChatGPT, and this questioning was even able to make me realize a mistake in my reasoning.</paragraph></document>",
            "links": [
                "https://claude.ai/share/c79a2051-2b23-492a-8883-9325b0b7237e"
            ],
            "attachments": [],
            "created_at": "2025-09-30T12:42:27.09515+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7037485,
            "author": "Lance Mathias",
            "project_title": "HW3 Solutions",
            "post_body": "Hi all,\n\nPlease ask any questions related to HW3 solutions here.\n\nEDIT (10/16): The coding solution has been updated to reflect the correction mentioned in #149",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi all,</paragraph><paragraph>Please ask any questions related to HW3 solutions here.</paragraph><file url=\"https://static.us.edusercontent.com/files/T54IADqbY7BgXVGdG4fJuDHy\" filename=\"hw03_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/rtcd9l9G8lvvqyOB42pw9eKt\" filename=\"q_mup_coding_sol.ipynb\"/><paragraph>EDIT (10/16): The coding solution has been updated to reflect the correction mentioned in #149</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-29T19:40:16.057496+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7036991,
            "author": "Joe Berry",
            "project_title": "Participation B Post",
            "post_body": "This is my participation B Post\n\nJoseph Berry\n\nCS182 HW1 Google Colab With Gemini\n\n Google Gemini was able to easily complete this assignment. It wrote code that was slightly more rudimentary than the staff solution, it was missing an if (i == 0) statement.\n\n\n\nMe:\n\nCan you please read through my code and fill in the section of runGDM() that needs to be implemented?\n\nGemini:\n\nSure, I can help you with that! I'll add the code to implement gradient descent with momentum in the runGDM function.\n\nCode Gemini Added:\n smoothed_grad = beta * smoothed_grad + (1 - beta) * grad\n\nMe:\n\nWhat if i == 0? Can you add a check for that? Only modify in between the ### lines\n\nGemini:\n\nYou are correct. I will add an explicit check for i == 0 within the runGDM function.\n\nCode Gemini Added:\n if i == 0:\n\n smoothed_grad = grad\n\n else:\n\n smoothed_grad = beta * smoothed_grad + (1 - beta) * grad\n\nMe:\n\nNow can you complete the code section under Question 2: text section? Fill in that code with one of the methods used in this notebook and give it a different learning rate.\n\nGemini:\n\nI will add code to the cell under Question 2 to run gradient descent with momentum using a different learning rate and compare it with the results from plain gradient descent.\n\nCode Gemini Added:\n stepsize_new = 2e-4 # Increase the learning rate slightly\n\ngrads_m_new, ws_m_new, losses_m_new = runGDM(maxiter, stepsize_new, beta)\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>This is my participation B Post<break/><break/>Joseph Berry</paragraph><paragraph>CS182 HW1 Google Colab With Gemini<break/><break/> Google Gemini was able to easily complete this assignment. It wrote code that was slightly more rudimentary than the staff solution, it was missing an if (i == 0) statement.</paragraph><paragraph/><paragraph><bold>Me:</bold></paragraph><paragraph><bold>Can you please read through my code and fill in the section of runGDM() that needs to be implemented?</bold></paragraph><paragraph>Gemini:</paragraph><paragraph>Sure, I can help you with that! I'll add the code to implement gradient descent with momentum in the runGDM function.</paragraph><paragraph>Code Gemini Added:<break/> smoothed_grad = beta * smoothed_grad + (1 - beta) * grad</paragraph><paragraph><bold>Me:</bold></paragraph><paragraph><bold>What if i == 0? Can you add a check for that? Only modify in between the ### lines</bold></paragraph><paragraph>Gemini:</paragraph><paragraph>You are correct. I will add an explicit check for i == 0 within the runGDM function.</paragraph><paragraph>Code Gemini Added:<break/> if i == 0:</paragraph><paragraph> smoothed_grad = grad</paragraph><paragraph> else:</paragraph><paragraph> smoothed_grad = beta * smoothed_grad + (1 - beta) * grad</paragraph><paragraph><bold>Me:</bold></paragraph><paragraph><bold>Now can you complete the code section under Question 2: text section? Fill in that code with one of the methods used in this notebook and give it a different learning rate.</bold></paragraph><paragraph>Gemini:</paragraph><paragraph>I will add code to the cell under Question 2 to run gradient descent with momentum using a different learning rate and compare it with the results from plain gradient descent.</paragraph><paragraph>Code Gemini Added:<break/> stepsize_new = 2e-4 # Increase the learning rate slightly</paragraph><paragraph>grads_m_new, ws_m_new, losses_m_new = runGDM(maxiter, stepsize_new, beta)</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/8NFg95iQVrFOCdww3VHUqDMh\" filename=\"q_sgd_momentum_analysis_Google_Colab_w_Gemini.ipynb\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-29T15:12:58.434367+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7034106,
            "author": "Joe Berry",
            "project_title": "Participation A Post",
            "post_body": "This is my participation A post. I have an executive summary and then the full logs attached. Please let me know if there is anything wrong with my format and I will repost. \n\nJoseph Berry\n CS182 HW 1 \n Claude Answer Analysis\n\nI used Claude Model Opus 4.1, with the Research button activated allowing for \u201cAgentic mode\u201d or web searches while answering a question. \n\nThis model was able to one shot most of the questions. It failed on questions 2 and 3 and was unable to compute the eigenvalues or discriminant of part 3 without help. Even when presented with the correct answer. \n\nProblem 1. Why Learning Rates Cannot be Too Big\n Part a.\n\n Answered the question completely.\nPart b. \n Solved the question, then proceeded to give me a second answer it thought was equivalent and an example with numerical value. \n\nPart c.\n\n Solved the question but arrived at a different solution of 2/\u03c3^2 instead of 1/\u03c3^2. Also defined loss L(W) as 1/2|| y \u2013 \u03a3w ||^2 instead of || y \u2013 \u03a3w ||^2. It claimed the \u00bd was a \u201cconvenience factor\u201d making the gradient slightly easier to compute, and that it would lead to a different effective learning rate, which it didn\u2019t believe was an issue. \n\nPart d.\n\n Solved the question and then continued explaining which \u03c3 value, large or small, would converge faster.\n\nPart e.\n\nGave a slightly incorrect answer:\n \u03b7= 1/(\u03c3\u2113 2 + \u03c3s 2 ) = 1/(\u03c3\u2113 2) instead of the course solution 1/(\u03c3\u2113 2 + \u03c3s 2 )\n\nPart f.\n\n Answered the question mathematically instead of using definitions. \n\nProblem 2. Stochastic Gradient Descent (when it is possible to interpolate)\n\nPart a.\n\n Full Solution.\n\nPart b.\n\n Full Solution.\n\nPart c.\n\n Found the correct answer then continued creating coordinate changes, and tried to create a formula for the coordinate changes. \n\nPart d.\n\n Full Solution. \n\nPart e.\n\n Claude wasn\u2019t able to produce the correct solution, but provided a similar solution (missing expectation of loss, just had loss) and then proceeded to try and show how the problem scaled with just \u03c3 and \u03b5. It was able to produce an answer that loss goes to 0 as t goes to infinity. \n\nPart f.\n\n Full Solution. \n\nPart g.\n\n Full Solution. \n\nPart h.\n\n Gave the correct answer but left out the learning rate term from c1. When asked why c1 did not include the learning rate it stated that the learning rate \u201cBy keeping \u03b7\\eta \u03b7 separate, we can later analyze how to choose \u03b7\\eta \u03b7 optimally\u201d\n\nPart i.\n\n Gave a solution without including the learning rate like in Part h. But also left out the Rho value, or any equivalent value, for the largest norm of the rows of coordinate shifted X. Then when asked if it could include a value representing this, it gave out the answer without including sigma max but now including Rho. \n When asked again it stated that sigma max and rho would be the same value. Stating that both solutions, including rho and excluding rho were correct. \n\nPart j.\n\n Full Solution. \n\nPart k. \n\n This question required reading a jupyter notebook. After inputting Claude explained a small amount about standard ridge regression and feature augmentation. \n\n Problem 3. Accelerating Gradient Descent with Momentum\n\nPart a. \n\n Full Solution.\n\nPart b. \n\n Full Solution.\n\nPart c. \n\n At this problem Claude took over 3 minutes \u201ccompiling source\u201d from the internet to provide a solution. I interrupted this and then repeated the question. Claude then gave me an incorrect answer for the discriminant and answers for eigenvalues that didn\u2019t include the square root term. \n\nPart d. \n\n Incorrect answer, due to an incorrect solution for part a. I then supplied it with the correct solution for part a. After giving it the correct discriminant and eigenvalues it still produced an incorrect answer. \n\nPart e. \n\n Incorrect solution.\n\nPart f. \n\n Full Solution\n\nPart g. \n\n Gave a close answer for Ordinary Gradient Descent (342 where true answer was 346) And a wildly incorrect answer for the momentum version (919 where true answer was 132)\n\nPart h.\n\n I skipped this question, it required a jupyter notebook\n\nPart i. \n\n  I skipped this question, it required a jupyter notebook\n\n4. Optimizers\n\n\n Part a. \n\n Full Solution.\n\nPart b. \n\nFull Solution.\n\n5. Regularization and Instance Noise\n\nPart a. \n\n Full Solution. \n\nPart b. \n\n Failed to produce the correct answer, was given hints on how to find the correct answer answer. On third prompt I gave it the correct answer and asked it to work backwards. It claimed that it needed to know that this was for the scalar case in order to give a correct answer. \n\nPart c. \n\n Full Solution\n\nPart d. \n\n Produced an equivalent correct answer\n\n6. General Case Tikhonov Regularization\n\nPart a. \n\n Full Solution\n\nPart b.\n\n Full Solution\n\nPart c.\n\n Full Solution\n\n\n\n7. An Alternate MAP Interpretation of Ridge Regression\n\nFull Solution.\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>This is my participation A post. I have an executive summary and then the full logs attached. Please let me know if there is anything wrong with my format and I will repost. <break/><break/>Joseph Berry<break/> CS182 HW 1 <break/> Claude Answer Analysis</paragraph><paragraph>I used Claude Model Opus 4.1, with the Research button activated allowing for \u201cAgentic mode\u201d or web searches while answering a question. </paragraph><paragraph>This model was able to one shot most of the questions. It failed on questions 2 and 3 and was unable to compute the eigenvalues or discriminant of part 3 without help. Even when presented with the correct answer. </paragraph><paragraph><bold>Problem 1. Why Learning Rates Cannot be Too Big<break/> Part a.</bold></paragraph><paragraph> Answered the question completely.<break/><bold>Part b.</bold> <break/> Solved the question, then proceeded to give me a second answer it thought was equivalent and an example with numerical value. </paragraph><paragraph><bold>Part c.</bold></paragraph><paragraph> Solved the question but arrived at a different solution of 2/\u03c3^2 instead of 1/\u03c3^2. Also defined loss L(W) as 1/2|| y \u2013 \u03a3w ||^2 instead of || y \u2013 \u03a3w ||^2. It claimed the \u00bd was a \u201cconvenience factor\u201d making the gradient slightly easier to compute, and that it would lead to a different effective learning rate, which it didn\u2019t believe was an issue. <break/><break/><bold>Part d.</bold></paragraph><paragraph> Solved the question and then continued explaining which \u03c3 value, large or small, would converge faster.<break/><break/><bold>Part e.</bold></paragraph><paragraph>Gave a slightly incorrect answer:<break/> \u03b7= 1/(\u03c3\u2113 2 + \u03c3s 2 ) = 1/(\u03c3\u2113 2) instead of the course solution 1/(\u03c3\u2113 2 + \u03c3s 2 )</paragraph><paragraph><bold>Part f.</bold></paragraph><paragraph> Answered the question mathematically instead of using definitions. </paragraph><paragraph><bold>Problem 2. Stochastic Gradient Descent (when it is possible to interpolate)<break/><break/>Part a.</bold></paragraph><paragraph> Full Solution.</paragraph><paragraph><bold>Part b.</bold></paragraph><paragraph> Full Solution.</paragraph><paragraph><bold>Part c.</bold></paragraph><paragraph> Found the correct answer then continued creating coordinate changes, and tried to create a formula for the coordinate changes. </paragraph><paragraph><bold>Part d.</bold></paragraph><paragraph> Full Solution. </paragraph><paragraph><bold>Part e.</bold></paragraph><paragraph> Claude wasn\u2019t able to produce the correct solution, but provided a similar solution (missing expectation of loss, just had loss) and then proceeded to try and show how the problem scaled with just \u03c3 and \u03b5. It was able to produce an answer that loss goes to 0 as t goes to infinity. </paragraph><paragraph><bold>Part f.</bold></paragraph><paragraph> Full Solution. </paragraph><paragraph><bold>Part g.</bold></paragraph><paragraph> Full Solution. </paragraph><paragraph><bold>Part h.</bold></paragraph><paragraph> Gave the correct answer but left out the learning rate term from c1. When asked why c1 did not include the learning rate it stated that the learning rate \u201cBy keeping \u03b7\\eta \u03b7 separate, we can later analyze how to choose \u03b7\\eta \u03b7 optimally\u201d</paragraph><paragraph><bold>Part i.</bold></paragraph><paragraph> Gave a solution without including the learning rate like in Part h. But also left out the Rho value, or any equivalent value, for the largest norm of the rows of coordinate shifted X. Then when asked if it could include a value representing this, it gave out the answer without including sigma max but now including Rho. <break/> When asked again it stated that sigma max and rho would be the same value. Stating that both solutions, including rho and excluding rho were correct. </paragraph><paragraph><bold>Part j.</bold></paragraph><paragraph> Full Solution. </paragraph><paragraph><bold>Part k.</bold> </paragraph><paragraph> This question required reading a jupyter notebook. After inputting Claude explained a small amount about standard ridge regression and feature augmentation. </paragraph><paragraph> <bold>Problem 3. Accelerating Gradient Descent with Momentum</bold></paragraph><paragraph><bold>Part a.</bold> </paragraph><paragraph> Full Solution.</paragraph><paragraph><bold>Part b.</bold> </paragraph><paragraph> Full Solution.</paragraph><paragraph><bold>Part c.</bold> </paragraph><paragraph> At this problem Claude took over 3 minutes \u201ccompiling source\u201d from the internet to provide a solution. I interrupted this and then repeated the question. Claude then gave me an incorrect answer for the discriminant and answers for eigenvalues that didn\u2019t include the square root term. </paragraph><paragraph><bold>Part d.</bold> </paragraph><paragraph> Incorrect answer, due to an incorrect solution for part a. I then supplied it with the correct solution for part a. After giving it the correct discriminant and eigenvalues it still produced an incorrect answer. </paragraph><paragraph><bold>Part e.</bold> </paragraph><paragraph> Incorrect solution.</paragraph><paragraph><bold>Part f.</bold> </paragraph><paragraph> Full Solution</paragraph><paragraph><bold>Part g.</bold> </paragraph><paragraph> Gave a close answer for Ordinary Gradient Descent (342 where true answer was 346) And a wildly incorrect answer for the momentum version (919 where true answer was 132)</paragraph><paragraph><bold>Part h.</bold></paragraph><paragraph> I skipped this question, it required a jupyter notebook</paragraph><paragraph><bold>Part i.</bold> </paragraph><paragraph>  I skipped this question, it required a jupyter notebook</paragraph><paragraph><bold>4. Optimizers</bold></paragraph><paragraph><bold><break/> Part a.</bold> </paragraph><paragraph> Full Solution.</paragraph><paragraph><bold>Part b.</bold> </paragraph><paragraph>Full Solution.</paragraph><paragraph><bold>5. Regularization and Instance Noise</bold></paragraph><paragraph><bold>Part a.</bold> </paragraph><paragraph> Full Solution. </paragraph><paragraph><bold>Part b.</bold> </paragraph><paragraph> Failed to produce the correct answer, was given hints on how to find the correct answer answer. On third prompt I gave it the correct answer and asked it to work backwards. It claimed that it needed to know that this was for the scalar case in order to give a correct answer. </paragraph><paragraph><bold>Part c.</bold> </paragraph><paragraph> Full Solution</paragraph><paragraph><bold>Part d.</bold> </paragraph><paragraph> Produced an equivalent correct answer</paragraph><paragraph><bold>6. General Case Tikhonov Regularization</bold></paragraph><paragraph><bold>Part a.</bold> </paragraph><paragraph> Full Solution</paragraph><paragraph><bold>Part b.</bold></paragraph><paragraph> Full Solution</paragraph><paragraph><bold>Part c.</bold></paragraph><paragraph> Full Solution</paragraph><paragraph/><paragraph><bold>7. An Alternate MAP Interpretation of Ridge Regression</bold></paragraph><paragraph>Full Solution.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/D7bfXOAWeivPhFWd0nmuYzdb\" filename=\"HW1_Claude_Notes.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-29T07:02:28.705216+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7030840,
            "author": "Nyx Iskandar",
            "project_title": "Special Participation E: ChatGPT as Quiz Tutor",
            "post_body": "Trace: https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b\n\nPrompted ChatGPT to teach me the CNN architecture step-by-step and quiz me after each concept. Pretty fun and useful as a lecture prep or consolidation! Can also extend this to uploading lecture notes and quizzing based on the notes.",
            "content_xml": "<document version=\"2.0\"><paragraph>Trace: <link href=\"https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b\">https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b</link></paragraph><paragraph>Prompted ChatGPT to teach me the CNN architecture step-by-step and quiz me after each concept. Pretty fun and useful as a lecture prep or consolidation! Can also extend this to uploading lecture notes and quizzing based on the notes.</paragraph></document>",
            "links": [
                "https://chatgpt.com/share/68d891e8-3f3c-8010-8f9f-edd2aff1297b"
            ],
            "attachments": [],
            "created_at": "2025-09-28T11:42:41.568091+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7027566,
            "author": "Hong Joey",
            "project_title": "HW4 Q7",
            "post_body": "Context: This problem analyzes the behavior of weights and gradients of a convolutional layer in detail. You will be asked to:\n\nDerive the gradient of a weight matrix as a weighted average of image patches\n\nAnalyze the mean and std of the gradient\n\nShow the effect of pooling on the gradient and in particular, how max pooling routes gradients. It is important to understand this here because the story in transformers is related. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This problem analyzes the behavior of weights and gradients of a convolutional layer in detail. You will be asked to:</paragraph><list style=\"bullet\"><list-item><paragraph>Derive the gradient of a weight matrix as a weighted average of image patches</paragraph></list-item><list-item><paragraph>Analyze the mean and std of the gradient</paragraph></list-item><list-item><paragraph>Show the effect of pooling on the gradient and in particular, how max pooling routes gradients. It is important to understand this here because the story in transformers is related. </paragraph></list-item></list><figure><image src=\"https://static.us.edusercontent.com/files/N6mLfVf8darcIYm9rcsqcKUn\" width=\"658\" height=\"788.9049295774647\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/b7JrGMiqSxkfLqC3dwoaSH3Y\" width=\"658\" height=\"879.7304189435337\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/bN5ZMzWSnshRvQUfnbXrhjTz\" width=\"658\" height=\"221.63001745200697\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T17:02:18.20626+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027562,
            "author": "Hong Joey",
            "project_title": "HW4 Q6",
            "post_body": "Context: This coding problem explores the important concept of inductive bias in CNNs. If you are unfamiliar with the term, inductive bias refers to assumptions about the input data that when satisfied, enable CNNs to work more effectively, i.e. locality (pixels closer to eachother are more correlated) and translation invariance. In the problem, you will investigate patterns learned by filters and how they evolve during training in different scenarios.",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This coding problem explores the important concept of inductive bias in CNNs. If you are unfamiliar with the term, inductive bias refers to assumptions about the input data that when satisfied, enable CNNs to work more effectively, i.e. locality (pixels closer to eachother are more correlated) and translation invariance. In the problem, you will investigate patterns learned by filters and how they evolve during training in different scenarios.</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/NzbrJZuHYqeuxA67ICIaiMP2\" width=\"658\" height=\"646.4965034965036\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/ajTW13n2TVzfpERtceFcuf9c\" width=\"658\" height=\"69.325\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T16:58:01.608037+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027553,
            "author": "Hong Joey",
            "project_title": "HW4 Q5",
            "post_body": "Context: This short coding question is designed to build an intuitive understanding of how convolutional filters work. In the question, you will manually design filters, which are essentially small matrices of weights, for blurring and edge detection. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This short coding question is designed to build an intuitive understanding of how convolutional filters work. In the question, you will manually design filters, which are essentially small matrices of weights, for blurring and edge detection. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/SZwliD4rUcJKvwW4eKC3xyCY\" width=\"658\" height=\"48.230366492146594\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/MO07NtKxkCJysRjCXwVYMrvC\" width=\"657.9999999999999\" height=\"219.71280276816606\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T16:51:39.495072+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027545,
            "author": "Hong Joey",
            "project_title": "HW4 Q4",
            "post_body": "Context: This problem  (the latter parts of which are from an old exam) serves as a practical exercise in determining the size of feature maps and number of parameters in CNN layers in a general convolutional layer. You will also compute the effect of operations such as max-pooling and downsampling on output feature shape and number of parameters in a specific CNN architecture.  ",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This problem  (the latter parts of which are from an old exam) serves as a practical exercise in determining the size of feature maps and number of parameters in CNN layers in a general convolutional layer. You will also compute the effect of operations such as max-pooling and downsampling on output feature shape and number of parameters in a specific CNN architecture.  </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/5FhJ3bJqRT2BMWckKZS24mbI\" width=\"658\" height=\"71.22680412371133\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/sgFuM70KUeamPglhe3qGxiR4\" width=\"658\" height=\"822.2262895174708\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/gIDyHeRMdFoKA4VFTrnSVe6g\" width=\"658\" height=\"796.348717948718\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T16:48:43.390493+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027532,
            "author": "Hong Joey",
            "project_title": "HW4 Q3",
            "post_body": "Context: This problem establishes a link between convolutional operations and discrete-time signal processing. The goal is to solidify understanding of the convolution operation and its properties (such as translational invariance). ",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This problem establishes a link between convolutional operations and discrete-time signal processing. The goal is to solidify understanding of the convolution operation and its properties (such as translational invariance). </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/YNfxQngQ376W15GWR7jg13Ht\" width=\"658\" height=\"382.37758112094394\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/Imc8WZFokafngtljYyOcPGoS\" width=\"658\" height=\"779.5659824046921\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T16:42:02.921189+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027521,
            "author": "Hong Joey",
            "project_title": "HW4 Q2",
            "post_body": "Context: This problem is aimed at cementing your understanding of muP. You will need to grasp the following points well in order to solve this problem\n\nImpact of weight initialization on scaling the forward pass\n\nHow to scale the weight updates under different scenarios\n\nEffect on the backward pass when scaling is applied",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This problem is aimed at cementing your understanding of muP. You will need to grasp the following points well in order to solve this problem</paragraph><list style=\"bullet\"><list-item><paragraph>Impact of weight initialization on scaling the forward pass</paragraph></list-item><list-item><paragraph>How to scale the weight updates under different scenarios</paragraph></list-item><list-item><paragraph>Effect on the backward pass when scaling is applied</paragraph></list-item></list><figure><image src=\"https://static.us.edusercontent.com/files/0h6fi8QfAsjCpMbSCuIXAOtw\" width=\"658\" height=\"478.54545454545456\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/C4HoEeeddP8nGEz4bLPm3CGm\" width=\"658\" height=\"427.2089552238806\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T16:38:33.426508+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027477,
            "author": "Hong Joey",
            "project_title": "HW4 Q1",
            "post_body": "Context: This problem asks you to analyze the runtime of a single iteration of Newton-Schulz. In most implementations, you may see that the matrix is transposed so that the row dimension is always smaller than the column dimension. This problem also will help you understand why that is done. ",
            "content_xml": "<document version=\"2.0\"><paragraph>Context: This problem asks you to analyze the runtime of a single iteration of Newton-Schulz. In most implementations, you may see that the matrix is transposed so that the row dimension is always smaller than the column dimension. This problem also will help you understand why that is done. </paragraph><figure><image src=\"https://static.us.edusercontent.com/files/sV5M6UHbDCvhMDJpQ0Yh7Nxo\" width=\"658\" height=\"260.6749435665914\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T16:09:55.573783+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 7027450,
            "author": "Hong Joey",
            "project_title": "Discussion 3 Solutions",
            "post_body": "It has come to our attention that Discussion 3 solutions were never posted. Apologies for the delay, but attached are questions and solutions for Discussion 3:\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>It has come to our attention that Discussion 3 solutions were never posted. Apologies for the delay, but attached are questions and solutions for Discussion 3:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/wt9GRta2emjV4f3gKz20Dr3J\" filename=\"dis03_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/ebx1ThCmISNc8qEZv4onIPhE\" filename=\"dis03_solution.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T15:55:48.359596+10:00",
            "category": "Admin"
        },
        {
            "guid": 7027430,
            "author": "Nyx Iskandar",
            "project_title": "Special Participation E: FlashcardGPT",
            "post_body": "Use FlashcardGPT to generate flashcards out of lecture notes etc. :)\n\nURL: https://github.com/xyntechx/flashcard-gpt\n\nFull disclosure:\n\nI made this app in about 3 hours + I'm not the best designer\n\nYou have to run this locally (follow the instructions in the README)\n\nYou need to use your own OpenAI API keys (sorry haha)\n\nWhen I was testing this, I used a pre-generated set of flashcards so that it won't take too long, and to save API credits, which is why the demo is \ud83d\udd25 blazingly fast \ud83d\udd25. The flashcards were indeed generated by GPT-5.\n\nOpen to feature requests / issues / PRs!\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Use FlashcardGPT to generate flashcards out of lecture notes etc. :)</paragraph><paragraph>URL: https://github.com/xyntechx/flashcard-gpt</paragraph><paragraph>Full disclosure:</paragraph><list style=\"bullet\"><list-item><paragraph>I made this app in about 3 hours + I'm not the best designer</paragraph></list-item><list-item><paragraph>You have to run this locally (follow the instructions in the README)</paragraph></list-item><list-item><paragraph>You need to use your own OpenAI API keys (sorry haha)</paragraph></list-item><list-item><paragraph>When I was testing this, I used a pre-generated set of flashcards so that it won't take too long, and to save API credits, which is why the demo is \ud83d\udd25 blazingly fast \ud83d\udd25. The flashcards were indeed generated by GPT-5.</paragraph></list-item></list><paragraph>Open to feature requests / issues / PRs!</paragraph><file url=\"https://static.us.edusercontent.com/files/2GNHHP8zSUbCiuZhzkvmJvoo\" filename=\"Screen Recording 2025-09-26 at 22.34.08.mov\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T15:47:18.640074+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 7027253,
            "author": "Hong Joey",
            "project_title": "Discussion 4 Solutions",
            "post_body": "Attached are the questions and solutions to Discussion 4 from this week:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Attached are the questions and solutions to Discussion 4 from this week:</paragraph><file url=\"https://static.us.edusercontent.com/files/fFhRXCuQme0LuA9NUsJ4mXPc\" filename=\"dis04_question.pdf\"/><paragraph/><file url=\"https://static.us.edusercontent.com/files/sXsjGXm55z57aPDnxAWPKvhY\" filename=\"dis04_solution.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-27T14:25:47.508519+10:00",
            "category": "Admin"
        },
        {
            "guid": 7007009,
            "author": "Gireeja Ranade",
            "project_title": "Lecture 6 and 7 slides and questions",
            "post_body": "Muon/MuP questions here!",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/5e2fumbMGggxcOkOZ6SBPyQH\" filename=\"Lecture 7.pdf\"/><file url=\"https://static.us.edusercontent.com/files/fJefvrPiaf5ZRgf4YSjzGNTJ\" filename=\"Lecture 6.pdf\"/><paragraph>Muon/MuP questions here!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-24T07:31:47.091163+10:00",
            "category": "Lectures"
        },
        {
            "guid": 7002423,
            "author": "Kevin Frans",
            "project_title": "HW2 Solutions",
            "post_body": "Analytic Solutions\n\nCoding Solutions",
            "content_xml": "<document version=\"2.0\"><paragraph>Analytic Solutions</paragraph><file url=\"https://static.us.edusercontent.com/files/Fl5ImcrPMJFalJvj2o7JhfIE\" filename=\"hw02_solution.pdf\"/><paragraph>Coding Solutions</paragraph><file url=\"https://static.us.edusercontent.com/files/S2JurSV6DcKgGcSAN3XWEjqe\" filename=\"hw02_solutions_coding.zip\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-23T11:07:53.485499+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6989296,
            "author": "Sultan Daniels",
            "project_title": "HW3 Q5",
            "post_body": "Problem context: This is another basic problem that was a former exam problem and is there to help you appreciate more about the \"systems\" dimension of deep learning. How to tradeoff computation and memory... Again, this helps you understand that you can understand ideas even beyond what is explicitly taught in lecture or discussion.\n\n",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/DI87dKkPpXbdzkCIfIazobes\" width=\"658\" height=\"1095.065693430657\"/></figure><paragraph>Problem context: This is another basic problem that was a former exam problem and is there to help you appreciate more about the \"systems\" dimension of deep learning. How to tradeoff computation and memory... Again, this helps you understand that you can understand ideas even beyond what is explicitly taught in lecture or discussion.</paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-20T15:12:57.287527+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6989292,
            "author": "Sultan Daniels",
            "project_title": "HW3 Q4",
            "post_body": "Problem context: This problem builds on the problem from last week to gently expose you to core ideas related to reinforcement learning. The goal continues to be to both empower you and help you see your own empowerment: we didn't touch on this stuff at all during lecture or discussion. But you can still understand it. \n\nWhereas the earlier problem had you explore and understand via code and experimentation, this helps you look at a particular piece from a mathematical lens. The use of the standard normal is designed to help you see how helpful the normal distribution is when getting started vis-a-vis insight, while the later parts helps you see how the pattern extends beyond normals. (Although notice: the normal case is where it is easiest to discover what the pattern actually is.)\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/aR60H0l3DbBJyR8jZIA5IPwa\" width=\"658\" height=\"836.1541501976285\"/></figure><paragraph>Problem context: This problem builds on the problem from last week to gently expose you to core ideas related to reinforcement learning. The goal continues to be to both empower you and help you see your own empowerment: we didn't touch on this stuff at all during lecture or discussion. But you can still understand it. </paragraph><paragraph>Whereas the earlier problem had you explore and understand via code and experimentation, this helps you look at a particular piece from a mathematical lens. The use of the standard normal is designed to help you see how helpful the normal distribution is when getting started vis-a-vis insight, while the later parts helps you see how the pattern extends beyond normals. (Although notice: the normal case is where it is easiest to discover what the pattern actually is.)</paragraph><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-20T15:11:26.238996+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6989291,
            "author": "Sultan Daniels",
            "project_title": "HW3 Q3",
            "post_body": "Problem context: We have tried to make this extremely important material accessible to you, and so we would not necessarily expect you to be able to understand these papers without what we have taught you. For Tensor Programs V, we wouldn't expect that even after our guidance. But one important skill for Deep Learning is to be able to extract some understanding and insight from papers even when you can't understand everything. This problem is designed to help guide you to do that. After all, you are going to have to learn on your own once you are done with this class. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/TNIh5ciAhAWGRbbrydqrZkno\" width=\"658\" height=\"611.4747474747475\"/></figure><paragraph>Problem context: We have tried to make this extremely important material accessible to you, and so we would not necessarily expect you to be able to understand these papers without what we have taught you. For Tensor Programs V, we wouldn't expect that even after our guidance. But one important skill for Deep Learning is to be able to extract some understanding and insight from papers even when you can't understand everything. This problem is designed to help guide you to do that. After all, you are going to have to learn on your own once you are done with this class. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-20T15:10:50.686214+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6989287,
            "author": "Sultan Daniels",
            "project_title": "HW3 Q2",
            "post_body": "\n\nProblem context: This is a critically important homework problem as it has you complement the analytically driven understanding you were given in lecture with seeing what happens in an actual toy neural net. This problem touches on many things that you have seen in the previous few lectures. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/BjfQ713wMpOYRSamgNKdUfDr\" width=\"658\" height=\"99.11297071129707\"/></figure><paragraph/><paragraph>Problem context: This is a critically important homework problem as it has you complement the analytically driven understanding you were given in lecture with seeing what happens in an actual toy neural net. This problem touches on many things that you have seen in the previous few lectures. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-20T15:09:59.1106+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6989285,
            "author": "Sultan Daniels",
            "project_title": "HW3 Q1",
            "post_body": "\n\nProblem context: this problem builds directly on discussion and lecture. It has you recapitulate things that you've seen in lecture, but they're important and you should internalize them. Consequently, we recommend you try to do this without constantly looking at the lecture. This needs to be in your head. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/3XC5gmvt3iwLFCKA0Jvx5qpn\" width=\"658\" height=\"480.5420560747663\"/></figure><paragraph/><paragraph>Problem context: this problem builds directly on discussion and lecture. It has you recapitulate things that you've seen in lecture, but they're important and you should internalize them. Consequently, we recommend you try to do this without constantly looking at the lecture. This needs to be in your head. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-20T15:09:17.716872+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6979789,
            "author": "Leon Kornfeld",
            "project_title": "Participation A (HW2): Grok",
            "post_body": "Q1. \n\nPart a of this problem was straight forward and was one-shotted by Grok. \n\nPart b was tougher. Because I directly copy and pasted from the PDF, the formatting was a bit weird and Grok understood the infinity norm to be squared. Regardless, it was still able to reason its way that this was a form of sign SGD. \n\nMy next prompt to it was \"You misread part b. the infinity norm is not squared.\" In response, it tried again and once again reached an incorrect answer (but it was on the right track). It said that term of u, corresponding to the max value of delta_theta, is\u2212\u03b1\u22c5sign(gk\u200b) and all other u terms are zero. This is not correct as all terms should be -a*sign(g). \n\nI decided to steer Grok in the right direction by saying \"Wouldn't it make sense to make all u equal to the negative max size of the step size times the sign of each element of g. This will minimize the inner product even more.\"  This resembles the process we did in class.\n\nUnfortunately, Grok then reverted back to the squared version of the infinity norm, but correctly said that this was an example of signSGD. Lastly, I affirmed that this was correct by saying \"You are right that the final answer recovers signSGD, but the original problem does not square the infinity norm. Please do not square it.\" This finally brought it to what I find to be the correct answer, yet through a different thought process that we had in class. \n\nPart b of this problem was by far the most complex one and the one Grok found most difficult to solve. Please see the individual reasoning times for each prompt. The first one took 5.5 minutes of reasoning in total.\n\n\n\nQ2. This problem was  one-shotted by Grok. I copy and pasted the description and all 3 sub-problems. Based on my review of the answers, Grok's thought process made sense and was very similar to the process I took for solving the problems. Grok did have a problem with rendering the latex originally so I had to reprompt it to render the latex properly. It took 1 minute and 40 seconds to reason the original answer but was very fast with rerendering the latex.\n\n\n\nQ5. This problem was one-shotted by Grok when I copy and pasted the entire question (including the table). I first tried saying fill in the blanks while adding a screenshot of the table. It had no context and it had a bit of trouble parsing the image. When I transcribed the table after the question context in a new chat, it was able to fill in all the blanks on the first try with the the proper explanations. The reasoning period to answer this question was little to none.\n\n\n\nHere is where Grok messed up with the screenshot of the table:\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Q1. </paragraph><paragraph>Part a of this problem was straight forward and was one-shotted by Grok. </paragraph><paragraph>Part b was tougher. Because I directly copy and pasted from the PDF, the formatting was a bit weird and Grok understood the infinity norm to be squared. Regardless, it was still able to reason its way that this was a form of sign SGD. </paragraph><paragraph>My next prompt to it was \"You misread part b. the infinity norm is not squared.\" In response, it tried again and once again reached an incorrect answer (but it was on the right track). It said that term of u, corresponding to the max value of delta_theta, is\u2212\u03b1\u22c5sign(gk\u200b) and all other u terms are zero. This is not correct as all terms should be -a*sign(g). </paragraph><paragraph>I decided to steer Grok in the right direction by saying \"Wouldn't it make sense to make all u equal to the negative max size of the step size times the sign of each element of g. This will minimize the inner product even more.\"  This resembles the process we did in class.</paragraph><paragraph>Unfortunately, Grok then reverted back to the squared version of the infinity norm, but correctly said that this was an example of signSGD. Lastly, I affirmed that this was correct by saying \"You are right that the final answer recovers signSGD, but the original problem does not square the infinity norm. Please do not square it.\" This finally brought it to what I find to be the correct answer, yet through a different thought process that we had in class. </paragraph><paragraph>Part b of this problem was by far the most complex one and the one Grok found most difficult to solve. Please see the individual reasoning times for each prompt. The first one took 5.5 minutes of reasoning in total.</paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/TfJUXY00alWLzlFs14iroScv\" filename=\"Optimization_ Linear Improvement, Norm Penalties - Grok.pdf\"/><paragraph>Q2. This problem was  one-shotted by Grok. I copy and pasted the description and all 3 sub-problems. Based on my review of the answers, Grok's thought process made sense and was very similar to the process I took for solving the problems. Grok did have a problem with rendering the latex originally so I had to reprompt it to render the latex properly. It took 1 minute and 40 seconds to reason the original answer but was very fast with rerendering the latex.</paragraph><file url=\"https://static.us.edusercontent.com/files/Cc9KtSSKzC1Co9o7W0oewkVA\" filename=\"Adam Optimizer Convergence Analysis - Grok.pdf\"/><paragraph/><paragraph>Q5. This problem was one-shotted by Grok when I copy and pasted the entire question (including the table). I first tried saying fill in the blanks while adding a screenshot of the table. It had no context and it had a bit of trouble parsing the image. When I transcribed the table after the question context in a new chat, it was able to fill in all the blanks on the first try with the the proper explanations. The reasoning period to answer this question was little to none.</paragraph><file url=\"https://static.us.edusercontent.com/files/3tveS0amgHGqgztEM5DGquLf\" filename=\"Distributed Training Paradigms Analysis - Grok.pdf\"/><paragraph/><paragraph>Here is where Grok messed up with the screenshot of the table:</paragraph><file url=\"https://static.us.edusercontent.com/files/l2chaJN40dBv7VmfK2LXgVHA\" filename=\"WrongDistributed Computing Message Size Patterns - Grok.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-18T13:55:45.022993+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6972386,
            "author": "Gireeja Ranade",
            "project_title": "Lecture 4 and 5 slides and thread",
            "post_body": "Notes from lectures 4 and 5. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/kcNG4UIFsMn1fFb4vQ5j2V0o\" filename=\"Lecture 5.pdf\"/><file url=\"https://static.us.edusercontent.com/files/saT4WyfenQI3bamAntRbUa17\" filename=\"Lecture 4.pdf\"/><paragraph>Notes from lectures 4 and 5. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-17T07:32:22.152256+10:00",
            "category": "Lectures"
        },
        {
            "guid": 6957534,
            "author": "Sultan Daniels",
            "project_title": "HW1 Solutions",
            "post_body": "A thread for the homework 1 solutions:",
            "content_xml": "<document version=\"2.0\"><paragraph>A thread for the homework 1 solutions:</paragraph><file url=\"https://static.us.edusercontent.com/files/GQjeXuC7D1PM5npnIotmftvF\" filename=\"hw01codesolution.zip\"/><file url=\"https://static.us.edusercontent.com/files/aO8NnPYdzjOpEyEphrp1j0nZ\" filename=\"hw01_solution.pdf\"/><file url=\"https://static.us.edusercontent.com/files/wfhyVdY3qm8RjcFtilajxu8o\" filename=\"hw01_question.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-14T10:28:03.327588+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6954670,
            "author": "Kevin Frans",
            "project_title": "HW2 Q6",
            "post_body": "Problem context: This is a problem this semester that serves two purposes. (1) While within the overall optimization theme, it hits material that has not been covered in lecture and discussion. This is intentional. Our learning objective is to have you be able to learn stuff on your own after this course is done. So we need to practice that too. The problem is carefully curated so you can learn as you work through it. (2) It is a part of our attempt to gently expose you to core ideas related to reinforcement learning with the objective of making sure that by the end of the semester, you have the mental tools to properly understand post-training of foundation models for LLMs. We take an optimization perspective here to bring out how randomness can help smooth things in a helpful manner. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/GiJJeipIZJMTage95kVl51OW\" width=\"588\" height=\"1145\"/></figure><paragraph>Problem context: This is a problem this semester that serves two purposes. (1) While within the overall optimization theme, it hits material that has not been covered in lecture and discussion. This is intentional. Our learning objective is to have you be able to learn stuff on your own after this course is done. So we need to practice that too. The problem is carefully curated so you can learn as you work through it. (2) It is a part of our attempt to gently expose you to core ideas related to reinforcement learning with the objective of making sure that by the end of the semester, you have the mental tools to properly understand post-training of foundation models for LLMs. We take an optimization perspective here to bring out how randomness can help smooth things in a helpful manner. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-13T13:17:54.285867+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6954668,
            "author": "Kevin Frans",
            "project_title": "HW2 Q5",
            "post_body": "Problem context: \n\nThis is another old (and easy) exam problem. It is there to do three things: (1) Get you to learn on your own --- this wasn't covered in lecture or discussion. But you can do this without anything else besides the problem itself and thinking on your part. (2) Act as fair warning that we can ask you to tackle truly new material on the final itself. (3) Get you light exposure to some of the practical systems-oriented side thinking of how to deal with training when you have multiple machines and decide to split the training data among them.  \n\nYou want to be in a position (at least after this course) to be able to read and understand:\nhttps://jax-ml.github.io/scaling-book/\n\nYou're not there yet. But this problem is meant to help you see that you don't need us to teach you this stuff in lecture itself. You can pick it up yourself.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/0srLafhaKfd12u2cNX5FMzaS\" width=\"607\" height=\"1110\"/></figure><paragraph>Problem context: </paragraph><paragraph>This is another old (and easy) exam problem. It is there to do three things: (1) Get you to learn on your own --- this wasn't covered in lecture or discussion. But you can do this without anything else besides the problem itself and thinking on your part. (2) Act as fair warning that we can ask you to tackle truly new material on the final itself. (3) Get you light exposure to some of the practical systems-oriented side thinking of how to deal with training when you have multiple machines and decide to split the training data among them.  <break/><break/>You want to be in a position (at least after this course) to be able to read and understand:<break/><link href=\"https://jax-ml.github.io/scaling-book/\">https://jax-ml.github.io/scaling-book/</link><break/><break/>You're not there yet. But this problem is meant to help you see that you don't need us to teach you this stuff in lecture itself. You can pick it up yourself.</paragraph></document>",
            "links": [
                "https://jax-ml.github.io/scaling-book/"
            ],
            "attachments": [],
            "created_at": "2025-09-13T13:17:34.250771+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6954665,
            "author": "Kevin Frans",
            "project_title": "HW2 Q4",
            "post_body": "Problem Context:\n\nThis engages with new material (the Taylor expansion perspective taught in lecture) and builds on the visualizations you saw in the first two discussion sections as well as the analytic part of the previous discussion. This problem requires you to translate what is being asked into math yourself, and then use those concepts to visualize what is going on by modifying a given jupyter notebook.  \n\nThis is a Deep Learning course, not a math course. Of course, we leverage math. This problem has lots of conceptual moving parts, and by trying to understand what is being asked and how to answer it, you will hopefully straighten out those concepts in your mind.\n\nAlong the way, this will also likely help many of you strengthen your understanding of classic dimensionality-reduction via PCA in machine learning. In particular, what are the dimensionality-reduced features when you apply them to new data...",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/2jfaBZof4468uTUnWThv68zZ\" width=\"658\" height=\"748.8177083333334\"/></figure><paragraph>Problem Context:</paragraph><paragraph>This engages with new material (the Taylor expansion perspective taught in lecture) and builds on the visualizations you saw in the first two discussion sections as well as the analytic part of the previous discussion. This problem requires you to translate what is being asked into math yourself, and then use those concepts to visualize what is going on by modifying a given jupyter notebook.  </paragraph><paragraph>This is a Deep Learning course, not a math course. Of course, we leverage math. This problem has lots of conceptual moving parts, and by trying to understand what is being asked and how to answer it, you will hopefully straighten out those concepts in your mind.</paragraph><paragraph>Along the way, this will also likely help many of you strengthen your understanding of classic dimensionality-reduction via PCA in machine learning. In particular, what are the dimensionality-reduced features when you apply them to new data...</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-13T13:16:32.338449+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6954664,
            "author": "Kevin Frans",
            "project_title": "HW2 Q3",
            "post_body": "\n\nProblem context: This problem lets you see the ideas of optimization and initialization play out in the context of real dataset: CIFAR10 using fully-connected neural nets.\n\nThe problem also lets you play with some of the standard kinds of plots that one uses in deep learning.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/kgt7epOyJftPOMaxWEJ6YtLB\" width=\"658\" height=\"213.3359375\"/></figure><paragraph/><paragraph>Problem context: This problem lets you see the ideas of optimization and initialization play out in the context of real dataset: CIFAR10 using fully-connected neural nets.</paragraph><paragraph>The problem also lets you play with some of the standard kinds of plots that one uses in deep learning.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-13T13:16:10.269664+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6954663,
            "author": "Kevin Frans",
            "project_title": "HW2 Q2",
            "post_body": "\n\nProblem context: This is a part of a past final exam question. It should help you appreciate how different optimizers can converge to different solutions when multiple solutions exist. As well as get a better sense for what the inductive bias of the different optimizers is like. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/IodSUOh6yQPdwZPr4qhUyw1n\" width=\"658\" height=\"455.80208333333337\"/></figure><paragraph/><paragraph>Problem context: This is a part of a past final exam question. It should help you appreciate how different optimizers can converge to different solutions when multiple solutions exist. As well as get a better sense for what the inductive bias of the different optimizers is like. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-13T13:15:41.368866+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6954661,
            "author": "Kevin Frans",
            "project_title": "HW2 Q1",
            "post_body": "\nProblem context: You've seen in your optimization courses how to move back and forth between constrained and unconstrained optimizations. You've seen this idea for (b) done in lecture explicitly with a hard constraint. This problem is there to help make sure you do things yourself and understand the connections more clearly. Do this problem as soon as you can, because it will help you appreciate lectures and discussions even more. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/hRccz92g9tQDDMP6tVfal4xC\" width=\"658\" height=\"695.5533498759305\"/></figure><paragraph><break/>Problem context: You've seen in your optimization courses how to move back and forth between constrained and unconstrained optimizations. You've seen this idea for (b) done in lecture explicitly with a hard constraint. This problem is there to help make sure you do things yourself and understand the connections more clearly. Do this problem as soon as you can, because it will help you appreciate lectures and discussions even more. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-13T13:15:03.332079+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6944928,
            "author": "Sultan Daniels",
            "project_title": "Discussion 2 Solution Thread",
            "post_body": "Discussion 2 and solutions:\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Discussion 2 and solutions:<break/></paragraph><file url=\"https://static.us.edusercontent.com/files/b8b5thSG1Ech1J0fEIMYvQhz\" filename=\"dis02_question.pdf\"/><file url=\"https://static.us.edusercontent.com/files/hijs7QSM33yu5J00a0t4jdoK\" filename=\"dis02_solution.pdf\"/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-11T15:42:43.561759+10:00",
            "category": "Sections"
        },
        {
            "guid": 6944706,
            "author": "Anant Sahai",
            "project_title": "Check your enrollment...",
            "post_body": "Dear students,\n\nIf you submitted HW0, you should now be in the class. \n\nIf you did not submit HW0, you should now be dropped from the class.\n\n\n\nIf the above didn't happen for you properly, please feel tree to either respond in this thread (where everyone else can see --- so you probably don't want to do that) or make a private post here in Ed. You should not send an email to us about this. \n\nHopefully, this being settled will reduce everyone's stress and you can focus on learning the material. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Dear students,</paragraph><paragraph>If you submitted HW0, you should now be in the class. </paragraph><paragraph>If you did not submit HW0, you should now be dropped from the class.</paragraph><paragraph/><paragraph>If the above didn't happen for you properly, please feel tree to either respond in this thread (where everyone else can see --- so you probably don't want to do that) or make a private post here in Ed. You should not send an email to us about this. </paragraph><paragraph>Hopefully, this being settled will reduce everyone's stress and you can focus on learning the material. </paragraph><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-11T14:29:15.973995+10:00",
            "category": "Admin"
        },
        {
            "guid": 6937658,
            "author": "Gireeja Ranade",
            "project_title": "Lecture 3 thread",
            "post_body": "Following up from the question in lecture: I only partially stated the conditions required for the Lyapunov function to converge, sorry about that. They are written out fully here, and also corrected in the attached notes. The proof is fully correct, I just misspoke. \n\n\n\nTo show that the expected loss, and therefore $z$, goes to zero, we have to show that:\n\n1. It is non-negative.\n\n2. $L(z) = 0$ implies $z = 0$.\n\n3. Expected loss decreases at every step, and that there is a constant downward pressure, so it cannot converge somewhere other than zero. For this we show:\n\n$$E[L(z_{t+1})] \\leq C L(z_t)$$, where $0< C <  1$ is a constant.\n\nEssentially this shows an exponential decay, and the decay will continue as long as $L(z_t) > 0.$Once we show this, we see that the only place the loss can converge to is zero, because converging anywhere else would mean you could still decrease the expected loss, which would be a contradiction.\n\n\n\nNotes for lecture 2 and 3 are below. \n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Following up from the question in lecture: I only partially stated the conditions required for the Lyapunov function to converge, sorry about that. They are written out fully here, and also corrected in the attached notes. The proof is fully correct, I just misspoke. </paragraph><paragraph/><paragraph>To show that the expected loss, and therefore $z$, goes to zero, we have to show that:</paragraph><paragraph>1. It is non-negative.</paragraph><paragraph>2. $L(z) = 0$ implies $z = 0$.</paragraph><paragraph>3. Expected loss decreases at every step, and that there is a constant downward pressure, so it cannot converge somewhere other than zero. For this we show:</paragraph><paragraph>$$E[L(z_{t+1})] \\leq C L(z_t)$$, where $0&lt; C &lt;  1$ is a constant.</paragraph><paragraph>Essentially this shows an exponential decay, and the decay will continue as long as $L(z_t) &gt; 0.$Once we show this, we see that the only place the loss can converge to is zero, because converging anywhere else would mean you could still decrease the expected loss, which would be a contradiction.</paragraph><paragraph/><paragraph>Notes for lecture 2 and 3 are below. </paragraph><file url=\"https://static.us.edusercontent.com/files/Er1pb2HvgYsi7GNsVhdWoKkA\" filename=\"Lecture 2 (1).pdf\"/><file url=\"https://static.us.edusercontent.com/files/NnFTZ6v9HiF05ho2UjNXAqh5\" filename=\"Lecture 3.pdf\"/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-10T09:10:53.900393+10:00",
            "category": "Lectures"
        },
        {
            "guid": 6932715,
            "author": "Sultan Daniels",
            "project_title": "HW0 Solutions",
            "post_body": "Here is a thread for discussing the solutions to HW 0. The datasets for the code can still be found at the Github repo for the course.",
            "content_xml": "<document version=\"2.0\"><paragraph>Here is a thread for discussing the solutions to HW 0. <link href=\"https://github.com/Berkeley-CS182/cs182fa25_public/tree/main/hw00/code/deeplearning/datasets\">The datasets for the code can still be found at the Github repo for the course.</link></paragraph><file url=\"https://static.us.edusercontent.com/files/Twv5xdhqAC0poSnqiYIrEBva\" filename=\"hw0codesolution.zip\"/><file/><file url=\"https://static.us.edusercontent.com/files/5bmdhY0mpj5ldLKyB8smTyK4\" filename=\"hw00_solution.pdf\"/></document>",
            "links": [
                "https://github.com/Berkeley-CS182/cs182fa25_public/tree/main/hw00/code/deeplearning/datasets"
            ],
            "attachments": [],
            "created_at": "2025-09-09T11:18:38.338212+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6931407,
            "author": "Anant Sahai",
            "project_title": "New GSI Office Hours and Discussion Sections (updated)",
            "post_body": "Starting tomorrow (Tue Sep 9th), we will have additional office hours staffed by GSIs. The scope for these is always going to be the current homework (So HW1 for this week), the solutions to the immediately past homework (So HW0 for this week), and the previous week's discussion section. Lecture questions should be asked either in Prof office hours or on the Ed thread for that lecture. \n\nGSI Office hours:\n\nTue 2-3pm in 102 Latimer\n\nTue 6-7pm in 405 Soda\n\nTue 7-8pm in 540 Cory  [Cancelled due to student request for day diversity]\n\nNEW: Fri 2-3 in 531 Cory\n\n\n\nDiscussion Sections (starting on Wed Sep 10th)\n\nWed 11-noon in 108 Wheeler\n\nWed 5-6pm in 242 Hearst Gym\n\nWed 6-7pm in 104 Social Sciences\n\nThe Wed 3-4pm and Wed 4-5pm discussions will also continue. With five discussion sections, we should be able to fit the expanded course. (Everyone who didn't do HW0 should expect to be dropped and everyone who did do HW0 should expect to get into the course.)\n\n\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Starting tomorrow (Tue Sep 9th), we will have additional office hours staffed by GSIs. The scope for these is always going to be the current homework (So HW1 for this week), the solutions to the immediately past homework (So HW0 for this week), and the previous week's discussion section. Lecture questions should be asked either in Prof office hours or on the Ed thread for that lecture. </paragraph><paragraph>GSI Office hours:</paragraph><paragraph>Tue 2-3pm in 102 Latimer</paragraph><paragraph>Tue 6-7pm in 405 Soda</paragraph><paragraph><strike>Tue 7-8pm in 540 Cory</strike>  [Cancelled due to student request for day diversity]</paragraph><paragraph><bold>NEW:</bold> Fri 2-3 in 531 Cory</paragraph><paragraph/><paragraph>Discussion Sections (starting on Wed Sep 10th)</paragraph><paragraph>Wed 11-noon in 108 Wheeler</paragraph><paragraph>Wed 5-6pm in 242 Hearst Gym</paragraph><paragraph>Wed 6-7pm in 104 Social Sciences</paragraph><paragraph>The Wed 3-4pm and Wed 4-5pm discussions will also continue. With five discussion sections, we should be able to fit the expanded course. (Everyone who didn't do HW0 should expect to be dropped and everyone who did do HW0 should expect to get into the course.)</paragraph><paragraph/><paragraph/><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-09T07:21:36.193959+10:00",
            "category": "Admin"
        },
        {
            "guid": 6920624,
            "author": "Justin Yang",
            "project_title": "Matrix Differentiation Notes",
            "post_body": "https://atmos.washington.edu/~dennis/MatrixCalculus.pdf was helpful for me for reviewing matrix operations for anyone else still reviewing.\n\nAlso I took some notes on it if anyone's interested\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph><link href=\"https://atmos.washington.edu/~dennis/MatrixCalculus.pdf\">https://atmos.washington.edu/~dennis/MatrixCalculus.pdf</link> was helpful for me for reviewing matrix operations for anyone else still reviewing.<break/><break/>Also I took some notes on it if anyone's interested<break/><break/></paragraph><file url=\"https://static.us.edusercontent.com/files/PDZmRfDF7HUBFqZcIHmZIPzy\" filename=\"Matrix Stuff.pdf\"/><paragraph/></document>",
            "links": [
                "https://atmos.washington.edu/~dennis/MatrixCalculus.pdf"
            ],
            "attachments": [],
            "created_at": "2025-09-06T19:48:02.041047+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 6919704,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q7",
            "post_body": "Problem context: \n\nThis can be viewed as a continuation of the problem on the last HW, where here, we are also providing you with an opportunity to review basic conditional expectations in the context of jointly normal vectors. This interpretation provides you with an intuitive anchor for the Kernel Ridge form. Although we do not ask here, it also gives you a way to get an estimate for uncertainty in the solution to ridge regression by looking at the entire posterior. (This problem should also help you review more probability.)\n\nThis question will also be helpful for the large number of you who might find yourself in need of using Gaussian-Process based Bayesian approaches for machine learning. These tend to be quite useful in a diverse set of application domains where uncertainty quantification is useful, and is a place where Deep Learning approaches are increasingly being folded in (to help metalearn good kernels for application domains).",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/lRPdaXgzmA1KcQNDE6o2VBCz\" width=\"658\" height=\"700.310421286031\"/></figure><paragraph>Problem context: </paragraph><paragraph>This can be viewed as a continuation of the problem on the last HW, where here, we are also providing you with an opportunity to review basic conditional expectations in the context of jointly normal vectors. This interpretation provides you with an intuitive anchor for the Kernel Ridge form. Although we do not ask here, it also gives you a way to get an estimate for uncertainty in the solution to ridge regression by looking at the entire posterior. (This problem should also help you review more probability.)</paragraph><paragraph>This question will also be helpful for the large number of you who might find yourself in need of using Gaussian-Process based Bayesian approaches for machine learning. These tend to be quite useful in a diverse set of application domains where uncertainty quantification is useful, and is a place where Deep Learning approaches are increasingly being folded in (to help metalearn good kernels for application domains).</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T11:00:02.670544+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6919698,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q6",
            "post_body": "Problem Context:\n\nMore review for you of basic ML and optimization ideas, although some of you may not have seen this exactly in your previous ML or optimzation course. However, it also provides you with a good opportunity to review the mathematical manipulations needed to understand this.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/M4gzjb1nsAgItiJRRWhmiVdD\" width=\"658\" height=\"550.3272727272727\"/></figure><paragraph>Problem Context:</paragraph><paragraph>More review for you of basic ML and optimization ideas, although some of you may not have seen this exactly in your previous ML or optimzation course. However, it also provides you with a good opportunity to review the mathematical manipulations needed to understand this.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T10:59:27.811611+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6919693,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q5",
            "post_body": "Problem context: This is a past midterm question that also adds another perspective on how data augmentation can provide a regularizing effect.  In the previous homework, you saw augmenting with fake data that was very different from the given data. Here, the augmentation is modifications of the existing data for use during training. \n\nData augmentation is a really important part of deep learning practice, and it is good to understand why it works in a very simple setting. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/vlTdR64ocdLWURJwcuEjVcL1\" width=\"658\" height=\"1028.580931263858\"/></figure><paragraph>Problem context: This is a past midterm question that also adds another perspective on how data augmentation can provide a regularizing effect.  In the previous homework, you saw augmenting with fake data that was very different from the given data. Here, the augmentation is modifications of the existing data for use during training. </paragraph><paragraph>Data augmentation is a really important part of deep learning practice, and it is good to understand why it works in a very simple setting. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T10:58:55.688746+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6919689,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q4",
            "post_body": "Problem context: \n\nThis is an old exam problem that is there to make sure you understand the basics of Adam as well as the connection of weight-decay to regularization in the SGD context.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/c9GWtb9VhhwxFP8vFwbkaorl\" width=\"658\" height=\"901.7558886509636\"/></figure><paragraph>Problem context: </paragraph><paragraph>This is an old exam problem that is there to make sure you understand the basics of Adam as well as the connection of weight-decay to regularization in the SGD context.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T10:58:19.415944+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6919686,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q3",
            "post_body": "\n\nProblem context:\n\nThis has you work out for yourself why momentum can help accelerate convergence. The earlier problem sets the crucial background for this problem since if you don't understand gradient descent without momentum terms, you aren't going to understand the point of momentum. \n\nParts of the calculation can feel a bit grungy at times. But that's just the nature of what is going on. In Deep Learning, we often just have to power through the grunge --- using computer algebra systems can be useful in this regard. ",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/toyuemf9NjplPv4HDpbKYiJF\" width=\"658\" height=\"1148.1767676767677\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/BjyPs9dFyjeXvb9MybNPlCIs\" width=\"658\" height=\"668.2545454545455\"/></figure><paragraph/><paragraph>Problem context:</paragraph><paragraph>This has you work out for yourself why momentum can help accelerate convergence. The earlier problem sets the crucial background for this problem since if you don't understand gradient descent without momentum terms, you aren't going to understand the point of momentum. </paragraph><paragraph>Parts of the calculation can feel a bit grungy at times. But that's just the nature of what is going on. In Deep Learning, we often just have to power through the grunge --- using computer algebra systems can be useful in this regard. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T10:57:42.672188+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6919682,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q2",
            "post_body": "Problem context:\n\nThis is a problem that asks you to carefully work through why SGD works for a simple setting. It's not clear that everyone in the class has seen a proof of SGD working in any setting, and it is important to understand this stuff for at least a simple example. (Just watching lecture is not enough.) The demo part is interesting to see so you can viscerally appreciate what is going on with SGD. There is a lot to observe and soak in from the demo actually, so we really want to encourage you to play with it.\n\nThis particular proof is elementary and gets at essential ideas, but it is not commonly appreciated or known. The core ideas here can be generalized broadly beyond this particular setting, but the mathematical abstractions involved (PL conditions, etc...) don't have the required \"conceptual bang for the buck\" needed to make it into this foundational course",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/v8FvhyhlTA9eaUQjejgvloFW\" width=\"568\" height=\"1300\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/JXGh6ySdvu0hHgg9su143s9x\" width=\"510\" height=\"838\"/></figure><paragraph>Problem context:</paragraph><paragraph>This is a problem that asks you to carefully work through why SGD works for a simple setting. It's not clear that everyone in the class has seen a proof of SGD working in any setting, and it is important to understand this stuff for at least a simple example. (Just watching lecture is not enough.) The demo part is interesting to see so you can viscerally appreciate what is going on with SGD. There is a lot to observe and soak in from the demo actually, so we really want to encourage you to play with it.</paragraph><paragraph>This particular proof is elementary and gets at essential ideas, but it is not commonly appreciated or known. The core ideas here can be generalized broadly beyond this particular setting, but the mathematical abstractions involved (PL conditions, etc...) don't have the required \"conceptual bang for the buck\" needed to make it into this foundational course</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T10:55:29.916796+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6919674,
            "author": "Sultan Daniels",
            "project_title": "HW1 Q1",
            "post_body": "Problem context:\n\nThis is likely review for most people, but without a solid understanding of what is going on here you can't understand why we use momentum or the need/motivation for adaptive methods like Adam. That's why it is really important for everyone to do this problem. Otherwise, you don't understand the most important optimization hyperparameter of them all: the learning rate.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/26gdOEb8pz13ZBAzANzgizgj\" width=\"658\" height=\"1056.3050847457628\"/></figure><paragraph>Problem context:</paragraph><paragraph>This is likely review for most people, but without a solid understanding of what is going on here you can't understand why we use momentum or the need/motivation for adaptive methods like Adam. That's why it is really important for everyone to do this problem. Otherwise, you don't understand the most important optimization hyperparameter of them all: the learning rate.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-06T10:52:48.264081+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6914620,
            "author": "Gireeja Ranade",
            "project_title": "Lecture 2 Thread",
            "post_body": "Lecture 2 questions thread. \n\n\n\n\n\nI will complete the SGD convergence proof in next weeks class, so save questions on that.",
            "content_xml": "<document version=\"2.0\"><paragraph>Lecture 2 questions thread. </paragraph><paragraph/><file url=\"https://static.us.edusercontent.com/files/mNn50bgPeQFXz5VtcQlj1oJI\" filename=\"Lecture 2.pdf\"/><paragraph/><paragraph>I will complete the SGD convergence proof in next weeks class, so save questions on that.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-05T09:04:50.447728+10:00",
            "category": "Lectures"
        },
        {
            "guid": 6911315,
            "author": "Anant Sahai",
            "project_title": "Discussion 1 Solution Thread",
            "post_body": "This thread is to support the discussion solution. By course policy, the discussion will be lightly supported for the week of discussion. After that, it will no longer be supported by us. For students, you have to stay caught up in the course. ",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/2KCUBO9rkyadPimvpN4YagZS\" filename=\"dis01_solution.pdf\"/><paragraph>This thread is to support the discussion solution. By course policy, the discussion will be lightly supported for the week of discussion. After that, it will no longer be supported by us. For students, you have to stay caught up in the course. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-04T14:59:14.800545+10:00",
            "category": "Sections"
        },
        {
            "guid": 6908196,
            "author": "Sultan Daniels",
            "project_title": "Discussion 1 Thread",
            "post_body": "Discussion 1 will be held at two times:\n\nWednesday at 3-4pm in Social Sciences Building 136\n\nand then nearby at:\n\nWednesday 4-5pm at Hearst Field Annex B1.\n\nIf you would like to run the coding portion of the lab locally, download this zip file: \n\nIf you would like to run the coding portion of the lab on Google Colab, go to this link: https://tinyurl.com/cs182-dis01-code.\n\nTo save time, it would be useful to get the code set up (including any environments, etc.) on your laptop before the discussion begins. \n\nFor the non-coding part, we will have printed discussion worksheets for you. We will have extras so even if students can't find a seat in the room, we can give you a worksheet so you can get together with other students without a seat and do your own discussion.\n\nThe structure of the discussion in the room will be very interactive. The time will be spent working in small groups on the problems and discussing the concepts, with course staff members circulating among the groups to aid with conceptual understanding, etc. \n\nThere will never be mini-lectures in this course and students are expected to come to discussion wanting and willing to work with others, and fully caught up on lectures and previously due homeworks.",
            "content_xml": "<document version=\"1.0\"><paragraph>Discussion 1 will be held at two times:</paragraph><paragraph>Wednesday at 3-4pm in Social Sciences Building 136</paragraph><paragraph>and then nearby at:</paragraph><paragraph>Wednesday 4-5pm at Hearst Field Annex B1.</paragraph><paragraph>If you would like to run the coding portion of the lab locally, download this zip file: </paragraph><paragraph>If you would like to run the coding portion of the lab on Google Colab, go to this link: https://tinyurl.com/cs182-dis01-code.</paragraph><paragraph>To save time, it would be useful to get the code set up (including any environments, etc.) on your laptop before the discussion begins. </paragraph><paragraph>For the non-coding part, we will have printed discussion worksheets for you. We will have extras so even if students can't find a seat in the room, we can give you a worksheet so you can get together with other students without a seat and do your own discussion.</paragraph><paragraph>The structure of the discussion in the room will be very interactive. The time will be spent working in small groups on the problems and discussing the concepts, with course staff members circulating among the groups to aid with conceptual understanding, etc. </paragraph><paragraph>There will never be mini-lectures in this course and students are expected to come to discussion wanting and willing to work with others, and fully caught up on lectures and previously due homeworks.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-04T04:54:39.687764+10:00",
            "category": "Sections"
        },
        {
            "guid": 6904759,
            "author": "Anant Sahai",
            "project_title": "Lecture 1 Thread",
            "post_body": "This is to discuss or ask questions pertaining to the lecture",
            "content_xml": "<document version=\"2.0\"><file url=\"https://static.us.edusercontent.com/files/2occ6GXddxDkaQD7QszYJpdk\" filename=\"Lecture1Sahai.pdf\"/><file url=\"https://static.us.edusercontent.com/files/5ehAy3zJMOpi7nlgKh5bxEK5\" filename=\"Lecture1Ranade.pdf\"/><paragraph>This is to discuss or ask questions pertaining to the lecture</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-03T09:18:48.709917+10:00",
            "category": "Lectures"
        },
        {
            "guid": 6899118,
            "author": "Anant Sahai",
            "project_title": "Study group facilitation thread",
            "post_body": "As was mentioned in lecture, we strongly recommend the use of small study groups to keep yourself accountable (come to or watch lecture together; share and compare notes; come to discussion together; do homework without distractions; etc.) and to have people that you can study with (talk about the homework problems, figure out what you don't understand, etc.). Study groups also sometimes act as default nucleation sites for forming project groups later. \n\nThis thread is designed to help you self-organize with other students in the course. You don't have to do this of course. This is just there as a resource to help people connect. Experience suggests that a study group with someone you don't already know works better if you: \n\nEstablish honest and straightforward expectations regarding what you're aiming to achieve in this course. We understand that some students are aiming for a B while others are looking to completely maximize their understanding. It's good for study group members to know this about each other to avoid future conflicts due to differing implicit assumptions.\n\nGet the logistics of meetings times outside of class worked out fast. In-person work together tends to work better, but even if not in-person, common times are required. \n\nEstablish honest and clear understandings of each other's background with regard to this material. Heterogenous background groups can sometimes work out, but it is good to avoid conflicts due to different implicit assumptions because you hadn't talked about this earlier. \n\nNot all this has to happen in this thread of course! We just think you should do it before finalizing your group. ",
            "content_xml": "<document version=\"2.0\"><paragraph>As was mentioned in lecture, we strongly recommend the use of small study groups to keep yourself accountable (come to or watch lecture together; share and compare notes; come to discussion together; do homework without distractions; etc.) and to have people that you can study with (talk about the homework problems, figure out what you don't understand, etc.). Study groups also sometimes act as default nucleation sites for forming project groups later. </paragraph><paragraph>This thread is designed to help you self-organize with other students in the course. You don't have to do this of course. This is just there as a resource to help people connect. Experience suggests that a study group with someone you don't already know works better if you: </paragraph><list style=\"bullet\"><list-item><paragraph>Establish honest and straightforward expectations regarding what you're aiming to achieve in this course. We understand that some students are aiming for a B while others are looking to completely maximize their understanding. It's good for study group members to know this about each other to avoid future conflicts due to differing implicit assumptions.</paragraph></list-item><list-item><paragraph>Get the logistics of meetings times outside of class worked out fast. In-person work together tends to work better, but even if not in-person, common times are required. </paragraph></list-item><list-item><paragraph>Establish honest and clear understandings of each other's background with regard to this material. Heterogenous background groups can sometimes work out, but it is good to avoid conflicts due to different implicit assumptions because you hadn't talked about this earlier. </paragraph></list-item></list><paragraph>Not all this has to happen in this thread of course! We just think you should do it before finalizing your group. </paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-09-02T03:27:51.139026+10:00",
            "category": "Admin"
        },
        {
            "guid": 6894737,
            "author": "Manan Roongta",
            "project_title": "Free Colab Pro for Students",
            "post_body": "Google Colab Pro is free for students (normally $10). You get monthly compute units and they are good for 90 days, so it's a good idea to sign up now and have them for heavier hws.\n\nhttps://colab.research.google.com/signup\n\n\n\n",
            "content_xml": "<document version=\"2.0\"><paragraph>Google Colab Pro is free for students (normally $10). You get monthly compute units and they are good for 90 days, so it's a good idea to sign up now and have them for heavier hws.</paragraph><paragraph><link href=\"https://colab.research.google.com/signup\">https://colab.research.google.com/signup</link></paragraph><paragraph/><paragraph/></document>",
            "links": [
                "https://colab.research.google.com/signup"
            ],
            "attachments": [],
            "created_at": "2025-08-31T13:09:03.195661+10:00",
            "category": "Admin"
        },
        {
            "guid": 6891458,
            "author": "Micah Mok",
            "project_title": "Friends to Talk about Deep Learning With",
            "post_body": "Hi guys! My name is Micah Mok. I'm definitely newer and very hungry to learn about ML. I would love to create a community where we can talk about the ideas we're thinking about and the projects we're working on. In addition, study buddies are always nice. If you're interested in any of that, I'm making a \"Deep Learning at Berkeley\" Slack workspace. Come join!\n\nThanks,\n\nhttps://join.slack.com/t/deeplearninga-j2h9314/shared_invite/zt-3c7b6s2uv-4m~g2YaJguBoPa9dsua1Bw",
            "content_xml": "<document version=\"2.0\"><paragraph>Hi guys! My name is Micah Mok. I'm definitely newer and very hungry to learn about ML. I would love to create a community where we can talk about the ideas we're thinking about and the projects we're working on. In addition, study buddies are always nice. If you're interested in any of that, I'm making a \"Deep Learning at Berkeley\" Slack workspace. Come join!</paragraph><paragraph>Thanks,</paragraph><paragraph>https://join.slack.com/t/deeplearninga-j2h9314/shared_invite/zt-3c7b6s2uv-4m~g2YaJguBoPa9dsua1Bw</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T07:33:59.1233+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 6890959,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q7",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/XmvrGEKwH9uzVWM36WlzZCiQ\" width=\"658\" height=\"184.3736040609137\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:36:52.16716+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6890956,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q6",
            "post_body": "\n\nProblem Context:\n\nWe need to make sure that everyone is comfortable with basic programming and also understands basic neural nets from their earlier ML course.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/5dDAu05etV7Ay2vmfHBjU1yE\" width=\"658\" height=\"184.3736040609137\"/></figure><paragraph/><paragraph>Problem Context:</paragraph><paragraph>We need to make sure that everyone is comfortable with basic programming and also understands basic neural nets from their earlier ML course.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:36:43.097429+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6890952,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q5",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/L0oVxC9pZukNWnLjnw2ySVQc\" width=\"658\" height=\"284.5766497461929\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/7srCK4ThqovJAax0aKGEVDi1\" width=\"658\" height=\"428.2010152284264\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/5ehaEvlWdFEkW7so7MVEk0Ub\" width=\"658\" height=\"184.3736040609137\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:36:17.65215+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6890943,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q4",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/gVVPsgCbOxqJqrvIKQHgh1fs\" width=\"658\" height=\"301.2771573604061\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/hzjN81Elty9OfXkAhLzSiaZP\" width=\"658\" height=\"371.4192893401015\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/y4EjpNH43JAFVf5fzAFmwmXo\" width=\"658\" height=\"213.0984771573604\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/TrSafHpmt9EskYnsNLRWfxjB\" width=\"658\" height=\"277.8964467005076\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/dkxZqi1b0HEGfloOgMBYPuXt\" width=\"658\" height=\"107.551269035533\"/></figure><paragraph/></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:34:07.828947+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6890933,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q3",
            "post_body": "\nProblem Context:\n\nThis is another review problem that is just there to help you bring some classic material back into your memory. You'll need facility with this --- moving to SVD coordinates, etc. --- to understand key ideas in the course.",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/pdjFoZiuDo9e1PY7TxW16MlZ\" width=\"658\" height=\"428.2010152284264\"/></figure><paragraph><break/>Problem Context:</paragraph><paragraph>This is another review problem that is just there to help you bring some classic material back into your memory. You'll need facility with this --- moving to SVD coordinates, etc. --- to understand key ideas in the course.</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:32:17.744468+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6890923,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q2",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/1XdBM8RHry8XFh80gvD2q8Ib\" width=\"658\" height=\"179.69746192893402\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/xg1HKKhUwriqEUPHx8uWsA8R\" width=\"658\" height=\"120.24365482233502\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:31:10.390007+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6890908,
            "author": "Patrick Mendoza",
            "project_title": "HW0 Q1",
            "post_body": "",
            "content_xml": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/EK7oHHcvefl8M4drKfgVB4qS\" width=\"658\" height=\"424.32394366197184\"/></figure></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-30T05:28:43.876101+10:00",
            "category": "Problem Sets"
        },
        {
            "guid": 6887897,
            "author": "Anant Sahai",
            "project_title": "Lecture 0 Thread",
            "post_body": "The lecture video is available:\n\n https://www.youtube.com/live/53sm-H51TqA?si=08DVgOuDDTgKeLj5\n\nThis is the thread for asking questions related to this lecture. In general, there will be lecture threads for every lecture given. Help your fellow students out by answering their questions. ",
            "content_xml": "<document version=\"2.0\"><paragraph>The lecture video is available:</paragraph><paragraph> <link href=\"https://www.youtube.com/live/53sm-H51TqA?si=08DVgOuDDTgKeLj5\">https://www.youtube.com/live/53sm-H51TqA?si=08DVgOuDDTgKeLj5</link></paragraph><paragraph>This is the thread for asking questions related to this lecture. In general, there will be lecture threads for every lecture given. Help your fellow students out by answering their questions. </paragraph></document>",
            "links": [
                "https://www.youtube.com/live/53sm-H51TqA?si=08DVgOuDDTgKeLj5"
            ],
            "attachments": [],
            "created_at": "2025-08-29T09:16:51.902539+10:00",
            "category": "Lectures"
        },
        {
            "guid": 6887086,
            "author": "Sammie Smith",
            "project_title": "Study Group: Women Identifying / AFAB Students",
            "post_body": "Study Group Meet Up! (opt in space for women) \n\nHey everyone, my name is Sammie! I'm a 4th year double major in Data Science and Computer Science, and I'm currently enrolled in this class. (I'm from rural Oregon, I'm on the Cal women's ultimate frisbee team, and I love to skate)\n\nI reserved Room B1M20E in Kresge Engineering & Mathematical Sciences Library (capacity 15 people) from 12pm-2pm next Wednesday, Sept 3.\n\nIf you self-identify as a woman, please show up so we can get a study group going / exchange numbers!\n\nIntroduce yourself on this thread in the meantime!\n\nName\n\nMajor, year\n\nWhere you're from/hobbies\n\nIf you're enrolled vs waitlisted in this class",
            "content_xml": "<document version=\"2.0\"><heading level=\"2\">Study Group Meet Up! (opt in space for women) </heading><paragraph>Hey everyone, my name is Sammie! I'm a 4th year double major in Data Science and Computer Science, and I'm currently enrolled in this class. (I'm from rural Oregon, I'm on the Cal women's ultimate frisbee team, and I love to skate)</paragraph><paragraph>I reserved <bold>Room B1M20E</bold> in Kresge Engineering &amp; Mathematical Sciences Library (capacity 15 people) from <bold>12pm-2pm next Wednesday, Sept 3</bold>.</paragraph><paragraph>If you self-identify as a woman, please show up so we can get a study group going / exchange numbers!</paragraph><paragraph>Introduce yourself on this thread in the meantime!</paragraph><list style=\"bullet\"><list-item><paragraph>Name</paragraph></list-item><list-item><paragraph>Major, year</paragraph></list-item><list-item><paragraph>Where you're from/hobbies</paragraph></list-item><list-item><paragraph>If you're enrolled vs waitlisted in this class</paragraph></list-item></list></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-29T06:07:25.11396+10:00",
            "category": "Curiosity"
        },
        {
            "guid": 6886970,
            "author": "Gireeja Ranade",
            "project_title": "Office Hours Now",
            "post_body": "Office Hours now in 400 Cory!",
            "content_xml": "<document version=\"2.0\"><paragraph>Office Hours now in 400 Cory!</paragraph></document>",
            "links": [],
            "attachments": [],
            "created_at": "2025-08-29T05:40:59.811182+10:00",
            "category": "Admin"
        }
    ]
}